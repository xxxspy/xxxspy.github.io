[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "在 R 中进行 Meta 分析",
    "section": "",
    "text": "这本书是由 Mathias Harrer 撰写的 Meta 分析的入门著作, 本书是开源的, 由 DataSense 翻译而来.\n\n源码仓库\n英文原版\n中文翻译版\n中文原版+数据+markdown源码\n咨询+交流平台",
    "crumbs": [
      "网站首页",
      "首页"
    ]
  },
  {
    "objectID": "index.html#开源代码库",
    "href": "index.html#开源代码库",
    "title": "在 R 中进行 Meta 分析",
    "section": "开源代码库",
    "text": "开源代码库\n\n本书是使用 {rmarkdown} 和 {bookdown} 构建的。公式使用 MathJax 渲染。我们用于编译本指南的所有材料和源代码都可以在 GitHub 上找到。您可以自由地 Fork、分享和重用内容。但是，该存储库主要用作“只读”；一般不考虑 PR（有关联系我们的方式，请参见下面的章节和前言）。\n\n\n\nGitHub followers",
    "crumbs": [
      "网站首页",
      "首页"
    ]
  },
  {
    "objectID": "index.html#如何使用本指南",
    "href": "index.html#如何使用本指南",
    "title": "在 R 中进行 Meta 分析",
    "section": "如何使用本指南",
    "text": "如何使用本指南\n\n本教程简要介绍了本指南，以及如何将其用于您自己的 Meta 分析项目。",
    "crumbs": [
      "网站首页",
      "首页"
    ]
  },
  {
    "objectID": "index.html#贡献",
    "href": "index.html#贡献",
    "title": "在 R 中进行 Meta 分析",
    "section": "贡献",
    "text": "贡献\n\n本指南是一个开源项目，我们要特别感谢我们的专家贡献者，他们在本指南的某些章节中提供了其他内容。\n\nLuke A. McGuinness, 布里斯托大学：第 15 章，偏倚风险图。\n\n想要自己为本指南做出贡献吗？请随时向 Mathias (mathias.harrer@fau.de) 发送电子邮件，告诉我们您提议添加的内容。",
    "crumbs": [
      "网站首页",
      "首页"
    ]
  },
  {
    "objectID": "index.html#引用本指南",
    "href": "index.html#引用本指南",
    "title": "在 R 中进行 Meta 分析",
    "section": "引用本指南",
    "text": "引用本指南\n\n建议的引用是：\n\n\n\nHarrer, M., Cuijpers, P., Furukawa, T.A., & Ebert, D.D. (2021). Doing Meta-Analysis with R: A Hands-On Guide. Boca Raton, FL and London: Chapman & Hall/CRC Press. ISBN 978-0-367-61007-4.\n\n\n\n下载参考文献为 BibTeX 或 .ris。",
    "crumbs": [
      "网站首页",
      "首页"
    ]
  },
  {
    "objectID": "index.html#引用软件包",
    "href": "index.html#引用软件包",
    "title": "在 R 中进行 Meta 分析",
    "section": "引用软件包",
    "text": "引用软件包\n\n在本指南中，我们介绍并使用了各种 R 软件包。我们所有人都可以免费使用这些软件包的原因是，世界各地的专家们为此投入了大量的时间和精力进行开发，而且通常是无偿的。如果您在自己的 Meta 分析中使用本书中提到的一些软件包，我们强烈建议您也在报告中引用它们。\n在本指南中，每次引入一个新的软件包时，我们也会提供可以通过其引用的参考文献。也可以运行 citation(\"package\") 来检索首选参考文献。谢谢！",
    "crumbs": [
      "网站首页",
      "首页"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "这本书是由 Mathias Harrer 撰写的 Meta 分析的入门著作, 本书是开源的, 由 DataSense 翻译而来.\n\n源码仓库\n英文原版\n中文翻译版\n中文原版+数据+markdown源码\n\n\nMeta 分析代做\n如果你的研究中使用了Meta分析方法, 我们可以提供哪些帮助:\n\n从文献提取数据\n分析数据\n撰写APA风格报告\n统计咨询\n\n\n\n联系我们\n\nQQ: 2726725926\nwechat: mllncn\nemail: mllncn@126.com\n咨询+交流平台: https://wx.zsxq.com/group/88888188828842"
  },
  {
    "objectID": "98-cite.html",
    "href": "98-cite.html",
    "title": "引用本指南",
    "section": "",
    "text": "引用本指南\n\n\n建议的引用格式如下：\n\n\n\nHarrer, M., Cuijpers, P., Furukawa, T.A., & Ebert, D.D. (2021). Doing Meta-Analysis with R: A Hands-On Guide. Boca Raton, FL and London: Chapmann & Hall/CRC Press. ISBN 978-0-367-61007-4.\n\n\n\n下载参考文件为 BibTeX 或 .ris.",
    "crumbs": [
      "网站首页",
      "引用"
    ]
  },
  {
    "objectID": "19-effect-size-calculation.html",
    "href": "19-effect-size-calculation.html",
    "title": "效应量计算 & 转换",
    "section": "",
    "text": "Meta 分析师经常面临的一个问题是，无法从所有纳入的研究中提取到合适的“原始”效应量数据。{meta} 程序包中的大多数函数，例如 metacont (第 @ref(pooling-smd) 章) 或 metabin (第 @ref(pooling-or-rr) 章)，只能在有完整的原始效应量数据时才能使用。\n在实践中，这通常会导致困难。一些已发表的文章，特别是较早的文章，其报告结果的方式无法提取所需的（原始）效应量数据。经常发现一项研究报告了 \\(t\\)-检验、单因素 ANOVA 或 \\(\\chi^2\\)-检验的结果，但没有报告我们进行 meta 分析所需的组间均值和标准差，或研究条件下的事件数。\n\n好消息是，我们有时可以将报告的信息转换为所需的效应量格式。这使得可以使用 metagen 将受影响的研究纳入具有预先计算数据（第 @ref(pre-calculated-es) 章）的 meta 分析中。例如，我们可以将双样本 \\(t\\)-检验的结果转换为标准化均值差及其标准误，然后使用 metagen 对预先计算的 SMD 执行 meta 分析。{esc} 程序包 [@esc] 提供了几个有用的函数，允许我们在 R 中直接执行此类转换。\n\n\n\n\n \n当从均值和标准误计算 SMD 或 Hedges’ \\(g\\) 时，我们可以利用均值的标准差定义为其标准误，并从中“分解出”样本大小的平方根 [@thalheimer2002calculate]：\n\\[\\begin{equation}\n\\text{SD} =\\text{SE}\\sqrt{n}\n(\\#eq:esc1)\n\\end{equation}\\]\n我们可以使用 esc_mean_se 函数计算 SMD 或 Hedges’ \\(g\\)。这是一个例子：\n\nlibrary(esc)\n\nesc_mean_se(grp1m = 8.5,   # 第 1 组的均值\n            grp1se = 1.5,  # 第 1 组的标准误\n            grp1n = 50,    # 第 1 组的样本量\n            grp2m = 11,    # 第 2 组的均值\n            grp2se = 1.8,  # 第 2 组的标准误\n            grp2n = 60,    # 第 2 组的样本量\n            es.type = \"d\") # 转换为 SMD；使用 \"g\" 表示 Hedges' g\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: mean and se to effect size d\n    Effect Size:  -0.2012\n Standard Error:   0.1920\n       Variance:   0.0369\n       Lower CI:  -0.5774\n       Upper CI:   0.1751\n         Weight:  27.1366\n\n\n\n\n\n\n\n可以从标准化或非标准化回归系数计算 SMD、Hedges’ \\(g\\) 或相关系数 \\(r\\) [@lipsey2001practical, Appendix B]。对于非标准化系数，我们可以使用 {esc} 中的 esc_B 函数。这是一个例子：\n\n\nlibrary(esc)\n\nesc_B(b = 3.3,       # 非标准化回归系数\n      sdy = 5,       # 预测变量 y 的标准差\n      grp1n = 100,   # 第一组的样本量\n      grp2n = 150,   # 第二组的样本量\n      es.type = \"d\") # 转换为 SMD；使用 \"g\" 表示 Hedges' g\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: unstandardized regression coefficient to effect size d\n    Effect Size:   0.6962\n Standard Error:   0.1328\n       Variance:   0.0176\n       Lower CI:   0.4359\n       Upper CI:   0.9565\n         Weight:  56.7018\n\n\n\nesc_B(b = 2.9,       # 非标准化回归系数\n      sdy = 4,       # 预测变量 y 的标准差\n      grp1n = 50,    # 第一组的样本量\n      grp2n = 50,    # 第二组的样本量\n      es.type = \"r\") # 转换为相关系数\n\n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: unstandardized regression coefficient \n##                  to effect size correlation\n##     Effect Size:   0.3611\n##  Standard Error:   0.1031\n##        Variance:   0.0106\n##        Lower CI:   0.1743\n##        Upper CI:   0.5229\n##          Weight:  94.0238\n##      Fisher's z:   0.3782\n##       Lower CIz:   0.1761\n##       Upper CIz:   0.5803\n可以使用 esc_beta 转换标准化回归系数。\n\nesc_beta(beta = 0.32,   # 标准化回归系数\n         sdy = 5,       # 预测变量 y 的标准差\n         grp1n = 100,   # 第一组的样本量\n         grp2n = 150,   # 第二组的样本量\n         es.type = \"d\") # 转换为 SMD；使用 \"g\" 表示 Hedges' g\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: standardized regression coefficient to effect size d\n    Effect Size:   0.6867\n Standard Error:   0.1327\n       Variance:   0.0176\n       Lower CI:   0.4266\n       Upper CI:   0.9468\n         Weight:  56.7867\n\n\n\nesc_beta(beta = 0.37,   # 标准化回归系数\n         sdy = 4,       # 预测变量 y 的标准差\n         grp1n = 50,    # 第一组的样本量\n         grp2n = 50,    # 第二组的样本量\n         es.type = \"r\") # 转换为相关系数\n\n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: standardized regression coefficient \n##                  to effect size correlation\n##     Effect Size:   0.3668\n##  Standard Error:   0.1033\n##        Variance:   0.0107\n##        Lower CI:   0.1803\n##        Upper CI:   0.5278\n##          Weight:  93.7884\n##      Fisher's z:   0.3847\n##       Lower CIz:   0.1823\n##       Upper CIz:   0.5871\n请注意，在 meta 分析中使用回归系数可能很棘手，因为我们假设所有研究都使用了相同的模型。如果系数是从多个回归模型中提取的，这尤其成问题，因为研究可能在其模型中控制了不同的协变量，这意味着 \\(b\\) 值不具有直接可比性。\n\n\n\n\n\n \n对于组大小相等的情况 (\\(n_1=n_2\\))，我们可以使用以下公式从点二列相关系数推导出 SMD [@lipsey2001practical, chapter 3]。\n\\[\\begin{equation}\nr_{pb} = \\frac{\\text{SMD}}{\\sqrt{\\text{SMD}^2+4}} ~~~~~~~~\n\\text{SMD}=\\frac{2r_{pb}}{\\sqrt{1-r^2_{pb}}} (\\#eq:esc2)\n\\end{equation}\\]\n对于组大小不相等的情况，必须使用不同的公式 [@aaron1998equating]：\n\\[\\begin{align}\nr_{pb} &= \\frac{\\text{SMD}}{\\sqrt{\\text{SMD}^2+\\dfrac{(N^2-2N)}{n_1n_2}}} \\notag \\\\\n\\text{SMD} &= \\dfrac{r_{pb}}{\\sqrt{(1-r^2)\\left(\\frac{n_1}{N}\\times\\left(1-\\frac{n_1}{N}\\right)\\right)}} (\\#eq:esc3)\n\\end{align}\\]\n要将 \\(r_{pb}\\) 转换为 SMD 或 Hedges’ \\(g\\)，我们可以使用 esc_rpb 函数。\n\nlibrary(esc)\n\nesc_rpb(r = 0.25,      # 点二列相关系数\n        grp1n = 99,    # 第 1 组的样本量\n        grp2n = 120,   # 第 2 组的样本量\n        es.type = \"d\") # 转换为 SMD；使用 \"g\" 表示 Hedges' g\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: point-biserial r to effect size d\n    Effect Size:   0.5188\n Standard Error:   0.1380\n       Variance:   0.0190\n       Lower CI:   0.2483\n       Upper CI:   0.7893\n         Weight:  52.4967\n\n\n\n\n\n\n\n\n我们还可以从具有两个组的单因素 ANOVA 的 \\(F\\)-值推导出 SMD。可以通过查看自由度来识别此类 ANOVA。在具有两个组的单因素 ANOVA 中，自由度应始终以 1 开头（例如，\\(F_{\\text{1,147}}\\)=5.31）。\n用于转换的公式如下 [基于 @rosnow1996computing; @rosnow2000contrasts; 参见 @thalheimer2002calculate]：\n\\[\\begin{equation}\n\\text{SMD} = \\sqrt{  F\\left(\\frac{n_1+n_2}{n_1 n_2}\\right)\\left(\\frac{n_1+n_2}{n_1+n_2-2}\\right)}\n(\\#eq:esc4)\n\\end{equation}\\]\n要从 \\(F\\)-值计算 SMD 或 Hedges’ \\(g\\)，我们可以使用 esc_f 函数。这是一个例子：\n\nesc_f(f = 5.04,      # 单因素方差分析的 F 值\n      grp1n = 519,   # 第 1 组的样本量\n      grp2n = 528,   # 第 2 组的样本量\n      es.type = \"g\") # 转换为 Hedges' g；使用 \"d\" 表示 SMD\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: F-value (one-way-Anova) to effect size Hedges' g\n    Effect Size:   0.1387\n Standard Error:   0.0619\n       Variance:   0.0038\n       Lower CI:   0.0174\n       Upper CI:   0.2600\n         Weight: 261.1022\n\n\n\n\n\n\n\n\n效应量表示为标准化均值差也可以从独立双样本 \\(t\\)-检验值导出，使用以下公式 [@rosnow2000contrasts; @thalheimer2002calculate]：\n\\[\\begin{equation}\n\\text{SMD} = \\frac {t(n_1+n_2)}{\\sqrt{(n_1+n_2-2)(n_1n_2)}}\n(\\#eq:esc5)\n\\end{equation}\\]\n在 R 中，我们可以使用 esc_t 函数从 \\(t\\)-值计算 SMD 或 Hedges’ g。这是一个例子：\n\nesc_t(t = 3.3,     # t 值\n      grp1n = 100, # group1 的样本量\n      grp2n = 150, # group 2 的样本量\n      es.type=\"d\") # 转换为 SMD；使用 \"g\" 表示 Hedges' g\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: t-value to effect size d\n    Effect Size:   0.4260\n Standard Error:   0.1305\n       Variance:   0.0170\n       Lower CI:   0.1703\n       Upper CI:   0.6818\n         Weight:  58.7211\n\n\n\n\n\n\n\n\n有时，研究仅报告效应量（例如，Cohen’s \\(d\\) 值）、该效应的 \\(p\\)-值，仅此而已。然而，要在 meta 分析中汇集结果，我们需要一种衡量效应量精确度的方法，最好是标准误。\n在这种情况下，我们必须从效应量的 \\(p\\)-值估计标准误。对于基于差异（即 SMD）或比率（即风险或优势比）的效应量，这是可行的，使用 Altman 和 Bland 的公式 [-@altman2011obtain]。这些公式在 R 的 se.from.p 函数中实现。\n\n\n\n\n“se.from.p”函数\n\n\nse.from.p 函数包含在 {dmetar} 程序包中。一旦在您的计算机上安装并加载 {dmetar}，该函数就可以使用了。如果您没有安装 {dmetar}，请按照以下说明操作：\n\n\n\n在线访问该函数的源代码 online。\n\n\n通过将源代码的全部内容复制并粘贴到控制台（R Studio 的左下窗格）中，然后按“Enter”，让 R “学习”该函数。\n\n\n\n\n假设一项研究有 \\(N=\\) 71 名参与者，报告的效应量为 \\(d=\\) 0.71，其中 \\(p=\\) 0.013，我们可以这样计算标准误：\n\nlibrary(dmetar)\n\nse.from.p(0.71,\n          p = 0.013,\n          N = 71,\n          effect.size.type = \"difference\")\n\n##   EffectSize StandardError StandardDeviation  LLCI  ULCI\n## 1       0.71         0.286             2.410 0.149 1.270\n对于一项有 \\(N=\\) 200 名参与者的研究，报告的效应量为 OR = 0.91，其中 \\(p=\\) 0.38，标准误的计算方式如下：\n\nlibrary(magrittr) # for pipe\n\nse.from.p(0.91, p = 0.38, N = 200,\n          effect.size.type = \"ratio\") %&gt;% t()\n\n##                        [,1]\n## logEffectSize        -0.094\n## logStandardError      0.105\n## logStandardDeviation  1.498\n## logLLCI              -0.302\n## logULCI               0.113\n## EffectSize            0.910\n## LLCI                  0.739\n## ULCI                  1.120\n当 effect.size.type = \"ratio\" 时，该函数还会自动计算对数转换的效应量和标准误，这是使用 metagen 函数（第 @ref(pre-calculated-es) 章）所必需的。\n\n\n\n\n\n\n要将 \\(\\chi^2\\) 统计量转换为优势比，可以使用 esc_chisq 函数（假设 d.f. = 1；例如，\\(\\chi^2_1\\) = 8.7）。这是一个例子：\n\nesc_chisq(chisq = 7.9,        # 卡方值\n          totaln = 100,       # 总样本量\n          es.type = \"cox.or\") # 转换为优势比\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: chi-squared-value to effect size Cox odds ratios\n    Effect Size:   2.6287\n Standard Error:   0.3440\n       Variance:   0.1183\n       Lower CI:   1.3394\n       Upper CI:   5.1589\n         Weight:   8.4502\n\n\n\n\n\n\n\n\nCohen’s \\(d\\) 或 Hedges’ \\(g\\) 等效应量通常难以从实践角度解释。想象一下，我们在 meta 分析中发现干预效果为 \\(g=\\) 0.35。我们如何向患者、政府官员、医疗专业人员或其他利益相关者传达这种效果的含义？\n为了让其他人更容易理解结果，meta 分析通常还会报告需治人数 (NNT)。该指标最常用于医学研究。它表示必须接受研究治疗的额外患者人数，才能预防一个额外的负面事件（例如，复发）或实现一个额外的正面事件（例如，症状缓解、反应）。例如，如果 NNT = 3，我们可以说必须接受治疗的三个人才能避免一个额外的复发病例；或者必须治疗三名患者才能实现一个额外的可靠症状缓解病例，具体取决于研究问题。\n当我们处理二元效应量数据时，NNT 的计算相对容易。公式如下：\n\\[\\begin{equation}\n\\text{NNT} = (p_{e_{\\text{treat}}}-p_{e_{\\text{control}}})^{-1}\n(\\#eq:esc6)\n\\end{equation}\\]\n在此公式中，\\(p_{e_{\\text{treat}}}\\) 和 \\(p_{e_{\\text{control}}}\\) 是在治疗组和对照组中经历该事件的参与者比例。这些比例与用于计算风险比的“风险”（第 @ref(rr) 章）相同，也称为实验组事件率 (EER) 和对照组事件率 (CER)。鉴于其公式，NTT 也可以描述为（绝对）风险差异的倒数。\n将标准化均值差或 Hedges’ \\(g\\) 转换为 NNT 更为复杂。有两种常用的方法：\n\n\nKraemer 和 Kupfer 的方法 [-@kraemer2006size]，该方法从曲线下面积 (AUC) 计算 NNT，AUC 定义为治疗组患者的结果优于对照组患者结果的概率。此方法允许直接从 SMD 或 \\(g\\) 计算 NNT，而无需任何额外信息。\nFurukawa 和 Leucht 的方法使用 CER 或其合理估计值从 SMD 计算 NNT 值。与 Kraemer & Kupfer 方法相比，Furukawa 的方法已被证明在估计真实 NNT 值方面更优 [@furukawa2011obtain]。如果我们可以对 CER 进行合理的估计，则应始终首选 Furukawa 的方法。\n\n当我们使用风险比或优势比作为效应量指标时，可以使用 nnt 函数直接从 {meta} 对象计算 NNT。在使用 metabin 运行 meta 分析（第 @ref(pooling-or-rr) 章）后，我们只需将结果插入 nnt 函数即可。这是一个例子：\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.1-0).\nType 'help(meta)' for a brief overview.\n\ndata(Olkin1995)\n\n# 使用二元效应量数据运行 meta 分析\nm.b &lt;- metabin(ev.exp, n.exp, ev.cont, n.cont, \n               data = Olkin1995,\n               sm = \"RR\")\nnnt(m.b)\n\nNumber needed to treat (common effect model): \n\n     RR    p.c    NNTB             95%-CI\n 0.7728 0.1440 30.5677 [26.1222; 37.2386]\n 0.7728 0.3750 11.7383 [10.0312; 14.3001]\n\nNumber needed to treat (random effects model): \n\n     RR    p.c    NNTB             95%-CI\n 0.7694 0.1440 30.1139 [24.0662; 41.3519]\n 0.7694 0.3750 11.5641 [ 9.2417; 15.8796]\n\n\nnnt 函数提供了针对不同假设 CER 的需治人数。这三行显示了数据集中最小、平均和最大 CER 的结果。平均 CER 估计值是通常报告的“典型”NNT。\n只要摘要度量 sm 是 \"RR\" 或 \"OR\"，也可以将 nnt 与 metagen 模型一起使用。对于此类模型，我们还需要在 nnt 的 p.c 参数中指定假设的 CER。以下是使用我们在第 @ref(m-gen-bin) 章中创建的 m.gen_bin meta 分析对象的示例：\n\n# Also show fixed-effect model results\nm.gen_bin &lt;- update(m.gen_bin, fixed = TRUE)\n\nWarning: Use argument 'common' instead of 'fixed' (deprecated).\n\nnnt(m.gen_bin, \n    p.c = 0.1) # 使用 0.1 的 CER\n\nNumber needed to treat (common effect model): \n\n     RR    p.c   NNTH            95%-CI\n 2.0319 0.1000 9.6906 [8.2116; 11.6058]\n\nNumber needed to treat (random effects model): \n\n     RR    p.c   NNTH            95%-CI\n 2.0218 0.1000 9.7870 [6.4761; 16.4843]\n\n\n\n可以使用 {dmetar} 中的 NNT 函数将标准化均值差或 Hedges’ \\(g\\) 转换为 NNT。\n\n\n\n“NNT”函数\n\n\n如果您没有安装 {dmetar}，请按照以下说明操作：\n\n\n\n在线访问 NNT 函数的源代码 online。\n\n\n通过将源代码的全部内容复制并粘贴到控制台（R Studio 的左下窗格）中，然后按“Enter”，让 R “学习”该函数。\n\n\n\n\n要使用 Kraemer & Kupfer 方法，我们只需要为 NNT 函数提供一个效应量（SMD 或 \\(g\\)）。只要提供了 CER 值，就会自动使用 Furukawa 的方法。\n\nsource('./NNT.R') # load NNT function\nNNT(d = 0.245)\n\n[1] 7.270711\nattr(,\"class\")\n[1] \"NNT\"     \"kk\"      \"numeric\"\n\nNNT(d = 0.245, CER = 0.35)\n\n[1] 10.61533\nattr(,\"class\")\n[1] \"NNT\"     \"fl\"      \"numeric\"\n\n\n\n\n\n一个需要谨慎对待的数字：对 NNT 的批评\n\n\n虽然很常见，但使用 NNT 来传达临床试验的结果并非没有争议。批评包括外行人经常误解它 [尽管据称它是其他效应量指标的“直观”替代方案，@christensen2006number]；以及研究人员经常错误地计算 NNT [@mendes2017number]。\n\n\n此外，无法计算 NNT 的可靠标准误（和置信区间），这意味着它们不能用于 meta 分析 [@hutton2010misleading]。只能在使用其他效应量指标进行合并后，才能将结果转换为 NNT。\n\n\n\n\n\n\n\n\n\n为避免单元分析错误（第 @ref(unit-of-analysis) 章），有时需要在计算（标准化）均值差之前，合并两个或多个试验组的均值和标准差。要合并两个组的连续效应量数据，我们可以使用以下等式：\n\\[\\begin{align}\nn_{\\text{pooled}} &= n_1 + n_2  \\\\\nm_{\\text{pooled}} &= \\frac{n_1m_1+n_2m_2}{n_1+n_2} \\\\\nSD_{\\text{pooled}} &= \\sqrt{\\frac{(n_1-1)SD^{2}_{1}+ (n_2-1)SD^{2}_{2}+\\frac{n_1n_2}{n_1+n_2}(m^{2}_1+m^{2}_2-2m_1m_2)} {n_1+n_2-1}}\n\\end{align}\\]\n我们可以使用 pool.groups 函数在 R 中应用此公式。\n\n\n\n“pool.groups”函数\n\n\npool.groups 函数包含在 {dmetar} 程序包中。一旦在您的计算机上安装并加载 {dmetar}，该函数就可以使用了。如果您没有安装 {dmetar}，请按照以下说明操作：\n\n\n\n在线访问该函数的源代码 online。\n\n\n通过将源代码的全部内容复制并粘贴到控制台（R Studio 的左下窗格）中，然后按“Enter”，让 R “学习”该函数。\n\n\n\n\n这是一个例子：\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\n\n\nAttaching package: 'dmetar'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    NNT\n\npool.groups(n1 = 50,   # 组 1 的样本量\n            n2 = 50,   # 组 2 的样本量\n            m1 = 3.5,  # 组 1 的均值\n            m2 = 4,    # 组 2 的均值\n            sd1 = 3,   # 组 1 的标准差\n            sd2 = 3.8) # 组 2 的标准差\n\n  Mpooled SDpooled Npooled\n1    3.75 3.415369     100\n\n\n\n\n\n\n\n{metafor} 中的 aggregate 函数可用于将几个相关的、预先计算的效应量聚合为一个估计值，例如因为它们是同一研究或集群的一部分。这是避免单元分析错误的一种方法（参见第 @ref(unit-of-analysis) 章），但这需要我们假设研究内部相关性的值，这通常是未知的。处理效应量依赖性的另一种（通常是更可取的）方法是（相关）分层模型，这将在第 @ref(multilevel-ma) 章中进行说明。\n在本例中，我们聚合 Chernobyl 数据集（参见第 @ref(multilevel-R) 章）的效应量，以便每个研究仅提供一个效应量：\n\nlibrary(metafor)\nlibrary(dmetar)\ndata(\"Chernobyl\")\n\n# 将 'Chernobyl' 数据转换为 'escalc' 对象\nChernobyl &lt;- escalc(yi = z,           # 效应量\n                    sei = se.z,       # 标准误\n                    data = Chernobyl)\n\n# 在研究层面聚合效应量\n# 我们假设相关性为 rho=0.6\nChernobyl.agg &lt;- aggregate(Chernobyl, \n                           cluster = author,\n                           rho = 0.6)\n\n# 显示聚合结果\nChernobyl.agg[,c(\"author\", \"yi\", \"vi\")]\n\n##                       author     yi     vi \n## 1 Aghajanyan & Suskov (2009) 0.2415 0.0079 \n## 2     Alexanin et al. (2010) 1.3659 0.0012 \n## 3             Bochkov (1993) 0.2081 0.0014 \n## 4      Dubrova et al. (1996) 0.3068 0.0132 \n## 5      Dubrova et al. (1997) 0.4453 0.0110\n## [...]\n请注意，aggregate 返回聚合的效应量 yi 以及它们的 方差 vi，其平方根是标准误。\n\\[\\tag*{$\\blacksquare$}\\]",
    "crumbs": [
      "网站首页",
      "效应量计算"
    ]
  },
  {
    "objectID": "19-effect-size-calculation.html#均值-标准误",
    "href": "19-effect-size-calculation.html#均值-标准误",
    "title": "效应量计算 & 转换",
    "section": "",
    "text": "当从均值和标准误计算 SMD 或 Hedges’ \\(g\\) 时，我们可以利用均值的标准差定义为其标准误，并从中“分解出”样本大小的平方根 [@thalheimer2002calculate]：\n\\[\\begin{equation}\n\\text{SD} =\\text{SE}\\sqrt{n}\n(\\#eq:esc1)\n\\end{equation}\\]\n我们可以使用 esc_mean_se 函数计算 SMD 或 Hedges’ \\(g\\)。这是一个例子：\n\nlibrary(esc)\n\nesc_mean_se(grp1m = 8.5,   # 第 1 组的均值\n            grp1se = 1.5,  # 第 1 组的标准误\n            grp1n = 50,    # 第 1 组的样本量\n            grp2m = 11,    # 第 2 组的均值\n            grp2se = 1.8,  # 第 2 组的标准误\n            grp2n = 60,    # 第 2 组的样本量\n            es.type = \"d\") # 转换为 SMD；使用 \"g\" 表示 Hedges' g\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: mean and se to effect size d\n    Effect Size:  -0.2012\n Standard Error:   0.1920\n       Variance:   0.0369\n       Lower CI:  -0.5774\n       Upper CI:   0.1751\n         Weight:  27.1366",
    "crumbs": [
      "网站首页",
      "效应量计算"
    ]
  },
  {
    "objectID": "19-effect-size-calculation.html#回归系数",
    "href": "19-effect-size-calculation.html#回归系数",
    "title": "效应量计算 & 转换",
    "section": "",
    "text": "可以从标准化或非标准化回归系数计算 SMD、Hedges’ \\(g\\) 或相关系数 \\(r\\) [@lipsey2001practical, Appendix B]。对于非标准化系数，我们可以使用 {esc} 中的 esc_B 函数。这是一个例子：\n\n\nlibrary(esc)\n\nesc_B(b = 3.3,       # 非标准化回归系数\n      sdy = 5,       # 预测变量 y 的标准差\n      grp1n = 100,   # 第一组的样本量\n      grp2n = 150,   # 第二组的样本量\n      es.type = \"d\") # 转换为 SMD；使用 \"g\" 表示 Hedges' g\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: unstandardized regression coefficient to effect size d\n    Effect Size:   0.6962\n Standard Error:   0.1328\n       Variance:   0.0176\n       Lower CI:   0.4359\n       Upper CI:   0.9565\n         Weight:  56.7018\n\n\n\nesc_B(b = 2.9,       # 非标准化回归系数\n      sdy = 4,       # 预测变量 y 的标准差\n      grp1n = 50,    # 第一组的样本量\n      grp2n = 50,    # 第二组的样本量\n      es.type = \"r\") # 转换为相关系数\n\n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: unstandardized regression coefficient \n##                  to effect size correlation\n##     Effect Size:   0.3611\n##  Standard Error:   0.1031\n##        Variance:   0.0106\n##        Lower CI:   0.1743\n##        Upper CI:   0.5229\n##          Weight:  94.0238\n##      Fisher's z:   0.3782\n##       Lower CIz:   0.1761\n##       Upper CIz:   0.5803\n可以使用 esc_beta 转换标准化回归系数。\n\nesc_beta(beta = 0.32,   # 标准化回归系数\n         sdy = 5,       # 预测变量 y 的标准差\n         grp1n = 100,   # 第一组的样本量\n         grp2n = 150,   # 第二组的样本量\n         es.type = \"d\") # 转换为 SMD；使用 \"g\" 表示 Hedges' g\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: standardized regression coefficient to effect size d\n    Effect Size:   0.6867\n Standard Error:   0.1327\n       Variance:   0.0176\n       Lower CI:   0.4266\n       Upper CI:   0.9468\n         Weight:  56.7867\n\n\n\nesc_beta(beta = 0.37,   # 标准化回归系数\n         sdy = 4,       # 预测变量 y 的标准差\n         grp1n = 50,    # 第一组的样本量\n         grp2n = 50,    # 第二组的样本量\n         es.type = \"r\") # 转换为相关系数\n\n## Effect Size Calculation for Meta Analysis\n## \n##      Conversion: standardized regression coefficient \n##                  to effect size correlation\n##     Effect Size:   0.3668\n##  Standard Error:   0.1033\n##        Variance:   0.0107\n##        Lower CI:   0.1803\n##        Upper CI:   0.5278\n##          Weight:  93.7884\n##      Fisher's z:   0.3847\n##       Lower CIz:   0.1823\n##       Upper CIz:   0.5871\n请注意，在 meta 分析中使用回归系数可能很棘手，因为我们假设所有研究都使用了相同的模型。如果系数是从多个回归模型中提取的，这尤其成问题，因为研究可能在其模型中控制了不同的协变量，这意味着 \\(b\\) 值不具有直接可比性。",
    "crumbs": [
      "网站首页",
      "效应量计算"
    ]
  },
  {
    "objectID": "19-effect-size-calculation.html#convert-corr",
    "href": "19-effect-size-calculation.html#convert-corr",
    "title": "效应量计算 & 转换",
    "section": "",
    "text": "对于组大小相等的情况 (\\(n_1=n_2\\))，我们可以使用以下公式从点二列相关系数推导出 SMD [@lipsey2001practical, chapter 3]。\n\\[\\begin{equation}\nr_{pb} = \\frac{\\text{SMD}}{\\sqrt{\\text{SMD}^2+4}} ~~~~~~~~\n\\text{SMD}=\\frac{2r_{pb}}{\\sqrt{1-r^2_{pb}}} (\\#eq:esc2)\n\\end{equation}\\]\n对于组大小不相等的情况，必须使用不同的公式 [@aaron1998equating]：\n\\[\\begin{align}\nr_{pb} &= \\frac{\\text{SMD}}{\\sqrt{\\text{SMD}^2+\\dfrac{(N^2-2N)}{n_1n_2}}} \\notag \\\\\n\\text{SMD} &= \\dfrac{r_{pb}}{\\sqrt{(1-r^2)\\left(\\frac{n_1}{N}\\times\\left(1-\\frac{n_1}{N}\\right)\\right)}} (\\#eq:esc3)\n\\end{align}\\]\n要将 \\(r_{pb}\\) 转换为 SMD 或 Hedges’ \\(g\\)，我们可以使用 esc_rpb 函数。\n\nlibrary(esc)\n\nesc_rpb(r = 0.25,      # 点二列相关系数\n        grp1n = 99,    # 第 1 组的样本量\n        grp2n = 120,   # 第 2 组的样本量\n        es.type = \"d\") # 转换为 SMD；使用 \"g\" 表示 Hedges' g\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: point-biserial r to effect size d\n    Effect Size:   0.5188\n Standard Error:   0.1380\n       Variance:   0.0190\n       Lower CI:   0.2483\n       Upper CI:   0.7893\n         Weight:  52.4967",
    "crumbs": [
      "网站首页",
      "效应量计算"
    ]
  },
  {
    "objectID": "19-effect-size-calculation.html#单因素-anova",
    "href": "19-effect-size-calculation.html#单因素-anova",
    "title": "效应量计算 & 转换",
    "section": "",
    "text": "我们还可以从具有两个组的单因素 ANOVA 的 \\(F\\)-值推导出 SMD。可以通过查看自由度来识别此类 ANOVA。在具有两个组的单因素 ANOVA 中，自由度应始终以 1 开头（例如，\\(F_{\\text{1,147}}\\)=5.31）。\n用于转换的公式如下 [基于 @rosnow1996computing; @rosnow2000contrasts; 参见 @thalheimer2002calculate]：\n\\[\\begin{equation}\n\\text{SMD} = \\sqrt{  F\\left(\\frac{n_1+n_2}{n_1 n_2}\\right)\\left(\\frac{n_1+n_2}{n_1+n_2-2}\\right)}\n(\\#eq:esc4)\n\\end{equation}\\]\n要从 \\(F\\)-值计算 SMD 或 Hedges’ \\(g\\)，我们可以使用 esc_f 函数。这是一个例子：\n\nesc_f(f = 5.04,      # 单因素方差分析的 F 值\n      grp1n = 519,   # 第 1 组的样本量\n      grp2n = 528,   # 第 2 组的样本量\n      es.type = \"g\") # 转换为 Hedges' g；使用 \"d\" 表示 SMD\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: F-value (one-way-Anova) to effect size Hedges' g\n    Effect Size:   0.1387\n Standard Error:   0.0619\n       Variance:   0.0038\n       Lower CI:   0.0174\n       Upper CI:   0.2600\n         Weight: 261.1022",
    "crumbs": [
      "网站首页",
      "效应量计算"
    ]
  },
  {
    "objectID": "19-effect-size-calculation.html#双样本-t-检验",
    "href": "19-effect-size-calculation.html#双样本-t-检验",
    "title": "效应量计算 & 转换",
    "section": "",
    "text": "效应量表示为标准化均值差也可以从独立双样本 \\(t\\)-检验值导出，使用以下公式 [@rosnow2000contrasts; @thalheimer2002calculate]：\n\\[\\begin{equation}\n\\text{SMD} = \\frac {t(n_1+n_2)}{\\sqrt{(n_1+n_2-2)(n_1n_2)}}\n(\\#eq:esc5)\n\\end{equation}\\]\n在 R 中，我们可以使用 esc_t 函数从 \\(t\\)-值计算 SMD 或 Hedges’ g。这是一个例子：\n\nesc_t(t = 3.3,     # t 值\n      grp1n = 100, # group1 的样本量\n      grp2n = 150, # group 2 的样本量\n      es.type=\"d\") # 转换为 SMD；使用 \"g\" 表示 Hedges' g\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: t-value to effect size d\n    Effect Size:   0.4260\n Standard Error:   0.1305\n       Variance:   0.0170\n       Lower CI:   0.1703\n       Upper CI:   0.6818\n         Weight:  58.7211",
    "crumbs": [
      "网站首页",
      "效应量计算"
    ]
  },
  {
    "objectID": "19-effect-size-calculation.html#p-值",
    "href": "19-effect-size-calculation.html#p-值",
    "title": "效应量计算 & 转换",
    "section": "",
    "text": "有时，研究仅报告效应量（例如，Cohen’s \\(d\\) 值）、该效应的 \\(p\\)-值，仅此而已。然而，要在 meta 分析中汇集结果，我们需要一种衡量效应量精确度的方法，最好是标准误。\n在这种情况下，我们必须从效应量的 \\(p\\)-值估计标准误。对于基于差异（即 SMD）或比率（即风险或优势比）的效应量，这是可行的，使用 Altman 和 Bland 的公式 [-@altman2011obtain]。这些公式在 R 的 se.from.p 函数中实现。\n\n\n\n\n“se.from.p”函数\n\n\nse.from.p 函数包含在 {dmetar} 程序包中。一旦在您的计算机上安装并加载 {dmetar}，该函数就可以使用了。如果您没有安装 {dmetar}，请按照以下说明操作：\n\n\n\n在线访问该函数的源代码 online。\n\n\n通过将源代码的全部内容复制并粘贴到控制台（R Studio 的左下窗格）中，然后按“Enter”，让 R “学习”该函数。\n\n\n\n\n假设一项研究有 \\(N=\\) 71 名参与者，报告的效应量为 \\(d=\\) 0.71，其中 \\(p=\\) 0.013，我们可以这样计算标准误：\n\nlibrary(dmetar)\n\nse.from.p(0.71,\n          p = 0.013,\n          N = 71,\n          effect.size.type = \"difference\")\n\n##   EffectSize StandardError StandardDeviation  LLCI  ULCI\n## 1       0.71         0.286             2.410 0.149 1.270\n对于一项有 \\(N=\\) 200 名参与者的研究，报告的效应量为 OR = 0.91，其中 \\(p=\\) 0.38，标准误的计算方式如下：\n\nlibrary(magrittr) # for pipe\n\nse.from.p(0.91, p = 0.38, N = 200,\n          effect.size.type = \"ratio\") %&gt;% t()\n\n##                        [,1]\n## logEffectSize        -0.094\n## logStandardError      0.105\n## logStandardDeviation  1.498\n## logLLCI              -0.302\n## logULCI               0.113\n## EffectSize            0.910\n## LLCI                  0.739\n## ULCI                  1.120\n当 effect.size.type = \"ratio\" 时，该函数还会自动计算对数转换的效应量和标准误，这是使用 metagen 函数（第 @ref(pre-calculated-es) 章）所必需的。",
    "crumbs": [
      "网站首页",
      "效应量计算"
    ]
  },
  {
    "objectID": "19-effect-size-calculation.html#chi2-检验",
    "href": "19-effect-size-calculation.html#chi2-检验",
    "title": "效应量计算 & 转换",
    "section": "",
    "text": "要将 \\(\\chi^2\\) 统计量转换为优势比，可以使用 esc_chisq 函数（假设 d.f. = 1；例如，\\(\\chi^2_1\\) = 8.7）。这是一个例子：\n\nesc_chisq(chisq = 7.9,        # 卡方值\n          totaln = 100,       # 总样本量\n          es.type = \"cox.or\") # 转换为优势比\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: chi-squared-value to effect size Cox odds ratios\n    Effect Size:   2.6287\n Standard Error:   0.3440\n       Variance:   0.1183\n       Lower CI:   1.3394\n       Upper CI:   5.1589\n         Weight:   8.4502",
    "crumbs": [
      "网站首页",
      "效应量计算"
    ]
  },
  {
    "objectID": "19-effect-size-calculation.html#nnt",
    "href": "19-effect-size-calculation.html#nnt",
    "title": "效应量计算 & 转换",
    "section": "",
    "text": "Cohen’s \\(d\\) 或 Hedges’ \\(g\\) 等效应量通常难以从实践角度解释。想象一下，我们在 meta 分析中发现干预效果为 \\(g=\\) 0.35。我们如何向患者、政府官员、医疗专业人员或其他利益相关者传达这种效果的含义？\n为了让其他人更容易理解结果，meta 分析通常还会报告需治人数 (NNT)。该指标最常用于医学研究。它表示必须接受研究治疗的额外患者人数，才能预防一个额外的负面事件（例如，复发）或实现一个额外的正面事件（例如，症状缓解、反应）。例如，如果 NNT = 3，我们可以说必须接受治疗的三个人才能避免一个额外的复发病例；或者必须治疗三名患者才能实现一个额外的可靠症状缓解病例，具体取决于研究问题。\n当我们处理二元效应量数据时，NNT 的计算相对容易。公式如下：\n\\[\\begin{equation}\n\\text{NNT} = (p_{e_{\\text{treat}}}-p_{e_{\\text{control}}})^{-1}\n(\\#eq:esc6)\n\\end{equation}\\]\n在此公式中，\\(p_{e_{\\text{treat}}}\\) 和 \\(p_{e_{\\text{control}}}\\) 是在治疗组和对照组中经历该事件的参与者比例。这些比例与用于计算风险比的“风险”（第 @ref(rr) 章）相同，也称为实验组事件率 (EER) 和对照组事件率 (CER)。鉴于其公式，NTT 也可以描述为（绝对）风险差异的倒数。\n将标准化均值差或 Hedges’ \\(g\\) 转换为 NNT 更为复杂。有两种常用的方法：\n\n\nKraemer 和 Kupfer 的方法 [-@kraemer2006size]，该方法从曲线下面积 (AUC) 计算 NNT，AUC 定义为治疗组患者的结果优于对照组患者结果的概率。此方法允许直接从 SMD 或 \\(g\\) 计算 NNT，而无需任何额外信息。\nFurukawa 和 Leucht 的方法使用 CER 或其合理估计值从 SMD 计算 NNT 值。与 Kraemer & Kupfer 方法相比，Furukawa 的方法已被证明在估计真实 NNT 值方面更优 [@furukawa2011obtain]。如果我们可以对 CER 进行合理的估计，则应始终首选 Furukawa 的方法。\n\n当我们使用风险比或优势比作为效应量指标时，可以使用 nnt 函数直接从 {meta} 对象计算 NNT。在使用 metabin 运行 meta 分析（第 @ref(pooling-or-rr) 章）后，我们只需将结果插入 nnt 函数即可。这是一个例子：\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.1-0).\nType 'help(meta)' for a brief overview.\n\ndata(Olkin1995)\n\n# 使用二元效应量数据运行 meta 分析\nm.b &lt;- metabin(ev.exp, n.exp, ev.cont, n.cont, \n               data = Olkin1995,\n               sm = \"RR\")\nnnt(m.b)\n\nNumber needed to treat (common effect model): \n\n     RR    p.c    NNTB             95%-CI\n 0.7728 0.1440 30.5677 [26.1222; 37.2386]\n 0.7728 0.3750 11.7383 [10.0312; 14.3001]\n\nNumber needed to treat (random effects model): \n\n     RR    p.c    NNTB             95%-CI\n 0.7694 0.1440 30.1139 [24.0662; 41.3519]\n 0.7694 0.3750 11.5641 [ 9.2417; 15.8796]\n\n\nnnt 函数提供了针对不同假设 CER 的需治人数。这三行显示了数据集中最小、平均和最大 CER 的结果。平均 CER 估计值是通常报告的“典型”NNT。\n只要摘要度量 sm 是 \"RR\" 或 \"OR\"，也可以将 nnt 与 metagen 模型一起使用。对于此类模型，我们还需要在 nnt 的 p.c 参数中指定假设的 CER。以下是使用我们在第 @ref(m-gen-bin) 章中创建的 m.gen_bin meta 分析对象的示例：\n\n# Also show fixed-effect model results\nm.gen_bin &lt;- update(m.gen_bin, fixed = TRUE)\n\nWarning: Use argument 'common' instead of 'fixed' (deprecated).\n\nnnt(m.gen_bin, \n    p.c = 0.1) # 使用 0.1 的 CER\n\nNumber needed to treat (common effect model): \n\n     RR    p.c   NNTH            95%-CI\n 2.0319 0.1000 9.6906 [8.2116; 11.6058]\n\nNumber needed to treat (random effects model): \n\n     RR    p.c   NNTH            95%-CI\n 2.0218 0.1000 9.7870 [6.4761; 16.4843]\n\n\n\n可以使用 {dmetar} 中的 NNT 函数将标准化均值差或 Hedges’ \\(g\\) 转换为 NNT。\n\n\n\n“NNT”函数\n\n\n如果您没有安装 {dmetar}，请按照以下说明操作：\n\n\n\n在线访问 NNT 函数的源代码 online。\n\n\n通过将源代码的全部内容复制并粘贴到控制台（R Studio 的左下窗格）中，然后按“Enter”，让 R “学习”该函数。\n\n\n\n\n要使用 Kraemer & Kupfer 方法，我们只需要为 NNT 函数提供一个效应量（SMD 或 \\(g\\)）。只要提供了 CER 值，就会自动使用 Furukawa 的方法。\n\nsource('./NNT.R') # load NNT function\nNNT(d = 0.245)\n\n[1] 7.270711\nattr(,\"class\")\n[1] \"NNT\"     \"kk\"      \"numeric\"\n\nNNT(d = 0.245, CER = 0.35)\n\n[1] 10.61533\nattr(,\"class\")\n[1] \"NNT\"     \"fl\"      \"numeric\"\n\n\n\n\n\n一个需要谨慎对待的数字：对 NNT 的批评\n\n\n虽然很常见，但使用 NNT 来传达临床试验的结果并非没有争议。批评包括外行人经常误解它 [尽管据称它是其他效应量指标的“直观”替代方案，@christensen2006number]；以及研究人员经常错误地计算 NNT [@mendes2017number]。\n\n\n此外，无法计算 NNT 的可靠标准误（和置信区间），这意味着它们不能用于 meta 分析 [@hutton2010misleading]。只能在使用其他效应量指标进行合并后，才能将结果转换为 NNT。",
    "crumbs": [
      "网站首页",
      "效应量计算"
    ]
  },
  {
    "objectID": "19-effect-size-calculation.html#pool-groups",
    "href": "19-effect-size-calculation.html#pool-groups",
    "title": "效应量计算 & 转换",
    "section": "",
    "text": "为避免单元分析错误（第 @ref(unit-of-analysis) 章），有时需要在计算（标准化）均值差之前，合并两个或多个试验组的均值和标准差。要合并两个组的连续效应量数据，我们可以使用以下等式：\n\\[\\begin{align}\nn_{\\text{pooled}} &= n_1 + n_2  \\\\\nm_{\\text{pooled}} &= \\frac{n_1m_1+n_2m_2}{n_1+n_2} \\\\\nSD_{\\text{pooled}} &= \\sqrt{\\frac{(n_1-1)SD^{2}_{1}+ (n_2-1)SD^{2}_{2}+\\frac{n_1n_2}{n_1+n_2}(m^{2}_1+m^{2}_2-2m_1m_2)} {n_1+n_2-1}}\n\\end{align}\\]\n我们可以使用 pool.groups 函数在 R 中应用此公式。\n\n\n\n“pool.groups”函数\n\n\npool.groups 函数包含在 {dmetar} 程序包中。一旦在您的计算机上安装并加载 {dmetar}，该函数就可以使用了。如果您没有安装 {dmetar}，请按照以下说明操作：\n\n\n\n在线访问该函数的源代码 online。\n\n\n通过将源代码的全部内容复制并粘贴到控制台（R Studio 的左下窗格）中，然后按“Enter”，让 R “学习”该函数。\n\n\n\n\n这是一个例子：\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\n\n\nAttaching package: 'dmetar'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    NNT\n\npool.groups(n1 = 50,   # 组 1 的样本量\n            n2 = 50,   # 组 2 的样本量\n            m1 = 3.5,  # 组 1 的均值\n            m2 = 4,    # 组 2 的均值\n            sd1 = 3,   # 组 1 的标准差\n            sd2 = 3.8) # 组 2 的标准差\n\n  Mpooled SDpooled Npooled\n1    3.75 3.415369     100",
    "crumbs": [
      "网站首页",
      "效应量计算"
    ]
  },
  {
    "objectID": "19-effect-size-calculation.html#aggregate-es",
    "href": "19-effect-size-calculation.html#aggregate-es",
    "title": "效应量计算 & 转换",
    "section": "",
    "text": "{metafor} 中的 aggregate 函数可用于将几个相关的、预先计算的效应量聚合为一个估计值，例如因为它们是同一研究或集群的一部分。这是避免单元分析错误的一种方法（参见第 @ref(unit-of-analysis) 章），但这需要我们假设研究内部相关性的值，这通常是未知的。处理效应量依赖性的另一种（通常是更可取的）方法是（相关）分层模型，这将在第 @ref(multilevel-ma) 章中进行说明。\n在本例中，我们聚合 Chernobyl 数据集（参见第 @ref(multilevel-R) 章）的效应量，以便每个研究仅提供一个效应量：\n\nlibrary(metafor)\nlibrary(dmetar)\ndata(\"Chernobyl\")\n\n# 将 'Chernobyl' 数据转换为 'escalc' 对象\nChernobyl &lt;- escalc(yi = z,           # 效应量\n                    sei = se.z,       # 标准误\n                    data = Chernobyl)\n\n# 在研究层面聚合效应量\n# 我们假设相关性为 rho=0.6\nChernobyl.agg &lt;- aggregate(Chernobyl, \n                           cluster = author,\n                           rho = 0.6)\n\n# 显示聚合结果\nChernobyl.agg[,c(\"author\", \"yi\", \"vi\")]\n\n##                       author     yi     vi \n## 1 Aghajanyan & Suskov (2009) 0.2415 0.0079 \n## 2     Alexanin et al. (2010) 1.3659 0.0012 \n## 3             Bochkov (1993) 0.2081 0.0014 \n## 4      Dubrova et al. (1996) 0.3068 0.0132 \n## 5      Dubrova et al. (1997) 0.4453 0.0110\n## [...]\n请注意，aggregate 返回聚合的效应量 yi 以及它们的 方差 vi，其平方根是标准误。\n\\[\\tag*{$\\blacksquare$}\\]",
    "crumbs": [
      "网站首页",
      "效应量计算"
    ]
  },
  {
    "objectID": "17-risk-of-bias-plots.html",
    "href": "17-risk-of-bias-plots.html",
    "title": "偏倚风险图",
    "section": "",
    "text": "作者：Luke A. McGuinness\n\n\n\n\n\n请引用本章如下：\nMcGuinness, L. A. (2021). 偏倚风险图。见 Harrer, M., Cuijpers, P., Furukawa, T.A., & Ebert, D.D., 使用 R 进行 Meta 分析：实操指南 (在线版本). bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/rob-plots.html.\n\n\n\n在本章中，我们将介绍如何使用 {robvis} 包在 R 中创建偏倚风险图。\n\n\n\n\n作为系统评价和 Meta 分析的一部分，您可能还需要使用相关的 基于领域的偏倚风险评估工具 检查纳入研究的内部有效性（偏倚风险），并以图形格式呈现此评估的结果。\nCochrane 手册推荐两种类型的图形：一种是汇总条形图，显示每个领域中具有给定偏倚风险判断的研究比例；另一种是交通灯图，显示每个研究的领域级别判断。\n然而，研究人员在创建这些图形时可用的选项有限。虽然 RevMan 具有创建图的功能，但许多研究人员不使用它来进行系统评价，因此将相关数据复制到系统中是一种低效的解决方案。\n同样，使用 MS PowerPoint 等软件手动制作图表既耗时，又意味着如果需要更改，则必须手动更新图表。此外，期刊通常要求图表具有出版质量（高于约 300-400dpi），这在从 RevMan 导出偏倚风险图或手动创建它们时很难实现。\n\n\n\n\n\nRevMan 输出示例。\n\n\n\n\n为了避免所有这些，您现在可以使用 {robvis} 包 [@mcguinness2020risk; @robvis] 在 R Studio 中轻松绘制偏倚风险图，该包提供将偏倚风险评估汇总表转换为汇总图或交通灯图的函数。\n\n\n\n\n假设您已经安装了 {dmetar} 包（参见第 @ref(dmetar) 章），请使用以下命令加载 {robvis} 包：\n\nlibrary(robvis)\n\n\n\n\n\n\n为了生成我们的图，我们首先必须将偏倚风险评估的结果从 Excel 导入到 R 中。请注意，{robvis} 期望您提供的数据具有某些事实，因此请务必在 Excel 中设置表时遵循以下指南：\n\n第一列标记为“Study”，包含研究标识符（例如，Anthony et al, 2019）\n倒数第二列标记为“Overall”，包含总体偏倚风险判断\n最后一列标记为“Weight”，包含研究精确度的一些度量，例如 Meta 分析中分配给每个研究的权重，或者如果没有进行 Meta 分析，则包含每个研究的样本量。有关更多详细信息，请参见第 @ref(fem) 章。\n所有其他列包含特定领域的偏倚风险评估结果。\n\n为了详细说明上述指南，以具有 5 个领域的 ROB2 工具为例。 {robvis} 期望的最终数据集将具有 8 列：\n\n第 1 列：研究标识符\n第 2-6 列：每列一个 RoB2 领域\n第 7 列：总体偏倚风险判断\n第 8 列：权重。\n\n在 Excel 中，此偏倚风险汇总表如下所示：\n\n\n\n\n\n\n\n\n\n\n\n\n列名\n\n\n对于四个工具模板中的三个（ROB2、ROBINS-I、QUADAS-2），包含领域级别判断的列的名称并不重要，因为 robvis 中的模板将使用正确的工具特定标题重新标记每个领域。\n\n\n\n将您在 Excel 中创建的表格以逗号分隔文件（例如“robdata.csv”）保存到工作目录后，您可以使用以下命令以编程方式将文件读取到 R 中，或者通过第 @ref(data-prep-R) 章中描述的“导入助手”方法。\n\nmy_rob_data &lt;- read.csv(\"robdata.csv\", header = TRUE)\n\n\n\n\n\n\n{robvis} 通过使用您提供的数据来填充特定于您使用的偏倚风险评估工具的模板图来生成偏倚风险图。目前，{robvis} 包含以下三个工具的模板：\n\nROB2，用于随机对照试验的新的 Cochrane 偏倚风险工具；\nROBINS-I，非随机研究中的偏倚风险 - 干预工具；\nQUADAS-2，诊断准确性研究的质量和适用性，第 2 版。\n\n{robvis} 还包含一个特殊的通用模板，标记为 ROB1。它设计用于原始 Cochrane 随机对照试验偏倚风险工具，也可用于可视化使用上面列表中未包含的其他基于领域的工具进行的评估结果。有关使用此模板时所需其他步骤的更多信息，请参见第 @ref(rob1-template) 章。\n\n\n\n\n\n{robvis} 包包含上面概述的每个模板的示例数据集。这些存储在以下对象中：\n\ndata_rob2：ROB2 工具的示例数据\ndata_robins：ROBINS-I 工具的示例数据\ndata_quadas：QUADAS-2 工具的示例数据\ndata_rob1：RoB-1 工具的示例数据。\n\n您可以使用 glimpse 函数探索这些数据集（参见第 @ref(class-conversion) 章）。例如，使用 library(robvis) 加载包后，可以通过运行以下命令查看 ROBINS-I 示例数据集：\n\nglimpse(data_robins)\n\n\n\nRows: 12\nColumns: 10\n$ Study   &lt;fct&gt; Study 1, Study 2, Study 3, Study 4, Study 5, Study 6, Study 7,…\n$ D1      &lt;fct&gt; Critical, Moderate, Moderate, Low, Serious, Critical, Critical…\n$ D2      &lt;fct&gt; Low, Low, Low, Low, Serious, Serious, Moderate, Moderate, Low,…\n$ D3      &lt;fct&gt; Critical, Low, Moderate, Serious, Low, Moderate, Moderate, Low…\n$ D4      &lt;fct&gt; Critical, Critical, Critical, Critical, Low, Critical, Serious…\n$ D5      &lt;fct&gt; Low, Low, Critical, Moderate, Moderate, Critical, Critical, Lo…\n$ D6      &lt;fct&gt; Low, Moderate, Low, Low, Low, Moderate, Serious, Low, Serious,…\n$ D7      &lt;fct&gt; Serious, Low, Serious, Critical, Moderate, Serious, Serious, C…\n$ Overall &lt;fct&gt; Critical, Low, Serious, Low, Serious, Serious, Moderate, Moder…\n$ Weight  &lt;dbl&gt; 33.3333333, 33.3333333, 0.1428571, 9.0909091, 12.5000000, 25.0…\n\n\n这些示例数据集用于创建本指南其余部分中介绍的图。\n\n\n\n\n\n\n\n\n\n一旦我们成功地将偏倚风险汇总表导入到 R 中，创建偏倚风险图就非常简单了。\n首先，通过运行以下代码，使用 ROB2 示例数据集 (data_rob2) 创建一个简单的加权汇总条形图：\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nrob_summary 函数具有以下参数：\n\ndata。包含汇总（领域）级别偏倚风险评估的数据框，其中第一列包含研究详细信息，第二列包含评估的第一个领域，最后一列包含分配给每个研究的权重。该函数假定数据包括一列用于总体偏倚风险。例如，ROB2.0 数据集将具有 8 列（1 列用于研究详细信息，5 列用于领域级别判断，1 列用于总体判断，1 列用于权重，按该顺序）。\ntool。使用的偏倚风险评估工具。目前支持 RoB2.0 (\"ROB2\"), \"ROBINS-I\" 和 \"QUADAS-2\"。\noverall。一个在图中包含总体偏倚风险的附加条的选项。默认为 FALSE。\nweighted。一个指定是否应在条形图中使用权重的选项。默认值为 TRUE，与当前的 Cochrane 协作指南一致。\ncolour。一个指定图的配色方案的参数。默认值为 \"cochrane\"，它使用无处不在的 Cochrane 颜色，而一个预设的适合色盲友好的调色板也可用 (colour = \"colourblind\")。\nquiet。一个以静默方式生成图而不显示它的逻辑选项。默认值为 FALSE。\n\n下面描述了每个参数的功能示例。\n\n\n\n\n一个定义您要使用的工具模板的参数。在上面的示例中，使用了 ROB2 模板。下面演示了另外两个主要模板 - ROBINS-I 和 QUADAS-2 模板：\n\nrob_summary(data = data_robins, \n            tool = \"ROBINS-I\")\n\n\n\n\n\n\n\n\n\nrob_summary(data = data_quadas, \n            tool = \"QUADAS-2\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n默认情况下，图中不包含表示总体偏倚风险判断的附加条。如果您想包含它，请设置 overall = TRUE。例如：\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\", \n            overall = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n默认情况下，条形图由研究精确度的某种度量加权，因此条形图显示的是信息的比例，而不是处于特定偏倚风险的研究的比例。此方法符合 Cochrane 手册。\n您可以通过设置 weighted = FALSE 来关闭此选项，以创建未加权条形图。例如，比较以下两个图：\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\")\n\n\n\n\n\n\n\n\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\",\n            weighted = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n英式英语拼写\n请注意 colour 的非美式英语拼写！\n\n\n两个绘图函数的 colour 参数允许用户从两个预定义的配色方案 \"cochrane\"（默认）或 \"colourblind\" 中选择，或者通过提供 十六进制代码 向量来定义自己的调色板。例如，要使用预定义的 \"colourblind\" 调色板：\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\", \n            colour = \"colourblind\")\n\n\n\n\n\n\n\n\n并定义您自己的配色方案：\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\", \n            colour = c(\"#f442c8\",\"#bef441\",\"#000000\"))\n\n\n\n\n\n\n\n\n在定义您自己的配色方案时，您必须确保离散判断的数量（例如“低”、“中等”、“高”、“严重”）和指定的颜色数量相同。此外，颜色必须按偏倚风险升序指定（例如“低”到“严重”），第一个十六进制代码对应于“低”偏倚风险。\n\n\n\n\n\n\n\n通常，研究人员希望展示每个评估的研究的每个领域的偏倚风险。生成的图通常称为交通灯图，可以使用 {robvis} 通过 rob_traffic_light 函数生成。\n\n\n\n\n首先，通过运行以下代码，使用 ROB2 示例数据集 (data_rob2) 创建交通灯图：\n\nrob_traffic_light(data = data_rob2, \n                  tool = \"ROB2\")\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 54 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrob_summary 函数具有以下参数：\n\ndata。包含汇总（领域）级别偏倚风险评估的数据框，其中第一列包含研究详细信息，第二列包含评估的第一个领域，最后一列包含分配给每个研究的权重。该函数假定数据包括一列用于总体偏倚风险。例如，ROB2.0 数据集将具有 8 列（1 列用于研究详细信息，5 列用于领域级别判断，1 列用于总体判断，1 列用于权重，按该顺序）。\ntool。使用的偏倚风险评估工具。目前支持 RoB2.0 (\"ROB2\"), \"ROBINS-I\" 和 \"QUADAS-2\"。\ncolour。一个指定图的配色方案的参数。默认值为 \"cochrane\"，它使用无处不在的 Cochrane 颜色，而一个预设的适合色盲友好的调色板也可用 (\"colourblind\")。\npsize。一个更改“交通灯”点大小的选项。默认值为 20。\nquiet。一个以静默方式生成图而不显示它的逻辑选项。默认值为 FALSE。\n\n\n\n\n\n一个定义您要使用的工具模板的参数。演示了 ROB2 模板，下面显示了另外两个主要模板 - ROBINS-I 和 QUADAS-2 模板：\n\nrob_traffic_light(data = data_robins, \n                  tool = \"ROBINS-I\")\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 96 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\nrob_traffic_light(data = data_quadas, \n                  tool = \"QUADAS-2\")\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 60 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n英式英语拼写\n请注意 colour 的非美式英语拼写！\n\n\n两个绘图函数的 colour 参数允许用户从两个预定义的配色方案 \"cochrane\"（默认）或 \"colourblind\" 中选择，或者通过提供十六进制代码向量来定义自己的调色板。\n例如，要使用预定义的 \"colourblind\" 调色板：\n\nrob_traffic_light(data = data_rob2, \n                  tool = \"ROB2\", \n                  colour = \"colourblind\")\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 54 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n并定义您自己的配色方案：\n\nrob_traffic_light(data = data_rob2, \n                  tool = \"ROB2\", \n                  colour = c(\"#f442c8\",\"#bef441\",\"#000000\"))\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 54 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n在定义您自己的配色方案时，您必须确保离散判断的数量（例如“低”、“中等”、“高”、“严重”）和指定的颜色数量相同。此外，颜色必须按偏倚风险升序指定（例如“低”到“严重”），第一个十六进制代码对应于“低”偏倚风险。\n\n\n\n\n\n有时，当执行了大量的偏倚风险评估时，生成的交通灯图可能太长而无法使用。用户可以通过将 rob_traffic_light 函数的 psize 参数修改为较小的数字（默认值为 20）来解决此问题。例如：\n\n# 创建更大的数据集（18 个研究）\nnew_rob2_data &lt;- rbind(data_rob2, data_rob2)\nnew_rob2_data$Study &lt;- paste(\"Study\", seq(1:length(new_rob2_data$Study))) \n\n# 绘制更大的数据集，将 psize 参数从 20 减小到 8\nrob_traffic_light(data = new_rob2_data, \n                  tool = \"ROB2\", \n                  psize = 8)\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 108 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n此模板在图中包含的领域中提供了更大的灵活性。它可以处理任意数量的领域（cf. 其他具有固定数量领域的工具模板），并使用用户定义的列标题作为生成的图中的领域标题。\n\n\n\n\n\n“ROB1”模板 (tool = \"ROB1\") 可以处理变化的列数。这最初是为 ROB1 评估工具设计的，该工具经常添加或删除领域。虽然此模板可用于呈现使用其他工具（ROB2、QUADAS-2、ROBINS-I）的调整版本进行的评估结果，但我们强烈建议作者不要这样做。使用其他已发布工具的作者应使用先前章节中介绍的更严格的模板，以确保他们符合指南。\n\n\n\n\n\n对于前面章节中列出的其他工具，包含领域级别偏倚风险判断的列的名称并不重要。例如，它们通常命名为 D1、D2、D3 等。但是，使用 \"ROB1\" 模板时并非如此。\n比较 data_rob2 和 data_rob1 的列标题（此处水平呈现，以便于比较）：\n\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\nComparison of column names in the `data_rob2` (left) and `data_rob1` (right) datasets.\n\n\nNo.\ndata_rob2\ndata_rob1\n\n\n\n\n1\nStudy\nStudy\n\n\n2\nD1\nRandom.sequence.generation.\n\n\n3\nD2\nAllocation.concealment.\n\n\n4\nD3\nBlinding.of.participants.and.personnel.\n\n\n5\nD4\nBlinding.of.outcome.assessment\n\n\n6\nD5\nIncomplete.outcome.data\n\n\n7\nOverall\nSelective.reporting.\n\n\n8\nWeight\nOther.sources.of.bias.\n\n\n9\n.\nOverall\n\n\n10\n.\nWeight\n\n\n\n\n\n\n\n\nROB2 示例数据集中的领域列（第 2-6 列）已被赋予任意名称 D1 - D5，因为它们将被该工具覆盖，以对应于 ROB2 指南给出的正确的领域标题。\n相比之下，ROB1 示例数据集中的领域列（第 2-8 列）已正确标记，因为这些将在 rob_summary 和 rob_traffic_light 生成的图中使用。\n例如，假设我们将“Random.sequence.generation”列的名称更改为“This is a test”。在 rob_summary 图中，第一个条的标题已更改，而在 rob_traffic_light 图中，字幕已更新以反映此更改。\n\n# 创建 data_rob1 数据集的副本\nnew_rob1_data &lt;- data_rob1\n\n# 更改第一个领域的列标题\ncolnames(new_rob1_data)[2] &lt;- \"This is a test\"\n\n# 创建汇总条形图\nrob_summary(data = new_rob1_data, tool = \"ROB1\")\n\n\n\n\n\n\n\n\n\n# 创建交通灯图\nrob_traffic_light(data = new_rob1_data, \n                  tool = \"ROB1\")\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 72 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{robvis} 函数（rob_summary 和 rob_traffic_light）都会生成一个 ggplot 对象，因此可以使用 {ggplot2} 包中的函数进行自定义和保存。使用以下代码加载此包：\n\nlibrary(ggplot2)\n\n\n\n\n\n\n您可以使用 {ggplot2} 函数对您的图进行一系列后期制作修改。一个有用的示例是向图中添加标题：\n\n# 确保您已安装并加载 ggplot2 包\nrob_summary(data_rob2, \"ROB2\") +\n  ggtitle(\"您的自定义标题\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n为了保存偏倚风险图，我们首先使用 &lt;- 运算符将其分配给一个对象，然后使用 {ggplot2} 包的 ggsave 函数保存它。\n保存汇总条形图时，我们建议使用以下代码，其中包含默认的高度和宽度值。\n\n# 创建您的图，并将其分配给一个对象\nrob_barplot &lt;- rob_summary(data_rob2, \"ROB2\")\n\n# 保存您的图\nggsave(plot = rob_barplot,        # 要保存的图对象\n       filename = \"robplot2.png\", # 目标文件\n       width = 8,                 # 图像宽度（推荐）\n       height = 2.41,             # 图像高度（推荐）\n       dpi = 1000)                # 图像分辨率\n\n保存交通灯图时，方法相同。但是，width 和 height 参数没有推荐值，因为这些参数的最佳值会因图而异，因为包含的研究的数量和名称会发生变化。\n\n\n\n\n\n只需更改文件名的扩展名（例如，从“.png”到“.pdf”），就可以使用上面概述的函数以多种格式保存图。可接受的格式包括 .png、.pdf、.tiff 和 .svg1。\n例如，要将上面创建的条形图 (rob_barplot) 保存为 PDF：\n\n# 保存您的图\nggsave(plot = rob_barplot,                  \n       filename = \"robplot2.pdf\", # 文件扩展名现在为“.pdf”\n       width = 8,                           \n       height = 2.41,                       \n       dpi = 1000)\n\n\n\n\n\n\n\n为了使用户能够快速探索 robvis 的功能，我们创建了一个 Web 应用程序，该应用程序提供了 {robvis} 包的图形界面。\nWeb 应用程序可在此处获得：here。下面简要介绍一下指导性演练。\n\n\n\n\n\n\n\n\n\n\n\n\n\n该页面提供了先前章节中指导的简洁版本，特别是与设置数据集有关的指导。更重要的是，用户可以将每个工具的示例数据集下载为 CSV 文件，并使用这些数据集与应用程序进行交互并探索其功能。\n\n\n\n\n\n单击第二个选项卡会将您带到下面显示的屏幕。\n\n\n\n\n\n\n\n\n\n此菜单充当 rob_traffic_light 函数的图形界面：\n\n通过单击“Browse…”并导航到存储 CSV 文件的位置来上传您的偏倚风险汇总表。\n使用下拉框选择用于执行偏倚风险评估的工具。\n\n基本的交通灯图现在应出现在窗口的右侧。您可以使用以下选项自定义图：\n\n选择您要使用的配色方案（“Cochrane”或“色盲友好”）\n修改点大小（当您希望在单个交通灯图上绘制大量研究时很有用）\n修改文本大小。\n\n对图满意后，您可以通过选择所需的格式（.png、.jpg、.tiff、.eps）并单击“Download plot”按钮来下载它。请注意，如果您不首先选择格式，您将收到下载错误。\n\n\n\n\n\n单击第三个选项卡会将您带到下面显示的屏幕。\n\n\n\n\n\n\n\n\n\n此菜单充当 rob_summary 函数的图形界面：\n\n通过单击“Browse…”并导航到存储 CSV 文件的位置来上传您的偏倚风险汇总表。\n使用下拉框选择用于执行偏倚风险评估的工具。\n\n基本的加权汇总条形图现在应出现在窗口的右侧。\n您可以使用以下选项自定义图：\n\n选择在创建图时是否使用权重\n包括表示总体偏倚风险判断分布的附加条\n选择您要使用的配色方案（“Cochrane”或“色盲友好”）\n\n与交通灯图选项卡一样，您可以通过选择所需的格式并单击“Download plot”按钮来下载您的图。\n\\[\\tag*{$\\blacksquare$}\\]",
    "crumbs": [
      "网站首页",
      "偏倚风险图"
    ]
  },
  {
    "objectID": "17-risk-of-bias-plots.html#引言",
    "href": "17-risk-of-bias-plots.html#引言",
    "title": "偏倚风险图",
    "section": "",
    "text": "作为系统评价和 Meta 分析的一部分，您可能还需要使用相关的 基于领域的偏倚风险评估工具 检查纳入研究的内部有效性（偏倚风险），并以图形格式呈现此评估的结果。\nCochrane 手册推荐两种类型的图形：一种是汇总条形图，显示每个领域中具有给定偏倚风险判断的研究比例；另一种是交通灯图，显示每个研究的领域级别判断。\n然而，研究人员在创建这些图形时可用的选项有限。虽然 RevMan 具有创建图的功能，但许多研究人员不使用它来进行系统评价，因此将相关数据复制到系统中是一种低效的解决方案。\n同样，使用 MS PowerPoint 等软件手动制作图表既耗时，又意味着如果需要更改，则必须手动更新图表。此外，期刊通常要求图表具有出版质量（高于约 300-400dpi），这在从 RevMan 导出偏倚风险图或手动创建它们时很难实现。\n\n\n\n\n\nRevMan 输出示例。\n\n\n\n\n为了避免所有这些，您现在可以使用 {robvis} 包 [@mcguinness2020risk; @robvis] 在 R Studio 中轻松绘制偏倚风险图，该包提供将偏倚风险评估汇总表转换为汇总图或交通灯图的函数。\n\n\n\n\n假设您已经安装了 {dmetar} 包（参见第 @ref(dmetar) 章），请使用以下命令加载 {robvis} 包：\n\nlibrary(robvis)\n\n\n\n\n\n\n为了生成我们的图，我们首先必须将偏倚风险评估的结果从 Excel 导入到 R 中。请注意，{robvis} 期望您提供的数据具有某些事实，因此请务必在 Excel 中设置表时遵循以下指南：\n\n第一列标记为“Study”，包含研究标识符（例如，Anthony et al, 2019）\n倒数第二列标记为“Overall”，包含总体偏倚风险判断\n最后一列标记为“Weight”，包含研究精确度的一些度量，例如 Meta 分析中分配给每个研究的权重，或者如果没有进行 Meta 分析，则包含每个研究的样本量。有关更多详细信息，请参见第 @ref(fem) 章。\n所有其他列包含特定领域的偏倚风险评估结果。\n\n为了详细说明上述指南，以具有 5 个领域的 ROB2 工具为例。 {robvis} 期望的最终数据集将具有 8 列：\n\n第 1 列：研究标识符\n第 2-6 列：每列一个 RoB2 领域\n第 7 列：总体偏倚风险判断\n第 8 列：权重。\n\n在 Excel 中，此偏倚风险汇总表如下所示：\n\n\n\n\n\n\n\n\n\n\n\n\n列名\n\n\n对于四个工具模板中的三个（ROB2、ROBINS-I、QUADAS-2），包含领域级别判断的列的名称并不重要，因为 robvis 中的模板将使用正确的工具特定标题重新标记每个领域。\n\n\n\n将您在 Excel 中创建的表格以逗号分隔文件（例如“robdata.csv”）保存到工作目录后，您可以使用以下命令以编程方式将文件读取到 R 中，或者通过第 @ref(data-prep-R) 章中描述的“导入助手”方法。\n\nmy_rob_data &lt;- read.csv(\"robdata.csv\", header = TRUE)\n\n\n\n\n\n\n{robvis} 通过使用您提供的数据来填充特定于您使用的偏倚风险评估工具的模板图来生成偏倚风险图。目前，{robvis} 包含以下三个工具的模板：\n\nROB2，用于随机对照试验的新的 Cochrane 偏倚风险工具；\nROBINS-I，非随机研究中的偏倚风险 - 干预工具；\nQUADAS-2，诊断准确性研究的质量和适用性，第 2 版。\n\n{robvis} 还包含一个特殊的通用模板，标记为 ROB1。它设计用于原始 Cochrane 随机对照试验偏倚风险工具，也可用于可视化使用上面列表中未包含的其他基于领域的工具进行的评估结果。有关使用此模板时所需其他步骤的更多信息，请参见第 @ref(rob1-template) 章。\n\n\n\n\n\n{robvis} 包包含上面概述的每个模板的示例数据集。这些存储在以下对象中：\n\ndata_rob2：ROB2 工具的示例数据\ndata_robins：ROBINS-I 工具的示例数据\ndata_quadas：QUADAS-2 工具的示例数据\ndata_rob1：RoB-1 工具的示例数据。\n\n您可以使用 glimpse 函数探索这些数据集（参见第 @ref(class-conversion) 章）。例如，使用 library(robvis) 加载包后，可以通过运行以下命令查看 ROBINS-I 示例数据集：\n\nglimpse(data_robins)\n\n\n\nRows: 12\nColumns: 10\n$ Study   &lt;fct&gt; Study 1, Study 2, Study 3, Study 4, Study 5, Study 6, Study 7,…\n$ D1      &lt;fct&gt; Critical, Moderate, Moderate, Low, Serious, Critical, Critical…\n$ D2      &lt;fct&gt; Low, Low, Low, Low, Serious, Serious, Moderate, Moderate, Low,…\n$ D3      &lt;fct&gt; Critical, Low, Moderate, Serious, Low, Moderate, Moderate, Low…\n$ D4      &lt;fct&gt; Critical, Critical, Critical, Critical, Low, Critical, Serious…\n$ D5      &lt;fct&gt; Low, Low, Critical, Moderate, Moderate, Critical, Critical, Lo…\n$ D6      &lt;fct&gt; Low, Moderate, Low, Low, Low, Moderate, Serious, Low, Serious,…\n$ D7      &lt;fct&gt; Serious, Low, Serious, Critical, Moderate, Serious, Serious, C…\n$ Overall &lt;fct&gt; Critical, Low, Serious, Low, Serious, Serious, Moderate, Moder…\n$ Weight  &lt;dbl&gt; 33.3333333, 33.3333333, 0.1428571, 9.0909091, 12.5000000, 25.0…\n\n\n这些示例数据集用于创建本指南其余部分中介绍的图。",
    "crumbs": [
      "网站首页",
      "偏倚风险图"
    ]
  },
  {
    "objectID": "17-risk-of-bias-plots.html#汇总图",
    "href": "17-risk-of-bias-plots.html#汇总图",
    "title": "偏倚风险图",
    "section": "",
    "text": "一旦我们成功地将偏倚风险汇总表导入到 R 中，创建偏倚风险图就非常简单了。\n首先，通过运行以下代码，使用 ROB2 示例数据集 (data_rob2) 创建一个简单的加权汇总条形图：\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nrob_summary 函数具有以下参数：\n\ndata。包含汇总（领域）级别偏倚风险评估的数据框，其中第一列包含研究详细信息，第二列包含评估的第一个领域，最后一列包含分配给每个研究的权重。该函数假定数据包括一列用于总体偏倚风险。例如，ROB2.0 数据集将具有 8 列（1 列用于研究详细信息，5 列用于领域级别判断，1 列用于总体判断，1 列用于权重，按该顺序）。\ntool。使用的偏倚风险评估工具。目前支持 RoB2.0 (\"ROB2\"), \"ROBINS-I\" 和 \"QUADAS-2\"。\noverall。一个在图中包含总体偏倚风险的附加条的选项。默认为 FALSE。\nweighted。一个指定是否应在条形图中使用权重的选项。默认值为 TRUE，与当前的 Cochrane 协作指南一致。\ncolour。一个指定图的配色方案的参数。默认值为 \"cochrane\"，它使用无处不在的 Cochrane 颜色，而一个预设的适合色盲友好的调色板也可用 (colour = \"colourblind\")。\nquiet。一个以静默方式生成图而不显示它的逻辑选项。默认值为 FALSE。\n\n下面描述了每个参数的功能示例。\n\n\n\n\n一个定义您要使用的工具模板的参数。在上面的示例中，使用了 ROB2 模板。下面演示了另外两个主要模板 - ROBINS-I 和 QUADAS-2 模板：\n\nrob_summary(data = data_robins, \n            tool = \"ROBINS-I\")\n\n\n\n\n\n\n\n\n\nrob_summary(data = data_quadas, \n            tool = \"QUADAS-2\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n默认情况下，图中不包含表示总体偏倚风险判断的附加条。如果您想包含它，请设置 overall = TRUE。例如：\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\", \n            overall = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n默认情况下，条形图由研究精确度的某种度量加权，因此条形图显示的是信息的比例，而不是处于特定偏倚风险的研究的比例。此方法符合 Cochrane 手册。\n您可以通过设置 weighted = FALSE 来关闭此选项，以创建未加权条形图。例如，比较以下两个图：\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\")\n\n\n\n\n\n\n\n\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\",\n            weighted = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n英式英语拼写\n请注意 colour 的非美式英语拼写！\n\n\n两个绘图函数的 colour 参数允许用户从两个预定义的配色方案 \"cochrane\"（默认）或 \"colourblind\" 中选择，或者通过提供 十六进制代码 向量来定义自己的调色板。例如，要使用预定义的 \"colourblind\" 调色板：\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\", \n            colour = \"colourblind\")\n\n\n\n\n\n\n\n\n并定义您自己的配色方案：\n\nrob_summary(data = data_rob2, \n            tool = \"ROB2\", \n            colour = c(\"#f442c8\",\"#bef441\",\"#000000\"))\n\n\n\n\n\n\n\n\n在定义您自己的配色方案时，您必须确保离散判断的数量（例如“低”、“中等”、“高”、“严重”）和指定的颜色数量相同。此外，颜色必须按偏倚风险升序指定（例如“低”到“严重”），第一个十六进制代码对应于“低”偏倚风险。",
    "crumbs": [
      "网站首页",
      "偏倚风险图"
    ]
  },
  {
    "objectID": "17-risk-of-bias-plots.html#交通灯图",
    "href": "17-risk-of-bias-plots.html#交通灯图",
    "title": "偏倚风险图",
    "section": "",
    "text": "通常，研究人员希望展示每个评估的研究的每个领域的偏倚风险。生成的图通常称为交通灯图，可以使用 {robvis} 通过 rob_traffic_light 函数生成。\n\n\n\n\n首先，通过运行以下代码，使用 ROB2 示例数据集 (data_rob2) 创建交通灯图：\n\nrob_traffic_light(data = data_rob2, \n                  tool = \"ROB2\")\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 54 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrob_summary 函数具有以下参数：\n\ndata。包含汇总（领域）级别偏倚风险评估的数据框，其中第一列包含研究详细信息，第二列包含评估的第一个领域，最后一列包含分配给每个研究的权重。该函数假定数据包括一列用于总体偏倚风险。例如，ROB2.0 数据集将具有 8 列（1 列用于研究详细信息，5 列用于领域级别判断，1 列用于总体判断，1 列用于权重，按该顺序）。\ntool。使用的偏倚风险评估工具。目前支持 RoB2.0 (\"ROB2\"), \"ROBINS-I\" 和 \"QUADAS-2\"。\ncolour。一个指定图的配色方案的参数。默认值为 \"cochrane\"，它使用无处不在的 Cochrane 颜色，而一个预设的适合色盲友好的调色板也可用 (\"colourblind\")。\npsize。一个更改“交通灯”点大小的选项。默认值为 20。\nquiet。一个以静默方式生成图而不显示它的逻辑选项。默认值为 FALSE。\n\n\n\n\n\n一个定义您要使用的工具模板的参数。演示了 ROB2 模板，下面显示了另外两个主要模板 - ROBINS-I 和 QUADAS-2 模板：\n\nrob_traffic_light(data = data_robins, \n                  tool = \"ROBINS-I\")\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 96 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\nrob_traffic_light(data = data_quadas, \n                  tool = \"QUADAS-2\")\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 60 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n英式英语拼写\n请注意 colour 的非美式英语拼写！\n\n\n两个绘图函数的 colour 参数允许用户从两个预定义的配色方案 \"cochrane\"（默认）或 \"colourblind\" 中选择，或者通过提供十六进制代码向量来定义自己的调色板。\n例如，要使用预定义的 \"colourblind\" 调色板：\n\nrob_traffic_light(data = data_rob2, \n                  tool = \"ROB2\", \n                  colour = \"colourblind\")\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 54 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n并定义您自己的配色方案：\n\nrob_traffic_light(data = data_rob2, \n                  tool = \"ROB2\", \n                  colour = c(\"#f442c8\",\"#bef441\",\"#000000\"))\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 54 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n在定义您自己的配色方案时，您必须确保离散判断的数量（例如“低”、“中等”、“高”、“严重”）和指定的颜色数量相同。此外，颜色必须按偏倚风险升序指定（例如“低”到“严重”），第一个十六进制代码对应于“低”偏倚风险。\n\n\n\n\n\n有时，当执行了大量的偏倚风险评估时，生成的交通灯图可能太长而无法使用。用户可以通过将 rob_traffic_light 函数的 psize 参数修改为较小的数字（默认值为 20）来解决此问题。例如：\n\n# 创建更大的数据集（18 个研究）\nnew_rob2_data &lt;- rbind(data_rob2, data_rob2)\nnew_rob2_data$Study &lt;- paste(\"Study\", seq(1:length(new_rob2_data$Study))) \n\n# 绘制更大的数据集，将 psize 参数从 20 减小到 8\nrob_traffic_light(data = new_rob2_data, \n                  tool = \"ROB2\", \n                  psize = 8)\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 108 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.",
    "crumbs": [
      "网站首页",
      "偏倚风险图"
    ]
  },
  {
    "objectID": "17-risk-of-bias-plots.html#rob1-template",
    "href": "17-risk-of-bias-plots.html#rob1-template",
    "title": "偏倚风险图",
    "section": "",
    "text": "此模板在图中包含的领域中提供了更大的灵活性。它可以处理任意数量的领域（cf. 其他具有固定数量领域的工具模板），并使用用户定义的列标题作为生成的图中的领域标题。\n\n\n\n\n\n“ROB1”模板 (tool = \"ROB1\") 可以处理变化的列数。这最初是为 ROB1 评估工具设计的，该工具经常添加或删除领域。虽然此模板可用于呈现使用其他工具（ROB2、QUADAS-2、ROBINS-I）的调整版本进行的评估结果，但我们强烈建议作者不要这样做。使用其他已发布工具的作者应使用先前章节中介绍的更严格的模板，以确保他们符合指南。\n\n\n\n\n\n对于前面章节中列出的其他工具，包含领域级别偏倚风险判断的列的名称并不重要。例如，它们通常命名为 D1、D2、D3 等。但是，使用 \"ROB1\" 模板时并非如此。\n比较 data_rob2 和 data_rob1 的列标题（此处水平呈现，以便于比较）：\n\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\nComparison of column names in the `data_rob2` (left) and `data_rob1` (right) datasets.\n\n\nNo.\ndata_rob2\ndata_rob1\n\n\n\n\n1\nStudy\nStudy\n\n\n2\nD1\nRandom.sequence.generation.\n\n\n3\nD2\nAllocation.concealment.\n\n\n4\nD3\nBlinding.of.participants.and.personnel.\n\n\n5\nD4\nBlinding.of.outcome.assessment\n\n\n6\nD5\nIncomplete.outcome.data\n\n\n7\nOverall\nSelective.reporting.\n\n\n8\nWeight\nOther.sources.of.bias.\n\n\n9\n.\nOverall\n\n\n10\n.\nWeight\n\n\n\n\n\n\n\n\nROB2 示例数据集中的领域列（第 2-6 列）已被赋予任意名称 D1 - D5，因为它们将被该工具覆盖，以对应于 ROB2 指南给出的正确的领域标题。\n相比之下，ROB1 示例数据集中的领域列（第 2-8 列）已正确标记，因为这些将在 rob_summary 和 rob_traffic_light 生成的图中使用。\n例如，假设我们将“Random.sequence.generation”列的名称更改为“This is a test”。在 rob_summary 图中，第一个条的标题已更改，而在 rob_traffic_light 图中，字幕已更新以反映此更改。\n\n# 创建 data_rob1 数据集的副本\nnew_rob1_data &lt;- data_rob1\n\n# 更改第一个领域的列标题\ncolnames(new_rob1_data)[2] &lt;- \"This is a test\"\n\n# 创建汇总条形图\nrob_summary(data = new_rob1_data, tool = \"ROB1\")\n\n\n\n\n\n\n\n\n\n# 创建交通灯图\nrob_traffic_light(data = new_rob1_data, \n                  tool = \"ROB1\")\n\nWarning in ggplot2::geom_point(shape = 1, colour = \"black\", size = psize, : All aesthetics have length 1, but the data has 72 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.",
    "crumbs": [
      "网站首页",
      "偏倚风险图"
    ]
  },
  {
    "objectID": "17-risk-of-bias-plots.html#自定义和保存",
    "href": "17-risk-of-bias-plots.html#自定义和保存",
    "title": "偏倚风险图",
    "section": "",
    "text": "{robvis} 函数（rob_summary 和 rob_traffic_light）都会生成一个 ggplot 对象，因此可以使用 {ggplot2} 包中的函数进行自定义和保存。使用以下代码加载此包：\n\nlibrary(ggplot2)\n\n\n\n\n\n\n您可以使用 {ggplot2} 函数对您的图进行一系列后期制作修改。一个有用的示例是向图中添加标题：\n\n# 确保您已安装并加载 ggplot2 包\nrob_summary(data_rob2, \"ROB2\") +\n  ggtitle(\"您的自定义标题\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n为了保存偏倚风险图，我们首先使用 &lt;- 运算符将其分配给一个对象，然后使用 {ggplot2} 包的 ggsave 函数保存它。\n保存汇总条形图时，我们建议使用以下代码，其中包含默认的高度和宽度值。\n\n# 创建您的图，并将其分配给一个对象\nrob_barplot &lt;- rob_summary(data_rob2, \"ROB2\")\n\n# 保存您的图\nggsave(plot = rob_barplot,        # 要保存的图对象\n       filename = \"robplot2.png\", # 目标文件\n       width = 8,                 # 图像宽度（推荐）\n       height = 2.41,             # 图像高度（推荐）\n       dpi = 1000)                # 图像分辨率\n\n保存交通灯图时，方法相同。但是，width 和 height 参数没有推荐值，因为这些参数的最佳值会因图而异，因为包含的研究的数量和名称会发生变化。\n\n\n\n\n\n只需更改文件名的扩展名（例如，从“.png”到“.pdf”），就可以使用上面概述的函数以多种格式保存图。可接受的格式包括 .png、.pdf、.tiff 和 .svg1。\n例如，要将上面创建的条形图 (rob_barplot) 保存为 PDF：\n\n# 保存您的图\nggsave(plot = rob_barplot,                  \n       filename = \"robplot2.pdf\", # 文件扩展名现在为“.pdf”\n       width = 8,                           \n       height = 2.41,                       \n       dpi = 1000)",
    "crumbs": [
      "网站首页",
      "偏倚风险图"
    ]
  },
  {
    "objectID": "17-risk-of-bias-plots.html#web-app",
    "href": "17-risk-of-bias-plots.html#web-app",
    "title": "偏倚风险图",
    "section": "",
    "text": "为了使用户能够快速探索 robvis 的功能，我们创建了一个 Web 应用程序，该应用程序提供了 {robvis} 包的图形界面。\nWeb 应用程序可在此处获得：here。下面简要介绍一下指导性演练。\n\n\n\n\n\n\n\n\n\n\n\n\n\n该页面提供了先前章节中指导的简洁版本，特别是与设置数据集有关的指导。更重要的是，用户可以将每个工具的示例数据集下载为 CSV 文件，并使用这些数据集与应用程序进行交互并探索其功能。\n\n\n\n\n\n单击第二个选项卡会将您带到下面显示的屏幕。\n\n\n\n\n\n\n\n\n\n此菜单充当 rob_traffic_light 函数的图形界面：\n\n通过单击“Browse…”并导航到存储 CSV 文件的位置来上传您的偏倚风险汇总表。\n使用下拉框选择用于执行偏倚风险评估的工具。\n\n基本的交通灯图现在应出现在窗口的右侧。您可以使用以下选项自定义图：\n\n选择您要使用的配色方案（“Cochrane”或“色盲友好”）\n修改点大小（当您希望在单个交通灯图上绘制大量研究时很有用）\n修改文本大小。\n\n对图满意后，您可以通过选择所需的格式（.png、.jpg、.tiff、.eps）并单击“Download plot”按钮来下载它。请注意，如果您不首先选择格式，您将收到下载错误。\n\n\n\n\n\n单击第三个选项卡会将您带到下面显示的屏幕。\n\n\n\n\n\n\n\n\n\n此菜单充当 rob_summary 函数的图形界面：\n\n通过单击“Browse…”并导航到存储 CSV 文件的位置来上传您的偏倚风险汇总表。\n使用下拉框选择用于执行偏倚风险评估的工具。\n\n基本的加权汇总条形图现在应出现在窗口的右侧。\n您可以使用以下选项自定义图：\n\n选择在创建图时是否使用权重\n包括表示总体偏倚风险判断分布的附加条\n选择您要使用的配色方案（“Cochrane”或“色盲友好”）\n\n与交通灯图选项卡一样，您可以通过选择所需的格式并单击“Download plot”按钮来下载您的图。\n\\[\\tag*{$\\blacksquare$}\\]",
    "crumbs": [
      "网站首页",
      "偏倚风险图"
    ]
  },
  {
    "objectID": "17-risk-of-bias-plots.html#footnotes",
    "href": "17-risk-of-bias-plots.html#footnotes",
    "title": "偏倚风险图",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n此格式要求您安装并加载 {svglite} 包：install.packages(\"svglite\"); library(svglite)。↩︎",
    "crumbs": [
      "网站首页",
      "偏倚风险图"
    ]
  },
  {
    "objectID": "15-bayesianma.html",
    "href": "15-bayesianma.html",
    "title": "贝叶斯元分析",
    "section": "",
    "text": "在 前面的章节中，我们深入探讨了元分析的一些更为复杂的扩展，例如“多层”模型（第 @ref(multilevel-ma) 章），元分析结构方程建模（第 @ref(sem) 章）和网络元分析（第 @ref(netwma) 章）。现在，我们将后退一步，再次回顾“传统”元分析——但这次是从另一个角度。在本章中，我们将讨论贝叶斯元分析。\n \n在上一章关于网络元分析中，我们已经介绍了一个贝叶斯模型。在那里，我们讨论了贝叶斯统计背后的主要思想，包括贝叶斯定理和先验分布的概念（参见第 @ref(bayesian-inference) 章）。在本章中，我们将在这些知识的基础上，尝试更彻底地理解进行元分析的“贝叶斯方式”。例如，当我们建立贝叶斯网络元分析模型时，{gemtc} 程序包会自动为我们指定先验。在这里，我们将自己完成这项工作。\n虽然其背景稍微复杂一些，但我们将看到，贝叶斯元分析本质上旨在完成与任何“传统”元分析相同的事情：它将观察到的效应量汇集到一个总体（真实）效应中。但是，与频率学派方法相比，使用贝叶斯模型还具有一些实际优势。这使得学习如何使用 R 实现此类模型是有价值的。\n\n\n\n\n\n为了执行贝叶斯元分析，我们采用所谓的贝叶斯分层模型 [@rover2017bayesian; @higgins2009re]。我们已经在网络元分析章节（第 @ref(bayesian-net-ma-model) 章）中简要介绍了这种类型的模型。\n在第 @ref(multilevel-ma) 章中，我们了解到每个元分析模型都具有固有的“多层”结构，因此也是分层结构。在第一层，我们有各个参与者。此级别的数据通常以每个研究 \\(k\\) 的计算效应量 \\(\\hat\\theta_k\\) 的形式到达我们手中。我们假设参与者嵌套在第二层的研究中，并且元分析中不同研究的真实效应量 \\(\\theta_k\\) 遵循其自身分布。这种真实效应的分布具有均值 \\(\\mu\\)（我们想要估计的汇集“真实”效应）和方差 \\(\\tau^2\\)，表示研究间的异质性。\n让我们尝试将此形式化。在第一层，我们假设研究 \\(k\\) 中报告的观察效应量 \\(\\hat\\theta_k\\) 是该研究中“真实”效应 \\(\\theta_k\\) 的估计值。由于抽样误差 \\(\\epsilon_k\\)，观察到的效应 \\(\\hat\\theta_k\\) 偏离 \\(\\theta_k\\)。这是因为我们假设 \\(\\hat\\theta_k\\) 是从 \\(k\\) 的基础人群中抽取（采样）的。该人群可以被视为具有均值 \\(\\theta_k\\)（研究的“真实”效应）和方差 \\(\\sigma^2\\) 的分布。\n在第二步中，我们假设真实效应量 \\(\\theta_k\\) 本身只是真实效应量总体分布的样本。此分布的均值 \\(\\mu\\) 是我们想要估计的汇集效应量。研究特定的真实效应 \\(\\theta_k\\) 偏离 \\(\\mu\\)，因为总体分布也具有方差 \\(\\tau^2\\)，表示研究间的异质性。综上所述，这给出了以下两个方程：\n\\[\\begin{align}\n\\hat\\theta_k &\\sim \\mathcal{N}(\\theta_k,\\sigma_k^2) \\notag \\\\\n\\theta_k &\\sim \\mathcal{N}(\\mu,\\tau^2) (\\#eq:by1)\n\\end{align}\\]\n这里，我们使用 \\(\\mathcal{N}\\) 来表示左侧的参数是从正态分布中采样的。有些人可能会争辩说，对于第二个方程来说，这是一个不必要的严格假设 [@higgins2009re]，但如此处所示的公式是使用最多的公式。如前所述，固定效应模型只是该模型的一个特例，在该模型中，我们假设 \\(\\tau^2 = 0\\)，这意味着不存在研究间的异质性，并且所有研究共享一个单一的真实效应量（即对于所有研究 \\(k\\)：\\(\\theta_k = \\mu\\)）。\n我们还可以使用边际形式简化此公式：\n\\[\\begin{equation}\n\\hat\\theta_k  \\sim \\mathcal{N}(\\mu,\\sigma_k^2 + \\tau^2)\n(\\#eq:by2)\n\\end{equation}\\]\n您可能已经发现这些公式看起来很像我们在讨论随机效应（第 @ref(rem) 章）和三层元分析（第 @ref(multilevel-nature) 章）模型时定义的公式。的确，这种公式化并没有什么特别的“贝叶斯”之处。但是，当我们添加以下公式时，情况会发生变化 [@williams2018bayesian]：\n\\[\\begin{align}\n(\\mu, \\tau^2) &\\sim p(.) \\notag \\\\\n\\tau^2 &&gt; 0 (\\#eq:by3)\n\\end{align}\\]\n\n第一行尤为重要。它定义了参数 \\(\\mu\\) 和 \\(\\tau^2\\) 的先验分布。这使我们能够先验地指定我们认为真实汇集效应量 \\(\\mu\\) 和研究间异质性 \\(\\tau^2\\) 可能看起来如何，以及我们对此有多确定。第二个方程添加了研究间异质性方差必须大于零的约束。但是，此公式未指定用于 \\(\\mu\\) 和 \\(\\tau^2\\) 的先验分布的确切类型。它仅告诉我们假设了某些先验分布。稍后，我们将更详细地介绍贝叶斯元分析模型合理的特定先验。\n \n在关于网络元分析的章节中，我们已经介绍了贝叶斯方法估计模型参数的方法。概括地说，这涉及使用基于 马尔可夫链蒙特卡洛 的抽样程序，例如 吉布斯抽样。在我们将在本章中使用的 {brms} 程序包中，使用了所谓的 无 U 形转弯 抽样 [NUTS, @hoffman2014no]1。\n \n在前面的章节中，我们主要使用了 {meta} 和 {metafor} 程序包。这些程序包允许基于非贝叶斯或 频率学派 框架进行元分析。因此，您可能想知道，鉴于我们已经可以使用“传统”方法求助于如此强大的工具，为什么还要开始使用贝叶斯方法。原因是贝叶斯元分析具有一些独特的优势 [@williams2018bayesian; @mcneish2016using; @chung2013nondegenerate]：\n\n贝叶斯方法允许直接对我们对 \\(\\tau^2\\) 的估计中的不确定性进行建模。它们在估计汇集效应方面也可能更出色，尤其是在包含的研究数量较少时（这在实践中非常常见）。\n贝叶斯方法为 \\(\\mu\\) 和 \\(\\tau^2\\) 生成完整的后验分布。这允许计算 \\(\\mu\\) 或 \\(\\tau^2\\) 小于或大于某个指定值的确切概率。这与频率学派方法形成对比，在频率学派方法中，我们仅计算置信区间。但是，（95%）置信区间仅说明，如果数据抽样重复多次，人口参数（例如 \\(\\mu\\) 或 \\(\\tau^2\\)）的真实值将在 95% 的样本中落入置信区间的范围内。它们没有告诉我们真实参数位于两个指定值之间的概率。\n贝叶斯方法允许我们在计算元分析时整合先验知识和假设。\n\n\n\n\n\n\n之前，我们形式化了可用于在贝叶斯元分析中汇集效应的分层模型。但是，要运行这样的模型，我们必须指定 \\(\\mu\\) 和 \\(\\tau^2\\) 的先验分布。尤其是在研究数量较少时，先验会对结果产生相当大的影响，因此我们应明智地选择它们。\n \n通常，一个好的方法是使用弱信息先验 [@williams2018bayesian]。弱信息先验可以与无信息先验形成对比。无信息先验是先验分布的最简单形式。它们通常基于均匀分布，并用于表示所有值都同样可信。\n另一方面，弱信息先验稍微复杂一些。它们依赖于表示我们微弱相信某些值比其他值更可信的分布。但是，它们仍然没有对要从我们的数据中估计的参数的值做出任何具体陈述。\n\n从直觉上讲，这很有意义。例如，在许多元分析中，假设真实效应位于 SMD = -2.0 和 2.0 之间的某个位置似乎是合理的，但不太可能是 SMD = 50。基于此理由，我们的 \\(\\mu\\) 先验的一个很好的起点可能是均值为 0 且方差为 1 的正态分布。这意味着我们授予大约 95% 的先验概率，即真实汇集效应量 \\(\\mu\\) 位于 −2.0 和 2.0 之间：\n\\[\\begin{equation}\n\\mu \\sim \\mathcal{N}(0,1)\n(\\#eq:by4)\n\\end{equation}\\]\n我们必须指定的下一个先验是 \\(\\tau^2\\) 的先验。这有点困难，因为我们知道 \\(\\tau^2\\) 应始终为非负数，但可以（接近）零。在这种情况下，推荐的分布，并且通常用于方差（例如 \\(\\tau^2\\)）的分布是 半柯西 先验。半柯西分布是柯西分布的一个特例，它仅为分布的“一半”（即正侧）定义2。\n半柯西分布由两个参数控制。第一个是位置参数 \\(x_0\\)，它指定分布的峰值。第二个是 \\(s\\)，即比例参数。它控制分布的重尾程度（即它“扩展”到更高值的程度）。半柯西分布用 \\(\\mathcal{HC}(x_0,s)\\) 表示。\n下图可视化了 \\(s\\) 的不同值的半柯西分布，其中 \\(x_0\\) 的值固定为 0。\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n\n\n\n\n半柯西分布通常具有相当重的尾部，这使其特别适合用作 \\(\\tau\\) 的先验分布。重尾确保我们仍然给予 \\(\\tau\\) 的非常高的值一些概率，同时假设较低的值更可能。\n在许多元分析中，\\(\\tau\\)（\\(\\tau^2\\) 的平方根）位于 0.3 附近，或者至少在同一范围内。要指定半柯西先验，我们可以因此使用 \\(s=\\) 0.3。这确保小于 \\(\\tau=\\) 0.3 的值具有 50% 的概率 [@williams2018bayesian]。我们可以使用 {extraDistr} 程序包 [@extradistr] 的 phcauchy 函数中实现的半柯西分布函数来确认这一点。\n\n\nlibrary(extraDistr)\nphcauchy(0.3, sigma = 0.3)\n\n[1] 0.5\n\n\n但是，这已经是关于 \\(\\tau\\) 的真实值的一个非常具体的假设。一种更保守的方法（我们将在我们的实践示例中遵循）是将 \\(s\\) 设置为 0.5；这使分布更平坦。通常，建议始终使用不同的先验规范进行敏感性分析，以检查它们是否会显着影响结果。使用 \\(s=\\) 0.5 作为半柯西分布的参数，我们可以像这样写下我们的 \\(\\tau\\) 先验：\n\\[\\begin{equation}\n\\tau \\sim \\mathcal{HC}(0,0.5)\n(\\#eq:by5)\n\\end{equation}\\]\n我们现在可以将分层模型的公式和我们的先验规范放在一起。这导致了我们可以用于贝叶斯元分析的完整模型：\n\\[\\begin{align}\n\\hat\\theta_k &\\sim \\mathcal{N}(\\theta_k,\\sigma_k^2) \\notag \\\\\n\\theta_k &\\sim \\mathcal{N}(\\mu,\\tau^2) \\notag \\\\\n\\mu &\\sim \\mathcal{N}(0,1) \\notag \\\\\n\\tau &\\sim \\mathcal{HC}(0,0.5) (\\#eq:by5)\n\\end{align}\\]\n\n\n\n\n\n \n现在我们已经定义了元分析的贝叶斯模型，现在是在 R 中实现它的时间了。在这里，我们使用 {brms} 程序包 [@burknerJSS; @burkner2017advanced] 来拟合我们的模型。{brms} 程序包是一个非常通用且强大的工具，用于拟合贝叶斯回归模型。它可以用于广泛的应用，包括多层（混合效应）模型、广义线性模型、多元模型和广义可加模型，仅举几例。这些模型中的大多数都需要个人级别的数据，但 {brms} 也可以用于元分析，在元分析中，我们处理（加权）研究级别的数据3。\n在我们开始拟合模型之前，我们首先必须安装并加载 {brms} 程序包。\n\nlibrary(brms)\n\n\n\n\n\n在我们的实践示例中，我们再次使用 ThirdWave 数据集，该数据集包含来自一项元分析的信息，该元分析调查了大学生中“第三波”心理疗法的效果（第 @ref(pre-calculated-es) 章）。在我们拟合模型之前，让我们首先指定总体效应量 \\(\\mu\\) 和研究间异质性 \\(\\tau\\) 的先验分布。之前，我们定义了 \\(\\mu \\sim \\mathcal{N}(0,1)\\) 和 \\(\\tau \\sim \\mathcal{HC}(0,0.5)\\)。\n我们可以使用 prior 函数来指定分布。该函数接受两个参数。在第一个参数中，我们指定要为先验假设的分布，包括分布参数。在第二个参数中，我们必须定义先验的 class。对于 \\(\\mu\\)，合适的类是 Intercept，因为它是一个固定的总体级别效应。对于 \\(\\tau\\)，类是 sd，因为它是一个方差（或者，更准确地说，是一个标准差）。我们可以使用 prior 函数定义这两个先验，然后将它们连接起来，并将结果对象另存为 priors。\n\npriors &lt;- c(prior(normal(0,1), class = Intercept),\n            prior(cauchy(0,0.5), class = sd))\n\n现在，我们可以继续并拟合模型。为此，我们使用 {brms} 中的 brm 函数。该函数有很多参数，但只有少数与我们相关。\n在 formula 参数中，指定了模型的公式。{brms} 程序包使用回归公式表示法，其中一个结果（在我们的例子中，是观察到的效应量）y 由一个或多个预测变量 x 预测。波浪号 (~) 用于指定存在预测关系：y ~ x。\n元分析有点特殊，因为我们没有预测效应量的变量（除非我们执行元回归）。这意味着 x 必须替换为 1，表示仅截距模型。此外，我们不能简单地按原样使用 y 中每个研究的效应量。我们还必须给具有更高精度（即样本量）的研究更大的权重。这可以通过使用 y|se(se_y) 而不是仅使用 y 来完成，其中 se(se_y) 部分代表我们数据集中每个效应量 y 的标准误差。\n如果我们想使用随机效应模型，最后一步是将随机效应项 (1|study) 添加到公式的右侧。这指定了 y 中的效应量被假定为嵌套在研究中，这些研究的真实效应本身是从真实效应的总体分布中随机抽取的。如果我们想使用固定效应模型，我们可以简单地省略此项。因此，随机效应模型的通用完整公式如下所示：y|se(se_y) ~ 1 + (1|random)。要了解有关 brm 模型中公式设置的更多信息，可以在控制台中键入 ?brmsformula 以打开文档。\n其他参数相当简单。在 prior 中，我们指定要为模型定义的先验。在我们的示例中，我们可以简单地插入我们之前创建的 priors 对象。iter 参数指定 MCMC 算法的迭代次数。您的模型越复杂，此数字就应该越高。但是，更多的迭代也意味着该函数将花费更长的时间才能完成。最后，我们还必须指定 data，我们在其中简单地提供数据集的名称。\n我们将拟合的贝叶斯元分析模型以名称 m.brm 保存。代码如下所示：\n\nm.brm &lt;- brm(TE|se(seTE) ~ 1 + (1|Author),\n             data = ThirdWave,\n             prior = priors,\n             iter = 4000)\n\n请注意，与我们之前介绍的标准元分析技术相比，贝叶斯方法的计算成本要高得多。因此，采样可能需要几分钟才能完成。\n\n\n\n\n\n\n在我们开始分析结果之前，我们必须确保模型已收敛（即 MCMC 算法找到了最佳解决方案）。如果不是这种情况，则参数不可信，不应解释。非收敛在贝叶斯模型中经常发生，通常可以通过使用更多迭代次数 (iter) 重新运行模型来解决。为了评估我们模型的收敛性和整体有效性，我们应该始终做两件事。首先，检查参数估计的 \\(\\hat{R}\\) 值，其次，进行后验预测检查。\n\\(\\hat{R}\\) 值表示我们在讨论贝叶斯网络元分析时已经介绍过的潜在尺度缩减因子 (PSRF)（第 @ref(bayesian-model-convergence) 章）。我们估计的 \\(\\hat{R}\\) 值应小于 1.01。要检查这一点，我们可以生成 m.brm 对象的 summary。\n\nsummary(m.brm)\n\n## Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: TE | se(seTE) ~ 1 + (1 | Author) \n##    Data: ThirdWave (Number of observations: 18) \n## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n##          total post-warmup samples = 8000\n## \n## Group-Level Effects: \n## ~Author (Number of levels: 18) \n##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS \n## sd(Intercept)     0.29      0.10     0.11     0.51 1.00     2086   \n## \n## Population-Level Effects: \n##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS \n## Intercept     0.57      0.09     0.39     0.76 1.00     3660    \n## \n##\n## [...]\n## \n## Samples were drawn using sampling(NUTS). For each parameter, \n## Bulk_ESS and Tail_ESS are effective sample size measures, \n## and Rhat is the potential scale reduction factor on split \n## chains (at convergence, Rhat = 1).\n正如我们所看到的，两个参数的 Rhat 值均为 1，表示收敛。这意味着可以解释结果。\n另一方面，在后验预测检查中，通过从后验预测分布中随机抽取来模拟数据，然后将其与观察到的数据进行比较。如果模型已收敛并且可以很好地捕获数据，我们可以预期复制的密度与观察到的数据的密度大致相似。可以使用 pp_check 函数的输出来轻松检查这一点。\n\npp_check(m.brm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n我们可以首先查看摘要输出中的 Group-Level Effects 来开始解释结果。本节保留给我们在公式中定义的随机效应。由于我们拟合了一个随机效应元分析模型，因此变量 ~Author（表示各个研究）已使用随机截距进行建模。正如我们之前描述的，这代表了我们对级别 2 的假设，即每个研究都有其自己的“真实”效应量，这些效应量是从真实效应的总体分布中抽取的。我们还看到我们的组级别效应有 18 个级别，与我们数据中的 \\(K=\\) 18 个研究相对应。\n研究间异质性的估计值 sd(Intercept) 为 \\(\\tau=\\) 0.29，因此与我们在设置先验时最初的“最佳猜测”非常相似。使用 ranef 函数，我们还可以提取每个研究的“真实”效应量与汇集效应的估计偏差：\n\nranef(m.brm)\n\n## $Author\n## , , Intercept\n##                           Estimate Est.Error         Q2.5       Q97.5\n## Call et al.             0.06836636 0.1991649 -0.327463365  0.47663987\n## Cavanagh et al.        -0.14151644 0.1767123 -0.510165576  0.18799272\n## DanitzOrsillo           0.48091338 0.2829719 -0.003425284  1.08636421\n## de Vibe et al.         -0.31923470 0.1454819 -0.612269461 -0.03795683\n## Frazier et al.         -0.11388029 0.1497128 -0.417029387  0.17085917\n## [...]\n我们可以解释的输出的下一部分是 Population-Level Effects。本节代表了我们建模的“固定”人口参数。在我们的例子中，这是 \\(\\mu\\)，即我们元分析的总体效应量。\n\n在输出中，我们看到估计值为 0.57 的（偏差校正的）SMD，其中 95% 的可信区间范围为 95%CrI：0.39−0.76。这表明在此元分析中研究的干预措施具有中等大小的总体效果。\n因为这是一个贝叶斯模型，所以我们在这里没有找到任何 \\(p\\) 值。但我们的示例应该强调，即使不必诉诸经典显着性检验，我们也可以做出合理的推断。在贝叶斯中，但在频率学派元分析中，我们可以做的一件很棒的事情是概率性地对我们要估计的参数进行建模。贝叶斯模型不仅估计感兴趣的参数，还估计 \\(\\tau^2\\) 和 \\(\\mu\\) 的整个后验分布，我们可以很容易地访问它们。我们只需要使用 posterior_samples 函数。\n\npost.samples &lt;- posterior_samples(m.brm, c(\"^b\", \"^sd\"))\nnames(post.samples)\n\n## [1] \"b_Intercept\"          \"sd_Author__Intercept\"\n结果数据框包含两列：b_Intercept，汇集效应量的后验样本数据，以及 sd_Author_Intercept，研究间异质性 \\(\\tau\\) 的数据。我们将列重命名为 smd 和 tau，以使名称更具信息性。\n\nnames(post.samples) &lt;- c(\"smd\", \"tau\")\n\n\n使用 post.samples 中的数据，我们现在可以生成后验分布的密度图。我们使用 {ggplot2} 程序包进行绘图。\n\nggplot(aes(x = smd), data = post.samples) +\n  geom_density(fill = \"lightblue\",                # set the color\n               color = \"lightblue\", alpha = 0.7) +  \n  geom_point(y = 0,                               # add point at mean\n             x = mean(post.samples$smd)) +\n  labs(x = expression(italic(SMD)),\n       y = element_blank()) +\n  theme_minimal()\n\nggplot(aes(x = tau), data = post.samples) +\n  geom_density(fill = \"lightgreen\",               # set the color\n               color = \"lightgreen\", alpha = 0.7) +  \n  geom_point(y = 0, \n             x = mean(post.samples$tau)) +        # add point at mean\n    labs(x = expression(tau),\n       y = element_blank()) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n我们看到后验分布遵循单峰且大致正态分布，在 \\(\\mu\\) 和 \\(\\tau\\) 的估计值附近达到峰值。\n贝叶斯方法为我们感兴趣的参数创建实际抽样分布这一事实意味着我们可以计算 \\(\\mu\\) 或 \\(\\tau\\) 大于或小于某个特定值的确切概率。假设我们在以前的文献中发现，如果干预措施的效果低于 SMD = 0.30，它们就不再有意义。因此，我们可以根据我们的模型计算出我们元分析中真实总体效应小于 SMD = 0.30 的概率。\n\n这可以通过查看经验累积分布函数 (ECDF) 来完成。ECDF 允许我们选择一个特定值 \\(X\\)，并根据提供的数据返回某个值 \\(x\\) 小于 \\(X\\) 的概率。在我们的示例中，可以在下面看到 \\(\\mu\\) 的后验分布的 ECDF。\n\n\n\n\n\n\n\n\n\n我们可以使用 ecdf 函数在 _",
    "crumbs": [
      "网站首页",
      "贝叶斯Meta分析"
    ]
  },
  {
    "objectID": "15-bayesianma.html#bayes-hierarchical-model",
    "href": "15-bayesianma.html#bayes-hierarchical-model",
    "title": "贝叶斯元分析",
    "section": "",
    "text": "为了执行贝叶斯元分析，我们采用所谓的贝叶斯分层模型 [@rover2017bayesian; @higgins2009re]。我们已经在网络元分析章节（第 @ref(bayesian-net-ma-model) 章）中简要介绍了这种类型的模型。\n在第 @ref(multilevel-ma) 章中，我们了解到每个元分析模型都具有固有的“多层”结构，因此也是分层结构。在第一层，我们有各个参与者。此级别的数据通常以每个研究 \\(k\\) 的计算效应量 \\(\\hat\\theta_k\\) 的形式到达我们手中。我们假设参与者嵌套在第二层的研究中，并且元分析中不同研究的真实效应量 \\(\\theta_k\\) 遵循其自身分布。这种真实效应的分布具有均值 \\(\\mu\\)（我们想要估计的汇集“真实”效应）和方差 \\(\\tau^2\\)，表示研究间的异质性。\n让我们尝试将此形式化。在第一层，我们假设研究 \\(k\\) 中报告的观察效应量 \\(\\hat\\theta_k\\) 是该研究中“真实”效应 \\(\\theta_k\\) 的估计值。由于抽样误差 \\(\\epsilon_k\\)，观察到的效应 \\(\\hat\\theta_k\\) 偏离 \\(\\theta_k\\)。这是因为我们假设 \\(\\hat\\theta_k\\) 是从 \\(k\\) 的基础人群中抽取（采样）的。该人群可以被视为具有均值 \\(\\theta_k\\)（研究的“真实”效应）和方差 \\(\\sigma^2\\) 的分布。\n在第二步中，我们假设真实效应量 \\(\\theta_k\\) 本身只是真实效应量总体分布的样本。此分布的均值 \\(\\mu\\) 是我们想要估计的汇集效应量。研究特定的真实效应 \\(\\theta_k\\) 偏离 \\(\\mu\\)，因为总体分布也具有方差 \\(\\tau^2\\)，表示研究间的异质性。综上所述，这给出了以下两个方程：\n\\[\\begin{align}\n\\hat\\theta_k &\\sim \\mathcal{N}(\\theta_k,\\sigma_k^2) \\notag \\\\\n\\theta_k &\\sim \\mathcal{N}(\\mu,\\tau^2) (\\#eq:by1)\n\\end{align}\\]\n这里，我们使用 \\(\\mathcal{N}\\) 来表示左侧的参数是从正态分布中采样的。有些人可能会争辩说，对于第二个方程来说，这是一个不必要的严格假设 [@higgins2009re]，但如此处所示的公式是使用最多的公式。如前所述，固定效应模型只是该模型的一个特例，在该模型中，我们假设 \\(\\tau^2 = 0\\)，这意味着不存在研究间的异质性，并且所有研究共享一个单一的真实效应量（即对于所有研究 \\(k\\)：\\(\\theta_k = \\mu\\)）。\n我们还可以使用边际形式简化此公式：\n\\[\\begin{equation}\n\\hat\\theta_k  \\sim \\mathcal{N}(\\mu,\\sigma_k^2 + \\tau^2)\n(\\#eq:by2)\n\\end{equation}\\]\n您可能已经发现这些公式看起来很像我们在讨论随机效应（第 @ref(rem) 章）和三层元分析（第 @ref(multilevel-nature) 章）模型时定义的公式。的确，这种公式化并没有什么特别的“贝叶斯”之处。但是，当我们添加以下公式时，情况会发生变化 [@williams2018bayesian]：\n\\[\\begin{align}\n(\\mu, \\tau^2) &\\sim p(.) \\notag \\\\\n\\tau^2 &&gt; 0 (\\#eq:by3)\n\\end{align}\\]\n\n第一行尤为重要。它定义了参数 \\(\\mu\\) 和 \\(\\tau^2\\) 的先验分布。这使我们能够先验地指定我们认为真实汇集效应量 \\(\\mu\\) 和研究间异质性 \\(\\tau^2\\) 可能看起来如何，以及我们对此有多确定。第二个方程添加了研究间异质性方差必须大于零的约束。但是，此公式未指定用于 \\(\\mu\\) 和 \\(\\tau^2\\) 的先验分布的确切类型。它仅告诉我们假设了某些先验分布。稍后，我们将更详细地介绍贝叶斯元分析模型合理的特定先验。\n \n在关于网络元分析的章节中，我们已经介绍了贝叶斯方法估计模型参数的方法。概括地说，这涉及使用基于 马尔可夫链蒙特卡洛 的抽样程序，例如 吉布斯抽样。在我们将在本章中使用的 {brms} 程序包中，使用了所谓的 无 U 形转弯 抽样 [NUTS, @hoffman2014no]1。\n \n在前面的章节中，我们主要使用了 {meta} 和 {metafor} 程序包。这些程序包允许基于非贝叶斯或 频率学派 框架进行元分析。因此，您可能想知道，鉴于我们已经可以使用“传统”方法求助于如此强大的工具，为什么还要开始使用贝叶斯方法。原因是贝叶斯元分析具有一些独特的优势 [@williams2018bayesian; @mcneish2016using; @chung2013nondegenerate]：\n\n贝叶斯方法允许直接对我们对 \\(\\tau^2\\) 的估计中的不确定性进行建模。它们在估计汇集效应方面也可能更出色，尤其是在包含的研究数量较少时（这在实践中非常常见）。\n贝叶斯方法为 \\(\\mu\\) 和 \\(\\tau^2\\) 生成完整的后验分布。这允许计算 \\(\\mu\\) 或 \\(\\tau^2\\) 小于或大于某个指定值的确切概率。这与频率学派方法形成对比，在频率学派方法中，我们仅计算置信区间。但是，（95%）置信区间仅说明，如果数据抽样重复多次，人口参数（例如 \\(\\mu\\) 或 \\(\\tau^2\\)）的真实值将在 95% 的样本中落入置信区间的范围内。它们没有告诉我们真实参数位于两个指定值之间的概率。\n贝叶斯方法允许我们在计算元分析时整合先验知识和假设。",
    "crumbs": [
      "网站首页",
      "贝叶斯Meta分析"
    ]
  },
  {
    "objectID": "15-bayesianma.html#priors",
    "href": "15-bayesianma.html#priors",
    "title": "贝叶斯元分析",
    "section": "",
    "text": "之前，我们形式化了可用于在贝叶斯元分析中汇集效应的分层模型。但是，要运行这样的模型，我们必须指定 \\(\\mu\\) 和 \\(\\tau^2\\) 的先验分布。尤其是在研究数量较少时，先验会对结果产生相当大的影响，因此我们应明智地选择它们。\n \n通常，一个好的方法是使用弱信息先验 [@williams2018bayesian]。弱信息先验可以与无信息先验形成对比。无信息先验是先验分布的最简单形式。它们通常基于均匀分布，并用于表示所有值都同样可信。\n另一方面，弱信息先验稍微复杂一些。它们依赖于表示我们微弱相信某些值比其他值更可信的分布。但是，它们仍然没有对要从我们的数据中估计的参数的值做出任何具体陈述。\n\n从直觉上讲，这很有意义。例如，在许多元分析中，假设真实效应位于 SMD = -2.0 和 2.0 之间的某个位置似乎是合理的，但不太可能是 SMD = 50。基于此理由，我们的 \\(\\mu\\) 先验的一个很好的起点可能是均值为 0 且方差为 1 的正态分布。这意味着我们授予大约 95% 的先验概率，即真实汇集效应量 \\(\\mu\\) 位于 −2.0 和 2.0 之间：\n\\[\\begin{equation}\n\\mu \\sim \\mathcal{N}(0,1)\n(\\#eq:by4)\n\\end{equation}\\]\n我们必须指定的下一个先验是 \\(\\tau^2\\) 的先验。这有点困难，因为我们知道 \\(\\tau^2\\) 应始终为非负数，但可以（接近）零。在这种情况下，推荐的分布，并且通常用于方差（例如 \\(\\tau^2\\)）的分布是 半柯西 先验。半柯西分布是柯西分布的一个特例，它仅为分布的“一半”（即正侧）定义2。\n半柯西分布由两个参数控制。第一个是位置参数 \\(x_0\\)，它指定分布的峰值。第二个是 \\(s\\)，即比例参数。它控制分布的重尾程度（即它“扩展”到更高值的程度）。半柯西分布用 \\(\\mathcal{HC}(x_0,s)\\) 表示。\n下图可视化了 \\(s\\) 的不同值的半柯西分布，其中 \\(x_0\\) 的值固定为 0。\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n\n\n\n\n半柯西分布通常具有相当重的尾部，这使其特别适合用作 \\(\\tau\\) 的先验分布。重尾确保我们仍然给予 \\(\\tau\\) 的非常高的值一些概率，同时假设较低的值更可能。\n在许多元分析中，\\(\\tau\\)（\\(\\tau^2\\) 的平方根）位于 0.3 附近，或者至少在同一范围内。要指定半柯西先验，我们可以因此使用 \\(s=\\) 0.3。这确保小于 \\(\\tau=\\) 0.3 的值具有 50% 的概率 [@williams2018bayesian]。我们可以使用 {extraDistr} 程序包 [@extradistr] 的 phcauchy 函数中实现的半柯西分布函数来确认这一点。\n\n\nlibrary(extraDistr)\nphcauchy(0.3, sigma = 0.3)\n\n[1] 0.5\n\n\n但是，这已经是关于 \\(\\tau\\) 的真实值的一个非常具体的假设。一种更保守的方法（我们将在我们的实践示例中遵循）是将 \\(s\\) 设置为 0.5；这使分布更平坦。通常，建议始终使用不同的先验规范进行敏感性分析，以检查它们是否会显着影响结果。使用 \\(s=\\) 0.5 作为半柯西分布的参数，我们可以像这样写下我们的 \\(\\tau\\) 先验：\n\\[\\begin{equation}\n\\tau \\sim \\mathcal{HC}(0,0.5)\n(\\#eq:by5)\n\\end{equation}\\]\n我们现在可以将分层模型的公式和我们的先验规范放在一起。这导致了我们可以用于贝叶斯元分析的完整模型：\n\\[\\begin{align}\n\\hat\\theta_k &\\sim \\mathcal{N}(\\theta_k,\\sigma_k^2) \\notag \\\\\n\\theta_k &\\sim \\mathcal{N}(\\mu,\\tau^2) \\notag \\\\\n\\mu &\\sim \\mathcal{N}(0,1) \\notag \\\\\n\\tau &\\sim \\mathcal{HC}(0,0.5) (\\#eq:by5)\n\\end{align}\\]",
    "crumbs": [
      "网站首页",
      "贝叶斯Meta分析"
    ]
  },
  {
    "objectID": "15-bayesianma.html#bayes-ma-R",
    "href": "15-bayesianma.html#bayes-ma-R",
    "title": "贝叶斯元分析",
    "section": "",
    "text": "现在我们已经定义了元分析的贝叶斯模型，现在是在 R 中实现它的时间了。在这里，我们使用 {brms} 程序包 [@burknerJSS; @burkner2017advanced] 来拟合我们的模型。{brms} 程序包是一个非常通用且强大的工具，用于拟合贝叶斯回归模型。它可以用于广泛的应用，包括多层（混合效应）模型、广义线性模型、多元模型和广义可加模型，仅举几例。这些模型中的大多数都需要个人级别的数据，但 {brms} 也可以用于元分析，在元分析中，我们处理（加权）研究级别的数据3。\n在我们开始拟合模型之前，我们首先必须安装并加载 {brms} 程序包。\n\nlibrary(brms)\n\n\n\n\n\n在我们的实践示例中，我们再次使用 ThirdWave 数据集，该数据集包含来自一项元分析的信息，该元分析调查了大学生中“第三波”心理疗法的效果（第 @ref(pre-calculated-es) 章）。在我们拟合模型之前，让我们首先指定总体效应量 \\(\\mu\\) 和研究间异质性 \\(\\tau\\) 的先验分布。之前，我们定义了 \\(\\mu \\sim \\mathcal{N}(0,1)\\) 和 \\(\\tau \\sim \\mathcal{HC}(0,0.5)\\)。\n我们可以使用 prior 函数来指定分布。该函数接受两个参数。在第一个参数中，我们指定要为先验假设的分布，包括分布参数。在第二个参数中，我们必须定义先验的 class。对于 \\(\\mu\\)，合适的类是 Intercept，因为它是一个固定的总体级别效应。对于 \\(\\tau\\)，类是 sd，因为它是一个方差（或者，更准确地说，是一个标准差）。我们可以使用 prior 函数定义这两个先验，然后将它们连接起来，并将结果对象另存为 priors。\n\npriors &lt;- c(prior(normal(0,1), class = Intercept),\n            prior(cauchy(0,0.5), class = sd))\n\n现在，我们可以继续并拟合模型。为此，我们使用 {brms} 中的 brm 函数。该函数有很多参数，但只有少数与我们相关。\n在 formula 参数中，指定了模型的公式。{brms} 程序包使用回归公式表示法，其中一个结果（在我们的例子中，是观察到的效应量）y 由一个或多个预测变量 x 预测。波浪号 (~) 用于指定存在预测关系：y ~ x。\n元分析有点特殊，因为我们没有预测效应量的变量（除非我们执行元回归）。这意味着 x 必须替换为 1，表示仅截距模型。此外，我们不能简单地按原样使用 y 中每个研究的效应量。我们还必须给具有更高精度（即样本量）的研究更大的权重。这可以通过使用 y|se(se_y) 而不是仅使用 y 来完成，其中 se(se_y) 部分代表我们数据集中每个效应量 y 的标准误差。\n如果我们想使用随机效应模型，最后一步是将随机效应项 (1|study) 添加到公式的右侧。这指定了 y 中的效应量被假定为嵌套在研究中，这些研究的真实效应本身是从真实效应的总体分布中随机抽取的。如果我们想使用固定效应模型，我们可以简单地省略此项。因此，随机效应模型的通用完整公式如下所示：y|se(se_y) ~ 1 + (1|random)。要了解有关 brm 模型中公式设置的更多信息，可以在控制台中键入 ?brmsformula 以打开文档。\n其他参数相当简单。在 prior 中，我们指定要为模型定义的先验。在我们的示例中，我们可以简单地插入我们之前创建的 priors 对象。iter 参数指定 MCMC 算法的迭代次数。您的模型越复杂，此数字就应该越高。但是，更多的迭代也意味着该函数将花费更长的时间才能完成。最后，我们还必须指定 data，我们在其中简单地提供数据集的名称。\n我们将拟合的贝叶斯元分析模型以名称 m.brm 保存。代码如下所示：\n\nm.brm &lt;- brm(TE|se(seTE) ~ 1 + (1|Author),\n             data = ThirdWave,\n             prior = priors,\n             iter = 4000)\n\n请注意，与我们之前介绍的标准元分析技术相比，贝叶斯方法的计算成本要高得多。因此，采样可能需要几分钟才能完成。\n\n\n\n\n\n\n在我们开始分析结果之前，我们必须确保模型已收敛（即 MCMC 算法找到了最佳解决方案）。如果不是这种情况，则参数不可信，不应解释。非收敛在贝叶斯模型中经常发生，通常可以通过使用更多迭代次数 (iter) 重新运行模型来解决。为了评估我们模型的收敛性和整体有效性，我们应该始终做两件事。首先，检查参数估计的 \\(\\hat{R}\\) 值，其次，进行后验预测检查。\n\\(\\hat{R}\\) 值表示我们在讨论贝叶斯网络元分析时已经介绍过的潜在尺度缩减因子 (PSRF)（第 @ref(bayesian-model-convergence) 章）。我们估计的 \\(\\hat{R}\\) 值应小于 1.01。要检查这一点，我们可以生成 m.brm 对象的 summary。\n\nsummary(m.brm)\n\n## Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: TE | se(seTE) ~ 1 + (1 | Author) \n##    Data: ThirdWave (Number of observations: 18) \n## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n##          total post-warmup samples = 8000\n## \n## Group-Level Effects: \n## ~Author (Number of levels: 18) \n##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS \n## sd(Intercept)     0.29      0.10     0.11     0.51 1.00     2086   \n## \n## Population-Level Effects: \n##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS \n## Intercept     0.57      0.09     0.39     0.76 1.00     3660    \n## \n##\n## [...]\n## \n## Samples were drawn using sampling(NUTS). For each parameter, \n## Bulk_ESS and Tail_ESS are effective sample size measures, \n## and Rhat is the potential scale reduction factor on split \n## chains (at convergence, Rhat = 1).\n正如我们所看到的，两个参数的 Rhat 值均为 1，表示收敛。这意味着可以解释结果。\n另一方面，在后验预测检查中，通过从后验预测分布中随机抽取来模拟数据，然后将其与观察到的数据进行比较。如果模型已收敛并且可以很好地捕获数据，我们可以预期复制的密度与观察到的数据的密度大致相似。可以使用 pp_check 函数的输出来轻松检查这一点。\n\npp_check(m.brm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n我们可以首先查看摘要输出中的 Group-Level Effects 来开始解释结果。本节保留给我们在公式中定义的随机效应。由于我们拟合了一个随机效应元分析模型，因此变量 ~Author（表示各个研究）已使用随机截距进行建模。正如我们之前描述的，这代表了我们对级别 2 的假设，即每个研究都有其自己的“真实”效应量，这些效应量是从真实效应的总体分布中抽取的。我们还看到我们的组级别效应有 18 个级别，与我们数据中的 \\(K=\\) 18 个研究相对应。\n研究间异质性的估计值 sd(Intercept) 为 \\(\\tau=\\) 0.29，因此与我们在设置先验时最初的“最佳猜测”非常相似。使用 ranef 函数，我们还可以提取每个研究的“真实”效应量与汇集效应的估计偏差：\n\nranef(m.brm)\n\n## $Author\n## , , Intercept\n##                           Estimate Est.Error         Q2.5       Q97.5\n## Call et al.             0.06836636 0.1991649 -0.327463365  0.47663987\n## Cavanagh et al.        -0.14151644 0.1767123 -0.510165576  0.18799272\n## DanitzOrsillo           0.48091338 0.2829719 -0.003425284  1.08636421\n## de Vibe et al.         -0.31923470 0.1454819 -0.612269461 -0.03795683\n## Frazier et al.         -0.11388029 0.1497128 -0.417029387  0.17085917\n## [...]\n我们可以解释的输出的下一部分是 Population-Level Effects。本节代表了我们建模的“固定”人口参数。在我们的例子中，这是 \\(\\mu\\)，即我们元分析的总体效应量。\n\n在输出中，我们看到估计值为 0.57 的（偏差校正的）SMD，其中 95% 的可信区间范围为 95%CrI：0.39−0.76。这表明在此元分析中研究的干预措施具有中等大小的总体效果。\n因为这是一个贝叶斯模型，所以我们在这里没有找到任何 \\(p\\) 值。但我们的示例应该强调，即使不必诉诸经典显着性检验，我们也可以做出合理的推断。在贝叶斯中，但在频率学派元分析中，我们可以做的一件很棒的事情是概率性地对我们要估计的参数进行建模。贝叶斯模型不仅估计感兴趣的参数，还估计 \\(\\tau^2\\) 和 \\(\\mu\\) 的整个后验分布，我们可以很容易地访问它们。我们只需要使用 posterior_samples 函数。\n\npost.samples &lt;- posterior_samples(m.brm, c(\"^b\", \"^sd\"))\nnames(post.samples)\n\n## [1] \"b_Intercept\"          \"sd_Author__Intercept\"\n结果数据框包含两列：b_Intercept，汇集效应量的后验样本数据，以及 sd_Author_Intercept，研究间异质性 \\(\\tau\\) 的数据。我们将列重命名为 smd 和 tau，以使名称更具信息性。\n\nnames(post.samples) &lt;- c(\"smd\", \"tau\")\n\n\n使用 post.samples 中的数据，我们现在可以生成后验分布的密度图。我们使用 {ggplot2} 程序包进行绘图。\n\nggplot(aes(x = smd), data = post.samples) +\n  geom_density(fill = \"lightblue\",                # set the color\n               color = \"lightblue\", alpha = 0.7) +  \n  geom_point(y = 0,                               # add point at mean\n             x = mean(post.samples$smd)) +\n  labs(x = expression(italic(SMD)),\n       y = element_blank()) +\n  theme_minimal()\n\nggplot(aes(x = tau), data = post.samples) +\n  geom_density(fill = \"lightgreen\",               # set the color\n               color = \"lightgreen\", alpha = 0.7) +  \n  geom_point(y = 0, \n             x = mean(post.samples$tau)) +        # add point at mean\n    labs(x = expression(tau),\n       y = element_blank()) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n我们看到后验分布遵循单峰且大致正态分布，在 \\(\\mu\\) 和 \\(\\tau\\) 的估计值附近达到峰值。\n贝叶斯方法为我们感兴趣的参数创建实际抽样分布这一事实意味着我们可以计算 \\(\\mu\\) 或 \\(\\tau\\) 大于或小于某个特定值的确切概率。假设我们在以前的文献中发现，如果干预措施的效果低于 SMD = 0.30，它们就不再有意义。因此，我们可以根据我们的模型计算出我们元分析中真实总体效应小于 SMD = 0.30 的概率。\n\n这可以通过查看经验累积分布函数 (ECDF) 来完成。ECDF 允许我们选择一个特定值 \\(X\\)，并根据提供的数据返回某个值 \\(x\\) 小于 \\(X\\) 的概率。在我们的示例中，可以在下面看到 \\(\\mu\\) 的后验分布的 ECDF。\n\n\n\n\n\n\n\n\n\n我们可以使用 ecdf 函数在 _",
    "crumbs": [
      "网站首页",
      "贝叶斯Meta分析"
    ]
  },
  {
    "objectID": "15-bayesianma.html#footnotes",
    "href": "15-bayesianma.html#footnotes",
    "title": "贝叶斯元分析",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNUTS 是所谓的 哈密顿蒙特卡洛 (HMC) 的扩展，后者是另一种类型的马尔可夫链蒙特卡洛方法。与其他方法（例如吉布斯抽样）相比，HMC 可以提供更有效的解决方案来估计分层模型 [例如用于元分析的模型，@betancourt2015hamiltonian]。HMC 和 NUTS 的简要描述可以在 Stan 参考手册 中找到（Stan 是 {brms} 基于的低级编程语言，请参见第 @ref(bayes-ma-R) 章）。↩︎\n标准柯西分布本身是自由度 \\(\\text{d.f.}=1\\) 的 \\(t\\) 分布的一个特例。↩︎\n{brms} 程序包基于 Stan，这是一种用于贝叶斯建模的低级编程语言。Stan 项目有自己的、积极维护的在线论坛 (https://discourse.mc-stan.org/)，也可以在那里讨论与 {brms} 相关的问题。该论坛还有一个“元分析”标签，可用于过滤掉可能相关的线程。↩︎",
    "crumbs": [
      "网站首页",
      "贝叶斯Meta分析"
    ]
  },
  {
    "objectID": "13-sem.html",
    "href": "13-sem.html",
    "title": "结构方程模型元分析",
    "section": "",
    "text": "I n 在上一章中，我们展示了元分析模型具有固有的多层结构。例如，这种特性可以用于将传统元分析扩展到三层模型。\n \n统计方法的一个特殊之处在于，它们通常被放入单独的“盒子”中。在研究和实践中，它们被视为不相关的，但事实并非如此。例如，对于许多社会科学专业的学生来说，听到方差分析（ANOVA）和带有分类预测变量的线性回归本质上做的是同一件事，通常会感到惊讶1。这种情况经常发生，因为这两种方法传统上用于不同的背景，并作为独立的实体进行教授。\n\n类似地，直到最近，研究人员才开始将多层模型视为结构方程模型的一种特殊形式，或 SEM [@mehta2005people; @bauer2003estimating]。正如我们所了解的，每个元分析都基于一个多层模型。因此，我们也可以将元分析视为结构方程模型，其中合并效应量被视为潜在（或未观察到的）变量 [@cheung2015meta, chapter 4.6]。简而言之：元分析是多层模型；因此，它们也可以表示为结构方程模型。\n \n这不仅意味着我们可以从结构方程建模的角度来概念化之前涵盖的元分析类型。它还允许我们使用 SEM 来构建更复杂的元分析模型。使用元分析 SEM，我们可以测试因子分析模型，或者执行包含多个感兴趣结果的多元元分析（仅举几个应用）。\n当我们想要评估文献中的某些模型在考虑所有可用证据后是否仍然成立时，元分析 SEM 会有所帮助。相反，它也可以用于检查某个理论是否没有证据支持；或者，更有趣的是，它是否只适用于某个特定个体或实体的亚组。\n当然，应用元分析 SEM 技术的前提是对结构方程建模有基本的了解。因此，在下一节中，我们将简要讨论结构方程建模背后的总体思路，以及它的元分析扩展。\n\n\n\n\n结构方程模型是一种用于检验关于显性（观察到的）和潜在变量之间关系的假设的统计技术 [@kline2015principles, chapter 1]。潜在变量要么未被观察到，要么无法观察到。例如，人格是一种只能间接测量的结构，例如通过问卷中的不同项目。在 SEM 中，使用显性、测量变量对显性和潜在变量之间假设的关系（“结构”）进行建模，同时考虑到它们的测量误差。\nSEM 分析与“传统”统计假设检验（例如 \\(t\\) 检验）有些不同。通常，统计检验涉及针对零假设进行检验，例如 \\(H_0: \\mu_1 = \\mu_2\\)（其中 \\(\\mu_1\\) 和 \\(\\mu_2\\) 是两组的均值）。在这样的检验中，研究人员“旨在”拒绝零假设，因为这允许得出两组不同的结论。然而，在 SEM 中，事先提出了一个特定的结构模型，如果拟合优度足够，研究人员反而“旨在”接受这个模型 [@cheung2015meta, chapter 2.4.6]。\n\n\n\n\n通常，SEM 通过一系列矩阵进行数学上的指定和表示。您可以将矩阵想象成一个简单的表格，包含行和列，很像 R 中的 data.frame 对象（事实上，大多数数据框可以使用 as.matrix 函数轻松转换为矩阵）。在视觉上，SEM 可以表示为路径图。这样的路径图通常非常直观，并且在解释上很简单。因此，我们将首先以可视化方式指定 SEM，然后转到矩阵表示法。\n\n\n\n\n\n路径图以图形方式表示我们的 SEM。关于如何绘制路径图没有完全一致的意见，但有一些约定俗成。以下是路径图的主要组成部分，以及它们所代表的含义。\n\n\n\n\n\n\nSymbol\nName\nDescription\n\n\n\n\n$\\square$\n矩形\n显性/观察到的变量。\n\n\n$\\circ$\n圆形\n潜在/未观察到的变量。\n\n\n$\\triangle$\n三角形\n截距（固定的 1 的向量）。\n\n\n$\\rightarrow$\n箭头\n预测。箭头开始处的变量预测箭头结束处的变量：预测变量 $\\rightarrow$ 目标变量。\n\n\n$\\leftrightarrow$\n双向箭头\n（共）方差。如果双向箭头连接两个变量（矩形/圆形），则表示两个变量之间的协方差/相关性。如果双向箭头在一个变量的顶部形成一个循环，则表示该变量的方差。\n\n\n\n\n\n\n\n\n作为说明，让我们为一个简单的线性（“非元分析”）回归模型创建一个路径图，其中我们想要用 \\(x\\) 预测 \\(y\\)。模型公式如下所示：\n\\[\\begin{equation}\ny_i = \\beta_0 + \\beta_1x_i + e_i\n(\\#eq:sem1)\n\\end{equation}\\]\n现在，让我们“解构”这个公式。在该模型中，\\(x_i\\) 和 \\(y_i\\) 是观察到的变量。没有未观察到的（潜在的）变量。\\(y\\) 的真实总体均值是回归截距 \\(\\beta_0\\)，而 \\(\\mu_x\\) 表示 \\(x\\) 的总体均值。我们观察到的预测变量 \\(x\\) 的方差用 \\(\\sigma^2_x\\) 表示。假设 \\(x\\) 不是 \\(y\\) 的完美预测变量，那么与 \\(y\\) 相关联的将存在一些残差误差方差 \\(\\sigma^2_{e_y}\\)。有两个回归系数：\\(\\beta_0\\)，截距，以及 \\(\\beta_1\\)，\\(x\\) 的斜率系数。\n使用这些组成部分，我们可以为我们的线性回归模型构建一个路径图，如下所示。\n\n\n\n\n\n\n\n\n\n我们也可以使用这个图形模型作为起点来重新组装回归模型方程。从该模型中，我们可以推断出 \\(y\\) 受两个组成部分的影响：\\(x \\times \\beta_1\\) 和 \\(1 \\times \\beta_0\\)。如果我们把这两个部分加在一起，我们再次得到之前 \\(y\\) 的公式。\n\n\n\n\n\n有几种方法可以通过矩阵来表示 SEM [@joreskog2006lisrel; @muthen2012mplus; @mcardle1984some]。在这里，我们将重点关注网状作用模型公式，或 RAM [@mcardle1984some]。我们这样做是因为这个公式被我们稍后将要介绍的 {metaSEM} 包使用。RAM 使用四个矩阵：\\(\\boldsymbol{F}\\)、\\(\\boldsymbol{A}\\)、\\(\\boldsymbol{S}\\) 和 \\(\\boldsymbol{M}\\)。因为 \\(\\boldsymbol{M}\\) 矩阵对于拟合我们涵盖的元分析 SEM 不是必需的，所以我们在这里省略它 [有关更广泛的介绍，请参见 @cheung2015meta]。\n我们现在将为之前的线性回归模型指定剩余的 \\(\\boldsymbol{A}\\)、\\(\\boldsymbol{F}\\) 和 \\(\\boldsymbol{S}\\) 矩阵。这三个矩阵都具有相同数量的行和列，与我们在模型中拥有的变量相对应：\\(x\\) 和 \\(y\\)。因此，我们的回归模型的通用矩阵结构始终如下所示：\n\n\n\n\n\n\n\n\n\n\n\\(\\boldsymbol{A}\\) 矩阵：单箭头\n\\(\\boldsymbol{A}\\) 矩阵表示我们路径模型中的非对称（单）箭头。我们可以通过搜索箭头开始的变量的列条目 (\\(x\\))，然后搜索箭头结束的变量的矩阵行条目 (\\(y\\)) 来填充这个矩阵。我们的箭头的值，\\(\\beta_1\\)，放在所选列和行在矩阵 (\\(i_{y,x}\\)) 中相交的位置。鉴于我们的模型中变量之间没有其他路径，我们用 0 填充剩余字段。因此，我们的示例的 \\(\\boldsymbol{A}\\) 矩阵如下所示：\n\n\n\n\n\n\n\n\n\n\n\\(\\boldsymbol{S}\\) 矩阵：单箭头\n\\(\\boldsymbol{S}\\) 矩阵表示我们想要为包含的变量估计的（共）方差。对于我们的预测变量 \\(x\\)，我们需要估计方差 \\(\\sigma^2_x\\)。对于我们预测的变量 \\(y\\)，我们想知道预测误差方差 \\(\\sigma^2_{e_y}\\)。因此，我们像这样指定 \\(\\boldsymbol{S}\\)：\n\n\n\n\n\n\n\n\n\n\n\\(\\boldsymbol{F}\\) 矩阵：单箭头\n\\(\\boldsymbol{F}\\) 矩阵允许我们指定模型中的观察到的变量。为了指定一个变量已被观察到，我们只需在矩阵的相应对角线字段中插入 1。鉴于 \\(x\\) 和 \\(y\\) 都在我们的模型中被观察到，我们将 1 插入到两个对角线字段中：\n\n\n\n\n\n\n\n\n\n\n一旦设置了这些矩阵，就可以估计我们 SEM 中的参数，并评估指定的模型与数据的拟合程度。这涉及一些矩阵代数和通过最大似然估计进行参数估计，我们在此省略其数学细节。如果您有兴趣了解此步骤背后的细节，您可以查看 @cheung2015meta, chapter 4.3。\n\n\n\n\n\n\n我们现在将结合我们关于元分析模型和 SEM 的知识，将元分析公式化为结构方程模型 [@cheung2008model]。\n首先，让我们回到随机效应模型的公式。之前，我们已经描述了元分析模型遵循一个多层结构（参见第 @ref(multilevel-nature) 章），如下所示：\n第 1 层\n\\[\\begin{equation}\n\\hat\\theta_k = \\theta_k + \\epsilon_k\n(\\#eq:sem2)\n\\end{equation}\\]\n第 2 层\n\\[\\begin{equation}\n\\theta_k = \\mu + \\zeta_k\n(\\#eq:sem3)\n\\end{equation}\\]\n在第一层，我们假设研究 \\(k\\) 中报告的效应量 \\(\\hat\\theta_k\\) 是真实效应量 \\(\\theta_k\\) 的估计量。观察到的效应量由于抽样误差 \\(\\epsilon_k\\) 而偏离真实效应量，抽样误差由方差 \\(\\widehat{\\text{Var}}(\\hat\\theta_k)=v_k\\) 表示。\n \n在随机效应模型中，我们假设即使每个研究的真实效应量也仅从第 2 层的真实效应量总体中抽取。这个真实效应量总体均值，\\(\\mu\\)，是我们想要估计的，因为它代表了合并效应量。为此，我们还需要估计真实效应量的方差 \\(\\widehat{\\text{Var}}(\\theta)=\\tau^2\\)（即研究间的异质性）。固定效应模型是随机效应模型的一个特例，其中 \\(\\tau^2\\) 被假定为零。\n将此模型表示为 SEM 图非常简单。我们使用第 1 层的参数作为潜在变量来“解释”我们观察到的效应量是如何产生的 [@cheung2015meta, chapter 4.6.2]：\n\n\n\n\n\n\n\n\n\n在图形模型中，我们看到一些研究 \\(k\\) 的观察到的效应量 \\(\\hat\\theta_k\\) 受两个分支的“影响”：方差为 \\(v_k\\) 的抽样误差 \\(\\epsilon_k\\) 和方差为 \\(\\tau^2\\) 的真实效应量 \\(\\theta_k\\)。\n\n\n\n\n\n上面，我们从 SEM 的角度定义了（随机效应）元分析模型。虽然这从理论角度来看很有趣，但上面的模型并不比我们之前介绍的元分析技术更强大：它描述了假设随机效应模型来合并效应量。\n为了真正利用元分析 SEM 的多功能性，需要一个两步法 [@tang2016testing; @cheung2015meta, chapter 7]。在两阶段结构方程模型（TSSEM）中，我们首先合并每个研究的效应量。通常，这些效应量是几个变量之间的相关性，我们想要使用这些变量进行建模。对于每个研究 \\(k\\)，我们有一组相关性，用向量 \\(\\boldsymbol{r_k} = (r_1, r_2, \\dots, r_p)\\) 表示，其中 \\(p\\) 是（唯一）相关性的总数。与正常的随机效应模型一样，我们假设研究 \\(k\\) 中观察到的每个相关性由于抽样误差 \\(\\epsilon_k\\) 和研究间异质性 \\(\\zeta_k\\) 而偏离真实平均相关性 \\(\\rho\\)。\n当我们考虑到 \\(\\boldsymbol{r_k}\\) 代表包含在一个研究中的几个相关性时，我们得到以下随机效应模型的方程：\n\\[\\begin{align}\n  \\boldsymbol{r_k} &= \\boldsymbol{\\rho} + \\boldsymbol{\\zeta_k} + \\boldsymbol{\\epsilon_k} \\notag \\\\\n  \\begin{bmatrix} r_1 \\\\ r_2 \\\\ \\vdots \\\\ r_p \\end{bmatrix} &=\n  \\begin{bmatrix} \\rho_1 \\\\ \\rho_2 \\\\ \\vdots \\\\ \\rho_p \\end{bmatrix} +\n  \\begin{bmatrix} \\zeta_1 \\\\ \\zeta_2 \\\\ \\vdots \\\\ \\zeta_p \\end{bmatrix} +\n  \\begin{bmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_p \\end{bmatrix} (\\#eq:sem4)\n\\end{align}\\]\n\n使用这个模型，我们可以计算一个合并相关性的向量，\\(\\boldsymbol{r}\\)。第一个合并步骤允许评估研究之间的效应异质性，以及是否应该使用随机效应模型或亚组分析。由于 {metaSEM} 包使用的基于最大似然的方法，即使是数据部分缺失的研究也可以包含在这一步中。\n\n在第二步中，我们然后使用加权最小二乘法（参见第 @ref(metareg-model-fit) 章）来拟合我们指定的结构方程模型。指定模型的函数 \\(\\rho(\\hat\\theta)\\) 是 [@cheung2009two; @cheung2015meta, chapter 7.4.2]：\n\\[\\begin{equation}\nF_{\\text{WLS}}(\\hat\\theta) =  (\\boldsymbol{r} - \\rho(\\hat\\theta))^\\top \\boldsymbol{V}^{-1} ({r} - \\rho(\\hat\\theta))\n(\\#eq:sem5)\n\\end{equation}\\]\n其中 \\(\\boldsymbol{r}\\) 是合并的相关向量。这个公式的重要部分是 \\(\\boldsymbol{V}^{-1}\\)，它是一个包含 \\(\\boldsymbol{r}\\) 的协方差的逆矩阵。这个矩阵用于加权。重要的是，无论我们假设随机效应模型还是固定效应模型，第二步中的公式都是相同的，因为研究间异质性（如果存在）已经在第 1 步中处理了。\n\n\n\n\n\n\n\n是时候深入研究我们的第一个已完成的元分析 SEM 示例了。我们将首先使用 SEM 方法进行多元元分析，这是我们尚未介绍的内容。在多元元分析中，我们尝试同时估计多个效应。当我们研究的研究主题有多个主要结果（而不仅仅是一个结果）时，这种类型的元分析很有帮助。\n想象一下，我们正在检查某种类型的治疗的效果。对于这种治疗，可能存在两种被大多数专家认为重要的结果，因此在大多数研究中都会评估。多元元分析可以通过在一个模型中联合估计两种结果的效应量来解决这个问题。这种多元方法还允许我们将两种结果之间的相关性考虑在内。这可以用于确定在一个结果上具有高效应量的研究是否在另一个结果上也具有更高的效应量。或者，我们可能还会发现两种结果之间存在负相关，或者根本没有关联。\n\n值得注意的是，多元元分析也可以在 SEM 框架之外执行 [@schwarzer2015meta, chapter 7; @mvmeta]。然而，在这里，我们将向您展示如何从 SEM 的角度执行它们。在本示例和以下示例中，我们将使用 {metaSEM}，这是一个由 Mike Cheung [-@metasem] 开发的用于元分析 SEM 的出色包。与往常一样，我们首先必须安装 {metaSEM} 包并从您的库中加载它。\n\nlibrary(metaSEM)\n\n\n在我们的示例中，我们将再次使用 {dmetar} 的 ThirdWave 数据集（参见第 @ref(pre-calculated-es) 章）。默认情况下，此数据集仅包含一个结果（感知压力）的效应。现在，想象一下，此元分析中的大多数研究还测量了焦虑的效应，这是另一个重要的与心理健康相关的结果。因此，我们可以使用多元元分析来联合估计压力和焦虑的效应，以及它们如何相互关联。\n为了继续，我们首先必须创建一个新的数据框，其中包含两种结果的数据。首先，我们定义一个包含每个研究中报告的焦虑效应（表示为 Hedges’ \\(g\\)）的向量，以及它们的标准误差。我们还需要定义一个包含每个研究中报告的压力和焦虑之间协方差的向量。一项研究没有评估焦虑结果，因此我们在三个向量中使用 NA 来表示信息缺失。\n\n# 定义包含焦虑效应（Hedges g）的向量\nAnxiety &lt;- c(0.224,0.389,0.913,0.255,0.615,-0.021,0.201, \n             0.665,0.373,1.118,0.158,0.252,0.142,NA, \n             0.410,1.139,-0.002,1.084)\n\n# 焦虑效应的标准误差\nAnxiety_SE &lt;- c(0.193,0.194,0.314,0.165,0.270,0.233,0.159,\n                0.298,0.153,0.388,0.206,0.256,0.256,NA,\n                0.431,0.242,0.274,0.250)\n\n# 压力和焦虑结果之间的协方差\nCovariance &lt;- c(0.023,0.028,0.065,0.008,0.018,0.032,0.026, \n                0.046,0.020,0.063,0.017,0.043,0.037,NA, \n                0.079,0.046,0.040,0.041)\n\n然后，我们将此数据与 ThirdWave 中的信息一起使用来创建一个名为 ThirdWaveMV 的新数据框。在此数据集中，我们包括效应量方差 Stress_var 和 Anxiety_var，可以通过将标准误差平方获得。\n\nThirdWaveMV &lt;- data.frame(Author = ThirdWave$Author,\n                          Stress = ThirdWave$TE,\n                          Stress_var = ThirdWave$seTE^2,\n                          Anxiety = Anxiety,\n                          Anxiety_var = Anxiety_SE^2,\n                          Covariance = Covariance)\n\nformat(head(ThirdWaveMV), digits = 2)\n\n##            Author Stress Stress_var Anxiety Anxiety_var Covariance\n## 1     Call et al.   0.71      0.068   0.224       0.037      0.023\n## 2 Cavanagh et al.   0.35      0.039   0.389       0.038      0.028\n## 3   DanitzOrsillo   1.79      0.119   0.913       0.099      0.065\n## 4  de Vibe et al.   0.18      0.014   0.255       0.027      0.008\n## 5  Frazier et al.   0.42      0.021   0.615       0.073      0.018\n## 6  Frogeli et al.   0.63      0.038  -0.021       0.054      0.032\n\n正如我们所看到的，新的数据集包含压力和焦虑的效应量，以及各自的抽样方差。Covariance 列存储每个研究中测量的压力和焦虑之间的协方差。\n实践中一个常见的问题是，原始研究中未报告两个结果之间的协方差（或相关性）。如果发生这种情况，我们必须根据关于结果之间相关性的合理假设来估计协方差。\n假设我们还不知道每个研究中的协方差。我们如何估计它？一个好方法是寻找评估两种结果之间相关性的先前文献，最好是在我们现在正在处理的相同类型的背景下。假设我们在文献中发现，在临床试验的后测中，压力和焦虑非常高度相关，其中 \\(r_{\\text{S,A}} \\approx\\) 0.6。基于这种假设的相关性，我们可以使用以下公式来近似某个研究 \\(k\\) 的协方差 [@schwarzer2015meta, chapter 7]：\n\\[\\begin{equation}\n\\widehat{\\text{Cov}}(\\theta_{1},\\theta_{2}) = SE_{\\theta_{1}} \\times SE_{\\theta_{2}} \\times \\hat\\rho_{1, 2}\n(\\#eq:sem6)\n\\end{equation}\\]\n使用我们的示例数据并假设 \\(r_{\\text{S,A}} \\approx\\) 0.6，这个公式可以在 R 中这样实现：\n\n# 我们使用方差的平方根，因为 SE = sqrt(var)\ncov.est &lt;- with(ThirdWaveMV, \n                sqrt(Stress_var) * sqrt(Anxiety_var) * 0.6)\n\n请注意，当我们以这种方式计算协方差时，假设相关性的选择会对结果产生深刻的影响。因此，强烈建议 (1) 始终报告假设的相关系数，以及 (2) 进行敏感性分析，在敏感性分析中，我们检查结果如何根据我们选择的相关性而变化。\n\n\n\n\n要指定多元元分析模型，我们不必以编程方式遵循 TSSEM 过程（参见上一章），也不必指定任何 RAM 矩阵。对于这样一个相对简单的模型，我们可以使用 {metaSEM} 中的 meta 函数一步到位地拟合元分析 SEM。要使用 meta，我们只需要指定三个基本参数：\n\ny。包含效应量数据集的数据列。在多元元分析中，我们必须使用 cbind 组合我们想要包含的效应量列。\nv。包含效应量数据集的数据列。在多元元分析中，我们必须使用 cbind 组合我们想要包含的方差列。我们还必须包括包含效应量之间协方差的列。参数的结构应为 cbind(variance_1, covariance, variance_2)。\ndata。存储效应量和方差的数据集。\n\n我们将拟合的模型保存在名称 m.mv 下。重要的是，在运行 meta 之前，请确保 {meta} 包未加载。{meta} 和 {metaSEM} 中的一些函数具有相同的名称，这可能会在 R 中运行代码时导致错误。可以使用 detach 函数“卸载”包。\n可以使用 summary 检查生成的 m.mv 对象。\n\nm.mv &lt;- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV)\n\nsummary(m.mv)\n\n## [...]\n## Coefficients:\n##            Estimate Std.Error lbound ubound z value Pr(&gt;|z|)    \n## Intercept1    0.570     0.087  0.399  0.740  6.5455  5.9e-13 ***\n## Intercept2    0.407     0.083  0.244  0.570  4.9006  9.5e-09 ***\n## Tau2_1_1      0.073     0.049 -0.023  0.169  1.4861   0.1372    \n## Tau2_2_1      0.028     0.035 -0.041  0.099  0.8040   0.4214    \n## Tau2_2_2      0.057     0.042 -0.025  0.140  1.3643   0.1725    \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n## [...]\n## \n## Heterogeneity indices (based on the estimated Tau2):\n##                              Estimate\n## Intercept1: I2 (Q statistic)   0.6203\n## Intercept2: I2 (Q statistic)   0.5292\n## \n## Number of studies (or clusters): 18\n## [...]\n## OpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\n## Other values may indicate problems.)\n\n\n\n\n\n\n鉴于 SEM 模型是使用最大似然算法拟合的，我们首先要做的是检查输出末尾的 OpenMx status。最大似然估计是一种优化过程，其中参数会迭代更改，直到找到手头数据的最佳解决方案。但是，尤其是在更复杂的模型中，即使经过多次迭代，也可能无法达到此最佳值；最大似然算法将停止并输出到目前为止已近似的参数值。但是，我们的模型组件的那些值很可能是不正确的，不应被信任。\n我们模型的 OpenMx status 为 0，这表明最大似然估计运行良好。如果状态不是 0 或 1，则需要使用以下代码重新运行模型：\n\nrerun(m.mv)\n\n在输出中，两个合并的效应量显示为 Intercept1 和 Intercept2。效应量按照我们将其插入到 meta 调用中的顺序进行编号。我们可以看到合并的效应量是 \\(g_{\\text{Stress}}\\) = 0.57 和 \\(g_{\\text{Anxiety}}\\) = 0.41。两个效应量都很显著。在 Heterogeneity indices 下，我们还可以看到 \\(I^2\\) 的值，分别为 \\(I^2_{\\text{Stress}}\\) = 62% 和 \\(I^2_{\\text{Anxiety}}\\) = 53%，表明两个结果中都存在相当大的研究间异质性。\n还提供了研究间异质性方差 \\(\\tau^2\\) 的直接估计。我们看到不仅有两个估计，而且有三个。要理解这意味着什么，我们可以从 m.mv 对象中提取“随机”值。\n\ntau.coefs &lt;- coef(m.mv, select = \"random\")\n\n然后，我们使用 vec2symMat 函数创建一个系数矩阵。我们为矩阵的行和列赋予变量的名称：Stress 和 Anxiety。\n\n# 创建矩阵\ntc.mat &lt;- vec2symMat(tau.coefs)\n\n# 标记行和列\ndimnames(tc.mat)[[1]] &lt;- dimnames(tc.mat)[[2]] &lt;- c(\"Stress\", \n                                                    \"Anxiety\")\n\ntc.mat\n\n            Stress    Anxiety\nStress  0.07331199 0.02894342\nAnxiety 0.02894342 0.05753271\n\n\n我们现在更好地理解了这三个 \\(\\tau^2\\) 值的含义：它们代表了矩阵对角线上的研究间方差（异质性）。在其他两个字段中，矩阵显示了压力和焦虑之间的估计协方差。鉴于协方差只是相关性的非标准化版本，我们可以使用 cov2cor 函数将这些值转换为相关性。\n\ncov2cor(tc.mat)\n\n           Stress   Anxiety\nStress  1.0000000 0.4456613\nAnxiety 0.4456613 1.0000000\n\n\n我们看到，很合乎逻辑的是，矩阵对角线元素中的相关性为 1。压力和焦虑效应之间的相关性为 \\(r_{\\text{S,A}}\\) = 0.45。这是一个有趣的发现：它表明治疗对感知压力的影响与其对焦虑的影响之间存在正相关关系。我们可以说，对压力有高影响的治疗似乎对焦虑也有更高的影响。\n\n值得注意的是，m.mv 摘要中提供的置信区间是 Wald 型区间（参见第 @ref(knapp-hartung) 章）。这种 Wald 型区间有时可能不准确，尤其是在小样本中 [@diciccio1996bootstrap]。因此，通过使用基于似然的置信区间以另一种方式构建置信区间可能很有价值。我们可以通过重新运行 meta 函数并另外指定 intervals.type = \"LB\" 来获得这些 CI。\n\nm.mv &lt;- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV,\n             intervals.type = \"LB\")\n\n我们已经看到，我们的 m.mv 的输出包含非零的估计值，用于研究间异质性 \\(\\tau^2\\)。因此，我们可以得出结论，我们刚刚拟合的模型是随机效应模型。meta 函数自动使用随机效应模型。考虑到输出中的 \\(I^2\\) 值，我们可以得出结论，这确实是足够的。但是，如果我们无论如何都想拟合固定效应模型，我们可以通过重新运行分析并添加参数 RE.constraints = matrix(0, nrow=2, ncol=2) 来做到这一点。这将创建一个 0 的矩阵，将所有 \\(\\tau^2\\) 值约束为零：\n\nm.mv &lt;- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV,\n             RE.constraints = matrix(0, nrow=2, ncol=2))\n\n\n\n\n\n\n要绘制多元元分析模型，我们可以使用 plot 函数。我们还进行了一些其他指定来更改图的外观。如果您想查看所有样式选项，可以将 ?metaSEM::plot.meta 粘贴到控制台中，然后按 Enter。\n\nplot(m.mv, \n     axis.labels = c(\"感知压力\", \"焦虑\"), \n     randeff.ellipse.col = \"#014d64\",\n     univariate.arrows.col = \"gray40\",\n     univariate.arrows.lwd = 9,\n     univariate.polygon.col = \"gray40\",\n     estimate.ellipse.col = \"gray40\",\n     estimate.col = \"firebrick\")\n\nlibrary(OpenImageR) knitr::include_graphics(’images/forest_metasem.png",
    "crumbs": [
      "网站首页",
      "结构方程模型"
    ]
  },
  {
    "objectID": "13-sem.html#what-is-meta-sem",
    "href": "13-sem.html#what-is-meta-sem",
    "title": "结构方程模型元分析",
    "section": "",
    "text": "结构方程模型是一种用于检验关于显性（观察到的）和潜在变量之间关系的假设的统计技术 [@kline2015principles, chapter 1]。潜在变量要么未被观察到，要么无法观察到。例如，人格是一种只能间接测量的结构，例如通过问卷中的不同项目。在 SEM 中，使用显性、测量变量对显性和潜在变量之间假设的关系（“结构”）进行建模，同时考虑到它们的测量误差。\nSEM 分析与“传统”统计假设检验（例如 \\(t\\) 检验）有些不同。通常，统计检验涉及针对零假设进行检验，例如 \\(H_0: \\mu_1 = \\mu_2\\)（其中 \\(\\mu_1\\) 和 \\(\\mu_2\\) 是两组的均值）。在这样的检验中，研究人员“旨在”拒绝零假设，因为这允许得出两组不同的结论。然而，在 SEM 中，事先提出了一个特定的结构模型，如果拟合优度足够，研究人员反而“旨在”接受这个模型 [@cheung2015meta, chapter 2.4.6]。\n\n\n\n\n通常，SEM 通过一系列矩阵进行数学上的指定和表示。您可以将矩阵想象成一个简单的表格，包含行和列，很像 R 中的 data.frame 对象（事实上，大多数数据框可以使用 as.matrix 函数轻松转换为矩阵）。在视觉上，SEM 可以表示为路径图。这样的路径图通常非常直观，并且在解释上很简单。因此，我们将首先以可视化方式指定 SEM，然后转到矩阵表示法。\n\n\n\n\n\n路径图以图形方式表示我们的 SEM。关于如何绘制路径图没有完全一致的意见，但有一些约定俗成。以下是路径图的主要组成部分，以及它们所代表的含义。\n\n\n\n\n\n\nSymbol\nName\nDescription\n\n\n\n\n$\\square$\n矩形\n显性/观察到的变量。\n\n\n$\\circ$\n圆形\n潜在/未观察到的变量。\n\n\n$\\triangle$\n三角形\n截距（固定的 1 的向量）。\n\n\n$\\rightarrow$\n箭头\n预测。箭头开始处的变量预测箭头结束处的变量：预测变量 $\\rightarrow$ 目标变量。\n\n\n$\\leftrightarrow$\n双向箭头\n（共）方差。如果双向箭头连接两个变量（矩形/圆形），则表示两个变量之间的协方差/相关性。如果双向箭头在一个变量的顶部形成一个循环，则表示该变量的方差。\n\n\n\n\n\n\n\n\n作为说明，让我们为一个简单的线性（“非元分析”）回归模型创建一个路径图，其中我们想要用 \\(x\\) 预测 \\(y\\)。模型公式如下所示：\n\\[\\begin{equation}\ny_i = \\beta_0 + \\beta_1x_i + e_i\n(\\#eq:sem1)\n\\end{equation}\\]\n现在，让我们“解构”这个公式。在该模型中，\\(x_i\\) 和 \\(y_i\\) 是观察到的变量。没有未观察到的（潜在的）变量。\\(y\\) 的真实总体均值是回归截距 \\(\\beta_0\\)，而 \\(\\mu_x\\) 表示 \\(x\\) 的总体均值。我们观察到的预测变量 \\(x\\) 的方差用 \\(\\sigma^2_x\\) 表示。假设 \\(x\\) 不是 \\(y\\) 的完美预测变量，那么与 \\(y\\) 相关联的将存在一些残差误差方差 \\(\\sigma^2_{e_y}\\)。有两个回归系数：\\(\\beta_0\\)，截距，以及 \\(\\beta_1\\)，\\(x\\) 的斜率系数。\n使用这些组成部分，我们可以为我们的线性回归模型构建一个路径图，如下所示。\n\n\n\n\n\n\n\n\n\n我们也可以使用这个图形模型作为起点来重新组装回归模型方程。从该模型中，我们可以推断出 \\(y\\) 受两个组成部分的影响：\\(x \\times \\beta_1\\) 和 \\(1 \\times \\beta_0\\)。如果我们把这两个部分加在一起，我们再次得到之前 \\(y\\) 的公式。\n\n\n\n\n\n有几种方法可以通过矩阵来表示 SEM [@joreskog2006lisrel; @muthen2012mplus; @mcardle1984some]。在这里，我们将重点关注网状作用模型公式，或 RAM [@mcardle1984some]。我们这样做是因为这个公式被我们稍后将要介绍的 {metaSEM} 包使用。RAM 使用四个矩阵：\\(\\boldsymbol{F}\\)、\\(\\boldsymbol{A}\\)、\\(\\boldsymbol{S}\\) 和 \\(\\boldsymbol{M}\\)。因为 \\(\\boldsymbol{M}\\) 矩阵对于拟合我们涵盖的元分析 SEM 不是必需的，所以我们在这里省略它 [有关更广泛的介绍，请参见 @cheung2015meta]。\n我们现在将为之前的线性回归模型指定剩余的 \\(\\boldsymbol{A}\\)、\\(\\boldsymbol{F}\\) 和 \\(\\boldsymbol{S}\\) 矩阵。这三个矩阵都具有相同数量的行和列，与我们在模型中拥有的变量相对应：\\(x\\) 和 \\(y\\)。因此，我们的回归模型的通用矩阵结构始终如下所示：\n\n\n\n\n\n\n\n\n\n\n\\(\\boldsymbol{A}\\) 矩阵：单箭头\n\\(\\boldsymbol{A}\\) 矩阵表示我们路径模型中的非对称（单）箭头。我们可以通过搜索箭头开始的变量的列条目 (\\(x\\))，然后搜索箭头结束的变量的矩阵行条目 (\\(y\\)) 来填充这个矩阵。我们的箭头的值，\\(\\beta_1\\)，放在所选列和行在矩阵 (\\(i_{y,x}\\)) 中相交的位置。鉴于我们的模型中变量之间没有其他路径，我们用 0 填充剩余字段。因此，我们的示例的 \\(\\boldsymbol{A}\\) 矩阵如下所示：\n\n\n\n\n\n\n\n\n\n\n\\(\\boldsymbol{S}\\) 矩阵：单箭头\n\\(\\boldsymbol{S}\\) 矩阵表示我们想要为包含的变量估计的（共）方差。对于我们的预测变量 \\(x\\)，我们需要估计方差 \\(\\sigma^2_x\\)。对于我们预测的变量 \\(y\\)，我们想知道预测误差方差 \\(\\sigma^2_{e_y}\\)。因此，我们像这样指定 \\(\\boldsymbol{S}\\)：\n\n\n\n\n\n\n\n\n\n\n\\(\\boldsymbol{F}\\) 矩阵：单箭头\n\\(\\boldsymbol{F}\\) 矩阵允许我们指定模型中的观察到的变量。为了指定一个变量已被观察到，我们只需在矩阵的相应对角线字段中插入 1。鉴于 \\(x\\) 和 \\(y\\) 都在我们的模型中被观察到，我们将 1 插入到两个对角线字段中：\n\n\n\n\n\n\n\n\n\n\n一旦设置了这些矩阵，就可以估计我们 SEM 中的参数，并评估指定的模型与数据的拟合程度。这涉及一些矩阵代数和通过最大似然估计进行参数估计，我们在此省略其数学细节。如果您有兴趣了解此步骤背后的细节，您可以查看 @cheung2015meta, chapter 4.3。\n\n\n\n\n\n\n我们现在将结合我们关于元分析模型和 SEM 的知识，将元分析公式化为结构方程模型 [@cheung2008model]。\n首先，让我们回到随机效应模型的公式。之前，我们已经描述了元分析模型遵循一个多层结构（参见第 @ref(multilevel-nature) 章），如下所示：\n第 1 层\n\\[\\begin{equation}\n\\hat\\theta_k = \\theta_k + \\epsilon_k\n(\\#eq:sem2)\n\\end{equation}\\]\n第 2 层\n\\[\\begin{equation}\n\\theta_k = \\mu + \\zeta_k\n(\\#eq:sem3)\n\\end{equation}\\]\n在第一层，我们假设研究 \\(k\\) 中报告的效应量 \\(\\hat\\theta_k\\) 是真实效应量 \\(\\theta_k\\) 的估计量。观察到的效应量由于抽样误差 \\(\\epsilon_k\\) 而偏离真实效应量，抽样误差由方差 \\(\\widehat{\\text{Var}}(\\hat\\theta_k)=v_k\\) 表示。\n \n在随机效应模型中，我们假设即使每个研究的真实效应量也仅从第 2 层的真实效应量总体中抽取。这个真实效应量总体均值，\\(\\mu\\)，是我们想要估计的，因为它代表了合并效应量。为此，我们还需要估计真实效应量的方差 \\(\\widehat{\\text{Var}}(\\theta)=\\tau^2\\)（即研究间的异质性）。固定效应模型是随机效应模型的一个特例，其中 \\(\\tau^2\\) 被假定为零。\n将此模型表示为 SEM 图非常简单。我们使用第 1 层的参数作为潜在变量来“解释”我们观察到的效应量是如何产生的 [@cheung2015meta, chapter 4.6.2]：\n\n\n\n\n\n\n\n\n\n在图形模型中，我们看到一些研究 \\(k\\) 的观察到的效应量 \\(\\hat\\theta_k\\) 受两个分支的“影响”：方差为 \\(v_k\\) 的抽样误差 \\(\\epsilon_k\\) 和方差为 \\(\\tau^2\\) 的真实效应量 \\(\\theta_k\\)。\n\n\n\n\n\n上面，我们从 SEM 的角度定义了（随机效应）元分析模型。虽然这从理论角度来看很有趣，但上面的模型并不比我们之前介绍的元分析技术更强大：它描述了假设随机效应模型来合并效应量。\n为了真正利用元分析 SEM 的多功能性，需要一个两步法 [@tang2016testing; @cheung2015meta, chapter 7]。在两阶段结构方程模型（TSSEM）中，我们首先合并每个研究的效应量。通常，这些效应量是几个变量之间的相关性，我们想要使用这些变量进行建模。对于每个研究 \\(k\\)，我们有一组相关性，用向量 \\(\\boldsymbol{r_k} = (r_1, r_2, \\dots, r_p)\\) 表示，其中 \\(p\\) 是（唯一）相关性的总数。与正常的随机效应模型一样，我们假设研究 \\(k\\) 中观察到的每个相关性由于抽样误差 \\(\\epsilon_k\\) 和研究间异质性 \\(\\zeta_k\\) 而偏离真实平均相关性 \\(\\rho\\)。\n当我们考虑到 \\(\\boldsymbol{r_k}\\) 代表包含在一个研究中的几个相关性时，我们得到以下随机效应模型的方程：\n\\[\\begin{align}\n  \\boldsymbol{r_k} &= \\boldsymbol{\\rho} + \\boldsymbol{\\zeta_k} + \\boldsymbol{\\epsilon_k} \\notag \\\\\n  \\begin{bmatrix} r_1 \\\\ r_2 \\\\ \\vdots \\\\ r_p \\end{bmatrix} &=\n  \\begin{bmatrix} \\rho_1 \\\\ \\rho_2 \\\\ \\vdots \\\\ \\rho_p \\end{bmatrix} +\n  \\begin{bmatrix} \\zeta_1 \\\\ \\zeta_2 \\\\ \\vdots \\\\ \\zeta_p \\end{bmatrix} +\n  \\begin{bmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_p \\end{bmatrix} (\\#eq:sem4)\n\\end{align}\\]\n\n使用这个模型，我们可以计算一个合并相关性的向量，\\(\\boldsymbol{r}\\)。第一个合并步骤允许评估研究之间的效应异质性，以及是否应该使用随机效应模型或亚组分析。由于 {metaSEM} 包使用的基于最大似然的方法，即使是数据部分缺失的研究也可以包含在这一步中。\n\n在第二步中，我们然后使用加权最小二乘法（参见第 @ref(metareg-model-fit) 章）来拟合我们指定的结构方程模型。指定模型的函数 \\(\\rho(\\hat\\theta)\\) 是 [@cheung2009two; @cheung2015meta, chapter 7.4.2]：\n\\[\\begin{equation}\nF_{\\text{WLS}}(\\hat\\theta) =  (\\boldsymbol{r} - \\rho(\\hat\\theta))^\\top \\boldsymbol{V}^{-1} ({r} - \\rho(\\hat\\theta))\n(\\#eq:sem5)\n\\end{equation}\\]\n其中 \\(\\boldsymbol{r}\\) 是合并的相关向量。这个公式的重要部分是 \\(\\boldsymbol{V}^{-1}\\)，它是一个包含 \\(\\boldsymbol{r}\\) 的协方差的逆矩阵。这个矩阵用于加权。重要的是，无论我们假设随机效应模型还是固定效应模型，第二步中的公式都是相同的，因为研究间异质性（如果存在）已经在第 1 步中处理了。",
    "crumbs": [
      "网站首页",
      "结构方程模型"
    ]
  },
  {
    "objectID": "13-sem.html#multivariate-ma",
    "href": "13-sem.html#multivariate-ma",
    "title": "结构方程模型元分析",
    "section": "",
    "text": "是时候深入研究我们的第一个已完成的元分析 SEM 示例了。我们将首先使用 SEM 方法进行多元元分析，这是我们尚未介绍的内容。在多元元分析中，我们尝试同时估计多个效应。当我们研究的研究主题有多个主要结果（而不仅仅是一个结果）时，这种类型的元分析很有帮助。\n想象一下，我们正在检查某种类型的治疗的效果。对于这种治疗，可能存在两种被大多数专家认为重要的结果，因此在大多数研究中都会评估。多元元分析可以通过在一个模型中联合估计两种结果的效应量来解决这个问题。这种多元方法还允许我们将两种结果之间的相关性考虑在内。这可以用于确定在一个结果上具有高效应量的研究是否在另一个结果上也具有更高的效应量。或者，我们可能还会发现两种结果之间存在负相关，或者根本没有关联。\n\n值得注意的是，多元元分析也可以在 SEM 框架之外执行 [@schwarzer2015meta, chapter 7; @mvmeta]。然而，在这里，我们将向您展示如何从 SEM 的角度执行它们。在本示例和以下示例中，我们将使用 {metaSEM}，这是一个由 Mike Cheung [-@metasem] 开发的用于元分析 SEM 的出色包。与往常一样，我们首先必须安装 {metaSEM} 包并从您的库中加载它。\n\nlibrary(metaSEM)\n\n\n在我们的示例中，我们将再次使用 {dmetar} 的 ThirdWave 数据集（参见第 @ref(pre-calculated-es) 章）。默认情况下，此数据集仅包含一个结果（感知压力）的效应。现在，想象一下，此元分析中的大多数研究还测量了焦虑的效应，这是另一个重要的与心理健康相关的结果。因此，我们可以使用多元元分析来联合估计压力和焦虑的效应，以及它们如何相互关联。\n为了继续，我们首先必须创建一个新的数据框，其中包含两种结果的数据。首先，我们定义一个包含每个研究中报告的焦虑效应（表示为 Hedges’ \\(g\\)）的向量，以及它们的标准误差。我们还需要定义一个包含每个研究中报告的压力和焦虑之间协方差的向量。一项研究没有评估焦虑结果，因此我们在三个向量中使用 NA 来表示信息缺失。\n\n# 定义包含焦虑效应（Hedges g）的向量\nAnxiety &lt;- c(0.224,0.389,0.913,0.255,0.615,-0.021,0.201, \n             0.665,0.373,1.118,0.158,0.252,0.142,NA, \n             0.410,1.139,-0.002,1.084)\n\n# 焦虑效应的标准误差\nAnxiety_SE &lt;- c(0.193,0.194,0.314,0.165,0.270,0.233,0.159,\n                0.298,0.153,0.388,0.206,0.256,0.256,NA,\n                0.431,0.242,0.274,0.250)\n\n# 压力和焦虑结果之间的协方差\nCovariance &lt;- c(0.023,0.028,0.065,0.008,0.018,0.032,0.026, \n                0.046,0.020,0.063,0.017,0.043,0.037,NA, \n                0.079,0.046,0.040,0.041)\n\n然后，我们将此数据与 ThirdWave 中的信息一起使用来创建一个名为 ThirdWaveMV 的新数据框。在此数据集中，我们包括效应量方差 Stress_var 和 Anxiety_var，可以通过将标准误差平方获得。\n\nThirdWaveMV &lt;- data.frame(Author = ThirdWave$Author,\n                          Stress = ThirdWave$TE,\n                          Stress_var = ThirdWave$seTE^2,\n                          Anxiety = Anxiety,\n                          Anxiety_var = Anxiety_SE^2,\n                          Covariance = Covariance)\n\nformat(head(ThirdWaveMV), digits = 2)\n\n##            Author Stress Stress_var Anxiety Anxiety_var Covariance\n## 1     Call et al.   0.71      0.068   0.224       0.037      0.023\n## 2 Cavanagh et al.   0.35      0.039   0.389       0.038      0.028\n## 3   DanitzOrsillo   1.79      0.119   0.913       0.099      0.065\n## 4  de Vibe et al.   0.18      0.014   0.255       0.027      0.008\n## 5  Frazier et al.   0.42      0.021   0.615       0.073      0.018\n## 6  Frogeli et al.   0.63      0.038  -0.021       0.054      0.032\n\n正如我们所看到的，新的数据集包含压力和焦虑的效应量，以及各自的抽样方差。Covariance 列存储每个研究中测量的压力和焦虑之间的协方差。\n实践中一个常见的问题是，原始研究中未报告两个结果之间的协方差（或相关性）。如果发生这种情况，我们必须根据关于结果之间相关性的合理假设来估计协方差。\n假设我们还不知道每个研究中的协方差。我们如何估计它？一个好方法是寻找评估两种结果之间相关性的先前文献，最好是在我们现在正在处理的相同类型的背景下。假设我们在文献中发现，在临床试验的后测中，压力和焦虑非常高度相关，其中 \\(r_{\\text{S,A}} \\approx\\) 0.6。基于这种假设的相关性，我们可以使用以下公式来近似某个研究 \\(k\\) 的协方差 [@schwarzer2015meta, chapter 7]：\n\\[\\begin{equation}\n\\widehat{\\text{Cov}}(\\theta_{1},\\theta_{2}) = SE_{\\theta_{1}} \\times SE_{\\theta_{2}} \\times \\hat\\rho_{1, 2}\n(\\#eq:sem6)\n\\end{equation}\\]\n使用我们的示例数据并假设 \\(r_{\\text{S,A}} \\approx\\) 0.6，这个公式可以在 R 中这样实现：\n\n# 我们使用方差的平方根，因为 SE = sqrt(var)\ncov.est &lt;- with(ThirdWaveMV, \n                sqrt(Stress_var) * sqrt(Anxiety_var) * 0.6)\n\n请注意，当我们以这种方式计算协方差时，假设相关性的选择会对结果产生深刻的影响。因此，强烈建议 (1) 始终报告假设的相关系数，以及 (2) 进行敏感性分析，在敏感性分析中，我们检查结果如何根据我们选择的相关性而变化。\n\n\n\n\n要指定多元元分析模型，我们不必以编程方式遵循 TSSEM 过程（参见上一章），也不必指定任何 RAM 矩阵。对于这样一个相对简单的模型，我们可以使用 {metaSEM} 中的 meta 函数一步到位地拟合元分析 SEM。要使用 meta，我们只需要指定三个基本参数：\n\ny。包含效应量数据集的数据列。在多元元分析中，我们必须使用 cbind 组合我们想要包含的效应量列。\nv。包含效应量数据集的数据列。在多元元分析中，我们必须使用 cbind 组合我们想要包含的方差列。我们还必须包括包含效应量之间协方差的列。参数的结构应为 cbind(variance_1, covariance, variance_2)。\ndata。存储效应量和方差的数据集。\n\n我们将拟合的模型保存在名称 m.mv 下。重要的是，在运行 meta 之前，请确保 {meta} 包未加载。{meta} 和 {metaSEM} 中的一些函数具有相同的名称，这可能会在 R 中运行代码时导致错误。可以使用 detach 函数“卸载”包。\n可以使用 summary 检查生成的 m.mv 对象。\n\nm.mv &lt;- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV)\n\nsummary(m.mv)\n\n## [...]\n## Coefficients:\n##            Estimate Std.Error lbound ubound z value Pr(&gt;|z|)    \n## Intercept1    0.570     0.087  0.399  0.740  6.5455  5.9e-13 ***\n## Intercept2    0.407     0.083  0.244  0.570  4.9006  9.5e-09 ***\n## Tau2_1_1      0.073     0.049 -0.023  0.169  1.4861   0.1372    \n## Tau2_2_1      0.028     0.035 -0.041  0.099  0.8040   0.4214    \n## Tau2_2_2      0.057     0.042 -0.025  0.140  1.3643   0.1725    \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n## [...]\n## \n## Heterogeneity indices (based on the estimated Tau2):\n##                              Estimate\n## Intercept1: I2 (Q statistic)   0.6203\n## Intercept2: I2 (Q statistic)   0.5292\n## \n## Number of studies (or clusters): 18\n## [...]\n## OpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\n## Other values may indicate problems.)\n\n\n\n\n\n\n鉴于 SEM 模型是使用最大似然算法拟合的，我们首先要做的是检查输出末尾的 OpenMx status。最大似然估计是一种优化过程，其中参数会迭代更改，直到找到手头数据的最佳解决方案。但是，尤其是在更复杂的模型中，即使经过多次迭代，也可能无法达到此最佳值；最大似然算法将停止并输出到目前为止已近似的参数值。但是，我们的模型组件的那些值很可能是不正确的，不应被信任。\n我们模型的 OpenMx status 为 0，这表明最大似然估计运行良好。如果状态不是 0 或 1，则需要使用以下代码重新运行模型：\n\nrerun(m.mv)\n\n在输出中，两个合并的效应量显示为 Intercept1 和 Intercept2。效应量按照我们将其插入到 meta 调用中的顺序进行编号。我们可以看到合并的效应量是 \\(g_{\\text{Stress}}\\) = 0.57 和 \\(g_{\\text{Anxiety}}\\) = 0.41。两个效应量都很显著。在 Heterogeneity indices 下，我们还可以看到 \\(I^2\\) 的值，分别为 \\(I^2_{\\text{Stress}}\\) = 62% 和 \\(I^2_{\\text{Anxiety}}\\) = 53%，表明两个结果中都存在相当大的研究间异质性。\n还提供了研究间异质性方差 \\(\\tau^2\\) 的直接估计。我们看到不仅有两个估计，而且有三个。要理解这意味着什么，我们可以从 m.mv 对象中提取“随机”值。\n\ntau.coefs &lt;- coef(m.mv, select = \"random\")\n\n然后，我们使用 vec2symMat 函数创建一个系数矩阵。我们为矩阵的行和列赋予变量的名称：Stress 和 Anxiety。\n\n# 创建矩阵\ntc.mat &lt;- vec2symMat(tau.coefs)\n\n# 标记行和列\ndimnames(tc.mat)[[1]] &lt;- dimnames(tc.mat)[[2]] &lt;- c(\"Stress\", \n                                                    \"Anxiety\")\n\ntc.mat\n\n            Stress    Anxiety\nStress  0.07331199 0.02894342\nAnxiety 0.02894342 0.05753271\n\n\n我们现在更好地理解了这三个 \\(\\tau^2\\) 值的含义：它们代表了矩阵对角线上的研究间方差（异质性）。在其他两个字段中，矩阵显示了压力和焦虑之间的估计协方差。鉴于协方差只是相关性的非标准化版本，我们可以使用 cov2cor 函数将这些值转换为相关性。\n\ncov2cor(tc.mat)\n\n           Stress   Anxiety\nStress  1.0000000 0.4456613\nAnxiety 0.4456613 1.0000000\n\n\n我们看到，很合乎逻辑的是，矩阵对角线元素中的相关性为 1。压力和焦虑效应之间的相关性为 \\(r_{\\text{S,A}}\\) = 0.45。这是一个有趣的发现：它表明治疗对感知压力的影响与其对焦虑的影响之间存在正相关关系。我们可以说，对压力有高影响的治疗似乎对焦虑也有更高的影响。\n\n值得注意的是，m.mv 摘要中提供的置信区间是 Wald 型区间（参见第 @ref(knapp-hartung) 章）。这种 Wald 型区间有时可能不准确，尤其是在小样本中 [@diciccio1996bootstrap]。因此，通过使用基于似然的置信区间以另一种方式构建置信区间可能很有价值。我们可以通过重新运行 meta 函数并另外指定 intervals.type = \"LB\" 来获得这些 CI。\n\nm.mv &lt;- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV,\n             intervals.type = \"LB\")\n\n我们已经看到，我们的 m.mv 的输出包含非零的估计值，用于研究间异质性 \\(\\tau^2\\)。因此，我们可以得出结论，我们刚刚拟合的模型是随机效应模型。meta 函数自动使用随机效应模型。考虑到输出中的 \\(I^2\\) 值，我们可以得出结论，这确实是足够的。但是，如果我们无论如何都想拟合固定效应模型，我们可以通过重新运行分析并添加参数 RE.constraints = matrix(0, nrow=2, ncol=2) 来做到这一点。这将创建一个 0 的矩阵，将所有 \\(\\tau^2\\) 值约束为零：\n\nm.mv &lt;- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV,\n             RE.constraints = matrix(0, nrow=2, ncol=2))\n\n\n\n\n\n\n要绘制多元元分析模型，我们可以使用 plot 函数。我们还进行了一些其他指定来更改图的外观。如果您想查看所有样式选项，可以将 ?metaSEM::plot.meta 粘贴到控制台中，然后按 Enter。\n\nplot(m.mv, \n     axis.labels = c(\"感知压力\", \"焦虑\"), \n     randeff.ellipse.col = \"#014d64\",\n     univariate.arrows.col = \"gray40\",\n     univariate.arrows.lwd = 9,\n     univariate.polygon.col = \"gray40\",\n     estimate.ellipse.col = \"gray40\",\n     estimate.col = \"firebrick\")\n\nlibrary(OpenImageR) knitr::include_graphics(’images/forest_metasem.png",
    "crumbs": [
      "网站首页",
      "结构方程模型"
    ]
  },
  {
    "objectID": "13-sem.html#footnotes",
    "href": "13-sem.html#footnotes",
    "title": "结构方程模型元分析",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n方差分析基于模型 \\(y_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\\)，其中 \\(\\tau_i\\) 是第 \\(i\\) 个因子水平/处理的效果，\\(\\epsilon_{ij}\\) 代表由于（未解释的）随机误差造成的偏差 [@montgomery，第 3.2 章]。这只不过是线性回归模型的一个特例。主要区别在于 \\(\\tau_i\\) 是效应编码的（例如，处理变量是 -1 或 1，因此分类处理效果的总和为零：\\(\\sum_{i=1}^{a} \\tau_i = 0\\)）。相比之下，分类预测变量在线性回归模型中通常是虚拟编码的（例如，0 和 1）。↩︎",
    "crumbs": [
      "网站首页",
      "结构方程模型"
    ]
  },
  {
    "objectID": "11-publication-bias.html",
    "href": "11-publication-bias.html",
    "title": "发表偏倚",
    "section": "",
    "text": "回顾前面的章节，我们发现已经涵盖了大量的元分析技术。我们不仅学习了如何合并效应量，现在也知道如何评估我们发现的稳健性，检查异质性模式，以及检验效应差异的原因的假设。\n所有这些方法都可以帮助我们从元分析中得出有效的结论。然而，这基于一个关于我们数据性质的未明确的假设，我们尚未对此提出质疑。在进行元分析时，我们认为收集的数据是全面的，或者至少是具有代表性的，代表了所考察的研究领域。\n回到第 @ref(study-search) 章，我们提到元分析通常试图包括所有可用的证据，以便得出一个能够充分描述研究领域的单一效应量。从统计学的角度来看，我们或许可以容忍分析中缺失一些研究——但前提是这些研究是偶然“遗漏”的。\n不幸的是，元分析往往无法包括所有现有的证据。更糟糕的是，我们也有充分的理由认为，我们收集的数据中，一些研究的缺失并非完全是“随机的”。我们的世界并不完美，管理科学实践的激励机制和“规则”也是如此。这意味着存在一些系统性的偏倚，可以决定一项研究是否最终出现在我们的元分析中。\n这个问题的很好例子可以在一个不太近期的药物治疗研究轶事中找到。早在 20 世纪 90 年代，人们就普遍认为抗抑郁药物（如选择性血清素再摄取抑制剂，或 SSRIs）在治疗抑郁症患者方面是有效的。大部分证据来自已发表的药物治疗试验的元分析，在这些试验中，将抗抑郁药与安慰剂药丸进行比较。考虑到抗抑郁药物市场价值数十亿美元，并且还在稳步增长，关于抗抑郁药物效果的问题是一个重要的问题。\n这可能有助于理解欧文·基尔施（Irving Kirsch）及其同事撰写的一篇文章《皇帝的新药》[-@kirsch2002emperor]引起的骚动，该文章认为情况可能并非那么乐观。\n基尔施及其同事根据“信息自由法案”，获得了制药公司向美国食品和药物管理局提供的先前未发表的抗抑郁药试验数据。他们发现，当也考虑到这些未发表的数据时，与安慰剂相比，抗抑郁药的益处充其量是微乎其微的，在临床上可以忽略不计。基尔施及其同事认为，这是因为公司只发表了具有有利结果的研究，而具有“令人失望”证据的研究则被隐瞒了 [@kirschemperorbook]。\n\n一场激烈的辩论随之而来，基尔施的说法至今仍存在争议。我们选择这个例子不是为了站队，而是为了说明缺失研究可能对元分析推论的有效性构成的潜在威胁。在元分析文献中，此类问题通常概括为发表偏倚。\n\n发表偏倚问题强调了元分析中的每一项发现都只能与其所依据的数据一样好。元分析技术只能处理手头的数据。因此，如果收集的数据被扭曲，即使是最好的统计模型也只会重现固有的偏倚。也许你还记得我们在本书的开头已经讨论过这个基本警告，当时我们讨论了“抽屉文件”问题（参见第 @ref(pitfalls) 章）。实际上，“抽屉文件问题”和“发表偏倚”这两个术语经常互换使用。\n发表偏倚及相关问题对元分析结果的影响可能是巨大的。它可能导致我们高估治疗效果、忽视负面副作用，或强化对实际上无效的理论的信念。\n因此，在本章中，我们将讨论发表偏倚可以通过哪些不同的形式和方式来扭曲我们的发现。我们还将了解一些元分析师可以用来检查我们数据中发表偏倚风险的方法；以及如何首先减轻发表偏倚。\n\n\n\n\n当一项研究的发表概率受到其结果的影响时，就存在发表偏倚 [@duval2005publication，第 2 章和第 5 章]。有大量证据表明，如果一项研究的发现具有统计学意义，或者证实了最初的假设，那么它更有可能进入公众视野 [@schmucker2014extent; @scherer2018full; @chan2014increasing; @dechartres2018association]。\n在搜索符合条件的研究时，我们通常仅限于以某种形式公开的证据，例如通过同行评审的文章、预印本、书籍或其他类型的可访问报告。在存在发表偏倚的情况下，这不仅意味着我们的数据集中缺少一些研究——这也意味着缺失的研究很可能是那些具有不利发现的研究。\n元分析技术使我们能够找到人群中平均效应量的无偏估计。但是，如果我们的样本本身被扭曲，那么即使从统计学角度来看是“真实”的效应估计也不会代表现实。这就像试图估计冰山的大小，但只测量它的尖端：我们的发现不可避免地会出错，即使我们能够以完美的精度测量水面以上的高度。\n \n发表偏倚实际上只是众多非报告偏倚之一。还有其他几个因素也会扭曲我们在元分析中获得的证据 [@page2020investigating]，包括：\n\n引用偏倚：即使已发表，具有负面或不确定结果的研究也不太可能被相关文献引用。这使得例如通过参考文献搜索更难检测到它们。\n时滞偏倚：具有积极结果的研究通常比具有不利结果的研究发表得更早。这意味着最近进行的具有积极结果的研究的发现通常已经可用，而那些具有不显着结果的研究则不可用。\n多次发表偏倚：“成功”研究的结果更有可能在多篇期刊文章中报告，这使得至少找到其中一篇更容易。“香肠切片”也称为跨多篇文章报告研究发现的做法。\n语言偏倚：在大多数学科中，发表证据的主要语言是英语。以其他语言发表的出版物不太可能被检测到，尤其是当研究人员自己无法在不翻译的情况下理解内容时。如果英语研究与以其他语言发表的研究系统性地不同，这也会引入偏倚。\n结果报告偏倚：许多研究，尤其是临床试验，测量不止一个感兴趣的结果。一些研究人员利用这一点，只报告那些获得积极结果的结果，而那些未证实假设的结果则被删除。这也可能导致偏倚：从技术上讲，该研究已经发表，但其（不利的）结果仍将在我们的元分析中缺失，因为它未被报告。\n\n\n非报告偏倚可以被视为系统性因素，使我们更难以找到现有的证据。但是，即使我们能够包括所有相关的发现，我们的结果可能仍然存在缺陷。由于研究人员在分析和报告他们的发现时应用了可疑的研究实践 (QRP)，因此也可能存在偏倚 [@simonsohn2020specification]。\n\n我们之前已经提到了“研究人员的自由度”的概念（第 @ref(pitfalls) 章）。QRP 可以定义为研究人员滥用这些自由度将结果“弯曲”到所需方向的做法。不幸的是，对于什么是 QRP 尚无明确的共识。但是，有一些常见的建议示例。\n最突出的 QRP 之一是 p 值操纵，其中调整分析直到达到 \\(p&lt;\\) 0.05 的传统显着性阈值。这可以包括删除异常值的方式、亚组分析或缺失数据处理。\n\n另一个 QRP 是 HARKing [@kerr1998harking]，它代表 在结果已知后提出假设。HARKing 的一种方法是假装探索性分析中的发现一直是该研究的先验假设。例如，研究人员可以在数据集上运行各种测试，然后围绕所有显着的测试“发明”假设。这是一种严重错误的方，会增加研究的错误发现率，从而增加虚假发现的风险（仅举几个问题）。另一种类型的 HARKing 是删除所有数据不支持的假设，这最终可能导致结果报告偏倚。\n\n\n\n\n\n很明显，发表偏倚、其他报告偏倚和 QRP 可能会对我们元分析的有效性产生强烈和有害的影响。它们构成了主要的挑战，因为通常实际上不可能知道偏倚的确切大小——或者它是否根本存在。\n \n在元分析中，我们可以应用一些技术，这些技术可以在一定程度上降低由于发表和报告偏倚以及 QRP 造成的扭曲的风险。其中一些方法与研究搜索有关，而另一些是统计方法。\n\n研究搜索。在第 @ref(study-search) 章中，我们讨论了搜索符合条件的研究的过程。如果存在发表偏倚，则此步骤非常重要，因为这意味着对已发表文献的搜索可能会产生不能完全代表所有证据的数据。我们可以通过搜索灰色文献来抵消这一点，其中包括论文、预印本、政府报告或会议记录。幸运的是，预注册在许多学科中也变得越来越普遍。这使得可以搜索研究注册表，例如 ICTRP 或 OSF 注册表（参见第 @ref(study-search) 章中的表 @ref(tab:bibdatabases)），以查找具有未发表数据的研究，并询问作者是否可以向我们提供尚未公开的数据1。灰色文献搜索可能既乏味又令人沮丧，但值得付出努力。一项大型研究发现，纳入灰色和未发表的文献可以帮助避免高估真实效应 [@mcauley2000does]。\n统计方法。也可以通过统计程序检查发表的存在。这些方法都不能直接识别发表偏倚，但它们可以检查我们数据的某些属性，这些属性可能表明存在发表偏倚。当校正发表偏倚时，一些方法也可以用于量化真实的总体效应。\n\n\n在本章中，我们将展示评估和控制发表偏倚的常用统计方法。我们首先介绍侧重于小型研究效应的方法 [@sterne2000publication; @schwarzer2015meta，第 5 章；@duval2005publication，第 5 章]。这些方法的一个共同点是通过查看研究的精度和观察到的效应量之间的关系来查找发表偏倚的指标。\n\n\n\n\n有各种小型研究效应方法来评估和校正元分析中的发表偏倚。多年来，许多技术一直沿用至今。正如其名称所说，这些方法特别关注小型研究。从统计学角度来看，这转化为具有较高标准误差的研究。小型研究效应方法假定小型研究更有可能成为发表偏倚的牺牲品。\n该假设基于三个核心思想 [参见 @borenstein2011introduction，第 30 章]：\n\n\n由于它们涉及大量资源和时间投入，因此大型研究很可能会发表，无论结果是否具有统计学意义。\n中等规模的研究更有可能不被发表。但是，即使统计功效仅为中等，通常也足以产生显着结果。这意味着只有一些研究不会被发表，因为它们提供了“不受欢迎”（即不显着）的结果。\n小型研究产生不显着结果的风险最高，因此仍然留在“抽屉文件”中。在小型研究中，只有非常大的效应才会变得显着。这意味着只有具有非常高效应量的小型研究才会被发表。\n\n我们看到这些假设背后的所谓机制非常简单。本质上，它表示存在发表偏倚，因为只有显着效应才会发表。由于获得显着结果的概率随着样本量的增加而增加，因此发表偏倚将不成比例地影响小型研究。\n\n\n\n\n\n在本指南的前面（第 @ref(what-is-es) 章），我们了解到研究的样本量和标准误差密切相关。效应量较大的标准误差会导致置信区间较宽，并增加效应不具有统计学意义的可能性。因此，假设小型研究效应将在很大程度上影响具有较大标准误差的研究是合理的。\n假设我们收集的数据受到发表偏倚的影响。如果是这种情况，我们可以假设具有较大标准误差的研究的效应量高于具有较小标准误差的研究。这是因为效应较小的小型研究不显着，因此从未考虑发表。因此，我们从未将它们纳入我们的元分析中。\n通常通过漏斗图检查小型研究效应。漏斗图是一个散点图，其中研究的观察到的效应量在 x 轴上，并以其标准误差的度量为 y 轴。通常，漏斗图中的 y 轴是倒置的（意味着 y 轴上的“较高”值表示较低标准误差）。\n当没有发表偏倚时，此类图中的数据点应形成大致对称的倒漏斗。这就是为什么它们被称为漏斗图。该图顶部（标准误差较低的那些）的研究应紧密地排列在一起，并且离合并效应量不远。在该图的下部，随着标准误差的增加，漏斗“打开”，并且预期效应量会更严重地散布在合并效应的左右两侧。\n当我们回想起我们在第 @ref(what-is-es) 章中学到的关于效应量的行为时，以及在第 @ref(fem) 章中讨论固定效应模型时（图 @ref(fig:funnel1)），更容易看到为什么研究应该形成漏斗。标准误差表明研究的精度：随着标准误差的降低，我们期望观察到的效应量越来越好地估计真实效应量。当标准误差较高时，效应量具有较低的精度，因此更有可能与人群中的实际效应相差甚远。\n我们现在将通过生成我们自己的漏斗图来使这更加具体。在 {meta} 包中，可以使用 meta::funnel2 函数来为元分析对象打印漏斗图。在这里，我们为我们的 m.gen 元分析对象生成一个漏斗图。我们指定了两个进一步的参数 xlim 和 studlab。第一个控制图中 x 轴的限制，而第二个告诉函数包括研究标签。运行 meta::funnel 后调用 title 函数会将标题添加到图中。\n我们的代码如下所示：\n```{r, message=F, fig.width=8, fig.height=6, out.width=“85%”, collapse = TRUE, results=‘hold’, fig.align=‘center’, eval = F} # 加载“meta”包 library(meta)\n# 生成漏斗图 meta::funnel(m.gen, xlim = c(-0.5, 2), studlab = TRUE)\n# 添加标题 title(“漏斗图（第三代心理疗法）”)\n```\n```{r, message=F, fig.width=8, fig.height=6, out.width=“85%”, collapse = TRUE, results=‘hold’, fig.align=‘center’, echo=F} # 加载“meta”包 library(meta)\npar(bg=“#FFFEFA”) # 生成漏斗图 meta::funnel(m.gen, xlim = c(-0.5, 2), studlab = TRUE)\n# 添加标题 title(“漏斗图（第三代心理疗法）”)\n```\n如所讨论的，生成的漏斗图显示了每项研究的效应量（表示为标准化平均差）在 x 轴上，以及标准误差（从大到小）在 y 轴上。为了便于解释，该图还包括我们期望我们的研究遵循的理想化漏斗形状。漏斗中间的垂直线显示了平均效应量。因为我们在生成 m.gen 时使用了随机效应模型，所以漏斗图也使用了随机效应估计。\n在不存在小型研究效应的情况下，我们的研究应大致遵循该图表中描绘的漏斗形状。在我们的例子中是这样吗？好吧，并非如此。虽然我们看到标准误差较低的研究更集中地位于估计的真实效应附近，但总体模式看起来不对称。这是因为在该图右下角有三项效应量非常高的小型研究（Shapiro、Kang 和 Danitz-Orsillo 的研究）。\n然而，这些研究在该图的左下角没有等效的研究。没有效应非常低或负面的小型研究来“平衡”那些效应非常高的研究。另一个令人担忧的细节是，我们样本中精度最高的 de Vibe 的研究似乎也没有很好地遵循漏斗模式。它的效应量比预期的要小得多。\n总体而言，数据集在漏斗图中显示出不对称的模式，这可能表明存在发表偏倚。可能是这三项小型研究很幸运地发现了足够高的效应，从而变得显着，但在未发表的研究中，存在一个具有类似标准误差的底层，但效应更小且因此不显着，没有通过筛选。\n检查不对称模式如何与统计学显着性相关的一个好方法是生成轮廓增强漏斗图 [@peters2008contour]。此类图可以帮助区分发表偏倚和其他形式的不对称。轮廓增强漏斗图包括颜色，这些颜色表示图中每项研究的显着性水平。在 meta::funnel 函数中，可以通过将所需的显着性阈值提供给 contour 参数来添加轮廓。通常，这些阈值为 0.9、0.95 和 0.99，分别等于 \\(p\\) &lt; 0.1、0.05 和 0.01。使用 col.contour 参数，我们还可以指定轮廓应具有的颜色。最后，之后可以使用 legend 函数将图例添加到图中，指定不同颜色的含义。我们可以使用 x 和 y 参数将图例放置在图上，在 legend 中提供标签，并使用 fill 参数添加填充颜色。\n这会产生以下代码：\n```{r, fig.width=8, fig.height=6, out.width=“82%”, collapse=TRUE, fig.align=‘center’, eval=F} # 定义轮廓的填充颜色 col.contour = c(“gray75”, “gray85”, “gray95”)\n# 生成漏斗图（我们在此处不包括研究标签） meta::funnel(m.gen, xlim = c(-0.5, 2), contour = c(0.9, 0.95, 0.99), col.contour = col.contour)\n# 添加图例 legend(x = 1.6, y = 0.01, legend = c(“p &lt; 0.1”, “p &lt; 0.05”, “p &lt; 0.01”), fill = col.contour)\n# 添加标题 title(“轮廓增强漏斗图（第三代心理疗法）”)\n```\n```{r, fig.width=8, fig.height=6, out.width=“75%”, collapse=TRUE, fig.align=‘center’, echo=F} # 定义轮廓的填充颜色 col.contour = c(“gray75”, “gray85”, “gray95”)\npar(bg=“#FFFEFA”) # 生成漏斗图（我们在此处不包括研究标签） meta::funnel(m.gen, xlim = c(-0.5, 2), contour = c(0.9, 0.95, 0.99), col.contour = col.contour)\n# 添加图例 legend(x = 1.6, y = 0.01, legend = c(“p &lt; 0.1”, “p &lt; 0.05”, “p &lt; 0.01”), fill = col.contour)\n# 添加标题 title(“轮廓增强漏斗图（第三代心理疗法）”)\n```\n我们看到漏斗图现在包含三个阴影区域。我们特别关注 \\(p&lt;\\) 0.05 和 \\(p&lt;\\) 0.01 区域，因为落入该区域的效应量传统上被认为是显着的。\n添加轮廓区域是有启发性的：它表明这三项小型研究都具有显着效应，尽管具有较大的标准误差。只有一项具有类似标准误差的研究不显着。如果我们在图的左下角“估算”缺失的研究以增加对称性，这些研究将位于该图的不显着区域中；或者它们实际上会产生显着的负面影响。\n较大研究的模式看起来略有不同。我们看到有几项研究的 \\(p&gt;\\) 0.05，并且效应的分布不太倾斜。尽管如此，可能存在问题的是，除了一个研究之外，所有研究都非常接近显着性阈值（即，它们位于 0.1 \\(&gt; p &gt;\\) 0.05 区域中）。这些研究可能只是在原始论文中以不同的方式计算了效应量，这导致了显着的结果。或者，也许发现趋势水平上显着的效应已经足以使该研究发表。\n总之，对轮廓增强漏斗图的检查证实了我们最初的直觉，即漏斗图中存在不对称，这可能是由发表偏倚引起的。但是，至关重要的是不要妄下结论，并谨慎地解释漏斗图。我们必须牢记，发表偏倚只是漏斗图不对称的众多可能原因之一。\n\n```{block, type=‘boxinfo’} 漏斗图不对称的替代解释\n虽然发表偏倚会导致不对称的漏斗图，但也有其他更“良性”的原因可能会产生类似的模式 [@page2020investigating]：\n\n不对称也可能由研究间的异质性引起。漏斗图假定效应量的分散是由研究的抽样误差引起的，但不控制研究可能是不同真实效应的估计量这一事实。\n\n\n小型研究中的研究程序可能有所不同，这导致了更高的效应。例如，在临床研究中，当样本量较小时，更容易确保每个参与者都按预期接受治疗。大型研究可能并非如此，导致治疗保真度较低，从而导致较低的效应。检查纳入研究的特征以评估这种替代解释是否合理是有意义的。\n\n\n一个常见的发现是，低质量的研究往往会显示出更大的效应量，因为存在更高的偏倚风险。大型研究需要更多的投资，因此它们的方法论也可能更严格。即使没有发表偏倚，这也可能导致漏斗图不对称。\n\n\n最后，完全有可能漏斗图不对称仅仅是偶然发生的。\n\n```\n\n我们看到，仅通过查看（轮廓增强）漏斗图的视觉检查就已经可以为我们提供一些“危险信号”，表明我们的结果可能受到发表偏倚的影响。\n但是，仅通过查看来解释漏斗图显然也有其局限性。当我们的结果“过于不对称”时，没有明确的规则，这意味着来自漏斗图的推论总是有些主观。因此，以定量方式评估漏斗图不对称的存在是有帮助的。这通常通过 Egger 的回归检验来实现，我们将在接下来讨论。\n\n\n\n\n\nEgger 的回归检验 [@egger1997bias] 是一种常用的定量方法，用于检验漏斗图中的不对称。与漏斗图的视觉检查一样，它只能识别小型研究效应，而不能直接告诉我们是否存在发表偏倚。该检验基于一个简单的线性回归模型，其公式如下所示：\n\\[\\begin{equation}\n\\frac{\\hat\\theta_k}{SE_{\\hat\\theta_k}} = \\beta_0 + \\beta_1 \\frac{1}{SE_{\\hat\\theta_k}}\n(\\#eq:pub1)\n\\end{equation}\\]\n此公式中的响应 \\(y\\) 是我们的元分析中观察到的效应量 \\(\\hat\\theta_k\\)，除以其标准误差。生成的值等效于 \\(z\\) 分数。这些分数直接告诉我们效应量是否显着；当 \\(z \\geq\\) 1.96 或 \\(\\leq\\) -1.96 时，我们知道该效应是显着的 (\\(p&lt;\\) 0.05)。此响应根据研究的标准误差的倒数进行回归，该倒数等效于它们的精度。\n但是，当使用 Egger 的检验时，我们对回归权重 \\(\\beta_1\\) 的大小和显着性不感兴趣，而是对截距 \\(\\beta_0\\) 感兴趣。为了评估漏斗不对称，我们检查 \\(\\hat\\beta_0\\) 的大小，以及它是否与零显着不同。当这种情况发生时，Egger 的检验表明漏斗图不对称。\n让我们花点时间来理解为什么回归截距的大小告诉我们一些关于漏斗图不对称的信息。在每个线性回归模型中，截距表示当所有其他预测变量为零时 \\(y\\) 的值。我们模型中的预测变量是研究的精度，因此截距显示了当精度为零时（即当研究的标准误差无限大时）预期的 \\(z\\) 分数。\n当没有发表偏倚时，预期的 \\(z\\) 分数应分散在零附近。这是因为具有极其大的标准误差的研究具有极其大的置信区间，使得几乎不可能达到 \\(|z| \\geq\\) 1.96 的值。但是，当漏斗图不对称时，例如由于发表偏倚，我们期望具有非常高效应量的小型研究在我们数据中将被过度表示，从而导致数量惊人的低精度研究，\\(z\\) 值大于或等于 1.96。由于这种扭曲，零精度 \\(y\\) 的预测值将远大于零，从而导致显着的截距。\n下图说明了漏斗图不对称对 Egger 检验的回归斜率和截距的影响。\n```{r eggers_alt, echo=F, out.width=“50%”, message=F, warning=F, fig.width=6, fig.height=5, eval=F} library(ggplot2)\nload(“data/m.egdat.rda”) load(“data/m.egdat.bias.rda”)\nmeta::funnel(m.egdat, xlab = “Effect Size”) title(“漏斗图（无不对称）”)\nm.egdat$data %&gt;%&gt; mutate(y = .TE/.seTE, x = 1/.seTE) %&gt;%&gt; ggplot(aes(y = y, x = x)) + xlim(c(0, 110)) + #ylim(c(0, 110)) + geom_point(fill = “grey”, pch=21) + geom_smooth(method = “lm”, se = F, fullrange = T, color = “black”) + theme_minimal() + ylab(“缩放效应量 (z)”) + xlab(“标准误差的倒数（精度）”) + annotate(“text”, x = 3, y = 33, label = bquote(hat(beta)[0]“=”0.21), hjust = “left”, cex = 6) + annotate(geom = “curve”, x = 0, y = 0.21, xend = 5, yend = 30, curvature = .3, arrow = arrow(length = unit(2, “mm”)), linetype = “dashed”) + ggtitle(“回归线（无不对称）”) + theme(plot.title = element_text(color=“black”, size=14, face=“bold”, hjust = 0.5), plot.margin = margin(1.08, 1, 1.08, 1, “cm”), plot.background = element_rect(fill = “#FFFEFA”, color = “#fbfbfb”), panel.background = element_rect(fill = “#FFFEFA”)) # ‘nearly-white’ used to keep knitr from cropping\nmeta::funnel(m.egdat.bias, xlab = “Effect Size”) title(“漏斗图（不对称）”)\nm.egdat.bias$data %&gt;%&gt; mutate(y = .TE/.seTE, x = 1/.seTE) %&gt;%&gt; ggplot(aes(y = y, x = x)) + xlim(c(0, 9)) + ylim(c(0,6)) + geom_point(fill = “grey”, pch=21) + geom_smooth(method = “lm”, se = F, fullrange = T, color = “black”) + theme_minimal() + ylab(“缩放效应量 (z)”) + xlab(“标准误差的倒数（精度）”) + annotate(“text”, x = 0.8, y = 0.5, label = bquote(hat(beta)[0]“=”2.85), hjust = “left”, cex = 6) + annotate(geom = “curve”, x = 0, y = 2.85, xend = 0.7, yend = 0.7, curvature = .3, arrow = arrow(length = unit(2, “mm”)), linetype = “dashed”) + ggtitle(“回归线（不对称）”) + theme(plot.title = element_text(color=“black”, size=14, face=“bold”, hjust = 0.5), plot.margin = margin(1.08, 1, 1.08, 1, “cm”), plot.background = element_rect(fill = “#feffff”, color = “#fbfbfb”), panel.background = element_rect(fill = “#feffff”)) # ‘nearly-white’ used to keep knitr from cropping\n```\n```{r eggers, echo=F, out.width=“50%”, message=F, warning=F, fig.width=6, fig.height=5} library(OpenImageR) knitr::include_graphics(‘images/eggers-1_sep.png’) knitr::include_graphics(‘images/eggers-2_sep.png’) knitr::include_graphics(‘images/eggers-3_sep.png’) knitr::include_graphics(‘images/eggers-4_sep.png’) ```\n\n让我们看看当我们对 m.gen 中的数据拟合这样的回归模型时会得到什么结果。使用 R，我们可以提取 m.gen 中的原始数据来计算响应 y 和我们的预测变量 x。在下面的代码中，我们使用管道（第 @ref(data-transform) 章）和 mutate 函数来执行此操作，该函数是 {tidyverse} 的一部分。之后，我们使用线性模型函数 lm 将 \\(z\\) 分数 y 回归到精度 x 上。在管道的最后一部分中，我们请求结果的 summary。\n```{r, eval = F} # 加载所需的包 library(tidyverse)\nm.gen$data %&gt;%&gt; mutate(y = TE/seTE, x = 1/seTE) %&gt;%&gt; lm(y ~ x, data = .) %&gt;%&gt; summary()\n```\n## [...]\n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)   4.1111     0.8790   4.677 0.000252 ***\n## x            -0.3407     0.1837  -1.855 0.082140 .  \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n## \n## [...]\n在结果中，我们看到我们的回归模型的截距为 \\(\\hat\\beta_0\\) = 4.11。这远大于零 (\\(t\\) = 4.677, \\(p&lt;\\) 0.001)，并且表明漏斗图中的数据确实不对称。总体而言，这证实了我们最初的发现，即存在小型研究效应。但是，重申一下，不确定这种模式是否是由发表偏倚引起的。\n执行 Egger 截距检验的更便捷方法是使用 {meta} 中的 metabias 函数。此函数仅需要元分析对象作为输入，并且我们必须将 method.bias 参数设置为 \"linreg\"。如果我们将该函数应用于 m.gen，我们会得到与之前相同的结果。\n```{r} metabias(m.gen, method.bias = “linreg”) ```\n```{block2, type=‘boxreport’} 报告 Egger 检验的结果\n对于 Egger 检验，通常足以报告截距的值、其 95% 置信区间，以及 \\(t\\) 值和 \\(p\\) 值。在 {dmetar} 包中，我们包含了一个名为 eggers.test 的便捷函数。此函数是 metabias 的包装器，并以适合报告的格式提供 Egger 检验的结果。如果您没有安装 {dmetar}，您可以在 在线 找到该函数的源代码。这是一个例子：\neggers.test(m.gen)\n\n\n\n\n\n\n\n\n\n\n\\(~\\)\n截距\n置信区间\nt\np\n\n\n\n\nEgger 检验\n4.111\n2.347-5.875\n4.677\n0.00025\n\n\n\n```\n\nm.gen 中使用的效应量度量是小样本偏倚校正的 SMD（Hedges’ \\(g\\)）。有人认为，在 SMD 上运行 Egger 检验可能导致假阳性结果膨胀 [@pustejovsky2019testing]。这是因为研究的标准化平均差和标准误差不是独立的。\n我们可以通过查看用于计算组间 SMD 标准误差的公式（公式 3.18，第 @ref(b-group-smd) 章）轻松地看到这一点。此公式包括 SMD 本身，这意味着研究的标准误差会随着观察到的效应的大小而变化（即 SMD 与其标准误差之间存在人为的相关性）。\nPustejovsky 和 Rodgers [-@pustejovsky2019testing] 建议在检验标准化平均差的漏斗图不对称时使用标准误差的修改版本。仅使用标准误差公式的第一部分，这意味着观察到的效应量会从等式中删除。因此，该公式如下所示：\n\\[\\begin{equation}\nSE^*_{\\text{SMD}_{\\text{between}}}= \\sqrt{\\frac{n_1+n_2}{n_1n_2}}\n(\\#eq:pub2)\n\\end{equation}\\]\n其中 $SE^*_{\\text{SMD",
    "crumbs": [
      "网站首页",
      "发表偏倚"
    ]
  },
  {
    "objectID": "11-publication-bias.html#types-of-pub-biases",
    "href": "11-publication-bias.html#types-of-pub-biases",
    "title": "发表偏倚",
    "section": "",
    "text": "当一项研究的发表概率受到其结果的影响时，就存在发表偏倚 [@duval2005publication，第 2 章和第 5 章]。有大量证据表明，如果一项研究的发现具有统计学意义，或者证实了最初的假设，那么它更有可能进入公众视野 [@schmucker2014extent; @scherer2018full; @chan2014increasing; @dechartres2018association]。\n在搜索符合条件的研究时，我们通常仅限于以某种形式公开的证据，例如通过同行评审的文章、预印本、书籍或其他类型的可访问报告。在存在发表偏倚的情况下，这不仅意味着我们的数据集中缺少一些研究——这也意味着缺失的研究很可能是那些具有不利发现的研究。\n元分析技术使我们能够找到人群中平均效应量的无偏估计。但是，如果我们的样本本身被扭曲，那么即使从统计学角度来看是“真实”的效应估计也不会代表现实。这就像试图估计冰山的大小，但只测量它的尖端：我们的发现不可避免地会出错，即使我们能够以完美的精度测量水面以上的高度。\n \n发表偏倚实际上只是众多非报告偏倚之一。还有其他几个因素也会扭曲我们在元分析中获得的证据 [@page2020investigating]，包括：\n\n引用偏倚：即使已发表，具有负面或不确定结果的研究也不太可能被相关文献引用。这使得例如通过参考文献搜索更难检测到它们。\n时滞偏倚：具有积极结果的研究通常比具有不利结果的研究发表得更早。这意味着最近进行的具有积极结果的研究的发现通常已经可用，而那些具有不显着结果的研究则不可用。\n多次发表偏倚：“成功”研究的结果更有可能在多篇期刊文章中报告，这使得至少找到其中一篇更容易。“香肠切片”也称为跨多篇文章报告研究发现的做法。\n语言偏倚：在大多数学科中，发表证据的主要语言是英语。以其他语言发表的出版物不太可能被检测到，尤其是当研究人员自己无法在不翻译的情况下理解内容时。如果英语研究与以其他语言发表的研究系统性地不同，这也会引入偏倚。\n结果报告偏倚：许多研究，尤其是临床试验，测量不止一个感兴趣的结果。一些研究人员利用这一点，只报告那些获得积极结果的结果，而那些未证实假设的结果则被删除。这也可能导致偏倚：从技术上讲，该研究已经发表，但其（不利的）结果仍将在我们的元分析中缺失，因为它未被报告。\n\n\n非报告偏倚可以被视为系统性因素，使我们更难以找到现有的证据。但是，即使我们能够包括所有相关的发现，我们的结果可能仍然存在缺陷。由于研究人员在分析和报告他们的发现时应用了可疑的研究实践 (QRP)，因此也可能存在偏倚 [@simonsohn2020specification]。\n\n我们之前已经提到了“研究人员的自由度”的概念（第 @ref(pitfalls) 章）。QRP 可以定义为研究人员滥用这些自由度将结果“弯曲”到所需方向的做法。不幸的是，对于什么是 QRP 尚无明确的共识。但是，有一些常见的建议示例。\n最突出的 QRP 之一是 p 值操纵，其中调整分析直到达到 \\(p&lt;\\) 0.05 的传统显着性阈值。这可以包括删除异常值的方式、亚组分析或缺失数据处理。\n\n另一个 QRP 是 HARKing [@kerr1998harking]，它代表 在结果已知后提出假设。HARKing 的一种方法是假装探索性分析中的发现一直是该研究的先验假设。例如，研究人员可以在数据集上运行各种测试，然后围绕所有显着的测试“发明”假设。这是一种严重错误的方，会增加研究的错误发现率，从而增加虚假发现的风险（仅举几个问题）。另一种类型的 HARKing 是删除所有数据不支持的假设，这最终可能导致结果报告偏倚。",
    "crumbs": [
      "网站首页",
      "发表偏倚"
    ]
  },
  {
    "objectID": "11-publication-bias.html#addressing-pubbias",
    "href": "11-publication-bias.html#addressing-pubbias",
    "title": "发表偏倚",
    "section": "",
    "text": "很明显，发表偏倚、其他报告偏倚和 QRP 可能会对我们元分析的有效性产生强烈和有害的影响。它们构成了主要的挑战，因为通常实际上不可能知道偏倚的确切大小——或者它是否根本存在。\n \n在元分析中，我们可以应用一些技术，这些技术可以在一定程度上降低由于发表和报告偏倚以及 QRP 造成的扭曲的风险。其中一些方法与研究搜索有关，而另一些是统计方法。\n\n研究搜索。在第 @ref(study-search) 章中，我们讨论了搜索符合条件的研究的过程。如果存在发表偏倚，则此步骤非常重要，因为这意味着对已发表文献的搜索可能会产生不能完全代表所有证据的数据。我们可以通过搜索灰色文献来抵消这一点，其中包括论文、预印本、政府报告或会议记录。幸运的是，预注册在许多学科中也变得越来越普遍。这使得可以搜索研究注册表，例如 ICTRP 或 OSF 注册表（参见第 @ref(study-search) 章中的表 @ref(tab:bibdatabases)），以查找具有未发表数据的研究，并询问作者是否可以向我们提供尚未公开的数据1。灰色文献搜索可能既乏味又令人沮丧，但值得付出努力。一项大型研究发现，纳入灰色和未发表的文献可以帮助避免高估真实效应 [@mcauley2000does]。\n统计方法。也可以通过统计程序检查发表的存在。这些方法都不能直接识别发表偏倚，但它们可以检查我们数据的某些属性，这些属性可能表明存在发表偏倚。当校正发表偏倚时，一些方法也可以用于量化真实的总体效应。\n\n\n在本章中，我们将展示评估和控制发表偏倚的常用统计方法。我们首先介绍侧重于小型研究效应的方法 [@sterne2000publication; @schwarzer2015meta，第 5 章；@duval2005publication，第 5 章]。这些方法的一个共同点是通过查看研究的精度和观察到的效应量之间的关系来查找发表偏倚的指标。\n\n\n\n\n有各种小型研究效应方法来评估和校正元分析中的发表偏倚。多年来，许多技术一直沿用至今。正如其名称所说，这些方法特别关注小型研究。从统计学角度来看，这转化为具有较高标准误差的研究。小型研究效应方法假定小型研究更有可能成为发表偏倚的牺牲品。\n该假设基于三个核心思想 [参见 @borenstein2011introduction，第 30 章]：\n\n\n由于它们涉及大量资源和时间投入，因此大型研究很可能会发表，无论结果是否具有统计学意义。\n中等规模的研究更有可能不被发表。但是，即使统计功效仅为中等，通常也足以产生显着结果。这意味着只有一些研究不会被发表，因为它们提供了“不受欢迎”（即不显着）的结果。\n小型研究产生不显着结果的风险最高，因此仍然留在“抽屉文件”中。在小型研究中，只有非常大的效应才会变得显着。这意味着只有具有非常高效应量的小型研究才会被发表。\n\n我们看到这些假设背后的所谓机制非常简单。本质上，它表示存在发表偏倚，因为只有显着效应才会发表。由于获得显着结果的概率随着样本量的增加而增加，因此发表偏倚将不成比例地影响小型研究。\n\n\n\n\n\n在本指南的前面（第 @ref(what-is-es) 章），我们了解到研究的样本量和标准误差密切相关。效应量较大的标准误差会导致置信区间较宽，并增加效应不具有统计学意义的可能性。因此，假设小型研究效应将在很大程度上影响具有较大标准误差的研究是合理的。\n假设我们收集的数据受到发表偏倚的影响。如果是这种情况，我们可以假设具有较大标准误差的研究的效应量高于具有较小标准误差的研究。这是因为效应较小的小型研究不显着，因此从未考虑发表。因此，我们从未将它们纳入我们的元分析中。\n通常通过漏斗图检查小型研究效应。漏斗图是一个散点图，其中研究的观察到的效应量在 x 轴上，并以其标准误差的度量为 y 轴。通常，漏斗图中的 y 轴是倒置的（意味着 y 轴上的“较高”值表示较低标准误差）。\n当没有发表偏倚时，此类图中的数据点应形成大致对称的倒漏斗。这就是为什么它们被称为漏斗图。该图顶部（标准误差较低的那些）的研究应紧密地排列在一起，并且离合并效应量不远。在该图的下部，随着标准误差的增加，漏斗“打开”，并且预期效应量会更严重地散布在合并效应的左右两侧。\n当我们回想起我们在第 @ref(what-is-es) 章中学到的关于效应量的行为时，以及在第 @ref(fem) 章中讨论固定效应模型时（图 @ref(fig:funnel1)），更容易看到为什么研究应该形成漏斗。标准误差表明研究的精度：随着标准误差的降低，我们期望观察到的效应量越来越好地估计真实效应量。当标准误差较高时，效应量具有较低的精度，因此更有可能与人群中的实际效应相差甚远。\n我们现在将通过生成我们自己的漏斗图来使这更加具体。在 {meta} 包中，可以使用 meta::funnel2 函数来为元分析对象打印漏斗图。在这里，我们为我们的 m.gen 元分析对象生成一个漏斗图。我们指定了两个进一步的参数 xlim 和 studlab。第一个控制图中 x 轴的限制，而第二个告诉函数包括研究标签。运行 meta::funnel 后调用 title 函数会将标题添加到图中。\n我们的代码如下所示：\n```{r, message=F, fig.width=8, fig.height=6, out.width=“85%”, collapse = TRUE, results=‘hold’, fig.align=‘center’, eval = F} # 加载“meta”包 library(meta)\n# 生成漏斗图 meta::funnel(m.gen, xlim = c(-0.5, 2), studlab = TRUE)\n# 添加标题 title(“漏斗图（第三代心理疗法）”)\n```\n```{r, message=F, fig.width=8, fig.height=6, out.width=“85%”, collapse = TRUE, results=‘hold’, fig.align=‘center’, echo=F} # 加载“meta”包 library(meta)\npar(bg=“#FFFEFA”) # 生成漏斗图 meta::funnel(m.gen, xlim = c(-0.5, 2), studlab = TRUE)\n# 添加标题 title(“漏斗图（第三代心理疗法）”)\n```\n如所讨论的，生成的漏斗图显示了每项研究的效应量（表示为标准化平均差）在 x 轴上，以及标准误差（从大到小）在 y 轴上。为了便于解释，该图还包括我们期望我们的研究遵循的理想化漏斗形状。漏斗中间的垂直线显示了平均效应量。因为我们在生成 m.gen 时使用了随机效应模型，所以漏斗图也使用了随机效应估计。\n在不存在小型研究效应的情况下，我们的研究应大致遵循该图表中描绘的漏斗形状。在我们的例子中是这样吗？好吧，并非如此。虽然我们看到标准误差较低的研究更集中地位于估计的真实效应附近，但总体模式看起来不对称。这是因为在该图右下角有三项效应量非常高的小型研究（Shapiro、Kang 和 Danitz-Orsillo 的研究）。\n然而，这些研究在该图的左下角没有等效的研究。没有效应非常低或负面的小型研究来“平衡”那些效应非常高的研究。另一个令人担忧的细节是，我们样本中精度最高的 de Vibe 的研究似乎也没有很好地遵循漏斗模式。它的效应量比预期的要小得多。\n总体而言，数据集在漏斗图中显示出不对称的模式，这可能表明存在发表偏倚。可能是这三项小型研究很幸运地发现了足够高的效应，从而变得显着，但在未发表的研究中，存在一个具有类似标准误差的底层，但效应更小且因此不显着，没有通过筛选。\n检查不对称模式如何与统计学显着性相关的一个好方法是生成轮廓增强漏斗图 [@peters2008contour]。此类图可以帮助区分发表偏倚和其他形式的不对称。轮廓增强漏斗图包括颜色，这些颜色表示图中每项研究的显着性水平。在 meta::funnel 函数中，可以通过将所需的显着性阈值提供给 contour 参数来添加轮廓。通常，这些阈值为 0.9、0.95 和 0.99，分别等于 \\(p\\) &lt; 0.1、0.05 和 0.01。使用 col.contour 参数，我们还可以指定轮廓应具有的颜色。最后，之后可以使用 legend 函数将图例添加到图中，指定不同颜色的含义。我们可以使用 x 和 y 参数将图例放置在图上，在 legend 中提供标签，并使用 fill 参数添加填充颜色。\n这会产生以下代码：\n```{r, fig.width=8, fig.height=6, out.width=“82%”, collapse=TRUE, fig.align=‘center’, eval=F} # 定义轮廓的填充颜色 col.contour = c(“gray75”, “gray85”, “gray95”)\n# 生成漏斗图（我们在此处不包括研究标签） meta::funnel(m.gen, xlim = c(-0.5, 2), contour = c(0.9, 0.95, 0.99), col.contour = col.contour)\n# 添加图例 legend(x = 1.6, y = 0.01, legend = c(“p &lt; 0.1”, “p &lt; 0.05”, “p &lt; 0.01”), fill = col.contour)\n# 添加标题 title(“轮廓增强漏斗图（第三代心理疗法）”)\n```\n```{r, fig.width=8, fig.height=6, out.width=“75%”, collapse=TRUE, fig.align=‘center’, echo=F} # 定义轮廓的填充颜色 col.contour = c(“gray75”, “gray85”, “gray95”)\npar(bg=“#FFFEFA”) # 生成漏斗图（我们在此处不包括研究标签） meta::funnel(m.gen, xlim = c(-0.5, 2), contour = c(0.9, 0.95, 0.99), col.contour = col.contour)\n# 添加图例 legend(x = 1.6, y = 0.01, legend = c(“p &lt; 0.1”, “p &lt; 0.05”, “p &lt; 0.01”), fill = col.contour)\n# 添加标题 title(“轮廓增强漏斗图（第三代心理疗法）”)\n```\n我们看到漏斗图现在包含三个阴影区域。我们特别关注 \\(p&lt;\\) 0.05 和 \\(p&lt;\\) 0.01 区域，因为落入该区域的效应量传统上被认为是显着的。\n添加轮廓区域是有启发性的：它表明这三项小型研究都具有显着效应，尽管具有较大的标准误差。只有一项具有类似标准误差的研究不显着。如果我们在图的左下角“估算”缺失的研究以增加对称性，这些研究将位于该图的不显着区域中；或者它们实际上会产生显着的负面影响。\n较大研究的模式看起来略有不同。我们看到有几项研究的 \\(p&gt;\\) 0.05，并且效应的分布不太倾斜。尽管如此，可能存在问题的是，除了一个研究之外，所有研究都非常接近显着性阈值（即，它们位于 0.1 \\(&gt; p &gt;\\) 0.05 区域中）。这些研究可能只是在原始论文中以不同的方式计算了效应量，这导致了显着的结果。或者，也许发现趋势水平上显着的效应已经足以使该研究发表。\n总之，对轮廓增强漏斗图的检查证实了我们最初的直觉，即漏斗图中存在不对称，这可能是由发表偏倚引起的。但是，至关重要的是不要妄下结论，并谨慎地解释漏斗图。我们必须牢记，发表偏倚只是漏斗图不对称的众多可能原因之一。\n\n```{block, type=‘boxinfo’} 漏斗图不对称的替代解释\n虽然发表偏倚会导致不对称的漏斗图，但也有其他更“良性”的原因可能会产生类似的模式 [@page2020investigating]：\n\n不对称也可能由研究间的异质性引起。漏斗图假定效应量的分散是由研究的抽样误差引起的，但不控制研究可能是不同真实效应的估计量这一事实。\n\n\n小型研究中的研究程序可能有所不同，这导致了更高的效应。例如，在临床研究中，当样本量较小时，更容易确保每个参与者都按预期接受治疗。大型研究可能并非如此，导致治疗保真度较低，从而导致较低的效应。检查纳入研究的特征以评估这种替代解释是否合理是有意义的。\n\n\n一个常见的发现是，低质量的研究往往会显示出更大的效应量，因为存在更高的偏倚风险。大型研究需要更多的投资，因此它们的方法论也可能更严格。即使没有发表偏倚，这也可能导致漏斗图不对称。\n\n\n最后，完全有可能漏斗图不对称仅仅是偶然发生的。\n\n```\n\n我们看到，仅通过查看（轮廓增强）漏斗图的视觉检查就已经可以为我们提供一些“危险信号”，表明我们的结果可能受到发表偏倚的影响。\n但是，仅通过查看来解释漏斗图显然也有其局限性。当我们的结果“过于不对称”时，没有明确的规则，这意味着来自漏斗图的推论总是有些主观。因此，以定量方式评估漏斗图不对称的存在是有帮助的。这通常通过 Egger 的回归检验来实现，我们将在接下来讨论。\n\n\n\n\n\nEgger 的回归检验 [@egger1997bias] 是一种常用的定量方法，用于检验漏斗图中的不对称。与漏斗图的视觉检查一样，它只能识别小型研究效应，而不能直接告诉我们是否存在发表偏倚。该检验基于一个简单的线性回归模型，其公式如下所示：\n\\[\\begin{equation}\n\\frac{\\hat\\theta_k}{SE_{\\hat\\theta_k}} = \\beta_0 + \\beta_1 \\frac{1}{SE_{\\hat\\theta_k}}\n(\\#eq:pub1)\n\\end{equation}\\]\n此公式中的响应 \\(y\\) 是我们的元分析中观察到的效应量 \\(\\hat\\theta_k\\)，除以其标准误差。生成的值等效于 \\(z\\) 分数。这些分数直接告诉我们效应量是否显着；当 \\(z \\geq\\) 1.96 或 \\(\\leq\\) -1.96 时，我们知道该效应是显着的 (\\(p&lt;\\) 0.05)。此响应根据研究的标准误差的倒数进行回归，该倒数等效于它们的精度。\n但是，当使用 Egger 的检验时，我们对回归权重 \\(\\beta_1\\) 的大小和显着性不感兴趣，而是对截距 \\(\\beta_0\\) 感兴趣。为了评估漏斗不对称，我们检查 \\(\\hat\\beta_0\\) 的大小，以及它是否与零显着不同。当这种情况发生时，Egger 的检验表明漏斗图不对称。\n让我们花点时间来理解为什么回归截距的大小告诉我们一些关于漏斗图不对称的信息。在每个线性回归模型中，截距表示当所有其他预测变量为零时 \\(y\\) 的值。我们模型中的预测变量是研究的精度，因此截距显示了当精度为零时（即当研究的标准误差无限大时）预期的 \\(z\\) 分数。\n当没有发表偏倚时，预期的 \\(z\\) 分数应分散在零附近。这是因为具有极其大的标准误差的研究具有极其大的置信区间，使得几乎不可能达到 \\(|z| \\geq\\) 1.96 的值。但是，当漏斗图不对称时，例如由于发表偏倚，我们期望具有非常高效应量的小型研究在我们数据中将被过度表示，从而导致数量惊人的低精度研究，\\(z\\) 值大于或等于 1.96。由于这种扭曲，零精度 \\(y\\) 的预测值将远大于零，从而导致显着的截距。\n下图说明了漏斗图不对称对 Egger 检验的回归斜率和截距的影响。\n```{r eggers_alt, echo=F, out.width=“50%”, message=F, warning=F, fig.width=6, fig.height=5, eval=F} library(ggplot2)\nload(“data/m.egdat.rda”) load(“data/m.egdat.bias.rda”)\nmeta::funnel(m.egdat, xlab = “Effect Size”) title(“漏斗图（无不对称）”)\nm.egdat$data %&gt;%&gt; mutate(y = .TE/.seTE, x = 1/.seTE) %&gt;%&gt; ggplot(aes(y = y, x = x)) + xlim(c(0, 110)) + #ylim(c(0, 110)) + geom_point(fill = “grey”, pch=21) + geom_smooth(method = “lm”, se = F, fullrange = T, color = “black”) + theme_minimal() + ylab(“缩放效应量 (z)”) + xlab(“标准误差的倒数（精度）”) + annotate(“text”, x = 3, y = 33, label = bquote(hat(beta)[0]“=”0.21), hjust = “left”, cex = 6) + annotate(geom = “curve”, x = 0, y = 0.21, xend = 5, yend = 30, curvature = .3, arrow = arrow(length = unit(2, “mm”)), linetype = “dashed”) + ggtitle(“回归线（无不对称）”) + theme(plot.title = element_text(color=“black”, size=14, face=“bold”, hjust = 0.5), plot.margin = margin(1.08, 1, 1.08, 1, “cm”), plot.background = element_rect(fill = “#FFFEFA”, color = “#fbfbfb”), panel.background = element_rect(fill = “#FFFEFA”)) # ‘nearly-white’ used to keep knitr from cropping\nmeta::funnel(m.egdat.bias, xlab = “Effect Size”) title(“漏斗图（不对称）”)\nm.egdat.bias$data %&gt;%&gt; mutate(y = .TE/.seTE, x = 1/.seTE) %&gt;%&gt; ggplot(aes(y = y, x = x)) + xlim(c(0, 9)) + ylim(c(0,6)) + geom_point(fill = “grey”, pch=21) + geom_smooth(method = “lm”, se = F, fullrange = T, color = “black”) + theme_minimal() + ylab(“缩放效应量 (z)”) + xlab(“标准误差的倒数（精度）”) + annotate(“text”, x = 0.8, y = 0.5, label = bquote(hat(beta)[0]“=”2.85), hjust = “left”, cex = 6) + annotate(geom = “curve”, x = 0, y = 2.85, xend = 0.7, yend = 0.7, curvature = .3, arrow = arrow(length = unit(2, “mm”)), linetype = “dashed”) + ggtitle(“回归线（不对称）”) + theme(plot.title = element_text(color=“black”, size=14, face=“bold”, hjust = 0.5), plot.margin = margin(1.08, 1, 1.08, 1, “cm”), plot.background = element_rect(fill = “#feffff”, color = “#fbfbfb”), panel.background = element_rect(fill = “#feffff”)) # ‘nearly-white’ used to keep knitr from cropping\n```\n```{r eggers, echo=F, out.width=“50%”, message=F, warning=F, fig.width=6, fig.height=5} library(OpenImageR) knitr::include_graphics(‘images/eggers-1_sep.png’) knitr::include_graphics(‘images/eggers-2_sep.png’) knitr::include_graphics(‘images/eggers-3_sep.png’) knitr::include_graphics(‘images/eggers-4_sep.png’) ```\n\n让我们看看当我们对 m.gen 中的数据拟合这样的回归模型时会得到什么结果。使用 R，我们可以提取 m.gen 中的原始数据来计算响应 y 和我们的预测变量 x。在下面的代码中，我们使用管道（第 @ref(data-transform) 章）和 mutate 函数来执行此操作，该函数是 {tidyverse} 的一部分。之后，我们使用线性模型函数 lm 将 \\(z\\) 分数 y 回归到精度 x 上。在管道的最后一部分中，我们请求结果的 summary。\n```{r, eval = F} # 加载所需的包 library(tidyverse)\nm.gen$data %&gt;%&gt; mutate(y = TE/seTE, x = 1/seTE) %&gt;%&gt; lm(y ~ x, data = .) %&gt;%&gt; summary()\n```\n## [...]\n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)   4.1111     0.8790   4.677 0.000252 ***\n## x            -0.3407     0.1837  -1.855 0.082140 .  \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n## \n## [...]\n在结果中，我们看到我们的回归模型的截距为 \\(\\hat\\beta_0\\) = 4.11。这远大于零 (\\(t\\) = 4.677, \\(p&lt;\\) 0.001)，并且表明漏斗图中的数据确实不对称。总体而言，这证实了我们最初的发现，即存在小型研究效应。但是，重申一下，不确定这种模式是否是由发表偏倚引起的。\n执行 Egger 截距检验的更便捷方法是使用 {meta} 中的 metabias 函数。此函数仅需要元分析对象作为输入，并且我们必须将 method.bias 参数设置为 \"linreg\"。如果我们将该函数应用于 m.gen，我们会得到与之前相同的结果。\n```{r} metabias(m.gen, method.bias = “linreg”) ```\n```{block2, type=‘boxreport’} 报告 Egger 检验的结果\n对于 Egger 检验，通常足以报告截距的值、其 95% 置信区间，以及 \\(t\\) 值和 \\(p\\) 值。在 {dmetar} 包中，我们包含了一个名为 eggers.test 的便捷函数。此函数是 metabias 的包装器，并以适合报告的格式提供 Egger 检验的结果。如果您没有安装 {dmetar}，您可以在 在线 找到该函数的源代码。这是一个例子：\neggers.test(m.gen)\n\n\n\n\n\n\n\n\n\n\n\\(~\\)\n截距\n置信区间\nt\np\n\n\n\n\nEgger 检验\n4.111\n2.347-5.875\n4.677\n0.00025\n\n\n\n```\n\nm.gen 中使用的效应量度量是小样本偏倚校正的 SMD（Hedges’ \\(g\\)）。有人认为，在 SMD 上运行 Egger 检验可能导致假阳性结果膨胀 [@pustejovsky2019testing]。这是因为研究的标准化平均差和标准误差不是独立的。\n我们可以通过查看用于计算组间 SMD 标准误差的公式（公式 3.18，第 @ref(b-group-smd) 章）轻松地看到这一点。此公式包括 SMD 本身，这意味着研究的标准误差会随着观察到的效应的大小而变化（即 SMD 与其标准误差之间存在人为的相关性）。\nPustejovsky 和 Rodgers [-@pustejovsky2019testing] 建议在检验标准化平均差的漏斗图不对称时使用标准误差的修改版本。仅使用标准误差公式的第一部分，这意味着观察到的效应量会从等式中删除。因此，该公式如下所示：\n\\[\\begin{equation}\nSE^*_{\\text{SMD}_{\\text{between}}}= \\sqrt{\\frac{n_1+n_2}{n_1n_2}}\n(\\#eq:pub2)\n\\end{equation}\\]\n其中 $SE^*_{\\text{SMD",
    "crumbs": [
      "网站首页",
      "发表偏倚"
    ]
  },
  {
    "objectID": "11-publication-bias.html#footnotes",
    "href": "11-publication-bias.html#footnotes",
    "title": "发表偏倚",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMahmood 及其同事 [-@mahood2014searching] 详细介绍了如何进行全面的灰色文献搜索，以及这可能带来的挑战。该文章可以在线公开访问。↩︎\n在本章中，我们在调用 funnel 函数时始终附加 meta::。这并非绝对必要，但在实践中可能有时有助于避免错误消息（以及相关的混乱），因为 metafor 包中还有另一个 funnel 函数，我们在此不作介绍。↩︎",
    "crumbs": [
      "网站首页",
      "发表偏倚"
    ]
  },
  {
    "objectID": "09-subgroup.html",
    "href": "09-subgroup.html",
    "title": "子组分析",
    "section": "",
    "text": "在 第 @ref(heterogeneity) 章中，我们讨论了研究间异质性的概念，以及它在元分析中的重要性。我们还学习了一些方法，允许我们识别哪些研究对观察到的异质性有贡献，作为离群值和影响分析的一部分。在这些分析中，我们从纯粹的统计角度来处理我们的元分析。我们“测量”数据中相当大的异质性，因此排除具有不合适的统计属性（即，离群和有影响的研究）的研究，以提高我们模型的稳健性。\n \n这种方法可以被看作是事后程序。离群值和影响分析是在看到数据之后进行的，而且通常是因为我们发现的结果。此外，它们除了数据本身之外，不关注任何其他东西。一个影响分析方法可能会告诉我们，某些研究没有正确地遵循我们模型的预期，但没有告诉我们为什么会这样。这可能是因为这项研究使用了稍微不同的研究方法或治疗方法。然而，我们无法仅凭这项研究的影响来了解这一点。\n想象一下，你进行了一项元分析，调查一种医疗手段的有效性。你发现，总的来说，这种治疗方法没有效果。然而，有三项研究发现了相当大的治疗效果。有可能在影响分析中检测到这些研究，但这不会告诉你它们为什么有影响力。有可能是这三项研究都使用了一种与所有其他研究略有不同的治疗方法，而这个小细节对治疗的有效性产生了深远的影响。这将是一个开创性的发现。然而，这仅仅通过离群值和影响分析是无法实现的。\n \n这清楚地表明，我们需要一种不同的方法，一种可以让我们识别为什么在我们的数据中可以找到特定的异质性模式的方法。子组分析，也称为调节效应分析，是做到这一点的一种方法。它们允许我们测试具体的假设，描述为什么某些类型的研究产生比其他研究更低或更高的效果。\n正如我们在第 @ref(analysis-plan) 章中学到的，子组测试应该先验定义。在我们开始进行元分析之前，我们应该定义可能影响观察到的效应量的不同研究特征，并相应地对每项研究进行编码。效应量可能不同的原因有很多，但我们应该将自己限制在与我们的分析相关的那些原因上。\n例如，我们可以检查某种类型的药物是否比另一种药物产生更高的效果。或者，我们可以将随访期较短的研究与随访期较长的研究进行比较。我们还可以检查观察到的效果是否因研究进行的文化区域而异。作为一名元分析师，拥有一些特定领域的专业知识会有所帮助，因为这可以让你找到与该领域的其他科学家或从业者实际相关的问题。\n子组分析背后的想法是，元分析不仅仅是计算平均效应量，它也可以是一种研究我们证据中变异的工具。在子组分析中，我们不仅仅将异质性视为一种麻烦，而是将其视为有趣的变异，这种变异可能可以用科学假设来解释，也可能无法解释。在最好的情况下，这可以进一步加深我们对周围世界的理解，或者至少产生指导未来决策的实际见解。\n在本章中，我们将描述子组分析背后的统计模型，以及我们如何在 R 中直接进行分析。\n\n\n\n\n\n在子组分析中，我们假设元分析中的研究并非来自一个总体。相反，我们假设它们属于不同的子组，并且每个子组都有其自身真实的总体效应。我们的目标是拒绝子组间效应量没有差异的零假设。\n子组分析的计算包括两个部分：首先，我们汇集每个子组中的效应。随后，使用统计检验比较子组的效应 [@borenstein2013meta]。\n\n\n\n\n第一部分相当简单，因为与没有子组的元分析（参见第 @ref(fem-rem) 章）的标准相同。如果我们假设子组中的所有研究都来自同一总体，并且具有一个共享的真实效应，我们可以使用固定效应模型。正如我们之前提到的，即使我们将研究划分为更小的组，这种假设在实践中也很难成立。\n\n因此，另一种选择是使用随机效应模型。这假设子组内的研究来自一个总体集合，我们想要估计这些总体的平均值。与正常元分析的区别在于，我们进行几个独立的随机效应元分析，每个子组一个。从逻辑上讲，这会导致每个子组 \\(g\\) 的汇集效应 \\(\\hat\\mu_g\\)。\n\n由于每个子组都有其自身独立的元分析，因此 \\(\\tau^2\\) 异质性的估计也会因组而异。然而，在实践中，各个异质性值 \\(\\hat\\tau^2_g\\) 通常会被替换为跨子组汇集的 \\(\\tau^2\\) 版本。\n这意味着假设所有子组共享研究间异质性的共同估计。这主要是出于实际原因。当子组中的研究数量很少时，例如 \\(k_g \\leq 5\\) [@borenstein2011introduction, chapter 19]，\\(\\tau^2\\) 的估计值可能不精确。在这种情况下，最好计算一个跨所有子组使用的 \\(\\tau^2\\) 的汇集版本，而不是依赖于一个子组中研究间异质性的非常不精确的估计。\n\n\n\n\n\n下一步，我们评估 \\(G\\) 个子组之间是否存在真实差异。假设是子组是不同的，这意味着至少有一个子组是不同研究总体的一部分。\n测试这一点的一个优雅方法是假装子组的汇集效应实际上只不过是一项大型研究的观察到的效应量[参见 @borenstein2011introduction, chapter 19]。例如，如果我们进行一个 \\(G=3\\) 个子组的子组分析，我们假装我们已经计算了三项大型研究的观察到的效应量（和标准误差）。\n一旦我们这样看待子组，就很明显，我们问自己的问题与我们在评估正常元分析的异质性时面临的问题非常相似。我们想知道效应量的差异仅仅是由于抽样误差造成的，还是由于效应量的真实差异造成的。\n\n因此，我们使用 \\(Q\\) 的值来确定子组差异是否足够大，以至于不能仅用抽样误差来解释。假设子组效应是观察到的效应量，我们计算 \\(Q\\) 的值。假设一个自由度为 \\(G-1\\) 的 \\(\\chi^2\\) 分布，\\(Q\\) 的这个观察到的值与它的预期值进行比较（第 @ref(cochran-q) 章）。\n当 \\(Q\\) 的观察值明显大于预期值时，\\(Q\\) 检验的 \\(p\\) 值将变得显著。这表明子组之间的真实效应量存在差异。这个 \\(Q\\) 检验是一个总括检验。它检验所有子组效应量相等的零假设，并且当至少两个子组或其组合存在差异时，该检验是显著的。\n虽然我们通常假设子组内的研究符合随机效应模型，但在汇集的子组水平上，情况看起来有所不同。Borenstein 和 Higgins [-@borenstein2013meta] 认为，在许多领域中，我们选择分析的子组不能被看作是从可能的子组“集合”中随机抽取的，而是代表我们想要检查的特征的固定水平。以就业状况为例。这个特征有两个固定的子组，“已就业”和“未就业”。例如，对于患有和不患有特定合并症的患者的研究，情况也是如此。\n \nBorenstein 和 Higgins 将子组分析的模型称为固定效应（复数）模型。之所以添加“复数”一词，是因为我们必须将其与标准的固定效应模型区分开来。固定效应（复数）模型可以看作是一种混合生物，既包含固定效应模型的特征，又包含随机效应模型的特征。与随机效应模型一样，我们假设存在不止一个真实效应量，因为我们的数据中存在子组。\n然而，我们不将子组视为从整个子组集合中随机抽取的。我们的子组水平是固定的，并且是详尽的，这意味着不需要推广。这清楚地表明了为什么我们将生成子组数据的过程称为固定效应“复数”模型：因为存在几个真实的效应量，但是真实的效应量代表假设为固定的子组水平。\nBorenstein 及其同事 [-@borenstein2011introduction, chapter 19] 认为，所有这些可能让我们感到有点困惑，因为“固定”一词在统计学中可以意味着不同的东西。在传统的元分析中，“固定效应”一词与“共同效应”同义。然而，在子组分析的上下文中，我们说“固定效应”是为了强调它们“不是随机的”。它们不仅仅是我们旨在推广到的一个总括分布的随机表现，而是变量可以归入的真实和唯一类别。\n图 @ref(fig:subgroups) 可视化了固定效应（复数）模型，假设子组内的研究遵循随机效应模型。\n\n\n\n\n\nVisualization of the fixed-effects (plural) model, assuming a random-effects model within subgroups.\n\n\n\n\n\n\n\n具有固定水平的子组变量的一些示例\n\n\n\n年龄组：儿童、年轻人、成人、老年人。\n\n\n\n\n文化背景：西方、非西方。\n\n\n\n\n对照组：替代治疗、最小治疗、不治疗。\n\n\n\n\n用于测量结果的工具：自我报告、专家评定。\n\n\n\n\n研究质量：高、低、不明确。\n\n\n\n\n物种：植物、动物。\n\n\n\n\n设置：学校、医院、私人家庭。\n\n\n\n请注意，子组的具体选择和定义可以而且应该根据您的元分析的目的和范围进行调整。\n\n\n\n \n因为固定效应（复数）模型既包含随机效应（子组内），又包含固定效应（因为假设子组是固定的），所以在文献中也称为混合效应模型。我们之前在第 @ref(pooling-props) 章中已经遇到过这个术语，我们在那里讨论了一种不同类型的（广义）混合效应模型，该模型可用于汇集，例如，比例。\n我们用于子组分析的模型与其他也经常用于元分析的方法密切相关。在第 @ref(metareg) 章中，我们将展示子组分析只是元回归的一个特例，为此我们也使用混合效应模型。\n\n此外，子组水平也可能不能假设为固定的。想象一下，我们想要评估效应量是否因观察到效应的位置而异。一些研究评估了在以色列的效应，一些在意大利，另一些在墨西哥，还有一些在中国大陆。有人可能会说“原籍国”不是一个具有固定水平的因素：世界上有许多国家，而我们的研究仅仅包括一个“随机”选择。\n在这种情况下，不将子组建模为固定的是有意义的，而是让我们的模型估计国家之间的变异性作为随机效应。这导致了多层模型，我们将在第 @ref(multilevel-ma) 章中介绍。\n\n\n\n\n\n\n\n直观地说，人们可能会认为子组分析是一种检测效应调节因素的绝佳工具。毕竟，元分析的目的是研究所有可用的证据。这意味着元分析中分析的个体总数通常会超过主要研究的数量级。\n然而，不幸的是，这并不一定为我们提供更多的统计功效来检测子组差异。这有几个原因 [@hedges2004power]：\n\n首先，请记住，在子组分析中，子组内的结果通常使用随机效应模型进行汇集。如果子组内存在大量的研究间异质性，这将降低汇集效应的精度（即增加标准误差）。然而，当子组效应估计非常不精确时，这意味着它们的置信区间将有很大的重叠。因此，即使这种差异确实存在，也更难找到子组之间的显著差异。\n同样，统计功效通常也很低，因为我们想要在子组分析中检测到的效应远低于正常元分析中的效应。想象一下，我们想要检查评估通过自我报告与专家评定感兴趣的结果的研究之间的效应是否存在差异。即使存在差异，也很可能是很小的。通常可以找到治疗组和对照组之间的显著差异。然而，检测研究之间的效应量差异通常要困难得多，因为差异较小，并且需要更多的统计功效。\n从以上几点得出一个重要的警告：缺乏证据并不意味着没有证据。如果我们没有发现子组之间的效应量差异，这并不自动意味着子组产生等效的结果。正如我们上面所说，有各种原因可以解释为什么我们的子组分析可能没有确定效应的真实差异所需的统计功效。如果是这种情况，那么说子组具有相同的效应将是一种严重的误解——我们根本不知道是否存在差异。当我们想要评估一种治疗方法是否比另一种更好时，这一点尤其具有爆炸性。包括公司在内的一些利益相关者，通常对显示治疗方法的等效性有既得利益。但是子组分析通常不是证明这一点的充分方法。\n我们可以事先执行子组功效分析来检查统计功效是否是我们的子组分析中的一个问题。在这样的分析中，我们可以检查我们能够在子组分析中检测到的最小效应量差异。在“有用的工具”部分的 @ref(power-subgroup) 章中，我们介绍了如何在 R 中执行子组功效分析。但请注意，功效分析充其量只能被视为有用的诊断，而不是证明我们的分析的功效足以表明子组是等效的。Schwarzer 及其同事 [@schwarzer2015meta, chapter 4.3] 提到，作为一般经验法则，子组分析只有在您的元分析包含至少 \\(K=\\) 10 项研究时才有意义。\n\n子组分析的另一个重要局限性是它们纯粹是观察性的 [@borenstein2013meta]。元分析通常只包括随机对照试验 (RCT)，其中参与者被随机分配到治疗组或对照组。如果正确进行，此类 RCT 可以提供证据表明治疗导致了研究中观察到的组间差异。这是因为可能影响评估结果的所有相关变量在两组中都是相等的。唯一的区别是一组接受了治疗，而另一组没有。\n子组分析，即使仅由随机研究组成，也不能显示因果关系。想象一下，我们的子组分析发现一种类型的治疗方法比另一种更有效。有很多原因可以解释为什么这一发现可能是虚假的；例如，可能调查治疗 A 的研究使用了与检查治疗 B 的研究不同的对照组。这意味着两种治疗方法可能同样有效——我们只是看到差异，因为治疗类型与方法学因素混淆了。这个例子应该强调，应该始终批判性地评估子组分析的结果。\n最后一个重要的陷阱涉及子组的定义方式。通常，根据汇总信息将研究分类到子组中可能很诱人。Schwarzer 及其同事 [@schwarzer2015meta, chapter 4.3] 将研究的平均年龄作为一个常见的例子。假设您想评估老年人（65 岁以上）和一般成年人群之间的效应是否存在差异。因此，您根据报告的平均年龄是否高于或低于 65 岁，将研究分为这两类。\n如果我们发现较高平均年龄的子组中的效应较高，我们可能会直观地认为这表明老年人的效应较高。但这种推理存在严重缺陷。当一项主要研究的平均年龄高于 65 岁时，它仍然可能包括很大一部分小于该年龄的个体。反之亦然，即使平均年龄较低，一项研究也完全有可能包括很大一部分大于 65 岁的个体。\n这意味着在“老年人”子组中发现的较高效应可能仅仅是由实际年龄小于 65 岁的个体驱动的。相反，在“年轻人”子组中，较低的效应可能是由研究中年龄大于 65 岁的个体引起的。\n这导致了一种自相矛盾的情况：在汇总水平上，我们发现平均年龄较高的研究具有较高的效应。但在个体水平上，情况恰恰相反：随着年龄的增长，一个人会经历较低的效应。\n\n我们刚刚描述的场景是由所谓的生态偏差引起的 [@thompson2002should; @piantadosi1988ecological]。每当我们想要使用汇总（宏观）水平的关系来预测个体（微观）水平的关联时，就会出现这种情况。\n避免生态偏差的最佳方法是永远不要在子组分析和元回归中使用汇总信息。但是，如果我们知道一项研究中的所有个体都属于一个类别，则情况会有所不同。例如，如果我们有一些研究仅包括 18 岁以下的青少年，而另一些研究仅允许成年人（18 岁以上）参与，则生态偏差的风险在很大程度上被消除。但是，仍然有可能效应差异是由混淆变量引起的，而不是由参与者的年龄引起的。\n\n\n\n子组分析：总结了 Dos & Don’ts\n\n\n\n子组分析取决于统计功效，因此当研究数量较少时（即 (K) &lt; 10），进行子组分析通常没有意义。\n\n\n\n\n如果您没有发现子组之间的效应量差异，这并不自动意味着子组产生等效的结果。\n\n\n\n\n子组分析纯粹是观察性的，因此我们应该始终牢记，效应差异也可能是由混淆变量引起的。\n\n\n\n\n在子组分析中使用汇总研究信息不是一个好主意，因为这可能会引入生态偏差。\n\n\n\n\n\n\n\n\n\n\n现在是时候在 R 中实施我们所学的内容了。使用 {meta} 包进行子组分析相对简单。在 {meta} 中的每个元分析函数中，都可以指定 subgroup 参数1。这会告诉函数哪个效应量属于哪个子组并运行子组分析。subgroup 参数接受 character、factor、logical 或 numeric 变量。我们唯一需要注意的是，同一子组中的研究具有完全相同的标签。\n在这个例子中，我们再次使用我们的 m.gen 元分析对象。我们用于计算元分析的 ThirdWave 数据集包含一些带有子组信息的列。在这里，我们想要检查具有高风险与低风险偏倚的研究之间的效应量是否存在差异。偏倚风险信息存储在 RiskOfBias 列中。\n让我们首先看一下这一列。在我们的代码中，我们使用 head 函数，以便只显示数据集的前几行。\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.1-0).\nType 'help(meta)' for a brief overview.\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\ndata(ThirdWave)\n# Show first entries of study name and 'RiskOfBias' column\nhead(ThirdWave[,c(\"Author\", \"RiskOfBias\")])\n\n           Author RiskOfBias\n1     Call et al.       high\n2 Cavanagh et al.        low\n3   DanitzOrsillo       high\n4  de Vibe et al.        low\n5  Frazier et al.        low\n6  Frogeli et al.        low\n\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = ThirdWave,\n                 sm = \"SMD\",\n                 comb.fixed = FALSE,\n                 comb.random = TRUE,\n                 method.tau = \"REML\",\n                 method.random.ci = \"HK\",\n                 title = \"Third Wave Psychotherapies\")\n\nWarning: Use argument 'common' instead of 'comb.fixed' (deprecated).\n\n\nWarning: Use argument 'random' instead of 'comb.random' (deprecated).\n\n\n我们看到我们数据集中的每项研究都有一个指定其偏倚风险评估的标签。当我们使用 metagen 计算元分析时，此信息在内部保存在 m.gen 对象中。要进行子组分析，我们可以使用 update 函数，为其提供 m.gen 对象，并使用 subgroup 参数来指定我们的数据集中哪一列包含子组标签。\n之前，我们还介绍了子组分析可以在子组间使用或不使用 \\(\\tau^2\\) 的共同估计来进行。这可以通过在 {meta} 中将 tau.common 设置为 TRUE 或 FALSE 来控制。现在，让我们在每个子组中使用研究间异质性方差的单独估计。\n在我们的例子中，我们想要应用固定效应（复数）模型并假设子组内的研究使用随机效应模型进行汇集。鉴于 m.gen 包含随机效应模型的结果（因为我们将 comb.fixed 设置为 FALSE 并且将 comb.random 设置为 TRUE），我们不需要更改任何内容。因为原始元分析是使用随机效应模型执行的，所以 update 自动假设子组内的研究也应该使用随机效应模型进行汇集。\n因此，生成的代码如下所示：\n\nupdate(m.gen, \n       subgroup = RiskOfBias, \n       tau.common = FALSE)\n\n## Review:     Third Wave Psychotherapies\n## \n## Number of studies combined: k = 18\n## \n##                              SMD            95%-CI    t  p-value\n## Random effects model (HK) 0.5771 [ 0.3782; 0.7760] 6.12 &lt; 0.0001\n## Prediction interval              [-0.0572; 1.2115]              \n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n##  I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n## \n## Test of heterogeneity:\n##      Q d.f. p-value\n##  45.50   17  0.0002\n## \n## Results for subgroups (random effects model (HK)):\n##                     k    SMD           95%-CI  tau^2    tau     Q   I^2\n## RiskOfBias = high   7 0.8126 [0.2835; 1.3417] 0.2423 0.4922 25.89 76.8%\n## RiskOfBias = low   11 0.4300 [0.2770; 0.5830] 0.0099 0.0997 13.42 25.5%\n## \n## Test for subgroup differences (random effects model (HK)):\n##                   Q d.f. p-value\n## Between groups 2.84    1  0.0917\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2\n## - Q-Profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp (HK) adjustment for random effects model (df = 17)\n## - Prediction interval based on t-distribution (df = 16)\n在输出中，我们看到一个名为 Results for subgroups 的新部分。输出的这一部分显示了每个子组的单独汇集效应量。我们看到有 \\(k=\\) 7 项研究具有高偏倚风险，有 11 项研究具有低偏倚风险。估计的研究间异质性差异很大，高偏倚风险研究中的 \\(I^2=\\) 77%，而低风险研究中的 \\(I^2\\) 只有 26%。\n子组的效应量也不同。对于 \\(g=\\) 0.43，低偏倚风险研究中的效应估计小于高偏倚风险研究中的效应估计。这是一个常见的发现，因为有偏倚的研究更有可能高估治疗的效果。\n但是这种差异在统计上是否显著？我们可以通过查看 Test for subgroup differences 的结果来检查这一点。这向我们展示了 \\(Q\\) 检验，在我们的示例中，它基于 2 个子组，基于一个自由度。检验的 \\(p\\) 值为 0.09，大于传统的显著性阈值，但仍然表明趋势水平上的差异。\n如果我们假设两个子组中 \\(\\tau^2\\) 的共同估计，我们也可以检查结果。我们只需要将 tau.common 设置为 TRUE。\n\nupdate(m.gen, subgroup = RiskOfBias, tau.common = TRUE)\n\n## [...]\n##                     k    SMD           95%-CI  tau^2    tau     Q   I^2\n## RiskOfBias = high   7 0.7691 [0.2533; 1.2848] 0.0691 0.2630 25.89 76.8%\n## RiskOfBias = low   11 0.4698 [0.3015; 0.6382] 0.0691 0.2630 13.42 25.5%\n## \n## Test for subgroup differences (random effects model (HK)):\n##                    Q d.f. p-value\n## Between groups  1.79    1  0.1814\n## Within groups  39.31   16  0.0010\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2\n##   (assuming common tau^2 in subgroups)\n## [...]\n在输出中，我们看到估计的研究间异质性方差为 \\(\\tau^2=\\) 0.069，并且在两个子组中相同。我们得到了两个 \\(Q\\) 检验：一个组间（实际的子组检验），另一个是子组内异质性。\n与正常的元分析一样，后者只是表明子组中存在过多的变异性（\\(p=\\) 0.001）。子组差异检验再次表明，低偏倚风险和高偏倚风险研究之间没有显著差异（\\(p=\\) 0.181）。\n我们现在假设 \\(\\tau^2\\) 的独立或共同估计来探索结果。由于我们不知道有什么好的理由假设两个子组中的异质性是相等的，并且考虑到我们在每个子组中至少有 \\(k=\\) 7 项研究，因此可能适合使用 \\(\\tau^2\\) 的单独估计。然而，我们看到，无论如何，至少在我们的示例中，我们对结果的解释对于这两种方法都是相似的。\n\n\n\n报告子组分析的结果\n子组分析的结果通常以表格形式报告，表格显示了每个子组中的估计效应和异质性，以及子组差异检验的 \\(p\\) 值。\n\n\n\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\n\n\n$g$\n95\\%CI\n$p$\n$I^2$\n95\\%CI\n$p$ (subgroup)\n\n\n\n\nRisk of Bias\n\n\n\n\n\n0.092\n\n\n- High\n0.81\n0.28-1.34\n0.009\n0.77\n0.51-0.89\n\n\n\n- Low\n0.43\n0.28-0.58\n&lt; 0.001\n0.25\n0.00-0.63\n\n\n\n\n\n\n\n\n\n\n\n\n在上表中，第三列中的两个 \\(p\\) 值显示了特定于子组的效应是否显著。我们可以看到，高偏倚风险和低偏倚风险研究都是这种情况。与此同时，\\(p_{\\textsf{subgroup}}\\) 下的值显示，高偏倚风险和低偏倚风险研究之间的效应_差异_不显著。\n要提取特定于子组的 \\(p\\) 值，需要将 update 的结果保存到对象中，然后使用 $ 运算符从该对象中提取 pval.random.w 元素。\n如果进行了多个子组分析，则可以将更多行添加到表中。\n\n\n\\[\\tag*{$\\blacksquare$}\\] \n\n\n\n\n\n\n测试您的知识！\n\n\n\n在最好的情况下，子组分析可以告诉我们什么影响和离群值分析无法告诉我们的信息？\n\n\n\n\n为什么子组分析背后的模型被称为固定效应（复数）模型？\n\n\n\n\n作为您的元分析的一部分，您想检查教育培训计划的效果是否因其交付的学区而异。使用固定效应（复数）模型进行子组分析是否适合回答这个问题？\n\n\n\n\n您的一个朋友进行了一项元分析，其中包含总共 9 项研究。其中五项研究属于一个子组，四项研究属于另一个子组。她问您进行子组分析是否有意义。您会推荐什么？\n\n\n\n\n您找到了一项元分析，其中作者声称分析的治疗方法在女性中比男性更有效。这一发现是基于一项子组分析，其中研究根据研究人群中包含的女性比例分为几组。这一发现是否可信，为什么（不）？\n\n\n\n这些问题的答案列在本 书 末尾的 附录 A 中。\n\n\n\n\n\n\n\n\n尽管有很多方法可以评估元分析的异质性，但这些方法并没有告诉我们为什么我们在数据中发现了过多的变异性。子组分析允许我们检验关于为什么一些研究的真实效应量高于或低于其他研究的假设。\n对于子组分析，我们通常假设一个固定效应（复数）模型。在大多数情况下，子组内的研究使用随机效应模型进行汇集。随后，使用基于总体子组结果的 \\(Q\\) 检验来确定组之间是否存在显著差异。\n子组分析模型被称为“固定效应”模型，因为假设不同的类别本身是固定的。子组水平不被视为从可能的类别集合中随机抽取的。它们代表子组变量可以采用的唯一值。\n在计算子组分析时，我们必须决定是应该使用单独的还是共同的研究间异质性估计来汇集子组内的结果。\n子组分析并非万能药。它们通常缺乏检测子组差异所需的统计功效。因此，子组差异的非显著性检验并不自动意味着子组产生等效的结果。",
    "crumbs": [
      "网站首页",
      "亚组分析"
    ]
  },
  {
    "objectID": "09-subgroup.html#fixed-effect-plural",
    "href": "09-subgroup.html#fixed-effect-plural",
    "title": "子组分析",
    "section": "",
    "text": "在子组分析中，我们假设元分析中的研究并非来自一个总体。相反，我们假设它们属于不同的子组，并且每个子组都有其自身真实的总体效应。我们的目标是拒绝子组间效应量没有差异的零假设。\n子组分析的计算包括两个部分：首先，我们汇集每个子组中的效应。随后，使用统计检验比较子组的效应 [@borenstein2013meta]。\n\n\n\n\n第一部分相当简单，因为与没有子组的元分析（参见第 @ref(fem-rem) 章）的标准相同。如果我们假设子组中的所有研究都来自同一总体，并且具有一个共享的真实效应，我们可以使用固定效应模型。正如我们之前提到的，即使我们将研究划分为更小的组，这种假设在实践中也很难成立。\n\n因此，另一种选择是使用随机效应模型。这假设子组内的研究来自一个总体集合，我们想要估计这些总体的平均值。与正常元分析的区别在于，我们进行几个独立的随机效应元分析，每个子组一个。从逻辑上讲，这会导致每个子组 \\(g\\) 的汇集效应 \\(\\hat\\mu_g\\)。\n\n由于每个子组都有其自身独立的元分析，因此 \\(\\tau^2\\) 异质性的估计也会因组而异。然而，在实践中，各个异质性值 \\(\\hat\\tau^2_g\\) 通常会被替换为跨子组汇集的 \\(\\tau^2\\) 版本。\n这意味着假设所有子组共享研究间异质性的共同估计。这主要是出于实际原因。当子组中的研究数量很少时，例如 \\(k_g \\leq 5\\) [@borenstein2011introduction, chapter 19]，\\(\\tau^2\\) 的估计值可能不精确。在这种情况下，最好计算一个跨所有子组使用的 \\(\\tau^2\\) 的汇集版本，而不是依赖于一个子组中研究间异质性的非常不精确的估计。\n\n\n\n\n\n下一步，我们评估 \\(G\\) 个子组之间是否存在真实差异。假设是子组是不同的，这意味着至少有一个子组是不同研究总体的一部分。\n测试这一点的一个优雅方法是假装子组的汇集效应实际上只不过是一项大型研究的观察到的效应量[参见 @borenstein2011introduction, chapter 19]。例如，如果我们进行一个 \\(G=3\\) 个子组的子组分析，我们假装我们已经计算了三项大型研究的观察到的效应量（和标准误差）。\n一旦我们这样看待子组，就很明显，我们问自己的问题与我们在评估正常元分析的异质性时面临的问题非常相似。我们想知道效应量的差异仅仅是由于抽样误差造成的，还是由于效应量的真实差异造成的。\n\n因此，我们使用 \\(Q\\) 的值来确定子组差异是否足够大，以至于不能仅用抽样误差来解释。假设子组效应是观察到的效应量，我们计算 \\(Q\\) 的值。假设一个自由度为 \\(G-1\\) 的 \\(\\chi^2\\) 分布，\\(Q\\) 的这个观察到的值与它的预期值进行比较（第 @ref(cochran-q) 章）。\n当 \\(Q\\) 的观察值明显大于预期值时，\\(Q\\) 检验的 \\(p\\) 值将变得显著。这表明子组之间的真实效应量存在差异。这个 \\(Q\\) 检验是一个总括检验。它检验所有子组效应量相等的零假设，并且当至少两个子组或其组合存在差异时，该检验是显著的。\n虽然我们通常假设子组内的研究符合随机效应模型，但在汇集的子组水平上，情况看起来有所不同。Borenstein 和 Higgins [-@borenstein2013meta] 认为，在许多领域中，我们选择分析的子组不能被看作是从可能的子组“集合”中随机抽取的，而是代表我们想要检查的特征的固定水平。以就业状况为例。这个特征有两个固定的子组，“已就业”和“未就业”。例如，对于患有和不患有特定合并症的患者的研究，情况也是如此。\n \nBorenstein 和 Higgins 将子组分析的模型称为固定效应（复数）模型。之所以添加“复数”一词，是因为我们必须将其与标准的固定效应模型区分开来。固定效应（复数）模型可以看作是一种混合生物，既包含固定效应模型的特征，又包含随机效应模型的特征。与随机效应模型一样，我们假设存在不止一个真实效应量，因为我们的数据中存在子组。\n然而，我们不将子组视为从整个子组集合中随机抽取的。我们的子组水平是固定的，并且是详尽的，这意味着不需要推广。这清楚地表明了为什么我们将生成子组数据的过程称为固定效应“复数”模型：因为存在几个真实的效应量，但是真实的效应量代表假设为固定的子组水平。\nBorenstein 及其同事 [-@borenstein2011introduction, chapter 19] 认为，所有这些可能让我们感到有点困惑，因为“固定”一词在统计学中可以意味着不同的东西。在传统的元分析中，“固定效应”一词与“共同效应”同义。然而，在子组分析的上下文中，我们说“固定效应”是为了强调它们“不是随机的”。它们不仅仅是我们旨在推广到的一个总括分布的随机表现，而是变量可以归入的真实和唯一类别。\n图 @ref(fig:subgroups) 可视化了固定效应（复数）模型，假设子组内的研究遵循随机效应模型。\n\n\n\n\n\nVisualization of the fixed-effects (plural) model, assuming a random-effects model within subgroups.\n\n\n\n\n\n\n\n具有固定水平的子组变量的一些示例\n\n\n\n年龄组：儿童、年轻人、成人、老年人。\n\n\n\n\n文化背景：西方、非西方。\n\n\n\n\n对照组：替代治疗、最小治疗、不治疗。\n\n\n\n\n用于测量结果的工具：自我报告、专家评定。\n\n\n\n\n研究质量：高、低、不明确。\n\n\n\n\n物种：植物、动物。\n\n\n\n\n设置：学校、医院、私人家庭。\n\n\n\n请注意，子组的具体选择和定义可以而且应该根据您的元分析的目的和范围进行调整。\n\n\n\n \n因为固定效应（复数）模型既包含随机效应（子组内），又包含固定效应（因为假设子组是固定的），所以在文献中也称为混合效应模型。我们之前在第 @ref(pooling-props) 章中已经遇到过这个术语，我们在那里讨论了一种不同类型的（广义）混合效应模型，该模型可用于汇集，例如，比例。\n我们用于子组分析的模型与其他也经常用于元分析的方法密切相关。在第 @ref(metareg) 章中，我们将展示子组分析只是元回归的一个特例，为此我们也使用混合效应模型。\n\n此外，子组水平也可能不能假设为固定的。想象一下，我们想要评估效应量是否因观察到效应的位置而异。一些研究评估了在以色列的效应，一些在意大利，另一些在墨西哥，还有一些在中国大陆。有人可能会说“原籍国”不是一个具有固定水平的因素：世界上有许多国家，而我们的研究仅仅包括一个“随机”选择。\n在这种情况下，不将子组建模为固定的是有意义的，而是让我们的模型估计国家之间的变异性作为随机效应。这导致了多层模型，我们将在第 @ref(multilevel-ma) 章中介绍。",
    "crumbs": [
      "网站首页",
      "亚组分析"
    ]
  },
  {
    "objectID": "09-subgroup.html#limits-subgroup",
    "href": "09-subgroup.html#limits-subgroup",
    "title": "子组分析",
    "section": "",
    "text": "直观地说，人们可能会认为子组分析是一种检测效应调节因素的绝佳工具。毕竟，元分析的目的是研究所有可用的证据。这意味着元分析中分析的个体总数通常会超过主要研究的数量级。\n然而，不幸的是，这并不一定为我们提供更多的统计功效来检测子组差异。这有几个原因 [@hedges2004power]：\n\n首先，请记住，在子组分析中，子组内的结果通常使用随机效应模型进行汇集。如果子组内存在大量的研究间异质性，这将降低汇集效应的精度（即增加标准误差）。然而，当子组效应估计非常不精确时，这意味着它们的置信区间将有很大的重叠。因此，即使这种差异确实存在，也更难找到子组之间的显著差异。\n同样，统计功效通常也很低，因为我们想要在子组分析中检测到的效应远低于正常元分析中的效应。想象一下，我们想要检查评估通过自我报告与专家评定感兴趣的结果的研究之间的效应是否存在差异。即使存在差异，也很可能是很小的。通常可以找到治疗组和对照组之间的显著差异。然而，检测研究之间的效应量差异通常要困难得多，因为差异较小，并且需要更多的统计功效。\n从以上几点得出一个重要的警告：缺乏证据并不意味着没有证据。如果我们没有发现子组之间的效应量差异，这并不自动意味着子组产生等效的结果。正如我们上面所说，有各种原因可以解释为什么我们的子组分析可能没有确定效应的真实差异所需的统计功效。如果是这种情况，那么说子组具有相同的效应将是一种严重的误解——我们根本不知道是否存在差异。当我们想要评估一种治疗方法是否比另一种更好时，这一点尤其具有爆炸性。包括公司在内的一些利益相关者，通常对显示治疗方法的等效性有既得利益。但是子组分析通常不是证明这一点的充分方法。\n我们可以事先执行子组功效分析来检查统计功效是否是我们的子组分析中的一个问题。在这样的分析中，我们可以检查我们能够在子组分析中检测到的最小效应量差异。在“有用的工具”部分的 @ref(power-subgroup) 章中，我们介绍了如何在 R 中执行子组功效分析。但请注意，功效分析充其量只能被视为有用的诊断，而不是证明我们的分析的功效足以表明子组是等效的。Schwarzer 及其同事 [@schwarzer2015meta, chapter 4.3] 提到，作为一般经验法则，子组分析只有在您的元分析包含至少 \\(K=\\) 10 项研究时才有意义。\n\n子组分析的另一个重要局限性是它们纯粹是观察性的 [@borenstein2013meta]。元分析通常只包括随机对照试验 (RCT)，其中参与者被随机分配到治疗组或对照组。如果正确进行，此类 RCT 可以提供证据表明治疗导致了研究中观察到的组间差异。这是因为可能影响评估结果的所有相关变量在两组中都是相等的。唯一的区别是一组接受了治疗，而另一组没有。\n子组分析，即使仅由随机研究组成，也不能显示因果关系。想象一下，我们的子组分析发现一种类型的治疗方法比另一种更有效。有很多原因可以解释为什么这一发现可能是虚假的；例如，可能调查治疗 A 的研究使用了与检查治疗 B 的研究不同的对照组。这意味着两种治疗方法可能同样有效——我们只是看到差异，因为治疗类型与方法学因素混淆了。这个例子应该强调，应该始终批判性地评估子组分析的结果。\n最后一个重要的陷阱涉及子组的定义方式。通常，根据汇总信息将研究分类到子组中可能很诱人。Schwarzer 及其同事 [@schwarzer2015meta, chapter 4.3] 将研究的平均年龄作为一个常见的例子。假设您想评估老年人（65 岁以上）和一般成年人群之间的效应是否存在差异。因此，您根据报告的平均年龄是否高于或低于 65 岁，将研究分为这两类。\n如果我们发现较高平均年龄的子组中的效应较高，我们可能会直观地认为这表明老年人的效应较高。但这种推理存在严重缺陷。当一项主要研究的平均年龄高于 65 岁时，它仍然可能包括很大一部分小于该年龄的个体。反之亦然，即使平均年龄较低，一项研究也完全有可能包括很大一部分大于 65 岁的个体。\n这意味着在“老年人”子组中发现的较高效应可能仅仅是由实际年龄小于 65 岁的个体驱动的。相反，在“年轻人”子组中，较低的效应可能是由研究中年龄大于 65 岁的个体引起的。\n这导致了一种自相矛盾的情况：在汇总水平上，我们发现平均年龄较高的研究具有较高的效应。但在个体水平上，情况恰恰相反：随着年龄的增长，一个人会经历较低的效应。\n\n我们刚刚描述的场景是由所谓的生态偏差引起的 [@thompson2002should; @piantadosi1988ecological]。每当我们想要使用汇总（宏观）水平的关系来预测个体（微观）水平的关联时，就会出现这种情况。\n避免生态偏差的最佳方法是永远不要在子组分析和元回归中使用汇总信息。但是，如果我们知道一项研究中的所有个体都属于一个类别，则情况会有所不同。例如，如果我们有一些研究仅包括 18 岁以下的青少年，而另一些研究仅允许成年人（18 岁以上）参与，则生态偏差的风险在很大程度上被消除。但是，仍然有可能效应差异是由混淆变量引起的，而不是由参与者的年龄引起的。\n\n\n\n子组分析：总结了 Dos & Don’ts\n\n\n\n子组分析取决于统计功效，因此当研究数量较少时（即 (K) &lt; 10），进行子组分析通常没有意义。\n\n\n\n\n如果您没有发现子组之间的效应量差异，这并不自动意味着子组产生等效的结果。\n\n\n\n\n子组分析纯粹是观察性的，因此我们应该始终牢记，效应差异也可能是由混淆变量引起的。\n\n\n\n\n在子组分析中使用汇总研究信息不是一个好主意，因为这可能会引入生态偏差。",
    "crumbs": [
      "网站首页",
      "亚组分析"
    ]
  },
  {
    "objectID": "09-subgroup.html#subgroup-R",
    "href": "09-subgroup.html#subgroup-R",
    "title": "子组分析",
    "section": "",
    "text": "现在是时候在 R 中实施我们所学的内容了。使用 {meta} 包进行子组分析相对简单。在 {meta} 中的每个元分析函数中，都可以指定 subgroup 参数1。这会告诉函数哪个效应量属于哪个子组并运行子组分析。subgroup 参数接受 character、factor、logical 或 numeric 变量。我们唯一需要注意的是，同一子组中的研究具有完全相同的标签。\n在这个例子中，我们再次使用我们的 m.gen 元分析对象。我们用于计算元分析的 ThirdWave 数据集包含一些带有子组信息的列。在这里，我们想要检查具有高风险与低风险偏倚的研究之间的效应量是否存在差异。偏倚风险信息存储在 RiskOfBias 列中。\n让我们首先看一下这一列。在我们的代码中，我们使用 head 函数，以便只显示数据集的前几行。\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.1-0).\nType 'help(meta)' for a brief overview.\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\ndata(ThirdWave)\n# Show first entries of study name and 'RiskOfBias' column\nhead(ThirdWave[,c(\"Author\", \"RiskOfBias\")])\n\n           Author RiskOfBias\n1     Call et al.       high\n2 Cavanagh et al.        low\n3   DanitzOrsillo       high\n4  de Vibe et al.        low\n5  Frazier et al.        low\n6  Frogeli et al.        low\n\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = ThirdWave,\n                 sm = \"SMD\",\n                 comb.fixed = FALSE,\n                 comb.random = TRUE,\n                 method.tau = \"REML\",\n                 method.random.ci = \"HK\",\n                 title = \"Third Wave Psychotherapies\")\n\nWarning: Use argument 'common' instead of 'comb.fixed' (deprecated).\n\n\nWarning: Use argument 'random' instead of 'comb.random' (deprecated).\n\n\n我们看到我们数据集中的每项研究都有一个指定其偏倚风险评估的标签。当我们使用 metagen 计算元分析时，此信息在内部保存在 m.gen 对象中。要进行子组分析，我们可以使用 update 函数，为其提供 m.gen 对象，并使用 subgroup 参数来指定我们的数据集中哪一列包含子组标签。\n之前，我们还介绍了子组分析可以在子组间使用或不使用 \\(\\tau^2\\) 的共同估计来进行。这可以通过在 {meta} 中将 tau.common 设置为 TRUE 或 FALSE 来控制。现在，让我们在每个子组中使用研究间异质性方差的单独估计。\n在我们的例子中，我们想要应用固定效应（复数）模型并假设子组内的研究使用随机效应模型进行汇集。鉴于 m.gen 包含随机效应模型的结果（因为我们将 comb.fixed 设置为 FALSE 并且将 comb.random 设置为 TRUE），我们不需要更改任何内容。因为原始元分析是使用随机效应模型执行的，所以 update 自动假设子组内的研究也应该使用随机效应模型进行汇集。\n因此，生成的代码如下所示：\n\nupdate(m.gen, \n       subgroup = RiskOfBias, \n       tau.common = FALSE)\n\n## Review:     Third Wave Psychotherapies\n## \n## Number of studies combined: k = 18\n## \n##                              SMD            95%-CI    t  p-value\n## Random effects model (HK) 0.5771 [ 0.3782; 0.7760] 6.12 &lt; 0.0001\n## Prediction interval              [-0.0572; 1.2115]              \n## \n## Quantifying heterogeneity:\n##  tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n##  I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n## \n## Test of heterogeneity:\n##      Q d.f. p-value\n##  45.50   17  0.0002\n## \n## Results for subgroups (random effects model (HK)):\n##                     k    SMD           95%-CI  tau^2    tau     Q   I^2\n## RiskOfBias = high   7 0.8126 [0.2835; 1.3417] 0.2423 0.4922 25.89 76.8%\n## RiskOfBias = low   11 0.4300 [0.2770; 0.5830] 0.0099 0.0997 13.42 25.5%\n## \n## Test for subgroup differences (random effects model (HK)):\n##                   Q d.f. p-value\n## Between groups 2.84    1  0.0917\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2\n## - Q-Profile method for confidence interval of tau^2 and tau\n## - Hartung-Knapp (HK) adjustment for random effects model (df = 17)\n## - Prediction interval based on t-distribution (df = 16)\n在输出中，我们看到一个名为 Results for subgroups 的新部分。输出的这一部分显示了每个子组的单独汇集效应量。我们看到有 \\(k=\\) 7 项研究具有高偏倚风险，有 11 项研究具有低偏倚风险。估计的研究间异质性差异很大，高偏倚风险研究中的 \\(I^2=\\) 77%，而低风险研究中的 \\(I^2\\) 只有 26%。\n子组的效应量也不同。对于 \\(g=\\) 0.43，低偏倚风险研究中的效应估计小于高偏倚风险研究中的效应估计。这是一个常见的发现，因为有偏倚的研究更有可能高估治疗的效果。\n但是这种差异在统计上是否显著？我们可以通过查看 Test for subgroup differences 的结果来检查这一点。这向我们展示了 \\(Q\\) 检验，在我们的示例中，它基于 2 个子组，基于一个自由度。检验的 \\(p\\) 值为 0.09，大于传统的显著性阈值，但仍然表明趋势水平上的差异。\n如果我们假设两个子组中 \\(\\tau^2\\) 的共同估计，我们也可以检查结果。我们只需要将 tau.common 设置为 TRUE。\n\nupdate(m.gen, subgroup = RiskOfBias, tau.common = TRUE)\n\n## [...]\n##                     k    SMD           95%-CI  tau^2    tau     Q   I^2\n## RiskOfBias = high   7 0.7691 [0.2533; 1.2848] 0.0691 0.2630 25.89 76.8%\n## RiskOfBias = low   11 0.4698 [0.3015; 0.6382] 0.0691 0.2630 13.42 25.5%\n## \n## Test for subgroup differences (random effects model (HK)):\n##                    Q d.f. p-value\n## Between groups  1.79    1  0.1814\n## Within groups  39.31   16  0.0010\n## \n## Details on meta-analytical method:\n## - Inverse variance method\n## - Restricted maximum-likelihood estimator for tau^2\n##   (assuming common tau^2 in subgroups)\n## [...]\n在输出中，我们看到估计的研究间异质性方差为 \\(\\tau^2=\\) 0.069，并且在两个子组中相同。我们得到了两个 \\(Q\\) 检验：一个组间（实际的子组检验），另一个是子组内异质性。\n与正常的元分析一样，后者只是表明子组中存在过多的变异性（\\(p=\\) 0.001）。子组差异检验再次表明，低偏倚风险和高偏倚风险研究之间没有显著差异（\\(p=\\) 0.181）。\n我们现在假设 \\(\\tau^2\\) 的独立或共同估计来探索结果。由于我们不知道有什么好的理由假设两个子组中的异质性是相等的，并且考虑到我们在每个子组中至少有 \\(k=\\) 7 项研究，因此可能适合使用 \\(\\tau^2\\) 的单独估计。然而，我们看到，无论如何，至少在我们的示例中，我们对结果的解释对于这两种方法都是相似的。\n\n\n\n报告子组分析的结果\n子组分析的结果通常以表格形式报告，表格显示了每个子组中的估计效应和异质性，以及子组差异检验的 \\(p\\) 值。\n\n\n\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\n\n\n$g$\n95\\%CI\n$p$\n$I^2$\n95\\%CI\n$p$ (subgroup)\n\n\n\n\nRisk of Bias\n\n\n\n\n\n0.092\n\n\n- High\n0.81\n0.28-1.34\n0.009\n0.77\n0.51-0.89\n\n\n\n- Low\n0.43\n0.28-0.58\n&lt; 0.001\n0.25\n0.00-0.63\n\n\n\n\n\n\n\n\n\n\n\n\n在上表中，第三列中的两个 \\(p\\) 值显示了特定于子组的效应是否显著。我们可以看到，高偏倚风险和低偏倚风险研究都是这种情况。与此同时，\\(p_{\\textsf{subgroup}}\\) 下的值显示，高偏倚风险和低偏倚风险研究之间的效应_差异_不显著。\n要提取特定于子组的 \\(p\\) 值，需要将 update 的结果保存到对象中，然后使用 $ 运算符从该对象中提取 pval.random.w 元素。\n如果进行了多个子组分析，则可以将更多行添加到表中。\n\n\n\\[\\tag*{$\\blacksquare$}\\]",
    "crumbs": [
      "网站首页",
      "亚组分析"
    ]
  },
  {
    "objectID": "09-subgroup.html#问题与解答",
    "href": "09-subgroup.html#问题与解答",
    "title": "子组分析",
    "section": "",
    "text": "测试您的知识！\n\n\n\n在最好的情况下，子组分析可以告诉我们什么影响和离群值分析无法告诉我们的信息？\n\n\n\n\n为什么子组分析背后的模型被称为固定效应（复数）模型？\n\n\n\n\n作为您的元分析的一部分，您想检查教育培训计划的效果是否因其交付的学区而异。使用固定效应（复数）模型进行子组分析是否适合回答这个问题？\n\n\n\n\n您的一个朋友进行了一项元分析，其中包含总共 9 项研究。其中五项研究属于一个子组，四项研究属于另一个子组。她问您进行子组分析是否有意义。您会推荐什么？\n\n\n\n\n您找到了一项元分析，其中作者声称分析的治疗方法在女性中比男性更有效。这一发现是基于一项子组分析，其中研究根据研究人群中包含的女性比例分为几组。这一发现是否可信，为什么（不）？\n\n\n\n这些问题的答案列在本 书 末尾的 附录 A 中。",
    "crumbs": [
      "网站首页",
      "亚组分析"
    ]
  },
  {
    "objectID": "09-subgroup.html#总结",
    "href": "09-subgroup.html#总结",
    "title": "子组分析",
    "section": "",
    "text": "尽管有很多方法可以评估元分析的异质性，但这些方法并没有告诉我们为什么我们在数据中发现了过多的变异性。子组分析允许我们检验关于为什么一些研究的真实效应量高于或低于其他研究的假设。\n对于子组分析，我们通常假设一个固定效应（复数）模型。在大多数情况下，子组内的研究使用随机效应模型进行汇集。随后，使用基于总体子组结果的 \\(Q\\) 检验来确定组之间是否存在显著差异。\n子组分析模型被称为“固定效应”模型，因为假设不同的类别本身是固定的。子组水平不被视为从可能的类别集合中随机抽取的。它们代表子组变量可以采用的唯一值。\n在计算子组分析时，我们必须决定是应该使用单独的还是共同的研究间异质性估计来汇集子组内的结果。\n子组分析并非万能药。它们通常缺乏检测子组差异所需的统计功效。因此，子组差异的非显著性检验并不自动意味着子组产生等效的结果。",
    "crumbs": [
      "网站首页",
      "亚组分析"
    ]
  },
  {
    "objectID": "09-subgroup.html#footnotes",
    "href": "09-subgroup.html#footnotes",
    "title": "子组分析",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n在 {meta} 的旧版本（5.0-0 之前的版本）中，此参数称为 byvar。↩︎",
    "crumbs": [
      "网站首页",
      "亚组分析"
    ]
  },
  {
    "objectID": "07-heterogeneity.html",
    "href": "07-heterogeneity.html",
    "title": "研究间异质性",
    "section": "",
    "text": "至 此，我们已经学会了如何在荟萃分析中合并效应量。正如我们所见，固定效应模型和随机效应模型的目标都是将许多不同研究的效应综合成一个单一的数值。然而，只有当我们不是在比较苹果和橘子时，这样做才有意义。例如，可能存在这样一种情况：虽然我们在荟萃分析中计算出的总体效应很小，但仍然存在一些效应量非常高的离群值。这些信息在汇总效应中丢失了，我们不知道所有研究都产生了小的效应量，还是存在例外。\n \n真效应量在荟萃分析中变化的程度称为研究间异质性。我们在上一章中已经简要地提到了这个概念，与随机效应模型相关联。随机效应模型假设研究间异质性导致研究的真效应量有所不同。因此，它包括对 \\(\\tau^2\\) 的估计，\\(\\tau^2\\) 量化了真效应中的这种方差。这允许计算合并效应，定义为真效应量分布的平均值。\n即使研究之间存在很大的异质性，随机效应模型也总是允许我们计算合并效应量。然而，它并没有告诉我们这个合并效应是否可以以有意义的方式解释。在许多情况下，单独的合并效应并不能很好地代表我们荟萃分析中的数据。\n想象这样一种情况：异质性非常高，这意味着真效应量（例如，某种治疗）的范围从高度正值到负值。如果这种荟萃分析的合并效应是正的，这并没有告诉我们有一些研究具有真正的负效应。治疗在某些研究中产生不利影响这一事实丢失了。\n高异质性也可能是由于我们的数据中有两个或多个亚组的研究具有不同的真效应。这些信息对于研究人员来说非常有价值，因为它可能使我们能够找到某些效应较低或较高的环境。然而，如果我们孤立地看待合并效应，这个细节很可能会被忽略。在极端情况下，非常高的异质性可能意味着这些研究没有任何共同之处，并且根本没有意义去解释合并效应。\n因此，荟萃分析师必须始终考虑被分析研究中的变化。每一个好的荟萃分析不仅应该报告一个总体效应，还应该说明这个估计的可信度。其中一个关键部分是量化和分析研究间的异质性。\n在本章中，我们将更仔细地研究测量异质性的不同方法，以及如何解释它们。我们还将介绍一些工具，这些工具允许我们检测导致数据中异质性的研究。最后，我们将讨论在“真实世界”荟萃分析中解决大量异质性的方法。\n\n\n\n\n在我们开始讨论异质性测量之前，我们首先应该明确异质性可能意味着不同的东西。例如，Rücker及其同事 [-@rucker2008undue] 区分了基线或设计相关的异质性和统计异质性。\n\n当研究的人群或研究设计在研究之间存在差异时，就会出现基线或设计相关的异质性。当我们讨论“苹果和橘子”问题（第 @ref(pitfalls) 章）以及定义研究问题的方法（第 @ref(research-question) 章）时，我们已经讨论过这种类型的异质性。可以通过建立一个合适的 PICO 来先验地减少与设计相关的异质性，该 PICO 确定哪些类型的人群和设计有资格进行荟萃分析。\n另一方面，统计异质性是一种可量化的属性，受荟萃分析中包含的效应量估计的离散程度和精度的影响。基线异质性可以导致统计异质性（例如，如果效应在包括的人群之间存在差异），但并非必须如此。荟萃分析也可能表现出较高的统计异质性，即使包括的研究本身实际上是相同的。在本指南（以及大多数其他荟萃分析文本）中，术语“研究间异质性”仅指统计异质性。\n\n\n\n\n\n\n基于随机效应模型，我们知道有两种变异来源导致观察到的效应在研究之间有所不同。有抽样误差 \\(\\epsilon_k\\)，以及由研究间异质性引起的误差 \\(\\zeta_k\\)（第 @ref(rem) 章）。当我们想要量化研究间异质性时，困难在于确定有多少变异可以归因于抽样误差，有多少可以归因于真效应量差异。\n传统上，荟萃分析师使用 Cochran 的 \\(Q\\) [@cochran1954some] 来区分研究的抽样误差和实际的研究间异质性。Cochran 的 \\(Q\\) 被定义为加权平方和 (WSS)。它使用每个研究的观察效应 \\(\\hat\\theta_k\\) 与汇总效应 \\(\\hat\\theta\\) 的偏差，并以研究方差的倒数 \\(w_k\\) 加权：\n\\[\\begin{equation}\nQ = \\sum^K_{k=1}w_k(\\hat\\theta_k-\\hat\\theta)^2\n(\\#eq:het1)\n\\end{equation}\\]\n\n让我们仔细看看这个公式。首先，我们看到它使用了与合并效应量相同的逆方差加权类型。公式中的平均值 \\(\\hat\\theta\\) 是根据固定效应模型得出的合并效应。各个效应与汇总效应的偏差量（残差）被平方（因此该值始终为正），加权然后求和。结果值是 Cochran 的 \\(Q\\)。\n由于 \\(w_k\\) 的加权， \\(Q\\) 的值不仅取决于 \\(\\hat\\theta_k\\) 与 \\(\\hat\\theta\\) 的偏差程度，还取决于研究的精度。如果效应量的标准误差非常低（因此精度非常高），即使与汇总效应的微小偏差也会被赋予更高的权重，从而导致更高的 \\(Q\\) 值。\n\\(Q\\) 的值可以用来检查我们的数据中是否存在过度变异，这意味着比仅从抽样误差预期的变异更大。如果是这种情况，我们可以假设其余的变异是由于研究间异质性造成的。我们将用一个小的模拟来说明这一点。\n\n在我们的模拟中，我们想要检查 \\(Q\\) 在两种不同情况下的行为：当没有研究间异质性时，以及当存在异质性时。让我们从没有异质性的情况开始。这意味着 \\(\\zeta_k=0\\)，并且残差 \\(\\hat\\theta_k-\\hat\\theta\\) 仅是抽样误差 \\(\\epsilon_k\\) 的产物。我们可以使用 rnorm 函数来模拟与某个平均效应量 \\(\\hat\\theta\\) 的偏差（假设它们遵循正态分布）。因为它们以 \\(\\hat\\theta\\) 为中心，我们可以预期这些“残差”的平均值为零（\\(\\mu\\) = 0）。对于这个例子，让我们假设总体标准差为 \\(\\sigma=\\) 1，这导致一个标准正态分布。\n正态分布通常用 \\(\\mathcal{N}\\) 表示，我们可以像这样象征残差是从 \\(\\mu=\\) 0 和 \\(\\sigma=\\) 1 的正态分布中抽取的：\n\\[\\begin{equation}\n\\hat\\theta_k-\\hat\\theta \\sim \\mathcal{N}(0,1)\n(\\#eq:het2)\n\\end{equation}\\]\n让我们在 R 中尝试一下，并使用 rnorm 抽取 \\(K\\)=40 个效应量残差 \\(\\hat\\theta_k-\\hat\\theta\\)。\n\nset.seed(123) # 需要重现结果\nrnorm(n = 40, mean = 0, sd = 1)\n\n##  [1] -0.56048 -0.23018  1.55871  0.07051  0.12929\n##  [6]  1.71506  0.46092 -1.26506 -0.68685 -0.44566\n##  [...]\n\n因为标准正态分布是 rnorm 的默认值，所以我们也可以使用更简单的代码 rnorm(40)。\n现在，让我们模拟重复多次抽取 \\(n=\\) 40 个样本的过程。我们可以使用 replicate 函数来实现这一点，我们告诉它重复 rnorm 调用一万次。我们将结果值保存在一个名为 error_fixed 的对象中。\n\nset.seed(123)\nerror_fixed &lt;- replicate(n = 10000, rnorm(40))\n\n我们继续第二个场景，其中我们假设除了抽样误差 \\(\\epsilon_k\\) 之外，还存在研究间异质性（\\(\\zeta_k\\) 误差）。我们可以通过添加对 rnorm 的第二次调用来模拟这一点，表示真效应量中的方差。在这个例子中，我们还假设真效应量遵循标准正态分布。\n我们可以使用以下代码模拟具有 \\(K\\)=40 项研究和大量研究间异质性的一万个荟萃分析的残差：\n\nset.seed(123)\nerror_random &lt;- replicate(n = 10000, rnorm(40) + rnorm(40))\n\n现在我们已经模拟了有和没有异质性的荟萃分析的 \\(\\hat\\theta_k-\\hat\\theta\\) 残差，让我们对 \\(Q\\) 的值做同样的事情。对于这个模拟，我们可以通过假设每个研究的方差以及权重 \\(w_k\\) 都是1，从而简化 \\(Q\\) 的公式，导致 \\(w_k\\) 从等式中消失。这意味着我们只需要使用之前对 rnorm 的调用，对结果进行平方和求和，并重复这个过程一万次。\n以下是该代码：\n\nset.seed(123)\nQ_fixed &lt;- replicate(10000, sum(rnorm(40)^2))\nQ_random &lt;- replicate(10000, sum((rnorm(40) + rnorm(40))^2))\n\n\\(Q\\) 的一个重要特性是假设它（近似）遵循 \\(\\chi^2\\) 分布。像加权平方和一样，\\(\\chi^2\\) 分布只能取正值。它由其自由度（或 d.f.）定义；对于小的 d.f.，\\(\\chi^2\\) 分布是右偏的，但是当自由度变得更大时，越来越接近正态分布。同时，自由度也是相应 \\(\\chi^2\\) 分布的期望值或平均值。\n假设 \\(Q\\) 将近似遵循具有 \\(K-1\\) 个自由度的 \\(\\chi^2\\) 分布（其中 \\(K\\) 是我们荟萃分析中的研究数量）——如果效应量差异仅由抽样误差引起。这意味着具有 \\(K-1\\) 个自由度的 \\(\\chi^2\\) 分布的平均值告诉我们仅通过抽样误差我们可以预期的 \\(Q\\) 值。\n这个解释非常抽象，所以让我们看一下模拟值的分布，使其更具体。在下面的代码中，我们使用 hist 函数来绘制效应量“残差”和 \\(Q\\) 值的直方图。我们还在每个图中添加了一条线，显示理想化的分布。\n可以使用 dnorm 函数生成正态分布的这种分布，并使用 dchisq 函数生成 \\(\\chi^2\\) 分布，其中 df 指定自由度。\n\n# 残差的直方图 (theta_k - theta)\n# - 我们为 error_fixed 和 error_random 中的模拟值生成直方图\n# - `lines` 用于添加蓝色正态分布。\n\nhist(error_fixed, \n     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, \n     breaks = 100, ylim = c(0, .45), xlim = c(-4,4),\n     main = \"没有异质性\")\nlines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), \n      col = \"blue\", lwd = 2)\n\nhist(error_random, \n     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, \n     breaks = 100,ylim = c(0, .45), xlim = c(-4,4),\n     main = \"异质性\")\nlines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), \n      col = \"blue\", lwd = 2)\n\n\n# 模拟 Q 值的直方图\n# - 我们为 Q_fixed 和 Q_random 中的模拟值生成直方图\n# - `lines` 用于添加蓝色卡方分布。\n\n# 首先，我们计算自由度 (k-1)\n# 记住：每次模拟使用 k=40 项研究\ndf &lt;- 40-1\n\nhist(Q_fixed, xlab = expression(italic(\"Q\")), prob = TRUE, \n     breaks = 100, ylim = c(0, .06),xlim = c(0,160),\n     main = \"没有异质性\")\nlines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), \n      col = \"blue\", lwd = 2)\n\nhist(Q_random,  xlab = expression(italic(\"Q\")), prob = TRUE, \n     breaks = 100, ylim = c(0, .06), xlim = c(0,160),\n     main = \"异质性\")\nlines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), \n      col = \"blue\", lwd = 2)\n\n以下是 R 为我们绘制的图：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n如果您发现我们用来生成绘图的代码难以理解，请不要担心。我们仅将其用于此模拟，这些不是作为实际荟萃分析的一部分会产生的绘图。\n让我们回顾一下我们在四个直方图中看到的内容。在第一行中，我们看到了效应量“残差”的分布，有和没有异质性。正如我们所看到的，没有异质性的数据与我们在绘图中包含的标准正态分布线非常吻合。这是非常合乎逻辑的，因为数据是由 rnorm 生成的，假设了这种精确的分布。我们添加了额外异质性的数据不遵循标准正态分布。数据的离散度更大，导致具有较重尾部的分布。\n\n现在，让我们探讨一下这与第二行中 \\(Q\\) 值的分布有何关系。当没有异质性时，\\(Q\\) 的值遵循一个特征性的右偏 \\(\\chi^2\\) 分布。在图中，实线显示了具有 39 个自由度的 \\(\\chi^2\\) 分布的形状（因为 d.f. = \\(K-1\\)，并且每次模拟使用 \\(K\\) = 40）。我们看到模拟数据很好地遵循了这条曲线。这不足为奇。我们已经了解到，当没有异质性时，\\(Q\\) 遵循具有 \\(K-1\\) 个自由度的 \\(\\chi^2\\) 分布。在我们的模拟数据中，情况正是如此：变异仅由于抽样误差而存在。\n对于我们的有异质性的示例，该分布看起来完全不同。模拟数据似乎根本不遵循预期的分布。值明显向右移动；分布的平均值大约高两倍。我们可以得出结论，当存在大量的研究间异质性时，\\(Q\\) 的值明显高于我们在没有异质性的假设下预期的 \\(K-1\\) 值。这并不奇怪，因为我们向数据添加了额外的变异以模拟研究间异质性的存在。\n\n这是一个有些冗长的解释，但可能帮助我们更好地理解如何利用 \\(Q\\) 的统计特性。Cochran 的 \\(Q\\) 可用于检验荟萃分析中的变异是否显着超过我们可以在没有异质性的零假设下预期的数量。\n这种异质性检验在荟萃分析中很常用，如果您回到第 @ref(pooling-es) 章，您会看到 {meta} 也会默认提供给我们。它通常被称为 Cochran 的 \\(Q\\) 检验，但实际上这是一种用词不当。Cochran 本人从未打算以这种方式使用 \\(Q\\) [@hoaglin2016misunderstandings]。\n \nCochran 的 \\(Q\\) 是一个非常重要的统计量，主要是因为其他常见的量化异质性的方法，例如 Higgins 和 Thompson 的 \\(I^2\\) 统计量和 \\(H^2\\)，都是基于它的。我们将在下一节中介绍这些测量方法。Cochran 的 \\(Q\\) 也被一些异质性方差估计器用来计算 \\(\\tau^2\\)，最著名的是 DerSimonian-Laird 估计器1。\n\n\n\n关于 (Q) 和 (Q) 检验的问题\n\n\n虽然 (Q) 在荟萃分析中被广泛使用和报告，但它有一些缺陷。例如，Hoaglin [-@hoaglin2016misunderstandings] 认为，(Q) 遵循具有 (K-1) 个自由度的 (^2) 分布的假设并不能反映 (Q) 在荟萃分析中的实际行为，并且相关程序（例如 DerSimonian-Laird 方法）因此可能存在偏差。\n\n\n一个更实际的担忧是，(Q) 会随着研究数量 (K) 的增加以及精度（即研究的样本量）的增加而增加。因此，(Q) 以及它是否显着高度取决于您的荟萃分析的大小，因此也取决于它的统计功效。\n\n\n由此可见，我们在评估异质性时，不应仅依赖于 (Q) 检验的显着性。有时，荟萃分析师根据 (Q) 检验的显着性来决定是应用固定效应模型还是随机效应模型。由于我们在此处陈述的原因，强烈不建议使用这种方法。\n\n\n\n\n\n\n\n\n\n\\(I^2\\) 统计量 [@higgins2002quantifying] 是另一种量化研究间异质性的方法，它直接基于 Cochran 的 \\(Q\\)。它被定义为效应量中不由抽样误差引起的变异百分比。 \\(I^2\\) 利用了 \\(Q\\) 在没有异质性的零假设下遵循具有 \\(K-1\\) 个自由度的 \\(\\chi^2\\) 分布的假设。它以百分比量化了 \\(Q\\) 的观察值在多大程度上超过了没有异质性时的预期 \\(Q\\) 值（即 \\(K-1\\)）。\n\\(I^2\\) 的公式如下所示：\n\\[\\begin{equation}\nI^2 = \\frac{Q-(K-1)}{Q}\n(\\#eq:het3)\n\\end{equation}\\]\n其中 \\(K\\) 是研究的总数。 \\(I^2\\) 的值不能低于 0%，因此如果 \\(Q\\) 恰好小于 \\(K-1\\)，我们只需使用 \\(0\\) 而不是负值2。\n我们可以使用之前模拟的 \\(Q\\) 值来说明如何计算 \\(I^2\\)。首先，让我们随机选取 Q_fixed 中第十个模拟值，其中我们假设没有异质性。然后，我们使用上面的公式计算 \\(I^2\\)。\n\n# 显示 Q 的第 10 个模拟的值\nQ_fixed[10]\n\n[1] 35.85787\n\n# 定义 k\nk &lt;- 40\n\n# 计算 I^2\n(Q_fixed[10] - (k-1))/Q_fixed[10]\n\n[1] -0.08762746\n\n\n由于结果为负，我们向上舍入为零，从而得到 \\(I^2\\) = 0%。该值告诉我们，效应量中零百分比的变异是由于研究间异质性引起的。这与我们模拟中使用的设置一致。\n现在，我们对 Q_random 中的第十个模拟值执行相同的操作。\n\n(Q_random[10] - (k-1))/Q_random[10]\n\n[1] 0.5692061\n\n\n我们看到此模拟的 \\(I^2\\) 值约为 50%，这意味着大约一半的变异是由于研究间异质性引起的。这也与我们的预期一致，因为此示例中的变异基于模拟的抽样误差和研究间异质性，各占一半。\n通常使用 \\(I^2\\) 统计量来报告荟萃分析中的研究间异质性，并且默认情况下，我们在 {meta} 中获得的输出中包含 \\(I^2\\)。该统计量的普及可能与其存在“经验法则”相关，说明我们如何解释它 [@higgins2002quantifying]：\n\n\\(I^2\\) = 25%: 低异质性\n\\(I^2\\) = 50%: 中等异质性\n\\(I^2\\) = 75%: 大量异质性。\n\n\n\n\n\n\n\\(H^2\\) 统计量 [@higgins2002quantifying] 也来自 Cochran 的 \\(Q\\)，并且与 \\(I^2\\) 相似。它描述了观察到的变异（由 \\(Q\\) 测量）与由于抽样误差引起的预期方差的比率：\n\\[\\begin{equation}\nH^2 = \\frac{Q}{K-1}\n(\\#eq:het4)\n\\end{equation}\\]\n\\(H^2\\) 的计算比 \\(I^2\\) 的计算略微优雅一些，因为当 \\(Q\\) 小于 \\(K-1\\) 时，我们不必人为地校正其值。当没有研究间异质性时，\\(H^2\\) 等于 1（或更小）。大于 1 的值表示存在研究间异质性。\n与 \\(I^2\\) 相比，在已发表的荟萃分析中发现报告该统计量的频率要低得多。但是，默认情况下，{meta} 的荟萃分析函数的输出中也包含 \\(H^2\\)。\n\n\n\n\n\n我们在第 @ref(rem) 章中已经详细讨论了异质性方差 \\(\\tau^2\\)。正如我们在那里提到的，\\(\\tau^2\\) 量化了我们数据基础的真效应量的方差。当我们取 \\(\\tau^2\\) 的平方根时，我们得到 \\(\\tau\\)，它是真效应量的标准差。\n\\(\\tau\\) 的一个很大的优点是它以与效应量度量相同的尺度表示。这意味着我们可以像解释一级研究中样本年龄的平均值和标准差一样来解释它。 \\(\\tau\\) 的值告诉我们一些关于真效应量的范围的信息。\n例如，我们可以通过将 \\(\\tau\\) 乘以 1.96 来计算真效应量的 95% 置信区间，然后从合并效应量中加上和减去该值。我们可以使用我们在第 @ref(pre-calculated-es) 章中计算的 m.gen 荟萃分析来尝试一下。\n让我们再次看看该荟萃分析中的合并效应和 \\(\\tau\\) 估计值是什么：\n\n# 合并效应\nm.gen$TE.random\n\n[1] 0.5771158\n\n# tau 的估计\nm.gen$tau\n\n[1] 0.2863311\n\n\n我们看到 \\(g=\\) 0.58 和 \\(\\tau=\\) 0.29。基于这些数据，我们可以计算 95% 真效应量置信区间的下限和上限：0.58 \\(-\\) 1.96 \\(\\times\\) 0.29 = 0.01 和 0.58 \\(+\\) 1.96 \\(\\times\\) 0.29 = 1.15。\n\n\n\n“我们不确定性的不确定性是什么？”：围绕 \\(\\tau^2\\) 计算置信区间\n量化我们研究间异质性方差估计的不确定性的方法（即围绕 \\(\\tau^2\\) 的置信区间）仍然是一个正在进行的研究领域。有几种方法是可能的，它们的充分性取决于 \\(\\tau^2\\) 估计器的类型（第 @ref(tau-estimators) 章）。\n{meta} 包遵循 Veronikki [-@veroniki2016methods] 的建议，并对大多数估计器使用 \\(Q\\)-Profile 方法 [@viechtbauer2007confidence]。\n\\(Q\\)-Profile 方法基于更改后的 \\(Q\\) 版本，即广义 \\(Q\\)-statistic \\(Q_{\\text{gen}}\\)。虽然标准版本的 \\(Q\\) 使用基于固定效应模型的合并效应，但 \\(Q_{\\text{gen}}\\) 基于随机效应模型。它使用根据随机效应模型得出的总体效应 \\(\\hat\\mu\\) 来计算偏差，以及基于随机效应模型的权重：\n\\[\\begin{equation}\nQ_{\\text{gen}} = \\sum_{k=1}^{K} w^*_k (\\hat\\theta_k-\\hat\\mu)^2\n(\\#eq:het5)\n\\end{equation}\\]\n其中 \\(w^*_k\\) 是随机效应权重（参见第 @ref(tau-estimators) 章）：\n\\[\\begin{equation}\nw^*_k = \\frac{1}{s^2_k+\\tau^2}\n(\\#eq:het6)\n\\end{equation}\\]\n\\(Q_{\\text{gen}}\\) 也被证明遵循具有 \\(K-1\\) 个自由度的 \\(\\chi^2\\) 分布。我们可以将广义 \\(Q\\) 统计量视为一个函数 \\(Q_{\\text{gen}}(\\tau^2)\\)，该函数为更高或更低的 \\(\\tau^2\\) 值返回不同的 \\(Q_{\\text{gen}}\\) 值。此函数的结果具有 \\(\\chi^2\\) 分布。\n由于 \\(\\chi^2\\) 分布遵循清晰可预测的模式，因此很容易确定具有例如 95% 覆盖率的置信区间。我们只需要根据其 \\(K-1\\) 个自由度获得第 2.5 个百分位数和第 97.5 个百分位数的 \\(\\chi^2\\) 值。在 R 中，可以使用分位数函数 qchisq 轻松完成此操作，例如：qchisq(0.975, df=5)。\n\\(Q\\)-Profile 方法利用这种关系，使用迭代过程（所谓的“分析”）计算围绕 \\(\\tau^2\\) 的置信区间。在这种方法中，重复计算 \\(Q_{\\text{gen}}(\\widetilde{\\tau}^2)\\)，同时增加 \\(\\tau^2\\) 的值，直到达到基于 \\(\\chi^2\\) 分布的置信区间的下限和上限的预期值。\n可以通过参数 method.tau.ci = \"QP\" 在 {meta} 函数中指定 \\(Q\\)-Profile 方法。这是默认设置，这意味着我们不必手动添加此参数。唯一的例外是当我们使用 DerSimonian-Laird 估计器 (method.tau = \"DL\") 时。在这种情况下，会自动使用 Jackson [-@jackson2013confidence] 的另一种方法（我们可以通过指定 method.tau.ci = \"J\" 手动执行此操作）。\n通常，没有必要偏离 {meta} 的默认行为，但对于其他人来说，报告已使用哪种方法在您的荟萃分析中计算围绕 \\(\\tau^2\\) 的置信区间可能会有所帮助。\n\n\n\n\n\n\n\n\n当我们在荟萃分析中评估和报告异质性时，我们需要一种稳健的测量方法，并且不会受到统计功效的过度影响。Cochran 的 \\(Q\\) 会随着研究数量的增加以及精度（即研究的样本量）的增加而增加。\n因此，\\(Q\\) 以及它是否显着高度取决于您的荟萃分析的大小，因此也取决于它的统计功效。因此，我们在评估研究间异质性时，不应仅依赖于 \\(Q\\)，尤其是 \\(Q\\) 检验。\n另一方面，\\(I^2\\) 对分析中研究数量的变化不敏感。它相对容易解释，并且许多研究人员都了解它的含义。总的来说，在我们的荟萃分析报告中包含 \\(I^2\\) 作为异质性测量方法并不是一个坏主意，特别是如果我们还为此统计量提供置信区间，以便其他人可以评估估计的精确度。\n \n然而，尽管 \\(I^2\\) 在文献中被广泛使用，但它也不是一个完美的异质性度量。它不是异质性的绝对度量，并且它的值仍然在很大程度上取决于所包含研究的精度 [@borenstein2017basics; @rucker2008undue]。正如之前所说，\\(I^2\\) 仅仅是不由抽样误差 \\(\\epsilon\\) 引起的变异百分比。如果我们的研究变得越来越大，则抽样误差趋向于零，同时，\\(I^2\\) 趋向于 100%——仅仅是因为这些研究具有更大的样本量。\n因此，仅依赖 \\(I^2\\) 也不是一个好的选择。由于 \\(H^2\\) 的行为与 \\(I^2\\) 相似，因此相同的注意事项也适用于此统计量。\n另一方面，\\(\\tau^2\\) 和 \\(\\tau\\) 的值对研究数量及其精度不敏感。随着研究数量及其规模的增加，它不会系统地增加。然而，通常很难从实际角度解释 \\(\\tau^2\\) 的相关性。例如，假设我们发现研究中真效应量的方差为 \\(\\tau^2=\\) 0.08。我们自己和其他人通常很难确定这种方差量是否有意义。\n\n预测区间 (PI) 是克服此限制的好方法 [@inthout2016plea]。预测区间为我们提供了一个范围，根据目前的证据，我们可以预期未来研究的效应会落入该范围。\n假设我们的预测区间完全位于支持干预的“正”侧。这意味着，尽管效应各不相同，但预计干预在未来我们研究的背景下是有益的。如果预测区间包括零，我们可以不太确定这一点，但应该注意的是，广泛的预测区间非常常见。\n为了计算围绕总体效应 \\(\\hat\\mu\\) 的预测区间，我们同时使用估计的研究间异质性方差 \\(\\hat\\tau^2\\) 和合并效应的标准误差 \\(SE_{\\hat\\mu}\\)。我们对平方标准误差和 \\(\\hat\\tau^2\\) 值求和，然后取结果的平方根。这使我们获得了预测区间的标准差 \\(SD_{\\text{PI}}\\)。假设预测范围的 \\(t\\) 分布具有 \\(K-1\\) 个自由度，这就是为什么我们将 \\(SD_{\\text{PI}}\\) 乘以 \\(t_{K-1}\\) 的第 97.5 个百分位数值，然后从 \\(\\hat\\mu\\) 中加上和",
    "crumbs": [
      "网站首页",
      "异质性"
    ]
  },
  {
    "objectID": "07-heterogeneity.html#het-measures",
    "href": "07-heterogeneity.html#het-measures",
    "title": "研究间异质性",
    "section": "",
    "text": "在我们开始讨论异质性测量之前，我们首先应该明确异质性可能意味着不同的东西。例如，Rücker及其同事 [-@rucker2008undue] 区分了基线或设计相关的异质性和统计异质性。\n\n当研究的人群或研究设计在研究之间存在差异时，就会出现基线或设计相关的异质性。当我们讨论“苹果和橘子”问题（第 @ref(pitfalls) 章）以及定义研究问题的方法（第 @ref(research-question) 章）时，我们已经讨论过这种类型的异质性。可以通过建立一个合适的 PICO 来先验地减少与设计相关的异质性，该 PICO 确定哪些类型的人群和设计有资格进行荟萃分析。\n另一方面，统计异质性是一种可量化的属性，受荟萃分析中包含的效应量估计的离散程度和精度的影响。基线异质性可以导致统计异质性（例如，如果效应在包括的人群之间存在差异），但并非必须如此。荟萃分析也可能表现出较高的统计异质性，即使包括的研究本身实际上是相同的。在本指南（以及大多数其他荟萃分析文本）中，术语“研究间异质性”仅指统计异质性。\n\n\n\n\n\n\n基于随机效应模型，我们知道有两种变异来源导致观察到的效应在研究之间有所不同。有抽样误差 \\(\\epsilon_k\\)，以及由研究间异质性引起的误差 \\(\\zeta_k\\)（第 @ref(rem) 章）。当我们想要量化研究间异质性时，困难在于确定有多少变异可以归因于抽样误差，有多少可以归因于真效应量差异。\n传统上，荟萃分析师使用 Cochran 的 \\(Q\\) [@cochran1954some] 来区分研究的抽样误差和实际的研究间异质性。Cochran 的 \\(Q\\) 被定义为加权平方和 (WSS)。它使用每个研究的观察效应 \\(\\hat\\theta_k\\) 与汇总效应 \\(\\hat\\theta\\) 的偏差，并以研究方差的倒数 \\(w_k\\) 加权：\n\\[\\begin{equation}\nQ = \\sum^K_{k=1}w_k(\\hat\\theta_k-\\hat\\theta)^2\n(\\#eq:het1)\n\\end{equation}\\]\n\n让我们仔细看看这个公式。首先，我们看到它使用了与合并效应量相同的逆方差加权类型。公式中的平均值 \\(\\hat\\theta\\) 是根据固定效应模型得出的合并效应。各个效应与汇总效应的偏差量（残差）被平方（因此该值始终为正），加权然后求和。结果值是 Cochran 的 \\(Q\\)。\n由于 \\(w_k\\) 的加权， \\(Q\\) 的值不仅取决于 \\(\\hat\\theta_k\\) 与 \\(\\hat\\theta\\) 的偏差程度，还取决于研究的精度。如果效应量的标准误差非常低（因此精度非常高），即使与汇总效应的微小偏差也会被赋予更高的权重，从而导致更高的 \\(Q\\) 值。\n\\(Q\\) 的值可以用来检查我们的数据中是否存在过度变异，这意味着比仅从抽样误差预期的变异更大。如果是这种情况，我们可以假设其余的变异是由于研究间异质性造成的。我们将用一个小的模拟来说明这一点。\n\n在我们的模拟中，我们想要检查 \\(Q\\) 在两种不同情况下的行为：当没有研究间异质性时，以及当存在异质性时。让我们从没有异质性的情况开始。这意味着 \\(\\zeta_k=0\\)，并且残差 \\(\\hat\\theta_k-\\hat\\theta\\) 仅是抽样误差 \\(\\epsilon_k\\) 的产物。我们可以使用 rnorm 函数来模拟与某个平均效应量 \\(\\hat\\theta\\) 的偏差（假设它们遵循正态分布）。因为它们以 \\(\\hat\\theta\\) 为中心，我们可以预期这些“残差”的平均值为零（\\(\\mu\\) = 0）。对于这个例子，让我们假设总体标准差为 \\(\\sigma=\\) 1，这导致一个标准正态分布。\n正态分布通常用 \\(\\mathcal{N}\\) 表示，我们可以像这样象征残差是从 \\(\\mu=\\) 0 和 \\(\\sigma=\\) 1 的正态分布中抽取的：\n\\[\\begin{equation}\n\\hat\\theta_k-\\hat\\theta \\sim \\mathcal{N}(0,1)\n(\\#eq:het2)\n\\end{equation}\\]\n让我们在 R 中尝试一下，并使用 rnorm 抽取 \\(K\\)=40 个效应量残差 \\(\\hat\\theta_k-\\hat\\theta\\)。\n\nset.seed(123) # 需要重现结果\nrnorm(n = 40, mean = 0, sd = 1)\n\n##  [1] -0.56048 -0.23018  1.55871  0.07051  0.12929\n##  [6]  1.71506  0.46092 -1.26506 -0.68685 -0.44566\n##  [...]\n\n因为标准正态分布是 rnorm 的默认值，所以我们也可以使用更简单的代码 rnorm(40)。\n现在，让我们模拟重复多次抽取 \\(n=\\) 40 个样本的过程。我们可以使用 replicate 函数来实现这一点，我们告诉它重复 rnorm 调用一万次。我们将结果值保存在一个名为 error_fixed 的对象中。\n\nset.seed(123)\nerror_fixed &lt;- replicate(n = 10000, rnorm(40))\n\n我们继续第二个场景，其中我们假设除了抽样误差 \\(\\epsilon_k\\) 之外，还存在研究间异质性（\\(\\zeta_k\\) 误差）。我们可以通过添加对 rnorm 的第二次调用来模拟这一点，表示真效应量中的方差。在这个例子中，我们还假设真效应量遵循标准正态分布。\n我们可以使用以下代码模拟具有 \\(K\\)=40 项研究和大量研究间异质性的一万个荟萃分析的残差：\n\nset.seed(123)\nerror_random &lt;- replicate(n = 10000, rnorm(40) + rnorm(40))\n\n现在我们已经模拟了有和没有异质性的荟萃分析的 \\(\\hat\\theta_k-\\hat\\theta\\) 残差，让我们对 \\(Q\\) 的值做同样的事情。对于这个模拟，我们可以通过假设每个研究的方差以及权重 \\(w_k\\) 都是1，从而简化 \\(Q\\) 的公式，导致 \\(w_k\\) 从等式中消失。这意味着我们只需要使用之前对 rnorm 的调用，对结果进行平方和求和，并重复这个过程一万次。\n以下是该代码：\n\nset.seed(123)\nQ_fixed &lt;- replicate(10000, sum(rnorm(40)^2))\nQ_random &lt;- replicate(10000, sum((rnorm(40) + rnorm(40))^2))\n\n\\(Q\\) 的一个重要特性是假设它（近似）遵循 \\(\\chi^2\\) 分布。像加权平方和一样，\\(\\chi^2\\) 分布只能取正值。它由其自由度（或 d.f.）定义；对于小的 d.f.，\\(\\chi^2\\) 分布是右偏的，但是当自由度变得更大时，越来越接近正态分布。同时，自由度也是相应 \\(\\chi^2\\) 分布的期望值或平均值。\n假设 \\(Q\\) 将近似遵循具有 \\(K-1\\) 个自由度的 \\(\\chi^2\\) 分布（其中 \\(K\\) 是我们荟萃分析中的研究数量）——如果效应量差异仅由抽样误差引起。这意味着具有 \\(K-1\\) 个自由度的 \\(\\chi^2\\) 分布的平均值告诉我们仅通过抽样误差我们可以预期的 \\(Q\\) 值。\n这个解释非常抽象，所以让我们看一下模拟值的分布，使其更具体。在下面的代码中，我们使用 hist 函数来绘制效应量“残差”和 \\(Q\\) 值的直方图。我们还在每个图中添加了一条线，显示理想化的分布。\n可以使用 dnorm 函数生成正态分布的这种分布，并使用 dchisq 函数生成 \\(\\chi^2\\) 分布，其中 df 指定自由度。\n\n# 残差的直方图 (theta_k - theta)\n# - 我们为 error_fixed 和 error_random 中的模拟值生成直方图\n# - `lines` 用于添加蓝色正态分布。\n\nhist(error_fixed, \n     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, \n     breaks = 100, ylim = c(0, .45), xlim = c(-4,4),\n     main = \"没有异质性\")\nlines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), \n      col = \"blue\", lwd = 2)\n\nhist(error_random, \n     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, \n     breaks = 100,ylim = c(0, .45), xlim = c(-4,4),\n     main = \"异质性\")\nlines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), \n      col = \"blue\", lwd = 2)\n\n\n# 模拟 Q 值的直方图\n# - 我们为 Q_fixed 和 Q_random 中的模拟值生成直方图\n# - `lines` 用于添加蓝色卡方分布。\n\n# 首先，我们计算自由度 (k-1)\n# 记住：每次模拟使用 k=40 项研究\ndf &lt;- 40-1\n\nhist(Q_fixed, xlab = expression(italic(\"Q\")), prob = TRUE, \n     breaks = 100, ylim = c(0, .06),xlim = c(0,160),\n     main = \"没有异质性\")\nlines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), \n      col = \"blue\", lwd = 2)\n\nhist(Q_random,  xlab = expression(italic(\"Q\")), prob = TRUE, \n     breaks = 100, ylim = c(0, .06), xlim = c(0,160),\n     main = \"异质性\")\nlines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), \n      col = \"blue\", lwd = 2)\n\n以下是 R 为我们绘制的图：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n如果您发现我们用来生成绘图的代码难以理解，请不要担心。我们仅将其用于此模拟，这些不是作为实际荟萃分析的一部分会产生的绘图。\n让我们回顾一下我们在四个直方图中看到的内容。在第一行中，我们看到了效应量“残差”的分布，有和没有异质性。正如我们所看到的，没有异质性的数据与我们在绘图中包含的标准正态分布线非常吻合。这是非常合乎逻辑的，因为数据是由 rnorm 生成的，假设了这种精确的分布。我们添加了额外异质性的数据不遵循标准正态分布。数据的离散度更大，导致具有较重尾部的分布。\n\n现在，让我们探讨一下这与第二行中 \\(Q\\) 值的分布有何关系。当没有异质性时，\\(Q\\) 的值遵循一个特征性的右偏 \\(\\chi^2\\) 分布。在图中，实线显示了具有 39 个自由度的 \\(\\chi^2\\) 分布的形状（因为 d.f. = \\(K-1\\)，并且每次模拟使用 \\(K\\) = 40）。我们看到模拟数据很好地遵循了这条曲线。这不足为奇。我们已经了解到，当没有异质性时，\\(Q\\) 遵循具有 \\(K-1\\) 个自由度的 \\(\\chi^2\\) 分布。在我们的模拟数据中，情况正是如此：变异仅由于抽样误差而存在。\n对于我们的有异质性的示例，该分布看起来完全不同。模拟数据似乎根本不遵循预期的分布。值明显向右移动；分布的平均值大约高两倍。我们可以得出结论，当存在大量的研究间异质性时，\\(Q\\) 的值明显高于我们在没有异质性的假设下预期的 \\(K-1\\) 值。这并不奇怪，因为我们向数据添加了额外的变异以模拟研究间异质性的存在。\n\n这是一个有些冗长的解释，但可能帮助我们更好地理解如何利用 \\(Q\\) 的统计特性。Cochran 的 \\(Q\\) 可用于检验荟萃分析中的变异是否显着超过我们可以在没有异质性的零假设下预期的数量。\n这种异质性检验在荟萃分析中很常用，如果您回到第 @ref(pooling-es) 章，您会看到 {meta} 也会默认提供给我们。它通常被称为 Cochran 的 \\(Q\\) 检验，但实际上这是一种用词不当。Cochran 本人从未打算以这种方式使用 \\(Q\\) [@hoaglin2016misunderstandings]。\n \nCochran 的 \\(Q\\) 是一个非常重要的统计量，主要是因为其他常见的量化异质性的方法，例如 Higgins 和 Thompson 的 \\(I^2\\) 统计量和 \\(H^2\\)，都是基于它的。我们将在下一节中介绍这些测量方法。Cochran 的 \\(Q\\) 也被一些异质性方差估计器用来计算 \\(\\tau^2\\)，最著名的是 DerSimonian-Laird 估计器1。\n\n\n\n关于 (Q) 和 (Q) 检验的问题\n\n\n虽然 (Q) 在荟萃分析中被广泛使用和报告，但它有一些缺陷。例如，Hoaglin [-@hoaglin2016misunderstandings] 认为，(Q) 遵循具有 (K-1) 个自由度的 (^2) 分布的假设并不能反映 (Q) 在荟萃分析中的实际行为，并且相关程序（例如 DerSimonian-Laird 方法）因此可能存在偏差。\n\n\n一个更实际的担忧是，(Q) 会随着研究数量 (K) 的增加以及精度（即研究的样本量）的增加而增加。因此，(Q) 以及它是否显着高度取决于您的荟萃分析的大小，因此也取决于它的统计功效。\n\n\n由此可见，我们在评估异质性时，不应仅依赖于 (Q) 检验的显着性。有时，荟萃分析师根据 (Q) 检验的显着性来决定是应用固定效应模型还是随机效应模型。由于我们在此处陈述的原因，强烈不建议使用这种方法。\n\n\n\n\n\n\n\n\n\n\\(I^2\\) 统计量 [@higgins2002quantifying] 是另一种量化研究间异质性的方法，它直接基于 Cochran 的 \\(Q\\)。它被定义为效应量中不由抽样误差引起的变异百分比。 \\(I^2\\) 利用了 \\(Q\\) 在没有异质性的零假设下遵循具有 \\(K-1\\) 个自由度的 \\(\\chi^2\\) 分布的假设。它以百分比量化了 \\(Q\\) 的观察值在多大程度上超过了没有异质性时的预期 \\(Q\\) 值（即 \\(K-1\\)）。\n\\(I^2\\) 的公式如下所示：\n\\[\\begin{equation}\nI^2 = \\frac{Q-(K-1)}{Q}\n(\\#eq:het3)\n\\end{equation}\\]\n其中 \\(K\\) 是研究的总数。 \\(I^2\\) 的值不能低于 0%，因此如果 \\(Q\\) 恰好小于 \\(K-1\\)，我们只需使用 \\(0\\) 而不是负值2。\n我们可以使用之前模拟的 \\(Q\\) 值来说明如何计算 \\(I^2\\)。首先，让我们随机选取 Q_fixed 中第十个模拟值，其中我们假设没有异质性。然后，我们使用上面的公式计算 \\(I^2\\)。\n\n# 显示 Q 的第 10 个模拟的值\nQ_fixed[10]\n\n[1] 35.85787\n\n# 定义 k\nk &lt;- 40\n\n# 计算 I^2\n(Q_fixed[10] - (k-1))/Q_fixed[10]\n\n[1] -0.08762746\n\n\n由于结果为负，我们向上舍入为零，从而得到 \\(I^2\\) = 0%。该值告诉我们，效应量中零百分比的变异是由于研究间异质性引起的。这与我们模拟中使用的设置一致。\n现在，我们对 Q_random 中的第十个模拟值执行相同的操作。\n\n(Q_random[10] - (k-1))/Q_random[10]\n\n[1] 0.5692061\n\n\n我们看到此模拟的 \\(I^2\\) 值约为 50%，这意味着大约一半的变异是由于研究间异质性引起的。这也与我们的预期一致，因为此示例中的变异基于模拟的抽样误差和研究间异质性，各占一半。\n通常使用 \\(I^2\\) 统计量来报告荟萃分析中的研究间异质性，并且默认情况下，我们在 {meta} 中获得的输出中包含 \\(I^2\\)。该统计量的普及可能与其存在“经验法则”相关，说明我们如何解释它 [@higgins2002quantifying]：\n\n\\(I^2\\) = 25%: 低异质性\n\\(I^2\\) = 50%: 中等异质性\n\\(I^2\\) = 75%: 大量异质性。\n\n\n\n\n\n\n\\(H^2\\) 统计量 [@higgins2002quantifying] 也来自 Cochran 的 \\(Q\\)，并且与 \\(I^2\\) 相似。它描述了观察到的变异（由 \\(Q\\) 测量）与由于抽样误差引起的预期方差的比率：\n\\[\\begin{equation}\nH^2 = \\frac{Q}{K-1}\n(\\#eq:het4)\n\\end{equation}\\]\n\\(H^2\\) 的计算比 \\(I^2\\) 的计算略微优雅一些，因为当 \\(Q\\) 小于 \\(K-1\\) 时，我们不必人为地校正其值。当没有研究间异质性时，\\(H^2\\) 等于 1（或更小）。大于 1 的值表示存在研究间异质性。\n与 \\(I^2\\) 相比，在已发表的荟萃分析中发现报告该统计量的频率要低得多。但是，默认情况下，{meta} 的荟萃分析函数的输出中也包含 \\(H^2\\)。\n\n\n\n\n\n我们在第 @ref(rem) 章中已经详细讨论了异质性方差 \\(\\tau^2\\)。正如我们在那里提到的，\\(\\tau^2\\) 量化了我们数据基础的真效应量的方差。当我们取 \\(\\tau^2\\) 的平方根时，我们得到 \\(\\tau\\)，它是真效应量的标准差。\n\\(\\tau\\) 的一个很大的优点是它以与效应量度量相同的尺度表示。这意味着我们可以像解释一级研究中样本年龄的平均值和标准差一样来解释它。 \\(\\tau\\) 的值告诉我们一些关于真效应量的范围的信息。\n例如，我们可以通过将 \\(\\tau\\) 乘以 1.96 来计算真效应量的 95% 置信区间，然后从合并效应量中加上和减去该值。我们可以使用我们在第 @ref(pre-calculated-es) 章中计算的 m.gen 荟萃分析来尝试一下。\n让我们再次看看该荟萃分析中的合并效应和 \\(\\tau\\) 估计值是什么：\n\n# 合并效应\nm.gen$TE.random\n\n[1] 0.5771158\n\n# tau 的估计\nm.gen$tau\n\n[1] 0.2863311\n\n\n我们看到 \\(g=\\) 0.58 和 \\(\\tau=\\) 0.29。基于这些数据，我们可以计算 95% 真效应量置信区间的下限和上限：0.58 \\(-\\) 1.96 \\(\\times\\) 0.29 = 0.01 和 0.58 \\(+\\) 1.96 \\(\\times\\) 0.29 = 1.15。\n\n\n\n“我们不确定性的不确定性是什么？”：围绕 \\(\\tau^2\\) 计算置信区间\n量化我们研究间异质性方差估计的不确定性的方法（即围绕 \\(\\tau^2\\) 的置信区间）仍然是一个正在进行的研究领域。有几种方法是可能的，它们的充分性取决于 \\(\\tau^2\\) 估计器的类型（第 @ref(tau-estimators) 章）。\n{meta} 包遵循 Veronikki [-@veroniki2016methods] 的建议，并对大多数估计器使用 \\(Q\\)-Profile 方法 [@viechtbauer2007confidence]。\n\\(Q\\)-Profile 方法基于更改后的 \\(Q\\) 版本，即广义 \\(Q\\)-statistic \\(Q_{\\text{gen}}\\)。虽然标准版本的 \\(Q\\) 使用基于固定效应模型的合并效应，但 \\(Q_{\\text{gen}}\\) 基于随机效应模型。它使用根据随机效应模型得出的总体效应 \\(\\hat\\mu\\) 来计算偏差，以及基于随机效应模型的权重：\n\\[\\begin{equation}\nQ_{\\text{gen}} = \\sum_{k=1}^{K} w^*_k (\\hat\\theta_k-\\hat\\mu)^2\n(\\#eq:het5)\n\\end{equation}\\]\n其中 \\(w^*_k\\) 是随机效应权重（参见第 @ref(tau-estimators) 章）：\n\\[\\begin{equation}\nw^*_k = \\frac{1}{s^2_k+\\tau^2}\n(\\#eq:het6)\n\\end{equation}\\]\n\\(Q_{\\text{gen}}\\) 也被证明遵循具有 \\(K-1\\) 个自由度的 \\(\\chi^2\\) 分布。我们可以将广义 \\(Q\\) 统计量视为一个函数 \\(Q_{\\text{gen}}(\\tau^2)\\)，该函数为更高或更低的 \\(\\tau^2\\) 值返回不同的 \\(Q_{\\text{gen}}\\) 值。此函数的结果具有 \\(\\chi^2\\) 分布。\n由于 \\(\\chi^2\\) 分布遵循清晰可预测的模式，因此很容易确定具有例如 95% 覆盖率的置信区间。我们只需要根据其 \\(K-1\\) 个自由度获得第 2.5 个百分位数和第 97.5 个百分位数的 \\(\\chi^2\\) 值。在 R 中，可以使用分位数函数 qchisq 轻松完成此操作，例如：qchisq(0.975, df=5)。\n\\(Q\\)-Profile 方法利用这种关系，使用迭代过程（所谓的“分析”）计算围绕 \\(\\tau^2\\) 的置信区间。在这种方法中，重复计算 \\(Q_{\\text{gen}}(\\widetilde{\\tau}^2)\\)，同时增加 \\(\\tau^2\\) 的值，直到达到基于 \\(\\chi^2\\) 分布的置信区间的下限和上限的预期值。\n可以通过参数 method.tau.ci = \"QP\" 在 {meta} 函数中指定 \\(Q\\)-Profile 方法。这是默认设置，这意味着我们不必手动添加此参数。唯一的例外是当我们使用 DerSimonian-Laird 估计器 (method.tau = \"DL\") 时。在这种情况下，会自动使用 Jackson [-@jackson2013confidence] 的另一种方法（我们可以通过指定 method.tau.ci = \"J\" 手动执行此操作）。\n通常，没有必要偏离 {meta} 的默认行为，但对于其他人来说，报告已使用哪种方法在您的荟萃分析中计算围绕 \\(\\tau^2\\) 的置信区间可能会有所帮助。",
    "crumbs": [
      "网站首页",
      "异质性"
    ]
  },
  {
    "objectID": "07-heterogeneity.html#het-measure-which",
    "href": "07-heterogeneity.html#het-measure-which",
    "title": "研究间异质性",
    "section": "",
    "text": "当我们在荟萃分析中评估和报告异质性时，我们需要一种稳健的测量方法，并且不会受到统计功效的过度影响。Cochran 的 \\(Q\\) 会随着研究数量的增加以及精度（即研究的样本量）的增加而增加。\n因此，\\(Q\\) 以及它是否显着高度取决于您的荟萃分析的大小，因此也取决于它的统计功效。因此，我们在评估研究间异质性时，不应仅依赖于 \\(Q\\)，尤其是 \\(Q\\) 检验。\n另一方面，\\(I^2\\) 对分析中研究数量的变化不敏感。它相对容易解释，并且许多研究人员都了解它的含义。总的来说，在我们的荟萃分析报告中包含 \\(I^2\\) 作为异质性测量方法并不是一个坏主意，特别是如果我们还为此统计量提供置信区间，以便其他人可以评估估计的精确度。\n \n然而，尽管 \\(I^2\\) 在文献中被广泛使用，但它也不是一个完美的异质性度量。它不是异质性的绝对度量，并且它的值仍然在很大程度上取决于所包含研究的精度 [@borenstein2017basics; @rucker2008undue]。正如之前所说，\\(I^2\\) 仅仅是不由抽样误差 \\(\\epsilon\\) 引起的变异百分比。如果我们的研究变得越来越大，则抽样误差趋向于零，同时，\\(I^2\\) 趋向于 100%——仅仅是因为这些研究具有更大的样本量。\n因此，仅依赖 \\(I^2\\) 也不是一个好的选择。由于 \\(H^2\\) 的行为与 \\(I^2\\) 相似，因此相同的注意事项也适用于此统计量。\n另一方面，\\(\\tau^2\\) 和 \\(\\tau\\) 的值对研究数量及其精度不敏感。随着研究数量及其规模的增加，它不会系统地增加。然而，通常很难从实际角度解释 \\(\\tau^2\\) 的相关性。例如，假设我们发现研究中真效应量的方差为 \\(\\tau^2=\\) 0.08。我们自己和其他人通常很难确定这种方差量是否有意义。\n\n预测区间 (PI) 是克服此限制的好方法 [@inthout2016plea]。预测区间为我们提供了一个范围，根据目前的证据，我们可以预期未来研究的效应会落入该范围。\n假设我们的预测区间完全位于支持干预的“正”侧。这意味着，尽管效应各不相同，但预计干预在未来我们研究的背景下是有益的。如果预测区间包括零，我们可以不太确定这一点，但应该注意的是，广泛的预测区间非常常见。\n为了计算围绕总体效应 \\(\\hat\\mu\\) 的预测区间，我们同时使用估计的研究间异质性方差 \\(\\hat\\tau^2\\) 和合并效应的标准误差 \\(SE_{\\hat\\mu}\\)。我们对平方标准误差和 \\(\\hat\\tau^2\\) 值求和，然后取结果的平方根。这使我们获得了预测区间的标准差 \\(SD_{\\text{PI}}\\)。假设预测范围的 \\(t\\) 分布具有 \\(K-1\\) 个自由度，这就是为什么我们将 \\(SD_{\\text{PI}}\\) 乘以 \\(t_{K-1}\\) 的第 97.5 个百分位数值，然后从 \\(\\hat\\mu\\) 中加上和",
    "crumbs": [
      "网站首页",
      "异质性"
    ]
  },
  {
    "objectID": "07-heterogeneity.html#footnotes",
    "href": "07-heterogeneity.html#footnotes",
    "title": "研究间异质性",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDerSimonian-Laird 方法使用 \\(\\hat\\tau^2 = \\dfrac{Q-(K-1)}{\\sum_{k=1}^{K}w_k-\\frac{\\sum_{k=1}^Kw^2_k}{\\sum_{k=1}^Kw_k}}\\) 估计异质性方差，当 \\(Q&lt;(K-1)\\) 时，\\(\\hat\\tau^2 := 0\\)；另见第 @ref(rem) 和 @ref(tau-estimators) 章。↩︎\n请注意，虽然 \\(I^2\\) 通常使用上面的公式计算，但并非所有软件都遵循此定义。例如，在 {metafor} 中，它的值是使用估计的研究间异质性 \\(\\tau^2\\) 推导出来的（参见 此处），因此：\\[I^2 = \\frac{\\hat{\\tau}^2}{\\hat{\\tau}^2 + \\tilde{v}};\\] 其中：\\[\\tilde{v} = \\frac{(K-1) \\sum w_k}{(\\sum w_k)^2 - \\sum w_k^2}\\] 是根据我们样本中所有研究 \\(k\\) 的权重 \\(w_k\\) 计算得出的“平均”或“典型”抽样方差（参见第 @ref(fem) 章）。与之前显示的公式相比，这种计算 \\(I^2\\) 的方式更容易看出 \\(I^2\\) 是异质性的 相对 度量。它取决于“典型”的研究内方差 \\(\\tilde{v}\\)，该方差可能因荟萃分析而异。我们在第 @ref(het-measure-which) 章中详细阐述了这一点。另请注意，这些不同的公式有时可以解释为什么荟萃分析工具可以返回 不同的值 \\(I^2\\)，即使合并了相同的数据。↩︎",
    "crumbs": [
      "网站首页",
      "异质性"
    ]
  },
  {
    "objectID": "05-effect_sizes.html#what-is-es",
    "href": "05-effect_sizes.html#what-is-es",
    "title": "R语言Meta分析",
    "section": "什么是效应量？",
    "text": "什么是效应量？\n\n在本书中使用的术语中，效应量被定义为量化两个实体之间关系的度量。它捕捉了这种关系的方向和大小。如果关系以相同的效应量表示，则可以比较它们。\n \n我们想在此强调，这只是定义效应量含义的一种方式。效应量的定义可以更广泛或更狭窄，并且不同的人使用该术语的方式也不同 [@borenstein2011introduction, 第 3 章]。有些研究人员只在提及干预研究的结果时才谈论效应量，这些研究通常表示为治疗组和对照组之间的差异（参见第 @ref(s-md) 章）。使用这种概念化，“效应量”是指治疗的效果，以及这种效果有多大。\n我们认为，这是一个相当狭隘的定义。不仅治疗可以对某些变量产生影响；效果也可以在没有任何直接人为干预的情况下自然出现。例如，社会人口变量（如父母的收入和教育）可能会对其子女的教育程度产生影响。相关性描述了我们通过一个变量的值预测另一个变量的值的能力，也可以被视为一种效应量。\n另一方面，说我们可以合并作为元分析一部分的所有内容都自动成为效应量可能有点过分。正如我们将要了解的，有一些中心趋势的度量，例如样本均值，也可以在元分析中使用。但是，单独的样本均值不能量化两种现象之间的关系，并且没有“效应”。尽管如此，在本书中，我们经常使用“效应量”这个词作为以部分代整体，代表实际效应的估计值，以及“单变量”和中心趋势度量。我们这样做不是因为这很准确，而是因为它更方便。\n其他人完全不赞成使用“效应量”这个术语。他们强调，“效应量”中的“效应”一词表明存在因果关系。然而，我们都知道相关性不是因果关系，并且干预组和对照组之间的差异不一定由治疗本身引起。最终，由您来决定您喜欢哪个定义，但请注意，当人们谈论效应量时，他们可能心中有不同的概念化。\n\n在数学符号中，通常使用希腊字母 theta (\\(\\theta\\)) 作为 真实 效应量的符号1。更准确地说，\\(\\theta_k\\) 代表研究 \\(k\\) 的真实效应量。重要的是，真实效应量与我们在研究发表的结果中发现的观察到的效应量不相同。观察到的效应量只是真实效应量的估计值。通常使用 帽子 (^) 符号来澄清我们所指的实体只是一个估计值。因此，研究 \\(k\\) 中观察到的效应量，我们对真实效应量的估计，可以写成 \\(\\hat\\theta_k\\)。\n但是，为什么 \\(\\hat\\theta_k\\) 与 \\(\\theta_k\\) 不同？它的不同是因为抽样误差，可以表示为 \\(\\epsilon_k\\)。在每个初步研究中，研究人员只能从整个总体中抽取一个小样本。例如，当我们想要检查定期锻炼对初级保健患者心血管健康的好处时，我们将只能包括一小部分患者，而不是世界上所有的初级保健患者。研究只能从无限大的总体中抽取小样本这一事实意味着观察到的效应将与真实的总体效应不同。\n简而言之，\\(\\hat\\theta_k\\) 因此与 \\(\\theta_k\\) 加上一些抽样误差 \\(\\epsilon_k\\) 相同2。\n\\[\\begin{align}\n\\hat\\theta_k = \\theta_k + \\epsilon_k\n(\\#eq:es1)\n\\end{align}\\]\n显然，我们希望研究 \\(k\\) 的效应量估计值 \\(\\hat\\theta_k\\) 尽可能接近真实的效应量，并且 \\(\\epsilon_k\\) 尽可能小。在其他条件相同的情况下，我们可以假设具有较小 \\(\\epsilon\\) 的研究将提供更精确的真实效应量估计值。元分析方法会考虑效应量估计值的精确程度（参见第 @ref(pooling-es) 章）。在合并不同研究的结果时，它们会赋予具有更大精确度（即更少抽样误差）的效应更高的权重，因为它们是真实效应的更好估计量 [@hedges2014statistical]。\n但是我们如何知道抽样误差有多大？不出所料，研究的真实效应 \\(\\theta_k\\) 是未知的，因此 \\(\\epsilon_k\\) 也是未知的。然而，通常我们可以使用统计理论来近似抽样误差。量化 \\(\\epsilon\\) 的一种常见方法是通过标准误 (\\(SE\\))。标准误定义为抽样分布的标准差。抽样分布是我们从总体中多次抽取具有相同样本大小 \\(n\\) 的随机样本时获得的度量的分布。\n我们可以通过在 R 中模拟数据来使这更具体。我们可以假装使用 rnorm 函数从更大的总体中抽取随机样本。此函数允许我们从正态分布中抽取随机样本，因此得名。rnorm 函数模拟了一个“完美世界”，在其中我们知道值如何在真实总体中分布，并允许我们抽取样本。\n该函数采用三个参数：n，我们希望在样本中拥有的观测数；mean，总体的真实均值；以及 sd，真实标准差。rnorm 函数具有随机分量，因此为了使结果可重现，我们必须首先设置一个种子。这可以使用 set.seed 函数来完成，我们必须为其提供一个数字。对于我们的示例，我们选择将种子设置为 123。此外，我们想模拟我们总体的真实均值为 \\(\\mu =\\) 10，真实标准差为 \\(\\sigma =\\) 2，并且我们的样本由 \\(n=\\) 50 个随机选择的观测值组成，我们将其保存在名称 sample 下。\n这是我们的代码的样子：\n\nset.seed(123)\nsample &lt;- rnorm(n = 50, mean = 10, sd = 2)\n\n现在，我们可以计算样本的均值。\n\nmean(sample)\n\n[1] 10.06881\n\n\n\n我们看到均值为 \\(\\bar{x} =\\) 10.07，这已经非常接近我们总体中的真实值。现在可以通过重复我们在这里所做的事情 - 抽取一个随机样本并计算其均值 - 无数次来创建抽样分布。为了为您模拟此过程，我们执行了之前 1000 次的步骤。\n图 @ref(fig:samplingdist) 中的直方图显示了结果。我们可以看到，样本的均值非常类似于均值为 10 的正态分布。如果我们抽取更多样本，均值的分布将更接近正态分布。这个想法在统计学最基本的原则之一中得到表达，即中心极限定理 [@aronow2019foundations, 第 3.2.4 章]。\n\n\n\n\n\n“抽样分布” 均值（1000 个样本）。\n\n\n\n\n标准误定义为此抽样分布的标准差。因此，我们计算了 1000 个模拟均值的标准差，以获得标准误的近似值。结果是 \\(SE =\\) 0.267。\n正如我们之前提到的，我们不能简单地通过模拟真实的抽样分布来计算现实生活中的标准误。但是，有一些基于统计理论的公式允许我们计算标准误的估计值，即使我们仅限于一个观察到的样本 - 我们通常是这样。均值的标准误的计算公式定义如下：\n\\[\\begin{align}\nSE = \\frac{s}{\\sqrt{n}}\n(\\#eq:es2)\n\\end{align}\\]\n它将标准误定义为样本的标准差 \\(s\\)，除以样本大小 \\(n\\) 的平方根。使用此公式，我们可以轻松地使用 R 计算之前 sample 对象的标准误。请记住，我们的随机样本的大小为 \\(n =\\) 50。\n\nsd(sample)/sqrt(50)\n\n[1] 0.2618756\n\n\n如果我们将此值与我们在抽样分布模拟中找到的值进行比较，我们会发现它们几乎相同。仅使用我们手头的样本，我们可以非常准确地使用公式估计标准误。\n在公式 3.2 中，我们可以看到均值的标准误取决于研究的样本大小。当 \\(n\\) 变大时，标准误变小，这意味着研究对真实总体均值的估计变得更加精确。\n为了举例说明这种关系，我们进行了另一次模拟。同样，我们使用了 rnorm 函数，并假设真实总体均值为 \\(\\mu =\\) 10，\\(\\sigma =\\) 2。但是这次，我们改变了样本大小，从 \\(n =\\) 2 到 \\(n =\\) 500。对于每次模拟，我们都使用公式 3.2 计算了均值和标准误。\n\n\n\n\n\n样本均值和标准误是样本大小的函数。\n\n\n\n\n图 @ref(fig:simulse) 显示了结果。我们可以看到，均值看起来像一个漏斗：随着样本大小的增加，均值估计变得越来越精确，并向 10 收敛。这种精确度的提高由标准误表示：随着样本大小的增加，标准误变得越来越小。\n我们现在已经探索了进行元分析所需的基本要素：（1）观察到的效应量或结果度量，以及（2）其精确度，以标准误表示。如果可以从已发表的研究中计算出这两种类型的信息，那么通常也可以执行元分析综合（参见第 @ref(pooling-es) 章）。\n在我们的模拟中，我们使用了变量的均值作为示例。重要的是要理解，我们在上面看到的属性也可以在其他结果度量中找到，包括常用的效应量。如果我们计算样本中的均值差异而不是均值，则此均值差异将表现出类似形状的抽样分布，并且随着样本大小的增加，均值差异的标准误也会降低（前提是标准差保持不变）。对于（Fisher 的 \\(z\\) 转换的）相关性，例如，也是如此。\n在以下各节中，我们将介绍元分析中最常用的效应量和结果度量。这些效应量度量如此频繁使用的一个原因是它们满足了我们在本章开头定义的两个标准：它们是可靠的和可计算的。\n在公式 3.2 中，我们描述了如何计算均值的标准误，但此公式只能直接应用于均值。对于其他效应量和结果度量，需要不同的公式来计算标准误。对于我们在此处介绍的效应量度量，幸运的是，这些公式存在，我们将向您展示所有这些公式。附录 中也可以找到这些公式的集合。其中一些公式有些复杂，但好消息是我们几乎不必手动计算标准误。R 中有各种函数可以为我们完成繁重的工作。\n在以下部分中，我们不仅要提供对不同效应量度量的理论讨论。我们还将向您展示必须在数据集中准备哪种信息，以便我们稍后使用的 R 元分析函数可以轻松地为我们计算效应量。\n我们根据效应量通常出现的研究设计类型对效应量进行分组：观察性设计（例如，自然主义研究或调查）和实验性设计（例如，对照临床试验）。请注意，这只是一种粗略的分类，而不是严格的规则。我们提供的许多效应量在技术上适用于任何类型的研究设计，只要结果数据的类型适合即可。",
    "crumbs": [
      "网站首页",
      "效应量"
    ]
  },
  {
    "objectID": "05-effect_sizes.html#single-group-es",
    "href": "05-effect_sizes.html#single-group-es",
    "title": "R语言Meta分析",
    "section": "观察性设计中的度量和效应量",
    "text": "观察性设计中的度量和效应量\n\n\n均值\n\n\n算术均值可能是最常用的中心趋势度量。尽管均值很少用作结果度量，但可以很容易地在元分析中合并它们。例如，可以通过合并几个具有代表性的研究来调查男性的平均身高，以厘米或英寸表示。\n算术均值 \\(\\bar{x}\\) 的计算方法是将样本中的所有单个值 \\(x_i\\) 相加，然后将总和除以样本大小。\n\\[\\begin{equation}\n\\bar{x} = \\frac{\\sum^{n}_{i=1}x_i}{n}\n(\\#eq:es3)\n\\end{equation}\\]\n我们已经介绍了如何计算均值的标准误（参见第 @ref(what-is-es) 章）。我们只需将样本标准差 \\(s\\) 除以样本大小的平方根即可。\n\\[\\begin{equation}\nSE_{\\bar{x}} = \\frac{s}{\\sqrt{n}}\n(\\#eq:es4)\n\\end{equation}\\]\n正如我们之前所见，均值及其标准误很容易在 R 中计算。\n\n# 为了可重现性，将种子设置为 123\n# 并抽取一个随机样本 (n=50)。\nset.seed(123)\nsample &lt;- rnorm(n = 50, mean = 20, sd = 5)\n\n# 计算均值\nmean(sample)\n\n[1] 20.17202\n\n# 计算标准误\nsd(sample)/sqrt(50)\n\n[1] 0.6546889\n\n\n要进行均值的元分析，我们的数据集应至少包含以下列：\n\nn。研究中的观测数（样本大小）。\nmean。研究中报告的均值。\nsd。研究中报告的变量的标准差。\n\n\n\n\n比例\n\n\n比例是另一种类型的中心趋势度量。它指定样本中有多少单位属于某个子组。比例可以取 0 到 1 之间的值，乘以 100 可以转换为百分比。例如，当我们想要检查给定时间点疾病的患病率时，比例可以用作结果度量。要计算比例 \\(p\\)，我们必须将属于特定子组的个体数 \\(k\\) 除以总样本大小 \\(n\\)。\n\\[\\begin{equation}\np = \\frac{k}{n}\n(\\#eq:es5)\n\\end{equation}\\]\n比例的标准误可以这样计算：\n\\[\\begin{equation}\nSE_{p} = \\sqrt{\\frac{p(1-p)}{n}}\n(\\#eq:es6)\n\\end{equation}\\]\n我们可以使用此代码在 R 中计算比例及其标准误：\n\n# 我们为 k 和 n 定义以下值：\nk &lt;- 25\nn &lt;- 125\n\n# 计算比例\np &lt;- k/n\np\n\n[1] 0.2\n\n# 计算标准误\nsqrt((p*(1-p))/n)\n\n[1] 0.03577709\n\n\n \n比例的范围限制在 0 到 1 之间的事实可能存在问题 [@lipsey2001practical, 第 3 章]。当 \\(p\\) 接近 0 或接近 1 时，标准误会被人为压缩，这导致我们高估了比例估计的精确度。\n这与抽样分布有关。当 \\(p\\) 的值非常低或非常高时，抽样分布将不会像图 @ref(fig:samplingdist) 中那样近似为正态分布。分布将右偏或左偏，因为随机样本不可能具有 0-1 范围之外的计算比例。\n为了避免这种情况，比例通常在合并之前进行 logit 转换。Logit 转换首先涉及计算比值（参见第 @ref(or) 章）。比值定义为属于特定类别的参与者比例，除以不属于该类别的单位比例。\n然后使用自然对数函数 \\(\\log_e\\) 将比值转换为 \\(p=\\) 0.5 等于 0 的值且没有范围限制的格式。这确保了抽样分布近似为正态分布，并且标准误没有偏差。\nLogit 转换比例及其标准误的计算可以使用以下公式 [@lipsey2001practical, 第 3 章]3：\n\\[\\begin{equation}\np_{\\text{logit}} = \\log_{e} \\left(\\frac{p}{1-p}\\right)\n(\\#eq:es7)\n\\end{equation}\\]\n\\[\\begin{equation}\nSE_{p_{\\text{logit}}} = \\sqrt{\\frac{1}{np}+\\frac{1}{n(1-p)}}\n(\\#eq:es8)\n\\end{equation}\\]\n幸运的是，我们可以在 R 中使用的元分析函数会自动为我们执行此 Logit 转换。因此，我们只需要在数据集中准备以下列：\n\nevent。属于特定子组的观测数 (\\(k\\))。\nn。总样本大小 \\(n\\)。\n\n\n\n\n相关性\n\n\nPearson 积矩相关\n\n \n相关性是一种表达两个变量之间协方差量的效应量。最常见的形式是 Pearson 积矩相关4，它可以为两个连续变量计算。例如，当元分析师想要检查关系质量和幸福感之间的关系时，可以使用积矩相关作为效应量。\n变量 \\(x\\) 和变量 \\(y\\) 之间的相关性 \\(r_{xy}\\) 定义为 \\(x\\) 和 \\(y\\) 的协方差 \\(\\text{Cov}(x,y)=\\sigma^{2}_{xy}\\)，除以其标准差 \\(\\sigma_x\\) 和 \\(\\sigma_y\\) 的乘积。\n\\[\\begin{equation}\nr_{xy} = \\frac{\\sigma^{2}_{xy}}{\\sigma_x \\sigma_y}\n(\\#eq:es9)\n\\end{equation}\\]\n使用样本大小 \\(n\\)，可以这样计算 \\(r_{xy}\\) 的标准误：\n\\[\\begin{equation}\nSE_{r_{xy}} = \\frac{1-r_{xy}^2}{\\sqrt{n-2}}\n(\\#eq:es10)\n\\end{equation}\\]\n在计算积矩相关时，我们通过两个变量的标准差来标准化两个变量之间的协方差。这意味着如果两个或多个研究在同一尺度上测量一个结构，那么它的相关性就会降低；一旦我们计算出相关性，就可以自动比较效应。\n相关性可以取 -1 和 1 之间的值。相关性的大小通常使用 Cohen [-@cohen1988statistical] 的约定来解释：\n\n\\(r \\approx\\) 0.10：小效应。\n\\(r \\approx\\) 0.30：中等效应。\n\\(r \\approx\\) 0.50：大效应。\n\n但是，应该注意的是，这些约定充其量可以被视为经验法则。通常最好根据主题和先前的研究将相关性量化为小或大。\n \n不幸的是，像比例（第 @ref(props) 章）一样，相关性在其范围内受到限制，并且当我们估计小样本研究的标准误时，可能会引入偏差 [@alexander1989statistical]。\n因此，在元分析中，相关性通常转换为 Fisher 的 \\(z\\)5。像 Logit 转换一样，这还需要使用自然对数函数来确保抽样分布近似为正态分布（有关更详细的说明，请参见第 @ref(ratios) 章）。公式如下：\n\\[\\begin{equation}\nz = 0.5\\log_{e}\\left(\\frac{1+r}{1-r}\\right)\n(\\#eq:es11)\n\\end{equation}\\]\n如果我们知道样本大小 \\(n\\)，则可以通过以下公式获得 Fisher 的 \\(z\\) 的近似标准误 [@olkin1995correlations]：\n\\[\\begin{equation}\nSE_{z} = \\frac{1}{\\sqrt{n-3}}\n(\\#eq:es12)\n\\end{equation}\\]\n我们也可以使用 cor 和 log 函数直接在 R 中计算 \\(r_{xy}\\) 和 \\(z\\)。\n\n# 模拟两个连续变量 x 和 y\nset.seed(12345)\nx &lt;- rnorm(20, 50, 10)\ny &lt;- rnorm(20, 10, 3)\n\n# 计算 x 和 y 之间的相关性\nr &lt;- cor(x,y)\nr\n\n[1] 0.2840509\n\n# 计算 Fisher 的 z\nz &lt;- 0.5*log((1+r)/(1-r))\nz\n\n[1] 0.2920831\n\n\n谢天谢地，在 R 中进行相关性元分析时，我们不必手动执行 Fisher 的 \\(z\\) 转换。我们只需要在数据集中添加以下列：\n\ncor。研究的（未转换的）相关系数。\nn。研究的样本大小。\n\n\n\n\n点二列相关\n\n \nPearson 积矩相关描述了两个连续变量之间的关系。如果只有一个变量 \\(y\\) 是连续的，而另一个变量 \\(x\\) 是二分的（即仅取两个值），则可以计算 点二列相关，该相关性表示 \\(y\\) 可以从 \\(x\\) 中的组成员资格预测的程度。\n可以使用以下公式计算点二列相关：\n\\[\\begin{equation}\n{r_{pb}}= \\frac{(\\bar{y_1}-\\bar{y_2})\\sqrt{p_1(1-p_1)}}{s_y}\n(\\#eq:es13)\n\\end{equation}\\]\n在此公式中，\\(\\bar{y_1}\\) 是仅考虑二分变量 \\(x\\) 的第一组时连续变量的均值，\\(\\bar{y_2}\\) 是仅考虑 \\(x\\) 的第二组时的均值；\\(p_1\\) 是属于 \\(x\\) 中第 1 组的案例比例，\\(s_y\\) 是 \\(y\\) 的标准差。\n可以使用 cor 函数在 R 中计算点二列相关（参见上一节）。如果其中一个提供的变量仅采用两个值，而另一个是连续的，则会自动计算（近似）点二列相关。\n\n点二列相关与标准化均值差非常相似，我们将在后面介绍（第 @ref(b-group-smd) 章）。两种效应量度量都量化了连续变量的值在两组之间的差异程度。然而，在元分析中合并点二列相关并不常见。像积矩相关一样，点二列相关对于元分析具有不良的统计特性，例如当组比例不相等时，范围会受到限制 [@bonett2019point]。\n因此，当我们对连续结果变量的组间差异感兴趣时，建议将点二列相关转换为标准化均值差以进行元分析 [@lipsey2001practical, 第 3 章]。本书“实用工具”部分的第 @ref(convert-corr) 章中可以找到将点二列相关转换为标准化均值差的公式。",
    "crumbs": [
      "网站首页",
      "效应量"
    ]
  },
  {
    "objectID": "05-effect_sizes.html#effect-sizes-in-control-group-designs",
    "href": "05-effect_sizes.html#effect-sizes-in-control-group-designs",
    "title": "R语言Meta分析",
    "section": "实验设计中的效应量",
    "text": "实验设计中的效应量\n\n\n(标准化) 均值差\n\n\n组间均值差\n\n组间均值差 \\(\\text{MD}_{\\text{between}}\\) 定义为两个独立组之间均值的原始、未标准化的差异。当研究至少包含两组时，可以计算组间均值差，这通常是受控试验或其他类型的实验研究的情况。在元分析中，只有当所有研究都在完全相同的尺度上测量感兴趣的结果时，才能使用均值差。例如，在科学研究中，体重几乎总是以千克为单位测量；在糖尿病学中，HbA\\(_{\\text{1c}}\\) 值通常用于测量血糖。\n均值差定义为组 1 的均值 \\(\\bar{x}_1\\) 减去组 2 的均值 \\(\\bar{x}_2\\)：\n\\[\\begin{equation}\n\\text{MD}_{\\text{between}} = \\bar{x}_1 - \\bar{x}_2\n(\\#eq:es14)\n\\end{equation}\\]\n可以使用以下公式获得标准误：\n\\[\\begin{equation}\nSE_{\\text{MD}_{\\text{between}}} = s_{\\text{pooled}}\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}\n(\\#eq:es15)\n\\end{equation}\\]\n\n在该公式中，\\(n_1\\) 代表组 1 中的样本大小，\\(n_2\\) 代表组 2 中的样本大小，\\(s_{\\text{pooled}}\\) 代表两组的合并标准差。使用组 1 的标准差 (\\(s_1\\)) 和组 2 的标准差 (\\(s_2\\))，可以这样计算 \\(s_{\\text{pooled}}\\) 的值：\n\\[\\begin{align}\ns_{\\text{pooled}} = \\sqrt{\\frac{(n_1-1)s^2_1+(n_2-1)s^2_2}{(n_1-1)+(n_2-1)}}\n(\\#eq:es16)\n\\end{align}\\]\n现在是提供一个示例的时候了，说明我们如何在 R 中计算均值差及其标准误。第一步，我们将模拟一些数据。我们在这里只这样做，以便我们有一些合理的值可以使用。在真正的元分析中，x1 和 x2 的均值以及它们的标准差 s1 和 s2 是我们希望可以从已发表的论文中提取的东西，与组样本大小 n1 和 n2 相同。因此，您不必太担心第一部分。\n\n# 生成具有不同总体均值的两个随机变量\nset.seed(123)\nx1 &lt;- rnorm(n = 20, mean = 10, sd = 3)\nx2 &lt;- rnorm(n = 20, mean = 15, sd = 3)\n\n# 计算公式所需的值\ns1 &lt;- sd(x1)\ns2 &lt;- sd(x2)\nn1 &lt;- 20\nn2 &lt;- 20\n\n有了这些数据，我们可以继续进行核心部分，在其中我们使用之前显示的公式计算均值差及其标准误：\n\n# 计算均值差\nMD &lt;- mean(x1) - mean(x2)\nMD\n\n## [1] -4.421357\n\n# 计算 s_pooled\ns_pooled &lt;- sqrt(\n  (((n1-1)*s1^2) + ((n2-1)*s2^2))/\n    ((n1-1)+(n2-1))\n)\n\n# 计算标准误\nse &lt;- s_pooled*sqrt((1/n1)+(1/n2))\nse\n\n## [1] 0.8577262\n通常没有必要像我们在这里所做的那样手动进行这些计算。对于均值差的元分析，我们只需要在数据集中准备以下列：\n\nn.e。干预/实验组中的观测数。\nmean.e。干预/实验组的均值。\nsd.e。干预/实验组中的标准差。\nn.c。对照组中的观测数。\nmean.c。对照组的均值。\nsd.c。对照组中的标准差。\n\n\n\n\n组间标准化均值差\n\n \n标准化组间均值差 \\(\\text{SMD}_{\\text{between}}\\) 定义为两个独立组之间均值的差异，通过合并标准差 \\(s_{\\text{pooled}}\\) 进行标准化。在文献中，标准化均值差也通常称为 Cohen 的 \\(d\\)，以心理学家和统计学家 Jacob Cohen 的名字命名。\n与未标准化均值差相比，\\(\\text{SMD}_{\\text{between}}\\) 以标准差单位表示两组之间的差异。这可以通过将两组的原始均值差 \\(\\bar{x_1}\\) 和 \\(\\bar{x_2}\\) 除以两组的合并标准差 \\(s_{\\text{pooled}}\\) 来实现：\n\\[\\begin{equation}\n\\text{SMD}_{\\text{between}} = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{\\text{pooled}}}\n(\\#eq:es17)\n\\end{equation}\\]\n其中 \\(s_{\\text{pooled}}\\) 使用我们在第 @ref(b-group-md) 章中已经介绍的相同公式 (3.16) 计算。标准化均值差比未标准化均值差更常用于元分析。这是因为 \\(\\text{SMD}_{\\text{between}}\\) 可以在研究之间进行比较，即使这些研究没有使用相同的工具来测量感兴趣的结果。\n标准化具有这样的效果：\\(\\text{SMD}_{\\text{between}}=\\) 1 始终表示两组均值相差",
    "crumbs": [
      "网站首页",
      "效应量"
    ]
  },
  {
    "objectID": "05-effect_sizes.html#footnotes",
    "href": "05-effect_sizes.html#footnotes",
    "title": "R语言Meta分析",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n在本书中，我们在讨论效应量时，将主要遵循 Schwarzer 等人 [-@schwarzer2015meta] 使用的符号。↩︎\n应该注意的是，除了抽样误差之外，观察到的效应量与真实效应量不同的原因通常还有更多；例如，研究方法的偏差或测量误差。在第 @ref(es-correction) 章中，我们将更详细地讨论这一点。↩︎\n要将 Logit 比例转换回原始比例，我们可以使用以下公式：\\(p=\\frac{\\exp(p_{\\text{logit}})}{1+\\exp(p_{\\text{logit}})}\\), 其中 \\(\\exp\\) 是指数函数，在 R 中通过 exp 实现（参见第 @ref(ppoolbin) 章）。↩︎\n这种类型的相关性以 Karl Pearson 的名字命名，他是一位著名的统计学家，也在元分析的历史中发挥了作用（参见第 @ref(history) 章）。↩︎\nFisher 的 \\(z\\) 以我们在第 @ref(history) 章中提到的另一位著名统计学家 Ronald A. Fisher 的名字命名。↩︎",
    "crumbs": [
      "网站首页",
      "效应量"
    ]
  },
  {
    "objectID": "03-introduction.html#what-are-mas",
    "href": "03-introduction.html#what-are-mas",
    "title": "(PART) 入门",
    "section": "什么是荟萃分析？",
    "text": "什么是荟萃分析？\n\n \n它的创始人之一，Gene V. Glass，将荟萃分析描述为“对分析的分析”[@glass1976primary]。这个简单的定义已经告诉我们很多。在传统的研究中，分析的单位是一些人、标本、国家或物体。在荟萃分析中，主要研究本身成为我们分析的要素。\n荟萃分析的目的是整合、总结和解释所有与明确定义的研究领域或研究问题相关的现有证据 [@lipsey2001practical, 第1章]。然而，这只是实现这一目的的一种方法。至少有三种不同的方法可以通过这些方法来综合来自多项研究的证据 [@cuijpers2016meta]。\n\n传统/叙述性综述。直到20世纪80年代，叙述性综述一直是总结研究领域最常见的方法。叙述性综述通常由研究领域的专家和权威人士撰写。关于叙述性综述中的研究如何选择，以及如何定义综述的范围，没有严格的规定。关于如何从综述的证据中得出结论，也没有固定的规则。总的来说，这可能导致偏向于作者的观点。尽管如此，当以平衡的方式撰写时，叙述性综述可以帮助读者全面了解一个领域的相关研究问题和证据基础。\n系统性综述。系统性综述试图使用明确定义的和透明的规则来总结证据。在系统性综述中，研究问题是预先确定的，并且存在一个明确的、可重现的方法论，通过该方法论选择和综述研究。系统性综述旨在涵盖所有可用的证据。它们还使用预定义的标准评估证据的有效性，并以系统的方式呈现结果的综合。\n荟萃分析。大多数荟萃分析可以被视为一种高级的系统性综述。荟萃分析的范围是预先明确定义的，主要研究也是以系统和可重现的方式选择的，并且也有明确的标准来评估证据的有效性。这就是为什么常见的是发现研究被称为“系统性综述和荟萃分析”。然而，有一个方面使荟萃分析与众不同。荟萃分析旨在以定量的方式结合先前研究的结果。荟萃分析的目标是将选定研究中报告的定量结果整合到一个数值估计中。然后，该估计总结了所有单个结果。例如，荟萃分析量化了药物的效果、疾病的患病率或两种属性之间的相关性，跨所有研究1。因此，它们只能应用于报告定量结果的研究。与系统性综述相比，荟萃分析通常必须对总结的证据类型更加排他。要进行荟萃分析，通常需要研究使用相同的设计和测量类型，和/或提供相同的干预（参见第 @ref(pitfalls) 章）。\n\n\n\n\n个体参与者数据荟萃分析\n\n\n根据定义，还有第四种证据综合方法，即所谓的个体参与者数据 (IPD) 荟萃分析 [@riley2010meta; @riley2021individual]。传统上，荟萃分析基于已发表文献中发现的研究的汇总结果（例如，均值和标准差，或比例）。在 IPD 荟萃分析中，所有研究的原始数据都会被收集并合并成一个大数据集。\n\n\nIPD 荟萃分析有几个优点。例如，可以推算缺失数据，并以完全相同的方式将统计方法应用于所有研究。此外，它们可以更容易地探索影响感兴趣结果的变量。在传统的荟萃分析中，只能使用所谓的研究层面变量（例如，发表年份或研究中使用的人群）来做到这一点。然而，通常是参与者层面信息（例如，个人的年龄或性别）可能作为结果的重要调节因素发挥作用。只能使用 IPD 荟萃分析来探索此类变量。\n\n\nIPD 荟萃分析是一种相对较新的方法，目前进行的大多数荟萃分析仍然是“传统”荟萃分析。这也是我们不将在本指南中介绍 IPD 荟萃分析方法的原因之一。\n\n\n这与传统荟萃分析更优越无关——事实恰恰相反。这仅仅是因为直到最近，在大多数学科中，公开提供所有研究数据一直非常罕见。虽然从已发表的研究报告中提取汇总结果相对容易，但从所有相关研究中获取原始数据则更具挑战性。例如，在生物医学研究中，已发现同时考虑个体参与者和汇总数据的研究只能从大约 64% 的符合条件的研究中获得 IPD [@riley2007evidence]。一项最新的综述发现，虽然 IPD 荟萃分析中包含的研究的中位数为 11 项，但只能从 7 项研究的中位数中获得个体参与者数据 [@wang2021methodological]。",
    "crumbs": [
      "网站首页",
      "介绍"
    ]
  },
  {
    "objectID": "03-introduction.html#history",
    "href": "03-introduction.html#history",
    "title": "(PART) 入门",
    "section": "“超级愚蠢的练习”：一段历史轶事",
    "text": "“超级愚蠢的练习”：一段历史轶事\n\n荟萃分析不是由一个人发明的，而是由许多创始之母和创始之父发明的 [@o2007historical]。首次尝试对独立但相似的研究的效果进行统计总结可以追溯到大约 100 年前，并且可以与卡尔·皮尔逊和罗纳德·A·费舍尔这两位有史以来最重要的统计学家联系起来。\n皮尔逊在 20 世纪初综合了关于英国帝国各地伤寒疫苗接种效果的发现，以计算汇总估计值 [@shannon2016statistical]。费舍尔在他 1935 年关于实验设计的开创性著作中，涵盖了分析来自农业研究的多项研究数据的方法，并且已经认识到研究结果可能因地点和时间而异的问题 [@fisher19351he; @o2007historical]。\n \n然而，“荟萃分析”这个名称及其开始崭露头角可以追溯到 20 世纪中叶激烈的一场学术争端。1952 年，著名的英国心理学家汉斯·于尔根·艾森克（图 @ref(fig:eysenck)）发表了一篇文章，声称心理疗法（当时这主要意味着弗洛伊德精神分析）是无效的。如果患者在治疗过程中好转，那是因为他们的病情无论如何都会因与治疗无关的因素而得到改善。更糟糕的是，艾森克声称，心理疗法经常会妨碍患者好转。\n心理疗法的声誉受到了沉重打击，直到 20 世纪 70 年代末才恢复。在此期间，Gene V. Glass 开发了一种他称之为“荟萃分析”的技术，该技术允许汇集标准化均数差2跨研究。他的技术首次广泛应用是在 美国心理学家 发表的一篇文章中，该文章由玛丽·L·史密斯和格拉斯本人撰写 [@smith1977meta]。在这项大型研究中，来自 375 项研究的结果与超过 4000 名参与者在荟萃分析中结合在一起。\n该研究发现，心理疗法的汇集效应为 0.68，这可以被认为是相当大的。格拉斯的工作产生了巨大的影响，因为它提供了定量证据表明艾森克的判断是错误的。然而，艾森克本人并不信服，称荟萃分析为“对学术的放弃”和“超级愚蠢的练习”[@eysenck1978exercise]。\n(ref:eysenck) 汉斯·于尔根·艾森克（Sirswindon/CC BY-SA 3.0）。\n\n\n\n\n\n(ref:eysenck)\n\n\n\n\n今天我们知道，史密斯和格拉斯的研究可能高估了心理疗法的效果，因为它没有控制纳入研究中的偏差 [@cuijpers2019eysenck]。然而，一些心理疗法是有效的这一主要发现已在随后的几十年中得到无数其他荟萃分析的证实。艾森克的严峻回应无法改变荟萃分析很快成为各个研究领域中常用的方法。这段时间被非常恰当地描述为“荟萃分析大爆炸”[@shadish2015meta]。\n大约在格拉斯开发他的荟萃分析方法的同时，亨特和施密特开始制作他们自己的荟萃分析技术，强调对测量伪影的校正 [@schmidt1977development; @hunter2004methods]。荟萃分析也通过彼得·埃尔伍德和阿奇·科克伦等人的开创性工作进入了医学领域，他们使用荟萃分析表明阿司匹林对心脏病发作的复发具有小的，但在统计学和临床上相关的预防作用 [@peto1980aspirin; @elwood2006first; @o2007historical]。\n在 80 年代中期，丽贝卡·德西莫尼安和南·莱尔德介绍了一种计算随机效应荟萃分析的方法（参见第 @ref(rem) 章），该方法一直沿用至今 [@dersimonian1986meta]。在过去的四十年中，无数其他创新有助于提高荟萃分析方法的适用性、稳健性和多功能性。\n \n\n\n\n科克伦和坎贝尔协作\n科克伦协作组织（或简称 科克伦），成立于 1993 年，以阿奇·科克伦的名字命名，在应用荟萃分析的发展中发挥了关键作用。科克伦是一个由研究人员、专业人士、患者和其他相关利益相关者组成的国际网络，他们“共同努力，制作可信、易于获取且不受商业赞助和其他利益冲突影响的健康信息”。\n科克伦使用严格的标准来综合生物医学领域的证据。该机构总部设在伦敦，但在世界多个国家也设有地方分支机构。\n科克伦协作组织定期发布更新的干预措施系统评价手册 [@higgins2019cochrane] 和 科克伦偏倚风险工具 [@sterni2019rob]。这两者都被广泛认为是系统评价和荟萃分析所有技术细节的标准参考著作（参见第 @ref(spec-search-coding) 章）。\n一个类似于科克伦的组织是位于奥斯陆的坎贝尔协作组织，它主要关注社会科学领域的研究。",
    "crumbs": [
      "网站首页",
      "介绍"
    ]
  },
  {
    "objectID": "03-introduction.html#pitfalls",
    "href": "03-introduction.html#pitfalls",
    "title": "(PART) 入门",
    "section": "苹果和橘子：荟萃分析陷阱快速游览",
    "text": "苹果和橘子：荟萃分析陷阱快速游览\n\n在过去的几十年里，荟萃分析已成为一种普遍接受的研究工具。这并非没有其自身的代价。进行高质量的初步研究通常非常昂贵，并且可能需要很多年才能最终分析结果。相比之下，可以不用太多资源并在相对较短的时间内生成荟萃分析。然而，荟萃分析通常具有很高的影响力，并且经常被引用 [@patsopoulos2005relative]。\n这意味着科学期刊通常非常倾向于发表荟萃分析，即使它们的质量或科学价值有限。不幸的是，这为研究人员创造了一种自然激励，以产生许多荟萃分析，并且科学考虑有时会退居其次。\nIoannidis [-@ioannidis2016mass] 批评说，每年都会产生大量的冗余和误导性荟萃分析。在一些“热门”主题上，有超过 20 个最新的荟萃分析。一些荟萃分析也可能受到公司利益的严重偏见，例如在药物治疗研究中 [@ebrahim2016meta; @kirsch2002emperor]。正如我们之前提到的，可重复性是良好科学的标志。然而，在现实中，许多荟萃分析的可重复性往往受到限制，因为没有报告重要信息 [@lakens2017examining]。\n一个常见的问题是，关于相同或重叠主题的不同荟萃分析得出不同的结论。例如，在心理治疗研究中，一直存在一场关于所有类型的心理治疗是否产生相同结果的问题的争论。已经发表了无数的评论，支持这种或另一种结论 [@wampold2013great; @cuijpers2019role]。\n虽然其中一些问题可能与科学过程的系统性问题有关，但另一些问题可以追溯到荟萃分析本身的缺陷。因此，我们想引导您快速了解常见的荟萃分析陷阱 [@borenstein2011introduction, 第 40 章; @greco2013meta; @sharpe1997apples]。\n \n\n\n“苹果和橘子”问题\n\n有人可能会说，荟萃分析意味着将苹果与橘子混合在一起。即使使用最严格的纳入标准，荟萃分析中的研究也永远不会完全相同。纳入的样本、干预的实施方式、研究设计或研究中使用的测量类型之间总是会存在或大或小的差异。\n这可能会有问题。荟萃分析意味着计算一个数值估计值，该估计值代表所有研究的结果。从统计角度来看，总是可以计算出这样的估计值，但是当研究不共享对于回答特定研究问题很重要的属性时，它就变得毫无意义。\n想象一下，一个不得不承认的荒谬场景，其中一位荟萃分析师决定将关于工作满意度对工作绩效影响的研究以及所有关于药物对糖尿病患者 HbA1c 值影响的可用证据都汇集到一个荟萃分析中。对于组织心理学家和糖尿病学家来说，结果都将毫无意义。\n现在，想象一下，同一个可怜的荟萃分析师，试图从先前的错误中吸取教训，过度补偿并进行荟萃分析，其中仅包含 1990 年至 1999 年间发表的研究，其中 60 多岁的加拿大男性患有中度抑郁症状，每天使用 40 毫克氟西汀治疗，正好六周。荟萃分析师可能会自豪地向精神科医生报告该研究的积极结果。然而，精神科医生可能只会问：“如果我的病人 45 岁并且是法国人，我该怎么办？”\n这使我们想到一个重要的观点。荟萃分析的目标不是不顾一切地将可以组合在一起的所有东西都扔在一起。荟萃分析可用于回答超出单个研究的特殊性的相关研究问题 [@borenstein2011introduction, 第 40 章]。因此，荟萃分析的范围和特异性应基于它想要回答的研究问题，并且该问题应具有实践相关性（参见第 @ref(spec-search-coding) 章）。\n例如，如果我们感兴趣的是，一种培训计划是否在各个年龄组、文化区域和环境中有效，那么不限制研究的人口和原籍国是完全有意义的。但是，建议对研究中评估的培训计划更加严格，并且仅包括培训具有一定长度或涵盖相似主题的培训计划。\n这样的荟萃分析的结果不仅使我们能够估计培训的汇集效应，而且还使我们能够量化这种效应是否以及在多大程度上可能变化。荟萃分析能够适应并理解这种形式的异质性。在第 @ref(heterogeneity) 章中，我们将更仔细地研究这个重要的概念。\n总而言之，“苹果和橘子”问题实际上是否是一个问题在很大程度上取决于荟萃分析想要回答的问题。研究之间的变化通常是没有问题的，甚至可以提供见解，如果它被正确地纳入荟萃分析的目的和问题规范中。\n\n\n\n“垃圾进，垃圾出”问题\n\n荟萃分析产生的证据质量在很大程度上取决于其总结的研究的质量。如果我们在纳入的发现中报告的结果有偏差或完全不正确，那么荟萃分析的结果也将同样存在缺陷。这就是“垃圾进，垃圾出”问题所指的。通过评估纳入研究的质量或偏倚风险（参见第 @ref(spec-search-coding) 章和 @ref(risk-of-bias-plots)），可以在一定程度上缓解此问题。\n然而，如果许多或大多数结果的质量都低于最佳水平并且可能存在偏差，即使是最严格的荟萃分析也无法平衡这一点。在这些情况下，通常可以得出的唯一结论是，对于审查的主题不存在可信的证据，并且将来必须进行更多高质量的研究。然而，即使是这样一个相当令人失望的结果也可能提供信息，并有助于指导未来的研究。\n\n\n\n“文件抽屉”问题\n\n文件抽屉问题指的是并非所有相关的研究结果都已发表，因此在我们的荟萃分析中缺失的问题。如果我们可以安全地假设研究结果在已发表的文献中随机缺失，那么无法在荟萃分析中整合所有证据将是不理想的，但至少是可以容忍的。\n不幸的是，事实并非如此。与失败的复制或具有消极和不确定结果的研究相比，积极的、“创新的”发现通常会产生更多的轰动效应。与此相符，研究表明，在过去的几十年中，越来越少的消极发现在许多学科中发表，尤其是在社会科学和生物医学领域 [@fanelli2012negative]。\n我们有充分的理由相信，具有消极或“令人失望”结果的研究在已发表的文献中被系统性地低估，并且存在所谓的发表偏倚。这种偏倚的确切性质和程度在荟萃分析中充其量只能是一个“已知的未知数”。\n然而，有一些方法可以通过这些方法来最大限度地减少发表偏倚。一种方法与研究的搜索和选择方式有关（参见第 @ref(spec-search-coding) 章）。另一种方法是统计方法，它试图估计荟萃分析中是否存在发表偏倚，以及其影响有多大。我们将在第 @ref(pub-bias) 章中介绍其中的一些方法。\n\n\n\n“研究者议程”问题\n\n在定义荟萃分析的范围、搜索和选择研究以及最终汇集结果测量时，研究人员必须做出无数的选择。荟萃分析带有许多“研究者自由度”[@wicherts2016degrees]，为可能有时是任意的，有时是未公开的个人偏好导致的决策留下了很大的空间。\n当研究人员有意识或无意识地受到他们自己的议程驱动时，荟萃分析师在他们的运作方式上的自由度变得尤其成问题。荟萃分析通常由应用研究人员进行，并且对审查的主题具有广泛的特定主题专业知识是一把双刃剑。一方面，它可以帮助在一个特定领域中得出并回答有意义的研究问题。\n另一方面，这些专家也对他们正在研究的研究领域进行了深入的投资。这意味着许多荟萃分析师可能对某些主题持有强烈的观点，并且可能有意识或无意识地将结果引导到符合他们信念的方向。\n有证据表明，给定相同的数据集，即使是具有最佳意图的经验丰富的分析师也可能得出截然不同的结论 [@silberzahn2018many]。在干预研究中，问题可能更加严重，在干预研究中，一些荟萃分析师具有实质性的研究者忠诚度，因为他们帮助开发了正在研究的干预类型。当然，这些研究人员可能比证据表明的更倾向于以更积极的方式解释荟萃分析的结果。\n减少研究者议程问题的一种方法是预先注册，并在开始收集荟萃分析的数据之前发布详细的分析计划（参见第 @ref(spec-search-coding) 章和 @ref(pre-registration)）。",
    "crumbs": [
      "网站首页",
      "介绍"
    ]
  },
  {
    "objectID": "03-introduction.html#spec-search-coding",
    "href": "03-introduction.html#spec-search-coding",
    "title": "(PART) 入门",
    "section": "问题规范、研究搜索与编码",
    "text": "问题规范、研究搜索与编码\n\n\n在上一章中，我们花了一些时间讨论荟萃分析的常见问题和局限性。其中许多问题，例如“苹果和橘子”问题、“文件抽屉”问题或“研究者议程”问题，都可以并且应该由每位荟萃分析师解决。\n这早在您开始计算第一个结果之前就开始了。没有数据就无法进行荟萃分析，而这些数据必须来自某个地方。我们首先必须指定我们计划进行的荟萃分析的研究问题和资格标准，搜索研究并选择相关的研究，提取我们需要用于计算的数据，然后对我们稍后要报告的重要信息进行编码。\n在这些步骤中的每一个步骤中，我们可以或应该遵循几个规则、标准和建议；它们可以帮助我们创建一个高质量的荟萃分析。这种高质量的荟萃分析包含对所有合适的证据的全面选择，在主题方面是公正和公正的，并且从其结果中得出有效、合理和具有实践相关性的结论。\n然而，即使“遵循所有规则”，可能也并不总是清楚哪个特定决策是在实践中实现这一目标的最佳选择。人们可能会不同意您处理某些事情的方式。这是正常的，通常也很好，只要您的方法论决策是透明的和可重复的 [@pigott2020methodological]。\n在本章中，我们将按时间顺序介绍一些在我们开始进行第一次计算之前需要的重要的构建块。本章的长度并不代表这种数据获取过程在现实中所花费的时间。根据我们的经验，统计分析仅占荟萃分析所花费时间的最多 15%，远低于之前的所有内容。但是，指定研究问题、系统地搜索研究和可靠地编码提取的数据至关重要。它构建了每个良好荟萃分析的基础。\n\n\n定义研究问题\n\n\n在设计研究时，我们首先要做的是定义研究问题。荟萃分析也不例外。要定义一个好的研究问题，首先将其视为一种问题规范的形式会有所帮助。要具有相关性和影响力，荟萃分析应解决一个问题。要识别此类问题，一些特定主题的知识是必要的。\n因此，如果您想找到一个好的荟萃分析的研究问题，最好选择一个您有一些背景知识的研究领域，并首先问自己几个基本问题。目前在这个特定领域中哪些问题是相关的？某些主题的当前知识是否存在差距？是否有任何未解决的公开讨论？考虑预期的目标受众也可能会有所帮助。哪些问题与其他研究人员相关？其他人，例如医疗保健专业人员、州机构、学校或人力资源部门可能面临哪些问题？\n荟萃分析取决于先前的研究。一旦您知道研究问题的大致方向，查看当前的文献会有所帮助。先前是否存在关于该主题的初步研究，他们如何解决该问题？他们使用了哪些方法和结果测量？他们在文章的背景和讨论部分中提到了哪些局限性？先前的评论和荟萃分析是否已解决该主题，他们留下了哪些未解决的问题？\n卡明斯及其同事 [-@cummings2013conceiving] 提出了一些我们可以用来指定我们的荟萃分析所涵盖的问题的标准，即 FINER 框架。它指出，一个研究问题应该是可行的，有趣的，新颖的，符合伦理道德的，并且具有相关性的。\n逐步地，问自己这些问题应该可以更轻松地定义您想通过荟萃分析实现的目标。也可能会清楚地表明荟萃分析不适合您的问题。例如，可能根本没有相关的研究已解决该主题；或者文献中可能已经存在最近的高质量荟萃分析，这些荟萃分析已充分解决了该问题。\n然而，如果您觉得您的问题与一个或多个群体的人相关，先前的研究已提供了与该问题相关的数据，并且先前的评论和荟萃分析尚未充分或适当地解决该问题，则您可以继续将其转化为研究问题。\n让我们给您一个如何做到这一点的例子。有证据表明，医学研究中存在性别偏见 [@hamberg2008gender; @nielsen2017one]。尤其是在早期的几十年中，许多临床试验仅或主要使用男性参与者，并且结果被简单地假设为也适用于女性。这可能导致女性在某些疾病（例如心脏病）方面的健康结果更差 [@kim2009status; @mosca2013fifteen]3。\n让我们想象一下，您是一名医学研究人员。您听说一种常用的药物 Chauvicepine 可能在女性中产生严重的副作用，但这些副作用在很大程度上尚未得到认识。您确定如果这是真的，这将是一个高度相关的问题，因为它将意味着许多女性被处方了一种可能对她们不安全的药物。\n对文献的回顾表明，大多数调查 Chauvicepine 的研究都是随机安慰剂对照试验。这些试验中的第一个是在仅或主要由男性组成的人群中进行的。但您还发现了一些更新的研究，其中性别构成更为平衡。许多这些试验甚至分别报告了在试验中发生的男性和女性的负面副作用的数量。您还在医学杂志上找到了一篇最近的评论，其中一位医生报告说，在她的诊所中，许多女性在接受该药物治疗时都经历了负面副作用。\n基于此，您决定在荟萃分析中解决此问题可能很有趣。因此，您将刚刚发现的问题转化为一个研究问题：“来自随机安慰剂对照试验的证据是否表明，与安慰剂相比，Chauvicepine 会导致女性的负面副作用显着增加”？\n\n得出研究问题的初步表述只是第一步。我们现在必须将其转化为具体的资格标准。这些资格标准将指导哪些研究将被纳入我们的荟萃分析的决策。因此，它们非常重要，并且应该是绝对透明和可重复的。\n开始指定资格标准的一个好方法是使用 PICO 框架 [@mattos2015systematic]。此框架主要针对干预研究，但它对其他类型的研究问题也有帮助。PICO 中的字母代表人群 (Population)、干预 (Intervention)、对照组 (Control group) 或比较以及结果 (Outcome)：\n\n人群：研究必须包括哪种类型的人或研究对象才能符合资格？同样，请记住尽可能精确地解决这些问题，并考虑每个定义的含义。如果您只想纳入对年轻人进行的研究，那么“年轻人”是什么意思？仅包括 18 至 30 岁之间的人吗？是否可以从已发表的文章中轻松确定这一点？还是只是重要的是，人们是从通常年轻人经常光顾的地方招募的，例如大学和 Cardi B 音乐会？如果您只想纳入对患有特定疾病的患者进行的研究，该疾病是如何诊断的？由训练有素的医疗保健专业人员进行诊断，还是自我报告的问卷调查就足够了？这些问题中的许多可以通过求助于 FINER 框架的 F 和 R 部分来回答。对已发表的研究施加这样的限制是否可行？这是一个相关的区分吗？\n干预：研究必须检查哪种类型的干预（或替代地，暴露）？如果您想研究干预的效果，务必清楚哪种类型的治疗符合资格。干预必须持续多长时间？允许谁提供干预？干预必须包括哪些内容？如果您不关注干预，自变量必须如何操作？是否必须通过特定的仪器进行测量？例如，如果您研究工作满意度，此构建必须如何在研究中进行操作？\n对照组或比较：研究结果与什么进行比较？接受注意力安慰剂的对照组，还是药丸安慰剂？等待名单？另一种治疗？还是什么都没有？也可能根本没有比较或对照组；例如，如果您想研究不同研究中疾病的患病率估计值，或者不同栖息地中有多少物种的标本。\n结果。研究必须测量哪种类型的结果或因变量？变量必须如何测量？是问卷调查分数的平均值和标准差吗？还是死亡或生病的患者人数？何时必须测量结果？仅仅在治疗后，无论治疗持续多长时间？还是在一年到两年后？\n\n \n\n\n\n系统评价和荟萃分析指南\n鉴于荟萃分析的质量通常低于最佳水平，因此已建立了一些关于如何进行荟萃分析的指南和标准。\n如果您在生物医学研究中或在干预措施的效果方面对证据进行荟萃分析，我们强烈建议您遵循系统评价和荟萃分析的首选报告项目或 PRISMA [@moher2009preferred]。PRISMA 声明包含关于如何报告荟萃分析过程的几乎所有方面的几项建议。该声明也可以在网上找到。4\n对于心理和行为研究的荟萃分析，可以遵循 美国心理学会 的 荟萃分析报告标准 [@appelbaum2018journal] 或 MARS。\n虽然这些标准主要评论了应如何报告荟萃分析，但它们也对进行荟萃分析时的最佳实践具有影响。PRISMA 和 MARS 共享许多核心要素，并且我们在本章中介绍的许多内容也在这些指南中提到。\n一个更详细的资源是干预措施系统评价的科克伦手册（参见第 @ref(history) 章），其中包含关于系统评价和荟萃分析几乎所有方面的精确建议。可以在 Pigott 和 Polanin [-@pigott2020methodological] 中找到社会科学中荟萃分析的方法学标准的概述。\n\n\n虽然 PICO 框架是指定荟萃分析的资格标准的绝佳方法，但它并不涵盖所有可能相关的信息。还有一些其他方面需要考虑 [@lipsey2001practical]。\n一个相关的细节是合格的研究设计。在循证医学中，通常只包括来自随机对照试验的证据（意味着参与者是通过机会分配到治疗组或对照组的研究）；但这并非总是必需的 [@borenstein2011introduction, 第 40 章]。\n\n指定合格研究的文化和语言范围也可能会有所帮助。大多数研究都基于 WEIRD 人群，这意味着西方、受过教育、工业化、富裕和民主的社会 [@henrich2010most]。尤其是在社会科学中，某些影响或现象很可能无法很好地推广到具有其他社会规范的国家。然而，许多研究人员只考虑用英语发表的荟萃分析文章，以避免不得不翻译其他语言的文章。\n这意味着来自不同语言区域的一些证据将不会被考虑在内。虽然英语是大多数学科中科学出版最常用的语言，但至少应在资格标准中明确说明存在此限制。然而，如果荟萃分析的目标之一是检查跨文化差异，通常建议将资格标准扩展到其他语言，前提是满足所有其他标准。\n\n另一个重要的方面是允许荟萃分析的出版类型。有时，荟萃分析师只纳入发表在同行评审的科学期刊上的研究文章。理由是从此来源获得的研究符合更高的标准，因为它们已经通过了该领域专家的批判性审查。这种理由并非没有缺陷。在第 @ref(pitfalls) 章中，我们已经介绍了“文件抽屉”问题会严重限制荟萃分析结果的有效性，因为积极的发现更有可能被发表。\n因此，减轻发表偏倚风险的一种方法是也包括灰色文献。灰色文献可以定义为所有类型的研究资料，这些资料尚未通过传统的出版形式提供。这包括研究报告、预印本、工作论文或会议贡献。学位论文通常也被视为灰色",
    "crumbs": [
      "网站首页",
      "介绍"
    ]
  },
  {
    "objectID": "03-introduction.html#footnotes",
    "href": "03-introduction.html#footnotes",
    "title": "(PART) 入门",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n当然，只有在荟萃分析技术应用合理，并且荟萃分析的结果允许进行这种概括的情况下，这种说法才是正确的。↩︎\n即，两组之间均值的差异，例如干预组和对照组，以两组的汇集标准差的单位表示（参见第 @ref(s-md) 章）。↩︎\n值得注意的是，性别偏见不仅会对女性产生负面影响，而且也会对男性产生负面影响；例如骨质疏松症等疾病 [@adler2014osteoporosis]。↩︎\n最近，已发布更新的 PRISMA 2020 声明 [@page2021prisma]，取代了 2009 年的旧版本。新颖之处包括一个摘要报告清单，一个修订的流程图，其中还包含了关于搜索更新的信息，以及更加强调声明竞争利益和数据共享。↩︎",
    "crumbs": [
      "网站首页",
      "介绍"
    ]
  },
  {
    "objectID": "01-preface.html",
    "href": "01-preface.html",
    "title": "前言",
    "section": "",
    "text": "“问题不是通过提供新的信息来解决， 而是通过安排我们早已知道的事情来解决。”\n– 路德维希·维特根斯坦, 哲学研究\n\n\n我 们的世界是复杂的，这是一个显而易见的观察。科学研究也不例外；在大多数研究领域，我们经常面临看似无法克服的先前研究。来自不同研究的证据可能是相互冲突的，并且很难理解各种信息来源。\n因此，证据合成方法在许多学科中起着至关重要的作用，例如社会科学、医学、生物学或计量经济学。Meta分析，一种用于合并各种研究或分析结果的统计程序，已成为许多研究领域不可或缺的工具。Meta分析可能非常重要，特别是当它们指导实践决策或未来的研究工作时。因此，许多应用研究人员在其“统计工具箱”中拥有一些Meta分析技能，而另一些人则希望学习如何在自己的研究领域中执行它们。Meta分析已经变得非常普遍，以至于许多研究生和本科生已经学习如何将其作为课程的一部分进行——有时热情程度各不相同。\nMeta分析的执行方式，就像整个统计计算一样，在过去几十年中发生了重大变化。这与开源、协作统计软件的兴起有很大关系，主要是以 R 统计编程语言和环境的形式。R 生态系统允许世界各地的研究人员和统计学家构建自己的包，并免费提供给所有人。这导致了 R 语言中现成的统计软件的惊人增长。在我们撰写本文时，CRAN 任务视图 列出了 130 多个专门用于 Meta 分析的包。\n在 R 中，你可以做任何事情——字面意思。它是一种完整的编程语言，因此如果你没有找到想要执行的操作的函数，你可以轻松地自己编写它。然而，对于 Meta 分析，几乎没有必要再这样做了。仅一小部分 R 包已经提供了你可以在当前“最先进”的 Meta 分析程序中找到的所有功能——而且是免费的。更重要的是，目前只能在 R 中应用许多新颖的 Meta 分析方法。简而言之：R 环境为研究人员提供了更多的 Meta 分析工具。在最好的情况下，这使我们能够从数据中得出更可靠的结论，从而更好地为决策提供信息。\n这就提出了一个问题，为什么不是每个人都使用 R 进行 Meta 分析。我们认为有两个主要原因：便利性和焦虑（有时两者兼而有之）。这两个原因都非常容易理解。大多数 Meta 分析师是应用研究人员；而不是统计学家或程序员。学习一种晦涩且看似复杂的编程语言的想法可能会起到威慑作用。Meta 分析方法也是如此，它们具有特殊的理论背景、无数的分析选择以及需要正确解释的不同统计数据。\n通过本指南，我们希望表明许多这些担忧是没有根据的，并且学习如何在 R 中进行 Meta 分析是值得的。我们希望本指南能帮助你学习掌握 R 中自己的 Meta 分析项目所需的技能。我们还希望本指南能让你更容易地不仅学习何时应用 Meta 分析方法，而且还要学习为什么我们应用它们。最后但并非最不重要的一点是，我们将本指南视为一种尝试，向你展示 Meta 分析方法和 R 编程不仅仅是不便之处，而是一个值得探索的迷人主题。\n\n\n\n\n本指南不是为 Meta 分析专家或统计学家编写的。我们不假设你对 Meta 分析方法有任何特殊的背景知识。只需要对基本数学和统计概念有基本的了解即可。例如，我们假设你以前听说过“平均值”、“标准差”、“相关性”、“回归”、“\\(p\\)-值”或“正态分布”之类的东西。如果这些术语让你想起了一些事情，那么你应该可以开始了。如果你真的从头开始，你可能想首先看看 Robert Stinerock 的统计初学者指南 [@stinerock2018statistics]，以获得包括 R 中的实践示例的全面介绍——或者你选择的其他一些介绍性统计教科书。\n尽管我们试图使其尽可能地简洁，但我们有时会使用数学公式和统计符号。但不要惊慌。公式和希腊字母乍一看似乎令人困惑，但它们通常是精确描述某些 Meta 分析方法背后思想的好方法。见过这些公式，并且知道它们代表什么，也将使你更容易理解你可能想要进一步阅读的更高级的文本。当然，我们尽最大努力始终详细解释某些符号或字母代表什么，以及特定公式想要告诉我们什么。在本书的附录 @ref(symbollist) 中，你可以找到我们使用的符号列表，以及它们代表什么。在后面的章节中，尤其是高级方法部分，我们需要变得更加技术化，以解释某些应用技术背后的思想。尽管如此，我们确保始终包括有关这些部分中使用的数学和统计概念的一些背景信息。\n不需要事先了解 R（或一般的编程）。在本指南中，我们尝试提供一个温和的 R 技能介绍，你需要这些技能来编写自己的 Meta 分析代码。我们还提供对足够资源的引用，以便继续学习。此外，我们将向你展示如何设置一个免费的计算机程序，该程序允许你在你的 PC 或 Mac 上方便地使用 R。\n正如标题所说，我们的书侧重于 Meta 分析的“执行”部分。我们的指南旨在成为应用研究人员、学生和想要开始使用 R 进行分析的数据科学家可以访问的资源。然而，Meta 分析是一个庞大且多方面的课题，因此很自然地，并非所有内容都可以在本指南中涵盖。对于本书，局限性尤其与三个领域相关：\n\n尽管我们提供了关于这些主题的简短入门，但我们没有详细介绍如何定义研究问题、系统地搜索和包括用于 Meta 分析的研究，以及如何评估它们的质量。这些主题中的每一个都值得拥有自己的书籍，幸运的是，已经存在许多有用的资源。因此，我们仅概述了在收集 Meta 分析数据时的重要考虑因素和陷阱，并将你推荐给处理细节的足够资源。\n本指南的第二个局限性与其技术性水平有关。本书明确地是为“凡人”而写的。我们的目标是向你展示何时、如何以及为什么应用某些 Meta 分析技术，以及它们的陷阱。我们还试图提供对我们所涵盖技术的易于理解的概念性理解，仅在有利于此任务时才诉诸更多技术细节。很自然地，这意味着指南的某些部分不会包含专家级 Meta 分析师和统计学家可能需要的对技术的深入研究。尽管如此，我们还在每个章节中为感兴趣的读者提供了对更高级资源和出版物的引用。\n一本书的内容在某种程度上总是反映其作者的背景和经验。我们相信，我们在此涵盖的方法适用于范围广泛的研究领域和学科。尽管如此，我们想披露本书的四位作者主要精通心理学、精神病学、医学和干预研究领域的当前研究。“现实世界”的用例和我们在本书中涵盖的示例因此集中在我们熟悉的领域的主题上。好消息是，Meta 分析方法（假设一些我们将会涵盖的假设）在很大程度上与数据来自的研究领域无关，并且可以用于各种类型的结局指标。尽管如此，尽管我们尽了最大的努力使本指南尽可能广泛地适用于尽可能多的应用研究学科，但本书中涵盖的某些方法可能仍然与某些研究领域比其他研究领域更相关。\n\n\n\n\n\n\n除其他外，本指南将涵盖以下主题：\n\n什么是 Meta 分析，以及它为什么被发明出来。\nMeta 分析的优点和常见问题。\n如何指定 Meta 分析的研究问题，以及如何进行研究搜索。\n如何设置 R，以及一个允许你以方便的方式使用 R 的计算机程序。\n如何将你的 Meta 分析数据导入到 R 中，以及如何通过代码操作它。\n什么是效应量，以及如何计算它们。\n如何在固定效应和随机效应 Meta 分析中汇集效应量。\n如何分析 Meta 分析的异质性，以及如何使用亚组分析和Meta 回归来探索它。\n选择性结局报告的问题，以及如何解决它们。\n如何执行高级类型的 Meta 分析技术，例如“多层”Meta 分析、Meta 分析结构方程建模、网络 Meta 分析或贝叶斯 Meta 分析。\n如何报告你的 Meta 分析结果，并使其具有可重复性。\n\n\n\n\n\n\n\n\n\n本书旨在以“线性”方式阅读。我们建议你从关于 Meta 分析和 R 基础知识的第一章开始，然后继续逐章阅读本书。直接跳到实践章节可能很诱人，但通常不建议这样做。在教学生和研究人员如何进行他们的第一次 Meta 分析时，我们发现对这项技术以及 R Studio 环境的基本熟悉是避免以后出现挫折的必要之恶。如果你没有 Meta 分析和 R 编程的经验，这一点尤其正确。有经验的 R 用户可以跳过介绍 R 和 R Studio 的 @ref(discovering-R) 章。但是，无论如何，通过本章进行快速复习肯定不会有任何坏处。\n虽然所有章节实际上都是独立的，但我们有时会参考前面章节中涵盖的主题。尤其是高级方法部分中的章节假定你熟悉我们之前涵盖的理论概念。\n本书的最后一节包含对你的 Meta 分析有用的工具。这并不意味着这些主题是你在执行 Meta 分析时必须考虑的最后一件事。我们只是将这些章节放在最后，因为它们主要用作你自己的 Meta 分析项目的参考作品。我们在本书中与主题相关的部分链接到这些工具。\n\n\n\n\n\n本书附带一个名为 {dmetar} 的伴随 R 包。该软件包主要有两个功能。首先，它旨在让你的生活更轻松。尽管那里有非常棒的 R 包用于 Meta 分析，具有广泛的功能，但仍然有一些事情目前在 R 中不容易实现，至少对于初学者来说是这样。\n{dmetar} 包旨在通过提供一些额外的功能来弥合这一差距，从而促进这些事情。其次，该软件包还包含我们用于本书中显示的实践示例的所有数据集。在 @ref(dmetar) 章中，详细介绍了 {dmetar} 包，我们向你逐步展示如何安装该软件包。尽管我们将确保没有重大更改，但 {dmetar} 仍在积极开发中，因此不时查看 软件包网站 以检查是否有新的或改进的功能可用于你的 Meta 分析可能会有所帮助。\n虽然建议这样做，但安装该软件包并不是必不可少的。无论我们在本书中使用 {dmetar} 的地方，我们还将为你提供函数的原始代码，或我们正在使用的数据集的下载链接。\n\n\n\n\n\n在整本书中，使用了一组文本框。\n\n\n\n一般说明\n\n\n一般说明包含与所涵盖主题相关的相关背景信息、见解、轶事、注意事项或要点信息。\n\n\n\n\n\n\n重要信息\n\n\n这些框包含你必须牢记的警告、问题、缺点或陷阱信息。\n\n\n\n\n\n\n问题\n\n\n在每章之后，此框将包含一些问题，你可以通过这些问题来测试你的知识。这些问题的答案可以在本书末尾的附录 A中找到。\n\n\n\n\n\n\n{dmetar} 说明\n\n\n每当使用伴随 R 软件包中包含的函数或数据集时，都会出现 {dmetar} 说明框。这些框还包含函数代码的 URL，或者供未安装该软件包的读者使用的数据集下载链接。\n\n\n\n\n\n\n我该如何报告这个？\n\n\n这些框包含关于如何在你的论文或研究文章中报告 R 输出的建议。\n\n\n\n\n\n\n\n\n\n在整本书中都遵循一些约定。\n\\[~\\]\n{packages}\n所有 R 软件包都以粗体书写，并放在大括号中。这是在 R 社区中编写软件包名称的常见方式。\n\\[~\\]\nR 代码\n我们在 R 中定义的所有 R 代码或对象都以这种等宽字体书写。\n\\[~\\]\n## R 输出\n在运行 R 代码后收到的输出也使用相同的等宽字体。但是，我们使用两个数字符号（井号）将其与 R 输入区分开来。\n\\[~\\]\n\\(公式\\)\n这种衬线字体专用于公式、统计数据和其他形式的数学符号。\n\n\n\n\n\n不可否认的是，在 R 中进行 Meta 分析的道路有时可能是一条坎坷的道路。尽管我们认为有时这种说法被夸大了，但 R 的学习曲线确实很陡峭。统计学很难。我们尽了最大的努力使你学习如何使用 R 进行 Meta 分析的体验尽可能地轻松。但是，这并不能保护你免受有时会感到沮丧的情况。这完全是自然的。我们都必须从头开始。根据我们自己的经验，我们可以向你保证，我们从未见过任何不能学习 R 或如何进行 Meta 分析的人。这只需要练习，并且要理解在任何时候都不会有你“完成”学习的时候。我们相信你。\n如果你正在寻找比这条励志信息更实用一些的东西：以下是一些在你遇到本指南无法回答的事情时可以做的事情。\n\n\n\n\n在 R 中迈出第一步时，许多人在第一个红色错误消息开始弹出时感到害怕。这是没有必要的。每个人都一直收到错误消息。与其惊慌失措或将电脑扔出窗外，不如深吸一口气，仔细看看错误消息。通常，只需进行一些调整即可使错误消息消失。你是否在代码中拼写错了什么？你是否忘记关闭括号，或者将某些内容放入引号中？\n另外，请确保你的输出实际上是错误消息。R 区分 Error、Warning 和普通消息。只有第一个意味着你的代码无法执行。Warning 意味着你的代码确实运行了，但是可能出了点问题。消息意味着你的代码确实完全运行了，通常会在函数只是想让你注意它在幕后为你所做的事情时显示。因此，它们也被称为诊断消息。\n\n\n\n\n\n一位软件开发人员朋友曾经告诉第一作者关于他的职业的这个笑话：“程序员是比普通人更擅长使用谷歌的人”。这个观察结果当然也适用于 R 编程。如果你发现自己无法理解收到的错误或警告消息，请不要犹豫，只需复制并粘贴它，然后进行谷歌搜索。在搜索中添加“R”通常有助于改善结果。另一个不错的选择是 rseek.org，它允许你运行谷歌搜索，其中会自动过滤掉非 R 命中。互联网上的大多数内容都是英文的；因此，如果你的 R 中的错误消息是另一种语言，请运行 Sys.setenv(LANGUAGE = \"en\")，然后再次重新运行你的代码。\n那里有一个庞大的 R 社区，很可能有人以前遇到过与你相同的问题。如果你想用你的数据做一些具体的事情，但不知道可以用什么 R 命令来做，谷歌也很有帮助。即使对于专家来说，在编写 R 代码时使用谷歌数十次也是绝对正常的。每当你遇到困难时，请不要犹豫这样做。\n\n\n\n\n\n在谷歌上搜索与 R 相关的问题时，你很快就会发现许多第一个命中会将你链接到一个名为 StackOverflow 的网站。StackOverflow 是一个大型的基于社区的论坛，用于讨论与一般编程相关的问题。在 StackOverflow 上，每个人（包括你）都可以提问和回答问题。\n与互联网上的许多其他论坛不同，你在 StackOverflow 上获得的答案通常以目标为导向且有帮助。如果搜索谷歌没有帮助你解决问题，那么在那里提出问题可能是一个不错的解决方案。但是，有一些事情需要记住。首先，在提问时，始终用 [R] 标记你的问题，以便人们知道你在谈论哪种编程语言。另外，在 R 中运行 sessionInfo() 并将你获得的输出附加到你的问题中。这让人们知道你正在使用的 R 和软件包版本，并且可能有助于找到问题。\n最后，不要期望过度的友善。许多 StackOverflow 用户是有经验的程序员，他们可能愿意向你指出某些解决方案；但不要期望任何人为你解决问题。也可能有人只是通知你这个主题已经在其他地方讨论过了，向你发送链接，然后继续前进。尽管如此，使用 StackOverflow 通常是获得对你正在处理的特定问题的高质量支持的最佳方式。\n顺便说一句，StackOverflow 主要用于讨论编程问题。如果你的问题也有统计学背景，你可以使用 CrossValidated 代替。CrossValidated 的工作方式与 StackOverflow 类似，但主要由统计学和机器学习专家使用。\n\n\n\n\n\n如果你觉得你的问题与本指南本身有关，你也可以联系我们。这尤其适用于本指南的配套 R 软件包 {dmetar} 的问题。如果你在安装软件包或使用它的某些功能时遇到问题，你可以访问我们的 网站，在那里你可以找到报告问题的方法。当某些问题频繁出现时，我们通常会尝试查看它们并寻找修复方法。已知问题也会显示在本指南在线版本的更正和备注部分（请参阅工作流程部分）。如果我们没有亲自回答你的问题，或者我们花了很长时间才回复你，请不要感到失望。我们每天收到许多与 Meta 分析和我们的软件包相关的问题，因此有时不可能直接回答每一个问题。\n\n\n\n\n\n\n我们要感谢 David Grubbs 和 Chapmann & Hall/CRC Press 向我们提出了将我们的在线指南变成你现在正在阅读的印刷书籍的美好想法，并感谢他们提供的宝贵编辑支持。\n自 2018 年末我们开始编写在线版本的初步版本以来，许多研究人员和学生与我们分享了他们使用本指南的反馈和经验。这些反馈非常有价值，并极大地帮助我们根据读者的需求进一步定制本书。感谢你们所有人。\n我们非常感谢所有参与开发本指南中介绍的 R Meta 分析基础设施的研究人员；但首先也是最重要的是要感谢 {meta} 和 {metafor} 软件包的维护者 Guido Schwarzer 和 Wolfgang Viechtbauer。如果没有你们的努力和奉献，本指南以及整个 R Meta 分析社区都不会存在。\n此外，特别感谢华丽的 {robvis} 软件包的作者 Luke McGuinness 编写了关于偏倚风险可视化的额外章节，你可以在本书的配套网站上找到该章节。Luke，我们非常感谢你对这个项目的持续支持。\n最后但并非最不重要的一点是，我们要感谢 Lea Schuurmans、Paula Kuper 和 Antonia Sprenger 在本书的开发和编写中为我们提供的支持。\n\n埃尔兰根、阿姆斯特丹、京都和慕尼黑\n\nMathias, Pim, Toshi & David",
    "crumbs": [
      "网站首页",
      "前言"
    ]
  },
  {
    "objectID": "01-preface.html#本书是为凡人而作",
    "href": "01-preface.html#本书是为凡人而作",
    "title": "前言",
    "section": "",
    "text": "本指南不是为 Meta 分析专家或统计学家编写的。我们不假设你对 Meta 分析方法有任何特殊的背景知识。只需要对基本数学和统计概念有基本的了解即可。例如，我们假设你以前听说过“平均值”、“标准差”、“相关性”、“回归”、“\\(p\\)-值”或“正态分布”之类的东西。如果这些术语让你想起了一些事情，那么你应该可以开始了。如果你真的从头开始，你可能想首先看看 Robert Stinerock 的统计初学者指南 [@stinerock2018statistics]，以获得包括 R 中的实践示例的全面介绍——或者你选择的其他一些介绍性统计教科书。\n尽管我们试图使其尽可能地简洁，但我们有时会使用数学公式和统计符号。但不要惊慌。公式和希腊字母乍一看似乎令人困惑，但它们通常是精确描述某些 Meta 分析方法背后思想的好方法。见过这些公式，并且知道它们代表什么，也将使你更容易理解你可能想要进一步阅读的更高级的文本。当然，我们尽最大努力始终详细解释某些符号或字母代表什么，以及特定公式想要告诉我们什么。在本书的附录 @ref(symbollist) 中，你可以找到我们使用的符号列表，以及它们代表什么。在后面的章节中，尤其是高级方法部分，我们需要变得更加技术化，以解释某些应用技术背后的思想。尽管如此，我们确保始终包括有关这些部分中使用的数学和统计概念的一些背景信息。\n不需要事先了解 R（或一般的编程）。在本指南中，我们尝试提供一个温和的 R 技能介绍，你需要这些技能来编写自己的 Meta 分析代码。我们还提供对足够资源的引用，以便继续学习。此外，我们将向你展示如何设置一个免费的计算机程序，该程序允许你在你的 PC 或 Mac 上方便地使用 R。\n正如标题所说，我们的书侧重于 Meta 分析的“执行”部分。我们的指南旨在成为应用研究人员、学生和想要开始使用 R 进行分析的数据科学家可以访问的资源。然而，Meta 分析是一个庞大且多方面的课题，因此很自然地，并非所有内容都可以在本指南中涵盖。对于本书，局限性尤其与三个领域相关：\n\n尽管我们提供了关于这些主题的简短入门，但我们没有详细介绍如何定义研究问题、系统地搜索和包括用于 Meta 分析的研究，以及如何评估它们的质量。这些主题中的每一个都值得拥有自己的书籍，幸运的是，已经存在许多有用的资源。因此，我们仅概述了在收集 Meta 分析数据时的重要考虑因素和陷阱，并将你推荐给处理细节的足够资源。\n本指南的第二个局限性与其技术性水平有关。本书明确地是为“凡人”而写的。我们的目标是向你展示何时、如何以及为什么应用某些 Meta 分析技术，以及它们的陷阱。我们还试图提供对我们所涵盖技术的易于理解的概念性理解，仅在有利于此任务时才诉诸更多技术细节。很自然地，这意味着指南的某些部分不会包含专家级 Meta 分析师和统计学家可能需要的对技术的深入研究。尽管如此，我们还在每个章节中为感兴趣的读者提供了对更高级资源和出版物的引用。\n一本书的内容在某种程度上总是反映其作者的背景和经验。我们相信，我们在此涵盖的方法适用于范围广泛的研究领域和学科。尽管如此，我们想披露本书的四位作者主要精通心理学、精神病学、医学和干预研究领域的当前研究。“现实世界”的用例和我们在本书中涵盖的示例因此集中在我们熟悉的领域的主题上。好消息是，Meta 分析方法（假设一些我们将会涵盖的假设）在很大程度上与数据来自的研究领域无关，并且可以用于各种类型的结局指标。尽管如此，尽管我们尽了最大的努力使本指南尽可能广泛地适用于尽可能多的应用研究学科，但本书中涵盖的某些方法可能仍然与某些研究领域比其他研究领域更相关。",
    "crumbs": [
      "网站首页",
      "前言"
    ]
  },
  {
    "objectID": "01-preface.html#本书涵盖的主题",
    "href": "01-preface.html#本书涵盖的主题",
    "title": "前言",
    "section": "",
    "text": "除其他外，本指南将涵盖以下主题：\n\n什么是 Meta 分析，以及它为什么被发明出来。\nMeta 分析的优点和常见问题。\n如何指定 Meta 分析的研究问题，以及如何进行研究搜索。\n如何设置 R，以及一个允许你以方便的方式使用 R 的计算机程序。\n如何将你的 Meta 分析数据导入到 R 中，以及如何通过代码操作它。\n什么是效应量，以及如何计算它们。\n如何在固定效应和随机效应 Meta 分析中汇集效应量。\n如何分析 Meta 分析的异质性，以及如何使用亚组分析和Meta 回归来探索它。\n选择性结局报告的问题，以及如何解决它们。\n如何执行高级类型的 Meta 分析技术，例如“多层”Meta 分析、Meta 分析结构方程建模、网络 Meta 分析或贝叶斯 Meta 分析。\n如何报告你的 Meta 分析结果，并使其具有可重复性。",
    "crumbs": [
      "网站首页",
      "前言"
    ]
  },
  {
    "objectID": "01-preface.html#如何使用本书",
    "href": "01-preface.html#如何使用本书",
    "title": "前言",
    "section": "",
    "text": "本书旨在以“线性”方式阅读。我们建议你从关于 Meta 分析和 R 基础知识的第一章开始，然后继续逐章阅读本书。直接跳到实践章节可能很诱人，但通常不建议这样做。在教学生和研究人员如何进行他们的第一次 Meta 分析时，我们发现对这项技术以及 R Studio 环境的基本熟悉是避免以后出现挫折的必要之恶。如果你没有 Meta 分析和 R 编程的经验，这一点尤其正确。有经验的 R 用户可以跳过介绍 R 和 R Studio 的 @ref(discovering-R) 章。但是，无论如何，通过本章进行快速复习肯定不会有任何坏处。\n虽然所有章节实际上都是独立的，但我们有时会参考前面章节中涵盖的主题。尤其是高级方法部分中的章节假定你熟悉我们之前涵盖的理论概念。\n本书的最后一节包含对你的 Meta 分析有用的工具。这并不意味着这些主题是你在执行 Meta 分析时必须考虑的最后一件事。我们只是将这些章节放在最后，因为它们主要用作你自己的 Meta 分析项目的参考作品。我们在本书中与主题相关的部分链接到这些工具。\n\n\n\n\n\n本书附带一个名为 {dmetar} 的伴随 R 包。该软件包主要有两个功能。首先，它旨在让你的生活更轻松。尽管那里有非常棒的 R 包用于 Meta 分析，具有广泛的功能，但仍然有一些事情目前在 R 中不容易实现，至少对于初学者来说是这样。\n{dmetar} 包旨在通过提供一些额外的功能来弥合这一差距，从而促进这些事情。其次，该软件包还包含我们用于本书中显示的实践示例的所有数据集。在 @ref(dmetar) 章中，详细介绍了 {dmetar} 包，我们向你逐步展示如何安装该软件包。尽管我们将确保没有重大更改，但 {dmetar} 仍在积极开发中，因此不时查看 软件包网站 以检查是否有新的或改进的功能可用于你的 Meta 分析可能会有所帮助。\n虽然建议这样做，但安装该软件包并不是必不可少的。无论我们在本书中使用 {dmetar} 的地方，我们还将为你提供函数的原始代码，或我们正在使用的数据集的下载链接。\n\n\n\n\n\n在整本书中，使用了一组文本框。\n\n\n\n一般说明\n\n\n一般说明包含与所涵盖主题相关的相关背景信息、见解、轶事、注意事项或要点信息。\n\n\n\n\n\n\n重要信息\n\n\n这些框包含你必须牢记的警告、问题、缺点或陷阱信息。\n\n\n\n\n\n\n问题\n\n\n在每章之后，此框将包含一些问题，你可以通过这些问题来测试你的知识。这些问题的答案可以在本书末尾的附录 A中找到。\n\n\n\n\n\n\n{dmetar} 说明\n\n\n每当使用伴随 R 软件包中包含的函数或数据集时，都会出现 {dmetar} 说明框。这些框还包含函数代码的 URL，或者供未安装该软件包的读者使用的数据集下载链接。\n\n\n\n\n\n\n我该如何报告这个？\n\n\n这些框包含关于如何在你的论文或研究文章中报告 R 输出的建议。",
    "crumbs": [
      "网站首页",
      "前言"
    ]
  },
  {
    "objectID": "01-preface.html#约定",
    "href": "01-preface.html#约定",
    "title": "前言",
    "section": "",
    "text": "在整本书中都遵循一些约定。\n\\[~\\]\n{packages}\n所有 R 软件包都以粗体书写，并放在大括号中。这是在 R 社区中编写软件包名称的常见方式。\n\\[~\\]\nR 代码\n我们在 R 中定义的所有 R 代码或对象都以这种等宽字体书写。\n\\[~\\]\n## R 输出\n在运行 R 代码后收到的输出也使用相同的等宽字体。但是，我们使用两个数字符号（井号）将其与 R 输入区分开来。\n\\[~\\]\n\\(公式\\)\n这种衬线字体专用于公式、统计数据和其他形式的数学符号。",
    "crumbs": [
      "网站首页",
      "前言"
    ]
  },
  {
    "objectID": "01-preface.html#当你遇到困难时该怎么办",
    "href": "01-preface.html#当你遇到困难时该怎么办",
    "title": "前言",
    "section": "",
    "text": "不可否认的是，在 R 中进行 Meta 分析的道路有时可能是一条坎坷的道路。尽管我们认为有时这种说法被夸大了，但 R 的学习曲线确实很陡峭。统计学很难。我们尽了最大的努力使你学习如何使用 R 进行 Meta 分析的体验尽可能地轻松。但是，这并不能保护你免受有时会感到沮丧的情况。这完全是自然的。我们都必须从头开始。根据我们自己的经验，我们可以向你保证，我们从未见过任何不能学习 R 或如何进行 Meta 分析的人。这只需要练习，并且要理解在任何时候都不会有你“完成”学习的时候。我们相信你。\n如果你正在寻找比这条励志信息更实用一些的东西：以下是一些在你遇到本指南无法回答的事情时可以做的事情。\n\n\n\n\n在 R 中迈出第一步时，许多人在第一个红色错误消息开始弹出时感到害怕。这是没有必要的。每个人都一直收到错误消息。与其惊慌失措或将电脑扔出窗外，不如深吸一口气，仔细看看错误消息。通常，只需进行一些调整即可使错误消息消失。你是否在代码中拼写错了什么？你是否忘记关闭括号，或者将某些内容放入引号中？\n另外，请确保你的输出实际上是错误消息。R 区分 Error、Warning 和普通消息。只有第一个意味着你的代码无法执行。Warning 意味着你的代码确实运行了，但是可能出了点问题。消息意味着你的代码确实完全运行了，通常会在函数只是想让你注意它在幕后为你所做的事情时显示。因此，它们也被称为诊断消息。\n\n\n\n\n\n一位软件开发人员朋友曾经告诉第一作者关于他的职业的这个笑话：“程序员是比普通人更擅长使用谷歌的人”。这个观察结果当然也适用于 R 编程。如果你发现自己无法理解收到的错误或警告消息，请不要犹豫，只需复制并粘贴它，然后进行谷歌搜索。在搜索中添加“R”通常有助于改善结果。另一个不错的选择是 rseek.org，它允许你运行谷歌搜索，其中会自动过滤掉非 R 命中。互联网上的大多数内容都是英文的；因此，如果你的 R 中的错误消息是另一种语言，请运行 Sys.setenv(LANGUAGE = \"en\")，然后再次重新运行你的代码。\n那里有一个庞大的 R 社区，很可能有人以前遇到过与你相同的问题。如果你想用你的数据做一些具体的事情，但不知道可以用什么 R 命令来做，谷歌也很有帮助。即使对于专家来说，在编写 R 代码时使用谷歌数十次也是绝对正常的。每当你遇到困难时，请不要犹豫这样做。\n\n\n\n\n\n在谷歌上搜索与 R 相关的问题时，你很快就会发现许多第一个命中会将你链接到一个名为 StackOverflow 的网站。StackOverflow 是一个大型的基于社区的论坛，用于讨论与一般编程相关的问题。在 StackOverflow 上，每个人（包括你）都可以提问和回答问题。\n与互联网上的许多其他论坛不同，你在 StackOverflow 上获得的答案通常以目标为导向且有帮助。如果搜索谷歌没有帮助你解决问题，那么在那里提出问题可能是一个不错的解决方案。但是，有一些事情需要记住。首先，在提问时，始终用 [R] 标记你的问题，以便人们知道你在谈论哪种编程语言。另外，在 R 中运行 sessionInfo() 并将你获得的输出附加到你的问题中。这让人们知道你正在使用的 R 和软件包版本，并且可能有助于找到问题。\n最后，不要期望过度的友善。许多 StackOverflow 用户是有经验的程序员，他们可能愿意向你指出某些解决方案；但不要期望任何人为你解决问题。也可能有人只是通知你这个主题已经在其他地方讨论过了，向你发送链接，然后继续前进。尽管如此，使用 StackOverflow 通常是获得对你正在处理的特定问题的高质量支持的最佳方式。\n顺便说一句，StackOverflow 主要用于讨论编程问题。如果你的问题也有统计学背景，你可以使用 CrossValidated 代替。CrossValidated 的工作方式与 StackOverflow 类似，但主要由统计学和机器学习专家使用。\n\n\n\n\n\n如果你觉得你的问题与本指南本身有关，你也可以联系我们。这尤其适用于本指南的配套 R 软件包 {dmetar} 的问题。如果你在安装软件包或使用它的某些功能时遇到问题，你可以访问我们的 网站，在那里你可以找到报告问题的方法。当某些问题频繁出现时，我们通常会尝试查看它们并寻找修复方法。已知问题也会显示在本指南在线版本的更正和备注部分（请参阅工作流程部分）。如果我们没有亲自回答你的问题，或者我们花了很长时间才回复你，请不要感到失望。我们每天收到许多与 Meta 分析和我们的软件包相关的问题，因此有时不可能直接回答每一个问题。",
    "crumbs": [
      "网站首页",
      "前言"
    ]
  },
  {
    "objectID": "01-preface.html#致谢",
    "href": "01-preface.html#致谢",
    "title": "前言",
    "section": "",
    "text": "我们要感谢 David Grubbs 和 Chapmann & Hall/CRC Press 向我们提出了将我们的在线指南变成你现在正在阅读的印刷书籍的美好想法，并感谢他们提供的宝贵编辑支持。\n自 2018 年末我们开始编写在线版本的初步版本以来，许多研究人员和学生与我们分享了他们使用本指南的反馈和经验。这些反馈非常有价值，并极大地帮助我们根据读者的需求进一步定制本书。感谢你们所有人。\n我们非常感谢所有参与开发本指南中介绍的 R Meta 分析基础设施的研究人员；但首先也是最重要的是要感谢 {meta} 和 {metafor} 软件包的维护者 Guido Schwarzer 和 Wolfgang Viechtbauer。如果没有你们的努力和奉献，本指南以及整个 R Meta 分析社区都不会存在。\n此外，特别感谢华丽的 {robvis} 软件包的作者 Luke McGuinness 编写了关于偏倚风险可视化的额外章节，你可以在本书的配套网站上找到该章节。Luke，我们非常感谢你对这个项目的持续支持。\n最后但并非最不重要的一点是，我们要感谢 Lea Schuurmans、Paula Kuper 和 Antonia Sprenger 在本书的开发和编写中为我们提供的支持。\n\n埃尔兰根、阿姆斯特丹、京都和慕尼黑\n\nMathias, Pim, Toshi & David",
    "crumbs": [
      "网站首页",
      "前言"
    ]
  },
  {
    "objectID": "02-author.html",
    "href": "02-author.html",
    "title": "关于作者",
    "section": "",
    "text": "关于作者\n\n\n Mathias Harrer 是慕尼黑工业大学和埃尔朗根-纽伦堡弗里德里希-亚历山大大学的研究员。Mathias 的研究重点是心理治疗研究中的统计和技术方法、临床研究综合的方法以及统计软件的开发。\n \n\n Pim Cuijpers 是阿姆斯特丹自由大学的临床心理学教授。 他专门从事随机对照试验和荟萃分析，重点是常见精神障碍的预防和治疗。 Pim 在国际同行评审科学期刊上发表了 800 多篇文章； 其中许多是临床试验的荟萃分析。\n\n\n\nTwitter URL\n\n\n\n Toshi A. Furukawa 是京都大学公共卫生学院的健康促进和人类行为学教授。 他的开创性研究既侧重于研究综合和荟萃分析的理论方面，也侧重于它们在循证医学中的应用。\n\n\n\nTwitter URL\n\n\n\n David D. Ebert 是慕尼黑工业大学的心理学和行为健康技术教授。 David 的研究重点是基于互联网的干预、临床流行病学以及该领域的应用研究综合。\n\n\n\nTwitter URL",
    "crumbs": [
      "网站首页",
      "作者"
    ]
  },
  {
    "objectID": "04-discovering_R.html",
    "href": "04-discovering_R.html",
    "title": "R语言探索",
    "section": "",
    "text": "在 这一章，我们将开始我们的 R 宇宙之旅。可能这是你第一次接触编程，你可能会感到有点焦虑。这是可以理解的，但没有理由担心。在过去的二十年里，世界各地成千上万的聪明人为 R 的用户贡献了使其更容易和更方便的方法。我们还将了解一个非常强大的计算机程序，我们可以用它来使编写和运行 R 代码变得不那么繁琐。\n尽管如此，与其他你可能使用过的数据分析程序相比，使用 R 仍然更难。 R 社区中最重要的成员之一 Hadley Wickham 曾经强调， R 从根本上不同于基于 图形用户界面 (GUI) 的统计软件 [@grolemund2014hands, Foreword]。GUI 允许你仅通过点击几个按钮来执行数据分析，但你最终只能使用开发人员认为重要的功能。\n另一方面， R 没有这些限制，但可能需要更多的背景知识。像任何语言一样， R 需要学习，并且需要实践才能成为熟练的用户。沮丧是这个过程中令人不快但很自然的一部分。在序言中，你可以找到一整个部分，其中我们描述了如果你遇到困难可以做的一些事情。\n我们想向你保证，学习 R 是值得的。 R 是最多才多艺、最全面和最常用的统计编程语言。 R 社区每年都在迅速扩大， R 的吸引力如此之大，以至于《纽约时报》也认为值得报道 [@vance2009data]。\n无论你是在学术界还是在公司工作，你在 R 中可以做的事情对其他人来说通常看起来像是一种超能力。但这是每个人都可以学习的超能力，只要付出一些时间和精力。话虽如此，现在是开始的时候了。\n\n\n\n\n\n在我们开始之前，我们必须下载并准备一个计算机程序，使我们能够以方便的方式使用 R 进行统计分析。目前最好的选择可能是 R Studio。这个程序为我们提供了一个用户界面，使我们更容易处理我们的数据、包和输出。最棒的是 R Studio 完全免费，并且可以随时在互联网上下载。最近，R Studio 的在线版本已经 发布，它通过你的网络浏览器为你提供基本相同的界面和功能。然而，在本书中，我们将重点介绍直接安装在我们计算机上的 R Studio 版本。\n\n\n\n在本章中，我们将重点介绍如何在你的计算机上安装 R 和 R Studio。如果你已经在你的计算机上安装了 R Studio，并且你是一位经验丰富的 R 用户，这些对你来说可能都不是新的。那么你可以跳过本章。如果你以前从未使用过 R ，请耐心等待。\n\n\n\n\n让我们完成设置 R 和 R Studio 以进行我们的首次编码尝试的必要步骤。\n\nR Studio 是一个界面，它允许我们编写 R 代码并以一种简单的方式运行它。但是 R Studio 与 R 并不相同；它要求 R 软件已经安装在你的计算机上。因此，首先我们必须安装最新的 R 版本。像 R Studio 一样， R 是完全免费的。它可以从 Comprehensive R Archive Network，或 CRAN 网站下载。你必须下载的 R 类型取决于你使用的是 Windows PC 还是 Mac。关于 R 的一个重要细节是它的 版本。 R 会定期更新，这意味着会有新版本可用。当你的 R 版本变得太旧时，可能会发生某些事情不再有效。因此，定期更新 R 版本是有帮助的，可能大约每年一次，通过重新安装 R 。对于本书，我们使用的是 R 版本 4.0.3。在你安装 R 时，可能已经有更高的版本可用，建议始终安装最新版本。\n在你下载并安装 R 之后，你可以从 R Studio 网站 下载 “R Studio Desktop”。也有一些 R Studio 版本需要购买许可证，但对于我们的目的来说，这绝对不是必需的。只需下载并安装免费版本的 R Studio Desktop。\n第一次打开 R Studio 时，它可能看起来很像图 @ref(fig:rstudio-1) 中的样子。R Studio 中有三个窗格。在右上角，我们有 环境 窗格，它显示了我们在 R 内部定义的（即保存的）对象。在右下角，你可以找到 文件、绘图、包和帮助 窗格。此窗格有多种功能；例如，它用于显示你计算机上的文件、显示绘图和已安装的包，以及访问帮助页面。然而，R Studio 的核心是左侧，在那里你可以找到 控制台。控制台是所有 R 代码输入然后运行的地方。\n\n\n\n\n\n\nR Studio 中的窗格。\n\n\n\n\n\nR Studio 中还有一个第四个窗格，通常在一开始不显示，即 源 窗格。你可以通过点击菜单中的 文件 &gt; 新建文件 &gt; R 脚本 来打开源窗格。这将在左上角打开一个新的窗格，其中包含一个空的 R 脚本。 R 脚本是将你的代码收集到一个地方的好方法；你也可以将它们保存为扩展名为 “.R” 的文件（例如 myscript.R）在你的计算机上。要在 R 脚本中运行代码，请通过将光标拖过所有相关行来选择它，然后点击右侧的 “运行” 按钮。这会将代码发送到控制台，在那里对其进行评估。一个快捷方式是 Ctrl + R (Windows) 或 Cmd + R (Mac)。\n\n\n\n\n\n\n \n我们现在将使用 R 代码安装几个 包。包是 R 如此强大的主要原因之一。它们允许世界各地的专家开发其他人可以下载然后在 R 中使用的 函数 集合。函数是 R 的核心元素；它们允许我们执行预定义类型的操作，通常是在我们自己的数据上。\n函数的数学公式 \\(f(x)\\) 与在 R 中定义函数的方式之间存在着平行关系。在 R 中，一个函数首先要写下它的名字，然后是包含函数输入和/或规范（所谓的 参数）的括号。\n假设我们想知道 9 的平方根是多少。在 R 中，我们可以使用 sqrt 函数来实现这一点。我们只需要提供 9 作为函数的输入即可获得结果。你可以自己尝试一下。在控制台中的小箭头 (&gt;) 旁边，写下 sqrt(9) 然后按 Enter。让我们看看会发生什么。\n\nsqrt(9)\n\n[1] 3\n\n\n我们现在收到了来自 R 的第一个 输出。它告诉我们 9 的平方根是 3。尽管 R 中有比这个更复杂的函数，但它们都遵循相同的原则：你提供函数所需的参数信息，函数使用此信息进行计算，最后，它为你提供输出。\n \n在 R 中，我们还使用一个名为 install.packages 的函数来 安装包。我们必须告诉这个函数的唯一事情是我们想要安装的包的名称。目前，我们应该安装三个包，因为它们在以后会有所帮助。\n\n{tidyverse}。{tidyverse} 包 [@tidyverse] 不是一个单独的包，而实际上是一个包的捆绑，它使得在 R 中操作和可视化数据变得容易。当我们安装 {tidyverse} 包时，这同时为我们提供了 {ggplot2}、{dplyr}、{tidyr}、{readr}、{purrr}、{stringr} 和 {forcats} 包。近年来，包含在 tidyverse 中的函数在 R 社区中变得非常流行，并被许多研究人员、程序员和数据科学家使用。如果你想了解更多关于 tidyverse 的信息，你可以访问它的 网站。\n{meta}。这个包包含了一些函数，可以很容易地运行不同类型的 meta 分析 [@meta]。我们主要会在本指南中关注这个包，因为它易于使用，文档齐全，而且非常通用。关于 {meta} 包的更多信息可以在其 网站 上找到。\n{metafor}。{metafor} 包 [@urviecht] 也致力于进行 meta 分析，并且在功能方面是一个真正的强大工具。由于我们有时会在后面的章节中使用这个包，并且由于 {meta} 包在许多应用中使用 {metafor}，因此最好安装它。 {metafor} 包还为各种与 meta 分析相关的主题提供了优秀的 文档。\n\ninstall.packages 函数只需要我们想要安装的包的名称作为输入。一个接一个的包，我们的代码应该看起来像这样：\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"meta\")\ninstall.packages(\"metafor\")\n\n只需将上面的代码输入到控制台中；然后按 Enter 开始安装（见图 @ref(fig:rstudio-1)）。\n\n\n\n\n\n安装一个包。\n\n\n\n\n\n\n\n不要忘记将包名称放入引号（\"\"）中。否则，你将收到一条错误消息。\n\n\n在你点击 Enter 之后， R 将开始安装该包并打印一些关于安装进度的信息。当 install.packages 函数完成时，该包就可以使用了。已安装的包被添加到 R 的 系统库 中。这个系统库可以在你的 R Studio 屏幕左下角的 包 窗格中访问。每当我们想使用已安装的包时，我们可以使用 library 函数从我们的库中加载它。让我们尝试一下，并加载 {tidyverse} 包。\n\nlibrary(tidyverse)\n\n\n\n\n\n\n\n在本指南中，我们希望使研究人员能够尽可能轻松地进行 meta 分析。尽管有一些很棒的包，比如 {meta} 和 {metafor} 包，它们完成了大部分繁重的工作，但我们仍然认为 meta 分析的某些方面很重要，但在目前 R 中不容易做到，特别是如果你没有编程或统计背景。\n为了填补这个空白，我们开发了 {dmetar} 包，它是本书的配套 R 包。 {dmetar} 包有自己的文档，可以在 网上 找到。 {dmetar} 包的函数为 {meta} 和 {metafor} 包（以及其他一些更高级的包）提供了额外的功能，我们将在本指南中经常使用它们。包含在 {dmetar} 包中的大多数函数以及它们如何改善你的 meta 分析工作流程将在本书中详细描述。我们在本指南中使用的大多数示例数据集也包含在 {dmetar} 中。\n\n\n\n虽然强烈建议，但不是必须安装 {dmetar} 包才能完成本指南。对于该包的每个函数，我们也会提供源代码，可以用来在你的计算机上本地保存该函数，以及这些函数所依赖的其他 R 包。我们还将为包含在该包中的数据集提供补充下载链接。\n但是，事先安装 {dmetar} 包要方便得多，因为这会预先安装所有函数和数据集在你的计算机上。\n\n\n\n要安装 {dmetar} 包，你计算机上的 R 版本必须为 3.6 或更高版本。如果你最近（重新）安装了 R，情况可能就是这样。要检查你的 R 版本是否足够新，你可以将此行代码粘贴到控制台中，然后按 Enter。\n\nR.Version()$version.string\n\n这将显示你当前的 R 版本。如果 R 版本低于 3.6，你将必须更新它。互联网上有一些很好的 博客文章 提供了有关如何执行此操作的指导。\n如果你想安装 {dmetar}，首先需要安装一个包在你的计算机上。这个包叫做 {devtools}。所以，如果 {devtools} 还没有在你的计算机上，你可以像我们之前做的那样安装它。\n\ninstall.packages(\"devtools\")\n\n然后你可以使用这行代码安装 {dmetar}：\n\ndevtools::install_github(\"MathiasHarrer/dmetar\")\n\n这将启动安装过程。很可能安装需要一些时间，因为必须与 {dmetar} 包一起安装其他几个包才能使其正常工作。在安装过程中，安装管理器可能会询问你是否要更新计算机上现有的 R 包。输出可能看起来像这样：\n## 这些包有更新的版本可用。\n## 你想更新哪个？\n## \n## 1：全部\n## 2：仅 CRAN 包\n## 3：无\n## 4：ggpubr (0.2.2 -&gt; 0.2.3) [CRAN]\n## 5：zip (2.0.3 -&gt; 2.0.4) [CRAN]\n## \n## 输入一个或多个数字，或输入一个空行以跳过更新：\n当你收到此消息时，最好告诉安装管理器不要更新任何包。在我们的示例中，这意味着将 3 粘贴到控制台中，然后按 Enter。同样地，当安装管理器提出这个问题时：\n## 有二进制版本可用，但源版本较新：\n## \n## [...]\n## \n## 你想从需要编译的源安装包吗？\n## y/n：\n最好选择 n（否）。如果使用此策略安装失败（意味着你收到一个 Error），请再次运行安装，但这次更新所有包。\n在编写本书和开发该包时，我们确保每个人都可以毫无错误地安装它。尽管如此，仍然有可能第一次尝试安装该包时不起作用。如果安装问题仍然存在，你可以查看本书序言中的 “联系我们” 部分。\n\n\n\n\n\n本章将告诉你如何使用 R Studio 将数据导入 R 。数据准备有时可能很繁琐和耗尽精力，但它是所有后续步骤的支柱。因此，我们必须密切注意将数据导入正确的格式，然后才能继续。\n通常，导入到 R 中的数据首先存储在 Microsoft Excel 电子表格中。我们建议在那里存储你的数据，因为这使得导入变得非常容易。在 Excel 中准备数据时，有一些 “应该做和不应该做” 的事项。\n\n命名电子表格的列非常重要。如果你已经在 Excel 中充分命名了工作表的列，那么你可以在以后节省大量时间，因为你的数据不必使用 R 进行转换。“命名” 电子表格的列仅仅意味着将变量的名称写入列的第一行； R 将自动检测到这是列的名称。\n列名不应包含任何空格。要在列名中分隔两个单词，可以使用下划线或点（例如 “column_name”）。\nExcel 电子表格中列的顺序无关紧要。它们只需要正确标记。\n也没有必要以任何方式格式化列。如果你在电子表格的第一行中键入列名， R 将自动将其检测为列名。\n同样重要的是要知道导入可能会扭曲特殊字符，如 ä、ü、ö、á、é、ê 等。你可能想在继续之前将它们转换为 “正常” 字母。\n确保你的 Excel 文件只包含一个工作表。\n如果你有一个或几个曾经包含数据的空行或列，请确保完全删除这些列/行，因为 R 可能会认为这些列包含（缺失的）数据并也导入它们。\n\n让我们从一个示例数据集开始。假设你计划进行一项自杀预防计划的 meta 分析。你想要在你的研究中关注的结果是自杀意念的严重程度（即个体思考、考虑或计划结束其生命的程度），通过问卷评估。你已经完成了研究搜索和数据提取，现在想在 R 中导入你的 meta 分析数据。\n因此，下一个任务是准备一个 Excel 工作表，其中包含所有相关数据。表 @ref(tab:suicidedata) 显示了我们想要导入的所有数据。在第一行中，此表还显示了我们如何根据我们列出的规则在 Excel 文件中命名我们的列。我们可以看到电子表格在一行中列出了每个研究。对于每个研究，干预组和对照组都包括样本量 (\\(n\\))、均值和标准差 (\\(SD\\))。这是计算效应量所需的结果数据，我们将在第 @ref(effects) 章中详细介绍。以下三列包含我们稍后要作为 meta 分析一部分进行分析的变量。\n我们为你准备了一个名为 “SuicidePrevention.xlsx” 的 Excel 文件，其中包含完全相同的数据。该文件可以从 Internet 下载。\n\n\n\n\n\nThe suicide prevention dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'author'\n\n\n'n.e'\n\n\n'mean.e'\n\n\n'sd.e'\n\n\n'n.c'\n\n\n'mean.c'\n\n\n'sd.c'\n\n\n'pubyear'\n\n\n'age_group'\n\n\n'control'\n\n\n\n\n\nIntervention Group\n\n\nControl Group\n\n\nSubgroups\n\n\n\nAuthor\nN\nMean\nSD\nN\nMean\nSD\nYear\nAge Group\nControl Group\n\n\n\n\nBerry et al.\n90\n14.98\n3.29\n95\n15.54\n4.41\n2006\ngeneral\nWLC\n\n\nDeVries et al.\n77\n16.21\n5.35\n69\n20.13\n7.43\n2019\nolder adult\nno intervention\n\n\nFleming et al.\n30\n3.01\n0.87\n30\n3.13\n1.23\n2006\ngeneral\nno intervention\n\n\nHunt & Burke\n64\n19.32\n6.41\n65\n20.22\n7.62\n2011\ngeneral\nWLC\n\n\nMcCarthy et al.\n50\n4.54\n2.75\n50\n5.61\n2.66\n1997\ngeneral\nWLC\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n\n\n\n\n\n\n\n为了在 R Studio 中导入我们的 Excel 文件，我们首先必须设置一个 工作目录。工作目录是你计算机上的一个文件夹， R 可以从中使用数据，并且在其中保存输出。要设置工作目录，你首先必须在你的计算机上创建一个文件夹，你希望将所有 meta 分析数据和结果保存在其中。你还应该将我们要导入的 “SuicidePrevention.xlsx” 文件保存在此文件夹中。\n然后启动 R Studio 并在左下角的 文件 窗格中打开你新创建的文件夹。一旦你打开了你的文件夹，你应该显示你刚刚保存在那里的 Excel 文件。然后通过点击窗格顶部的小齿轮，然后在弹出菜单中点击 设置为工作目录 来将此文件夹设置为工作目录。这将使当前打开的文件夹成为工作目录。\n\n\n\n\n\n设置工作目录；数据集加载到 R 环境中。\n\n\n\n\n我们现在可以继续并将数据导入 R 。在 文件 窗格中，只需点击 “SuicidePrevention.xlsx” 文件。然后点击 导入数据集…。现在应该弹出一个导入助手，它也在加载你的数据的预览。这有时可能很耗时，所以你可以跳过这一步，直接点击 导入。\n\n你的数据集应该以名称 SuicidePrevention 列在右上角的 环境 窗格中。这意味着你的数据现在已加载并且可以被 R 代码使用。像我们在这里导入的表格数据集在 R 中被称为 数据框 (data.frame)。数据框是具有列和行的数据集，就像我们刚刚导入的 Excel 电子表格一样。\n\n\n\n\n{openxlsx}\n也可以使用代码直接导入数据文件。我们可以用来做到这一点的一个好的包叫做 {openxslx} [@openxlsx]。与所有 R 包一样，你必须首先安装它。然后你可以使用 read.xlsx 函数导入 Excel 工作表。\n如果该文件保存在你的工作目录中，你只需为该函数提供该文件的名称，并将导入的数据分配给 R 中的一个对象。例如，如果我们希望我们的数据集在 R 中具有名称 data，我们可以使用此代码：\nlibrary(openxlsx)  data &lt;- read.xlsx(\"SuicidePrevention.xlsx\")\n\n\n\n\n\n\n\n现在我们已经使用 R Studio 导入了我们的第一个数据集，让我们做一些操作。数据整理，意味着转换数据以使其可用于进一步分析，是所有数据分析的重要组成部分。一些职业，例如数据科学家，花费他们的大部分时间将原始的 “不整洁” 的数据变成 “整洁” 的数据集。 {tidyverse} 的函数为数据整理提供了一个出色的工具箱。如果你还没有从你的库中加载该包，你应该立即加载它以用于以下示例。\n\nlibrary(tidyverse)\n\n\n\n\n\n首先，我们应该看一下我们在上一章中导入的 SuicidePrevention 数据集。为此，我们可以使用 {tidyverse} 提供的 glimpse 函数。\n\nglimpse(SuicidePrevention)\n\nRows: 9\nColumns: 10\n$ author    &lt;chr&gt; \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt & …\n$ n.e       &lt;chr&gt; \"90\", \"77\", \"30\", \"64\", \"50\", \"109\", \"60\", \"40\", \"51\"\n$ mean.e    &lt;chr&gt; \"14.98\", \"16.21\", \"3.01\", \"19.32\", \"4.54\", \"15.11\", \"3.44\", …\n$ sd.e      &lt;chr&gt; \"3.29\", \"5.35\", \"0.87\", \"6.41\", \"2.75\", \"4.63\", \"1.26\", \"0.7…\n$ n.c       &lt;dbl&gt; 95, 69, 30, 65, 50, 111, 60, 40, 56\n$ mean.c    &lt;chr&gt; \"15.54\", \"20.13\", \"3.13\", \"20.22\", \"5.61\", \"16.46\", \"3.42\", …\n$ sd.c      &lt;chr&gt; \"4.41\", \"7.43\", \"1.23\", \"7.62\", \"2.66\", \"5.39\", \"1.88\", \"1.4…\n$ pubyear   &lt;dbl&gt; 2006, 2019, 2006, 2011, 1997, 2000, 2013, 2015, 2014\n$ age_group &lt;chr&gt; \"general\", \"older adult\", \"general\", \"general\", \"general\", \"…\n$ control   &lt;chr&gt; \"WLC\", \"no intervention\", \"no intervention\", \"WLC\", \"WLC\", \"…\n\n\n我们看到这为我们提供了关于我们存储在数据集的每一列中的数据类型的详细信息。有不同的缩写表示不同的数据类型。在 R 中，它们被称为 类。\n\n&lt;num&gt; 代表 numeric。这是所有存储为数字的数据（例如 1.02）。\n&lt;chr&gt; 代表 character。这是所有存储为单词的数据。\n&lt;log&gt; 代表 logical。这些是二进制变量，意味着它们表明一个条件是 TRUE 还是 FALSE。\n&lt;factor&gt; 代表 factor。因子存储为数字，每个数字表示变量的不同级别。变量可能的因子级别可能是 1 = “low”，2 = “medium”，3 = “high”。\n\n我们还可以使用 class 函数检查列的类。我们可以通过将 $ 运算符添加到其名称，然后再添加列的名称来直接访问数据框中的列。让我们尝试一下。首先，我们让 R 为我们提供 n.e 列中包含的数据。之后，我们检查该列的类。\n\nSuicidePrevention$n.e\n\n[1] \"90\"  \"77\"  \"30\"  \"64\"  \"50\"  \"109\" \"60\"  \"40\"  \"51\" \n\nclass(SuicidePrevention$n.e)\n\n[1] \"character\"\n\n\n我们看到包含干预组样本量的 n.e 列的类是 character。但是等等，这是错误的类！在导入过程中，此列被错误地分类为 character 变量，而它实际上应该具有 numeric 类。这对进一步的分析步骤有影响。例如，如果我们想计算平均样本量，我们会得到以下警告：\n\nmean(SuicidePrevention$n.e)\n\nWarning in mean.default(SuicidePrevention$n.e): argument is not numeric or\nlogical: returning NA\n\n\n[1] NA\n\n\n为了使我们的数据集可用，我们通常必须首先将我们的列转换为正确的类。为此，我们可以使用一组以 “as.” 开头的函数：as.numeric、as.character、as.logical 和 as.factor。让我们来看几个例子。\n在之前 glimpse 函数的输出中，我们看到有几个列被赋予了 character 类，而它们应该是 numeric。这涉及到列 n.e、mean.e、sd.e、mean.c 和 sd.c。我们看到出版年份 pubyear 具有 &lt;dbl&gt; 类。这代表 double，意味着该列是一个数值向量。这是一个历史异常现象，在 R 中 double 和 numeric 都用于指代数值数据类型。然而，通常这没有实际的实际意义。\n然而，在我们的数据集中，一些数值被编码为 字符，这将导致下游问题，因此我们应该使用 as.numeric 函数更改该类。我们为该函数提供我们要更改的列，然后使用 赋值运算符 (&lt;-) 将输出保存回其原始位置。这导致了以下代码。\n\nSuicidePrevention$n.e &lt;- as.numeric(SuicidePrevention$n.e)\nSuicidePrevention$mean.e &lt;- as.numeric(SuicidePrevention$mean.e)\nSuicidePrevention$sd.e &lt;- as.numeric(SuicidePrevention$sd.e)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\nSuicidePrevention$mean.c &lt;- as.numeric(SuicidePrevention$mean.c)\nSuicidePrevention$sd.c &lt;- as.numeric(SuicidePrevention$sd.c)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\n\n我们还在 glimpse 输出中看到 age_group 和 control，我们数据中的子组，被编码为字符。然而，实际上，将它们编码为因子更合适，每个因子级别有两个。我们可以使用 as.factor 函数更改类。\n\nSuicidePrevention$age_group &lt;- as.factor(SuicidePrevention$age_group)\nSuicidePrevention$control &lt;- as.factor(SuicidePrevention$control)\n\n使用 levels 和 nlevels 函数，我们还可以查看因子标签和因子中的级别数。\n\nlevels(SuicidePrevention$age_group)\n\n[1] \"general\"     \"older adult\"\n\nnlevels(SuicidePrevention$age_group)\n\n[1] 2\n\n\n我们还可以使用 levels 函数更改因子标签的名称。我们只需为原始标签分配新名称。要在 R 中执行此操作，我们必须使用 concatenate，或 c 函数。此函数可以将两个或多个单词或数字连接在一起并创建一个元素。让我们尝试一下。\n\nnew.factor.levels &lt;- c(\"gen\", \"older\")\nnew.factor.levels\n\n[1] \"gen\"   \"older\"\n\n\n完美。我们现在可以使用新创建的 new.factor.levels 对象，并将其分配给 age_group 列的因子标签。\n\nlevels(SuicidePrevention$age_group) &lt;- new.factor.levels\n\n让我们检查一下重命名是否有效。\n\nSuicidePrevention$age_group\n\n[1] gen   older gen   gen   gen   gen   gen   older older\nLevels: gen older\n\n\n也可以使用 as.logical 创建逻辑值。假设我们想要重新编码 pubyear 列，以便它仅显示研究是否在 2009 年之后发表。为此，我们必须通过代码定义一个是/否规则。我们可以使用 “大于或等于” 运算符 &gt;= 来做到这一点，然后将其用作 as.logical 函数的输入。\n\nSuicidePrevention$pubyear\n\n[1] 2006 2019 2006 2011 1997 2000 2013 2015 2014\n\nas.logical(SuicidePrevention$pubyear &gt;= 2010)\n\n[1] FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n\n\n我们可以看到，这会将 pubyear 中的每个元素编码为 TRUE 或 FALSE，具体取决于发表年份是否大于或等于 2010。\n\n\n\n\n\n在 R 中，有几种方法可以提取数据框的子集。我们已经介绍了一种方法，即 $ 运算符，它可以用于提取列。从数据集中提取切片的更通用方法是使用方括号。我们使用方括号时必须遵循的通用形式是 data.frame[rows, columns]。始终可以通过使用它们在数据集中出现的数字来提取行和列。例如，我们可以使用以下代码提取数据框第二行中的数据。\n\nSuicidePrevention[2,]\n\n          author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n2 DeVries et al.  77  16.21 5.35  69  20.13 7.43    2019     older\n          control\n2 no intervention\n\n\n我们可以更具体地告诉 R ，我们只想要第二行第一列中的信息。\n\nSuicidePrevention[2, 1]\n\n[1] \"DeVries et al.\"\n\n\n要选择特定的切片，我们必须再次使用连接 (c) 函数。例如，如果我们想提取第 2 行和第 3 行以及第 4 列和第 6 列，我们可以使用此代码。\n\nSuicidePrevention[c(2,3), c(4,6)]\n\n  sd.e mean.c\n2 5.35  20.13\n3 0.87   3.13\n\n\n通常只能按行号选择行。但是，对于列，也可以提供列名称而不是数字。\n\nSuicidePrevention[, c(\"author\", \"control\")]\n\n           author         control\n1    Berry et al.             WLC\n2  DeVries et al. no intervention\n3  Fleming et al. no intervention\n4    Hunt & Burke             WLC\n5 McCarthy et al.             WLC\n6   Meijer et al. no intervention\n7   Rivera et al. no intervention\n8  Watkins et al. no intervention\n9  Zaytsev et al. no intervention\n\n\n另一种可能性是根据行值 过滤 数据集。我们可以使用 filter 函数来做到这一点。在该函数中，我们需要指定我们的数据集名称，以及一个过滤逻辑。一个相对简单的例子是过滤所有 n.e 等于或小于 50 的研究。\n\nfilter(SuicidePrevention, n.e &lt;= 50)\n\n           author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n1  Fleming et al.  30   3.01 0.87  30   3.13 1.23    2006       gen\n2 McCarthy et al.  50   4.54 2.75  50   5.61 2.66    1997       gen\n3  Watkins et al.  40   7.10 0.76  40   7.38 1.41    2015     older\n          control\n1 no intervention\n2             WLC\n3 no intervention\n\n\n但也可以按名称进行过滤。假设我们想提取作者为 Meijer 和 Zaytsev 的研究。为此，我们必须使用 %in% 运算符和连接函数来定义我们的过滤逻辑。\n\nfilter(SuicidePrevention, author %in% c(\"Meijer et al.\",\n                                        \"Zaytsev et al.\"))\n\n          author n.e mean.e sd.e n.c mean.c  sd.c pubyear age_group\n1  Meijer et al. 109  15.11 4.63 111  16.46  5.39    2000       gen\n2 Zaytsev et al.  51  23.74 7.24  56  24.91 10.65    2014     older\n          control\n1 no intervention\n2 no intervention\n\n\n相反，我们也可以通过在过滤逻辑前放置一个感叹号来提取所有除了 Meijer 和 Zaytsev 的研究。\n\nfilter(SuicidePrevention, !author %in% c(\"Meijer et al.\", \n                                         \"Zaytsev et al.\"))\n\n\n\n\n\n\n当然，也可以更改 R 数据框中的特定值，或者扩展它们。要更改我们保存在 R 内部的数据，我们必须使用 赋值运算符。让我们重新使用我们之前学到的关于数据切片的知识来更改我们数据集中的特定值。假设我们犯了一个错误，并且 DeVries et al. 研究的发表年份错误地报告为 2019 年，而它应该是 2018 年。我们可以通过相应地切片我们的数据集，然后分配新值来更改该值。记住，DeVries et al. 的结果在数据集的第二行中报告。\n\nSuicidePrevention[2, \"pubyear\"] &lt;- 2018\nSuicidePrevention[2, \"pubyear\"]\n\n## [1] 2018\n也可以一次更改多个值。例如，如果我们想在我们的数据集中为每个干预组均值加 5，我们可以使用以下代码来做到这一点。\n\nSuicidePrevention$mean.e + 5\n\n[1] 19.98 21.21  8.01 24.32  9.54 20.11  8.44 12.10 28.74\n\n\n我们还可以使用两列或多列来进行计算。一个实际相关的例子是我们可能对计算每个研究的干预组和对照组均值之间的 均值差异 感兴趣。与其他编程语言相比，这在 R 中非常容易。\n\nSuicidePrevention$mean.e - SuicidePrevention$mean.c\n\n[1] -0.56 -3.92 -0.12 -0.90 -1.07 -1.35  0.02 -0.28 -1.17\n\n\n正如你所看到的，这获取了每个研究的干预组均值，然后减去对照组均值，每次都使用同一行的值。假设我们想在以后使用这个均值差异。因此，我们想将它保存为一个名为 md 的额外对象，并将它作为一个新列添加到我们的 SuicidePrevention 数据框中。使用赋值运算符很容易做到这两点。\n\nmd &lt;- SuicidePrevention$mean.e - SuicidePrevention$mean.c\n\nSuicidePrevention$md &lt;- SuicidePrevention$mean.e - \n                            SuicidePrevention$mean.c\n\n\n我们想向你展示的最后一件事是 管道运算符。在 R 中，管道写成 %&gt;%。管道本质上允许我们将一个函数应用于一个对象，而无需直接在函数调用中指定对象名称。我们只需使用管道运算符连接对象和函数。让我们给你一个简单的例子。如果我们想计算对照组中的平均样本量，我们可以像这样使用 mean 函数和管道运算符：\n\nSuicidePrevention$n.c %&gt;% mean()\n\n[1] 64\n\n\n诚然，在这个例子中，很难看到这种管道的附加价值。管道的特殊优势在于它们允许我们将许多函数 链接 在一起。假设我们想知道平均对照组样本量的平方根，但仅适用于 2009 年之后发表的研究。管道让我们可以在一步中方便地做到这一点。\n\nSuicidePrevention %&gt;% \n  filter(pubyear &gt; 2009) %&gt;% \n  pull(n.c) %&gt;% \n  mean() %&gt;% \n  sqrt()\n\n[1] 7.615773\n\n\n在管道中，我们使用了一个我们之前没有介绍的函数，即 pull 函数。这个函数可以被看作是 $ 运算符的等价物，我们可以在管道中使用它。它只是 “拉出” 我们在函数中指定的变量，因此它可以被转发到管道的下一部分。\n\n\n\n访问 R 文档\n\n\nR 中的许多函数都需要几个参数，并且不可能记住如何正确使用所有函数。谢天谢地，没有必要用心记住如何使用每个函数。R Studio 让我们很容易访问 R 文档，其中每个函数都有一个详细的描述页面。\n\n\n有两种方法可以搜索函数文档页面。第一种是访问 R Studio 左下角的 帮助 窗格，然后使用搜索栏查找关于特定函数的信息。更方便的方法是简单地运行 ?，后跟控制台中函数的名称，例如 ?mean。这将自动打开该函数的文档条目。\n\n\n一个函数的 R 文档通常至少包含一个 用法、参数 和 示例 部分。参数 和 示例 部分通常对于理解如何使用一个函数特别有帮助。\n\n\n\n\n\n\n\n\n一旦我们用我们的数据完成了转换并将它们保存在 R 内部，我们必须在某个时候 导出 它。我们建议你在保存 R 数据框时使用两种类型的文件格式：.rda 和 .csv。\n文件结尾 .rda 代表 R 数据。这是一种专门为 R 设计的文件类型，具有所有的优点和缺点。.rda 文件的优点是它们可以很容易地在 R 中重新打开，并且没有你的数据在导出过程中可能会被扭曲的风险。它们",
    "crumbs": [
      "网站首页",
      "发现R"
    ]
  },
  {
    "objectID": "04-discovering_R.html#install-R",
    "href": "04-discovering_R.html#install-R",
    "title": "R语言探索",
    "section": "",
    "text": "在我们开始之前，我们必须下载并准备一个计算机程序，使我们能够以方便的方式使用 R 进行统计分析。目前最好的选择可能是 R Studio。这个程序为我们提供了一个用户界面，使我们更容易处理我们的数据、包和输出。最棒的是 R Studio 完全免费，并且可以随时在互联网上下载。最近，R Studio 的在线版本已经 发布，它通过你的网络浏览器为你提供基本相同的界面和功能。然而，在本书中，我们将重点介绍直接安装在我们计算机上的 R Studio 版本。\n\n\n\n在本章中，我们将重点介绍如何在你的计算机上安装 R 和 R Studio。如果你已经在你的计算机上安装了 R Studio，并且你是一位经验丰富的 R 用户，这些对你来说可能都不是新的。那么你可以跳过本章。如果你以前从未使用过 R ，请耐心等待。\n\n\n\n\n让我们完成设置 R 和 R Studio 以进行我们的首次编码尝试的必要步骤。\n\nR Studio 是一个界面，它允许我们编写 R 代码并以一种简单的方式运行它。但是 R Studio 与 R 并不相同；它要求 R 软件已经安装在你的计算机上。因此，首先我们必须安装最新的 R 版本。像 R Studio 一样， R 是完全免费的。它可以从 Comprehensive R Archive Network，或 CRAN 网站下载。你必须下载的 R 类型取决于你使用的是 Windows PC 还是 Mac。关于 R 的一个重要细节是它的 版本。 R 会定期更新，这意味着会有新版本可用。当你的 R 版本变得太旧时，可能会发生某些事情不再有效。因此，定期更新 R 版本是有帮助的，可能大约每年一次，通过重新安装 R 。对于本书，我们使用的是 R 版本 4.0.3。在你安装 R 时，可能已经有更高的版本可用，建议始终安装最新版本。\n在你下载并安装 R 之后，你可以从 R Studio 网站 下载 “R Studio Desktop”。也有一些 R Studio 版本需要购买许可证，但对于我们的目的来说，这绝对不是必需的。只需下载并安装免费版本的 R Studio Desktop。\n第一次打开 R Studio 时，它可能看起来很像图 @ref(fig:rstudio-1) 中的样子。R Studio 中有三个窗格。在右上角，我们有 环境 窗格，它显示了我们在 R 内部定义的（即保存的）对象。在右下角，你可以找到 文件、绘图、包和帮助 窗格。此窗格有多种功能；例如，它用于显示你计算机上的文件、显示绘图和已安装的包，以及访问帮助页面。然而，R Studio 的核心是左侧，在那里你可以找到 控制台。控制台是所有 R 代码输入然后运行的地方。\n\n\n\n\n\n\nR Studio 中的窗格。\n\n\n\n\n\nR Studio 中还有一个第四个窗格，通常在一开始不显示，即 源 窗格。你可以通过点击菜单中的 文件 &gt; 新建文件 &gt; R 脚本 来打开源窗格。这将在左上角打开一个新的窗格，其中包含一个空的 R 脚本。 R 脚本是将你的代码收集到一个地方的好方法；你也可以将它们保存为扩展名为 “.R” 的文件（例如 myscript.R）在你的计算机上。要在 R 脚本中运行代码，请通过将光标拖过所有相关行来选择它，然后点击右侧的 “运行” 按钮。这会将代码发送到控制台，在那里对其进行评估。一个快捷方式是 Ctrl + R (Windows) 或 Cmd + R (Mac)。",
    "crumbs": [
      "网站首页",
      "发现R"
    ]
  },
  {
    "objectID": "04-discovering_R.html#packages",
    "href": "04-discovering_R.html#packages",
    "title": "R语言探索",
    "section": "",
    "text": "我们现在将使用 R 代码安装几个 包。包是 R 如此强大的主要原因之一。它们允许世界各地的专家开发其他人可以下载然后在 R 中使用的 函数 集合。函数是 R 的核心元素；它们允许我们执行预定义类型的操作，通常是在我们自己的数据上。\n函数的数学公式 \\(f(x)\\) 与在 R 中定义函数的方式之间存在着平行关系。在 R 中，一个函数首先要写下它的名字，然后是包含函数输入和/或规范（所谓的 参数）的括号。\n假设我们想知道 9 的平方根是多少。在 R 中，我们可以使用 sqrt 函数来实现这一点。我们只需要提供 9 作为函数的输入即可获得结果。你可以自己尝试一下。在控制台中的小箭头 (&gt;) 旁边，写下 sqrt(9) 然后按 Enter。让我们看看会发生什么。\n\nsqrt(9)\n\n[1] 3\n\n\n我们现在收到了来自 R 的第一个 输出。它告诉我们 9 的平方根是 3。尽管 R 中有比这个更复杂的函数，但它们都遵循相同的原则：你提供函数所需的参数信息，函数使用此信息进行计算，最后，它为你提供输出。\n \n在 R 中，我们还使用一个名为 install.packages 的函数来 安装包。我们必须告诉这个函数的唯一事情是我们想要安装的包的名称。目前，我们应该安装三个包，因为它们在以后会有所帮助。\n\n{tidyverse}。{tidyverse} 包 [@tidyverse] 不是一个单独的包，而实际上是一个包的捆绑，它使得在 R 中操作和可视化数据变得容易。当我们安装 {tidyverse} 包时，这同时为我们提供了 {ggplot2}、{dplyr}、{tidyr}、{readr}、{purrr}、{stringr} 和 {forcats} 包。近年来，包含在 tidyverse 中的函数在 R 社区中变得非常流行，并被许多研究人员、程序员和数据科学家使用。如果你想了解更多关于 tidyverse 的信息，你可以访问它的 网站。\n{meta}。这个包包含了一些函数，可以很容易地运行不同类型的 meta 分析 [@meta]。我们主要会在本指南中关注这个包，因为它易于使用，文档齐全，而且非常通用。关于 {meta} 包的更多信息可以在其 网站 上找到。\n{metafor}。{metafor} 包 [@urviecht] 也致力于进行 meta 分析，并且在功能方面是一个真正的强大工具。由于我们有时会在后面的章节中使用这个包，并且由于 {meta} 包在许多应用中使用 {metafor}，因此最好安装它。 {metafor} 包还为各种与 meta 分析相关的主题提供了优秀的 文档。\n\ninstall.packages 函数只需要我们想要安装的包的名称作为输入。一个接一个的包，我们的代码应该看起来像这样：\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"meta\")\ninstall.packages(\"metafor\")\n\n只需将上面的代码输入到控制台中；然后按 Enter 开始安装（见图 @ref(fig:rstudio-1)）。\n\n\n\n\n\n安装一个包。\n\n\n\n\n\n\n\n不要忘记将包名称放入引号（\"\"）中。否则，你将收到一条错误消息。\n\n\n在你点击 Enter 之后， R 将开始安装该包并打印一些关于安装进度的信息。当 install.packages 函数完成时，该包就可以使用了。已安装的包被添加到 R 的 系统库 中。这个系统库可以在你的 R Studio 屏幕左下角的 包 窗格中访问。每当我们想使用已安装的包时，我们可以使用 library 函数从我们的库中加载它。让我们尝试一下，并加载 {tidyverse} 包。\n\nlibrary(tidyverse)",
    "crumbs": [
      "网站首页",
      "发现R"
    ]
  },
  {
    "objectID": "04-discovering_R.html#dmetar",
    "href": "04-discovering_R.html#dmetar",
    "title": "R语言探索",
    "section": "",
    "text": "在本指南中，我们希望使研究人员能够尽可能轻松地进行 meta 分析。尽管有一些很棒的包，比如 {meta} 和 {metafor} 包，它们完成了大部分繁重的工作，但我们仍然认为 meta 分析的某些方面很重要，但在目前 R 中不容易做到，特别是如果你没有编程或统计背景。\n为了填补这个空白，我们开发了 {dmetar} 包，它是本书的配套 R 包。 {dmetar} 包有自己的文档，可以在 网上 找到。 {dmetar} 包的函数为 {meta} 和 {metafor} 包（以及其他一些更高级的包）提供了额外的功能，我们将在本指南中经常使用它们。包含在 {dmetar} 包中的大多数函数以及它们如何改善你的 meta 分析工作流程将在本书中详细描述。我们在本指南中使用的大多数示例数据集也包含在 {dmetar} 中。\n\n\n\n虽然强烈建议，但不是必须安装 {dmetar} 包才能完成本指南。对于该包的每个函数，我们也会提供源代码，可以用来在你的计算机上本地保存该函数，以及这些函数所依赖的其他 R 包。我们还将为包含在该包中的数据集提供补充下载链接。\n但是，事先安装 {dmetar} 包要方便得多，因为这会预先安装所有函数和数据集在你的计算机上。\n\n\n\n要安装 {dmetar} 包，你计算机上的 R 版本必须为 3.6 或更高版本。如果你最近（重新）安装了 R，情况可能就是这样。要检查你的 R 版本是否足够新，你可以将此行代码粘贴到控制台中，然后按 Enter。\n\nR.Version()$version.string\n\n这将显示你当前的 R 版本。如果 R 版本低于 3.6，你将必须更新它。互联网上有一些很好的 博客文章 提供了有关如何执行此操作的指导。\n如果你想安装 {dmetar}，首先需要安装一个包在你的计算机上。这个包叫做 {devtools}。所以，如果 {devtools} 还没有在你的计算机上，你可以像我们之前做的那样安装它。\n\ninstall.packages(\"devtools\")\n\n然后你可以使用这行代码安装 {dmetar}：\n\ndevtools::install_github(\"MathiasHarrer/dmetar\")\n\n这将启动安装过程。很可能安装需要一些时间，因为必须与 {dmetar} 包一起安装其他几个包才能使其正常工作。在安装过程中，安装管理器可能会询问你是否要更新计算机上现有的 R 包。输出可能看起来像这样：\n## 这些包有更新的版本可用。\n## 你想更新哪个？\n## \n## 1：全部\n## 2：仅 CRAN 包\n## 3：无\n## 4：ggpubr (0.2.2 -&gt; 0.2.3) [CRAN]\n## 5：zip (2.0.3 -&gt; 2.0.4) [CRAN]\n## \n## 输入一个或多个数字，或输入一个空行以跳过更新：\n当你收到此消息时，最好告诉安装管理器不要更新任何包。在我们的示例中，这意味着将 3 粘贴到控制台中，然后按 Enter。同样地，当安装管理器提出这个问题时：\n## 有二进制版本可用，但源版本较新：\n## \n## [...]\n## \n## 你想从需要编译的源安装包吗？\n## y/n：\n最好选择 n（否）。如果使用此策略安装失败（意味着你收到一个 Error），请再次运行安装，但这次更新所有包。\n在编写本书和开发该包时，我们确保每个人都可以毫无错误地安装它。尽管如此，仍然有可能第一次尝试安装该包时不起作用。如果安装问题仍然存在，你可以查看本书序言中的 “联系我们” 部分。",
    "crumbs": [
      "网站首页",
      "发现R"
    ]
  },
  {
    "objectID": "04-discovering_R.html#data-prep-R",
    "href": "04-discovering_R.html#data-prep-R",
    "title": "R语言探索",
    "section": "",
    "text": "本章将告诉你如何使用 R Studio 将数据导入 R 。数据准备有时可能很繁琐和耗尽精力，但它是所有后续步骤的支柱。因此，我们必须密切注意将数据导入正确的格式，然后才能继续。\n通常，导入到 R 中的数据首先存储在 Microsoft Excel 电子表格中。我们建议在那里存储你的数据，因为这使得导入变得非常容易。在 Excel 中准备数据时，有一些 “应该做和不应该做” 的事项。\n\n命名电子表格的列非常重要。如果你已经在 Excel 中充分命名了工作表的列，那么你可以在以后节省大量时间，因为你的数据不必使用 R 进行转换。“命名” 电子表格的列仅仅意味着将变量的名称写入列的第一行； R 将自动检测到这是列的名称。\n列名不应包含任何空格。要在列名中分隔两个单词，可以使用下划线或点（例如 “column_name”）。\nExcel 电子表格中列的顺序无关紧要。它们只需要正确标记。\n也没有必要以任何方式格式化列。如果你在电子表格的第一行中键入列名， R 将自动将其检测为列名。\n同样重要的是要知道导入可能会扭曲特殊字符，如 ä、ü、ö、á、é、ê 等。你可能想在继续之前将它们转换为 “正常” 字母。\n确保你的 Excel 文件只包含一个工作表。\n如果你有一个或几个曾经包含数据的空行或列，请确保完全删除这些列/行，因为 R 可能会认为这些列包含（缺失的）数据并也导入它们。\n\n让我们从一个示例数据集开始。假设你计划进行一项自杀预防计划的 meta 分析。你想要在你的研究中关注的结果是自杀意念的严重程度（即个体思考、考虑或计划结束其生命的程度），通过问卷评估。你已经完成了研究搜索和数据提取，现在想在 R 中导入你的 meta 分析数据。\n因此，下一个任务是准备一个 Excel 工作表，其中包含所有相关数据。表 @ref(tab:suicidedata) 显示了我们想要导入的所有数据。在第一行中，此表还显示了我们如何根据我们列出的规则在 Excel 文件中命名我们的列。我们可以看到电子表格在一行中列出了每个研究。对于每个研究，干预组和对照组都包括样本量 (\\(n\\))、均值和标准差 (\\(SD\\))。这是计算效应量所需的结果数据，我们将在第 @ref(effects) 章中详细介绍。以下三列包含我们稍后要作为 meta 分析一部分进行分析的变量。\n我们为你准备了一个名为 “SuicidePrevention.xlsx” 的 Excel 文件，其中包含完全相同的数据。该文件可以从 Internet 下载。\n\n\n\n\n\nThe suicide prevention dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'author'\n\n\n'n.e'\n\n\n'mean.e'\n\n\n'sd.e'\n\n\n'n.c'\n\n\n'mean.c'\n\n\n'sd.c'\n\n\n'pubyear'\n\n\n'age_group'\n\n\n'control'\n\n\n\n\n\nIntervention Group\n\n\nControl Group\n\n\nSubgroups\n\n\n\nAuthor\nN\nMean\nSD\nN\nMean\nSD\nYear\nAge Group\nControl Group\n\n\n\n\nBerry et al.\n90\n14.98\n3.29\n95\n15.54\n4.41\n2006\ngeneral\nWLC\n\n\nDeVries et al.\n77\n16.21\n5.35\n69\n20.13\n7.43\n2019\nolder adult\nno intervention\n\n\nFleming et al.\n30\n3.01\n0.87\n30\n3.13\n1.23\n2006\ngeneral\nno intervention\n\n\nHunt & Burke\n64\n19.32\n6.41\n65\n20.22\n7.62\n2011\ngeneral\nWLC\n\n\nMcCarthy et al.\n50\n4.54\n2.75\n50\n5.61\n2.66\n1997\ngeneral\nWLC\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n\n\n\n\n\n\n\n为了在 R Studio 中导入我们的 Excel 文件，我们首先必须设置一个 工作目录。工作目录是你计算机上的一个文件夹， R 可以从中使用数据，并且在其中保存输出。要设置工作目录，你首先必须在你的计算机上创建一个文件夹，你希望将所有 meta 分析数据和结果保存在其中。你还应该将我们要导入的 “SuicidePrevention.xlsx” 文件保存在此文件夹中。\n然后启动 R Studio 并在左下角的 文件 窗格中打开你新创建的文件夹。一旦你打开了你的文件夹，你应该显示你刚刚保存在那里的 Excel 文件。然后通过点击窗格顶部的小齿轮，然后在弹出菜单中点击 设置为工作目录 来将此文件夹设置为工作目录。这将使当前打开的文件夹成为工作目录。\n\n\n\n\n\n设置工作目录；数据集加载到 R 环境中。\n\n\n\n\n我们现在可以继续并将数据导入 R 。在 文件 窗格中，只需点击 “SuicidePrevention.xlsx” 文件。然后点击 导入数据集…。现在应该弹出一个导入助手，它也在加载你的数据的预览。这有时可能很耗时，所以你可以跳过这一步，直接点击 导入。\n\n你的数据集应该以名称 SuicidePrevention 列在右上角的 环境 窗格中。这意味着你的数据现在已加载并且可以被 R 代码使用。像我们在这里导入的表格数据集在 R 中被称为 数据框 (data.frame)。数据框是具有列和行的数据集，就像我们刚刚导入的 Excel 电子表格一样。\n\n\n\n\n{openxlsx}\n也可以使用代码直接导入数据文件。我们可以用来做到这一点的一个好的包叫做 {openxslx} [@openxlsx]。与所有 R 包一样，你必须首先安装它。然后你可以使用 read.xlsx 函数导入 Excel 工作表。\n如果该文件保存在你的工作目录中，你只需为该函数提供该文件的名称，并将导入的数据分配给 R 中的一个对象。例如，如果我们希望我们的数据集在 R 中具有名称 data，我们可以使用此代码：\nlibrary(openxlsx)  data &lt;- read.xlsx(\"SuicidePrevention.xlsx\")",
    "crumbs": [
      "网站首页",
      "发现R"
    ]
  },
  {
    "objectID": "04-discovering_R.html#data-manip-R",
    "href": "04-discovering_R.html#data-manip-R",
    "title": "R语言探索",
    "section": "",
    "text": "现在我们已经使用 R Studio 导入了我们的第一个数据集，让我们做一些操作。数据整理，意味着转换数据以使其可用于进一步分析，是所有数据分析的重要组成部分。一些职业，例如数据科学家，花费他们的大部分时间将原始的 “不整洁” 的数据变成 “整洁” 的数据集。 {tidyverse} 的函数为数据整理提供了一个出色的工具箱。如果你还没有从你的库中加载该包，你应该立即加载它以用于以下示例。\n\nlibrary(tidyverse)\n\n\n\n\n\n首先，我们应该看一下我们在上一章中导入的 SuicidePrevention 数据集。为此，我们可以使用 {tidyverse} 提供的 glimpse 函数。\n\nglimpse(SuicidePrevention)\n\nRows: 9\nColumns: 10\n$ author    &lt;chr&gt; \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt & …\n$ n.e       &lt;chr&gt; \"90\", \"77\", \"30\", \"64\", \"50\", \"109\", \"60\", \"40\", \"51\"\n$ mean.e    &lt;chr&gt; \"14.98\", \"16.21\", \"3.01\", \"19.32\", \"4.54\", \"15.11\", \"3.44\", …\n$ sd.e      &lt;chr&gt; \"3.29\", \"5.35\", \"0.87\", \"6.41\", \"2.75\", \"4.63\", \"1.26\", \"0.7…\n$ n.c       &lt;dbl&gt; 95, 69, 30, 65, 50, 111, 60, 40, 56\n$ mean.c    &lt;chr&gt; \"15.54\", \"20.13\", \"3.13\", \"20.22\", \"5.61\", \"16.46\", \"3.42\", …\n$ sd.c      &lt;chr&gt; \"4.41\", \"7.43\", \"1.23\", \"7.62\", \"2.66\", \"5.39\", \"1.88\", \"1.4…\n$ pubyear   &lt;dbl&gt; 2006, 2019, 2006, 2011, 1997, 2000, 2013, 2015, 2014\n$ age_group &lt;chr&gt; \"general\", \"older adult\", \"general\", \"general\", \"general\", \"…\n$ control   &lt;chr&gt; \"WLC\", \"no intervention\", \"no intervention\", \"WLC\", \"WLC\", \"…\n\n\n我们看到这为我们提供了关于我们存储在数据集的每一列中的数据类型的详细信息。有不同的缩写表示不同的数据类型。在 R 中，它们被称为 类。\n\n&lt;num&gt; 代表 numeric。这是所有存储为数字的数据（例如 1.02）。\n&lt;chr&gt; 代表 character。这是所有存储为单词的数据。\n&lt;log&gt; 代表 logical。这些是二进制变量，意味着它们表明一个条件是 TRUE 还是 FALSE。\n&lt;factor&gt; 代表 factor。因子存储为数字，每个数字表示变量的不同级别。变量可能的因子级别可能是 1 = “low”，2 = “medium”，3 = “high”。\n\n我们还可以使用 class 函数检查列的类。我们可以通过将 $ 运算符添加到其名称，然后再添加列的名称来直接访问数据框中的列。让我们尝试一下。首先，我们让 R 为我们提供 n.e 列中包含的数据。之后，我们检查该列的类。\n\nSuicidePrevention$n.e\n\n[1] \"90\"  \"77\"  \"30\"  \"64\"  \"50\"  \"109\" \"60\"  \"40\"  \"51\" \n\nclass(SuicidePrevention$n.e)\n\n[1] \"character\"\n\n\n我们看到包含干预组样本量的 n.e 列的类是 character。但是等等，这是错误的类！在导入过程中，此列被错误地分类为 character 变量，而它实际上应该具有 numeric 类。这对进一步的分析步骤有影响。例如，如果我们想计算平均样本量，我们会得到以下警告：\n\nmean(SuicidePrevention$n.e)\n\nWarning in mean.default(SuicidePrevention$n.e): argument is not numeric or\nlogical: returning NA\n\n\n[1] NA\n\n\n为了使我们的数据集可用，我们通常必须首先将我们的列转换为正确的类。为此，我们可以使用一组以 “as.” 开头的函数：as.numeric、as.character、as.logical 和 as.factor。让我们来看几个例子。\n在之前 glimpse 函数的输出中，我们看到有几个列被赋予了 character 类，而它们应该是 numeric。这涉及到列 n.e、mean.e、sd.e、mean.c 和 sd.c。我们看到出版年份 pubyear 具有 &lt;dbl&gt; 类。这代表 double，意味着该列是一个数值向量。这是一个历史异常现象，在 R 中 double 和 numeric 都用于指代数值数据类型。然而，通常这没有实际的实际意义。\n然而，在我们的数据集中，一些数值被编码为 字符，这将导致下游问题，因此我们应该使用 as.numeric 函数更改该类。我们为该函数提供我们要更改的列，然后使用 赋值运算符 (&lt;-) 将输出保存回其原始位置。这导致了以下代码。\n\nSuicidePrevention$n.e &lt;- as.numeric(SuicidePrevention$n.e)\nSuicidePrevention$mean.e &lt;- as.numeric(SuicidePrevention$mean.e)\nSuicidePrevention$sd.e &lt;- as.numeric(SuicidePrevention$sd.e)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\nSuicidePrevention$mean.c &lt;- as.numeric(SuicidePrevention$mean.c)\nSuicidePrevention$sd.c &lt;- as.numeric(SuicidePrevention$sd.c)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\n\n我们还在 glimpse 输出中看到 age_group 和 control，我们数据中的子组，被编码为字符。然而，实际上，将它们编码为因子更合适，每个因子级别有两个。我们可以使用 as.factor 函数更改类。\n\nSuicidePrevention$age_group &lt;- as.factor(SuicidePrevention$age_group)\nSuicidePrevention$control &lt;- as.factor(SuicidePrevention$control)\n\n使用 levels 和 nlevels 函数，我们还可以查看因子标签和因子中的级别数。\n\nlevels(SuicidePrevention$age_group)\n\n[1] \"general\"     \"older adult\"\n\nnlevels(SuicidePrevention$age_group)\n\n[1] 2\n\n\n我们还可以使用 levels 函数更改因子标签的名称。我们只需为原始标签分配新名称。要在 R 中执行此操作，我们必须使用 concatenate，或 c 函数。此函数可以将两个或多个单词或数字连接在一起并创建一个元素。让我们尝试一下。\n\nnew.factor.levels &lt;- c(\"gen\", \"older\")\nnew.factor.levels\n\n[1] \"gen\"   \"older\"\n\n\n完美。我们现在可以使用新创建的 new.factor.levels 对象，并将其分配给 age_group 列的因子标签。\n\nlevels(SuicidePrevention$age_group) &lt;- new.factor.levels\n\n让我们检查一下重命名是否有效。\n\nSuicidePrevention$age_group\n\n[1] gen   older gen   gen   gen   gen   gen   older older\nLevels: gen older\n\n\n也可以使用 as.logical 创建逻辑值。假设我们想要重新编码 pubyear 列，以便它仅显示研究是否在 2009 年之后发表。为此，我们必须通过代码定义一个是/否规则。我们可以使用 “大于或等于” 运算符 &gt;= 来做到这一点，然后将其用作 as.logical 函数的输入。\n\nSuicidePrevention$pubyear\n\n[1] 2006 2019 2006 2011 1997 2000 2013 2015 2014\n\nas.logical(SuicidePrevention$pubyear &gt;= 2010)\n\n[1] FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n\n\n我们可以看到，这会将 pubyear 中的每个元素编码为 TRUE 或 FALSE，具体取决于发表年份是否大于或等于 2010。\n\n\n\n\n\n在 R 中，有几种方法可以提取数据框的子集。我们已经介绍了一种方法，即 $ 运算符，它可以用于提取列。从数据集中提取切片的更通用方法是使用方括号。我们使用方括号时必须遵循的通用形式是 data.frame[rows, columns]。始终可以通过使用它们在数据集中出现的数字来提取行和列。例如，我们可以使用以下代码提取数据框第二行中的数据。\n\nSuicidePrevention[2,]\n\n          author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n2 DeVries et al.  77  16.21 5.35  69  20.13 7.43    2019     older\n          control\n2 no intervention\n\n\n我们可以更具体地告诉 R ，我们只想要第二行第一列中的信息。\n\nSuicidePrevention[2, 1]\n\n[1] \"DeVries et al.\"\n\n\n要选择特定的切片，我们必须再次使用连接 (c) 函数。例如，如果我们想提取第 2 行和第 3 行以及第 4 列和第 6 列，我们可以使用此代码。\n\nSuicidePrevention[c(2,3), c(4,6)]\n\n  sd.e mean.c\n2 5.35  20.13\n3 0.87   3.13\n\n\n通常只能按行号选择行。但是，对于列，也可以提供列名称而不是数字。\n\nSuicidePrevention[, c(\"author\", \"control\")]\n\n           author         control\n1    Berry et al.             WLC\n2  DeVries et al. no intervention\n3  Fleming et al. no intervention\n4    Hunt & Burke             WLC\n5 McCarthy et al.             WLC\n6   Meijer et al. no intervention\n7   Rivera et al. no intervention\n8  Watkins et al. no intervention\n9  Zaytsev et al. no intervention\n\n\n另一种可能性是根据行值 过滤 数据集。我们可以使用 filter 函数来做到这一点。在该函数中，我们需要指定我们的数据集名称，以及一个过滤逻辑。一个相对简单的例子是过滤所有 n.e 等于或小于 50 的研究。\n\nfilter(SuicidePrevention, n.e &lt;= 50)\n\n           author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n1  Fleming et al.  30   3.01 0.87  30   3.13 1.23    2006       gen\n2 McCarthy et al.  50   4.54 2.75  50   5.61 2.66    1997       gen\n3  Watkins et al.  40   7.10 0.76  40   7.38 1.41    2015     older\n          control\n1 no intervention\n2             WLC\n3 no intervention\n\n\n但也可以按名称进行过滤。假设我们想提取作者为 Meijer 和 Zaytsev 的研究。为此，我们必须使用 %in% 运算符和连接函数来定义我们的过滤逻辑。\n\nfilter(SuicidePrevention, author %in% c(\"Meijer et al.\",\n                                        \"Zaytsev et al.\"))\n\n          author n.e mean.e sd.e n.c mean.c  sd.c pubyear age_group\n1  Meijer et al. 109  15.11 4.63 111  16.46  5.39    2000       gen\n2 Zaytsev et al.  51  23.74 7.24  56  24.91 10.65    2014     older\n          control\n1 no intervention\n2 no intervention\n\n\n相反，我们也可以通过在过滤逻辑前放置一个感叹号来提取所有除了 Meijer 和 Zaytsev 的研究。\n\nfilter(SuicidePrevention, !author %in% c(\"Meijer et al.\", \n                                         \"Zaytsev et al.\"))\n\n\n\n\n\n\n当然，也可以更改 R 数据框中的特定值，或者扩展它们。要更改我们保存在 R 内部的数据，我们必须使用 赋值运算符。让我们重新使用我们之前学到的关于数据切片的知识来更改我们数据集中的特定值。假设我们犯了一个错误，并且 DeVries et al. 研究的发表年份错误地报告为 2019 年，而它应该是 2018 年。我们可以通过相应地切片我们的数据集，然后分配新值来更改该值。记住，DeVries et al. 的结果在数据集的第二行中报告。\n\nSuicidePrevention[2, \"pubyear\"] &lt;- 2018\nSuicidePrevention[2, \"pubyear\"]\n\n## [1] 2018\n也可以一次更改多个值。例如，如果我们想在我们的数据集中为每个干预组均值加 5，我们可以使用以下代码来做到这一点。\n\nSuicidePrevention$mean.e + 5\n\n[1] 19.98 21.21  8.01 24.32  9.54 20.11  8.44 12.10 28.74\n\n\n我们还可以使用两列或多列来进行计算。一个实际相关的例子是我们可能对计算每个研究的干预组和对照组均值之间的 均值差异 感兴趣。与其他编程语言相比，这在 R 中非常容易。\n\nSuicidePrevention$mean.e - SuicidePrevention$mean.c\n\n[1] -0.56 -3.92 -0.12 -0.90 -1.07 -1.35  0.02 -0.28 -1.17\n\n\n正如你所看到的，这获取了每个研究的干预组均值，然后减去对照组均值，每次都使用同一行的值。假设我们想在以后使用这个均值差异。因此，我们想将它保存为一个名为 md 的额外对象，并将它作为一个新列添加到我们的 SuicidePrevention 数据框中。使用赋值运算符很容易做到这两点。\n\nmd &lt;- SuicidePrevention$mean.e - SuicidePrevention$mean.c\n\nSuicidePrevention$md &lt;- SuicidePrevention$mean.e - \n                            SuicidePrevention$mean.c\n\n\n我们想向你展示的最后一件事是 管道运算符。在 R 中，管道写成 %&gt;%。管道本质上允许我们将一个函数应用于一个对象，而无需直接在函数调用中指定对象名称。我们只需使用管道运算符连接对象和函数。让我们给你一个简单的例子。如果我们想计算对照组中的平均样本量，我们可以像这样使用 mean 函数和管道运算符：\n\nSuicidePrevention$n.c %&gt;% mean()\n\n[1] 64\n\n\n诚然，在这个例子中，很难看到这种管道的附加价值。管道的特殊优势在于它们允许我们将许多函数 链接 在一起。假设我们想知道平均对照组样本量的平方根，但仅适用于 2009 年之后发表的研究。管道让我们可以在一步中方便地做到这一点。\n\nSuicidePrevention %&gt;% \n  filter(pubyear &gt; 2009) %&gt;% \n  pull(n.c) %&gt;% \n  mean() %&gt;% \n  sqrt()\n\n[1] 7.615773\n\n\n在管道中，我们使用了一个我们之前没有介绍的函数，即 pull 函数。这个函数可以被看作是 $ 运算符的等价物，我们可以在管道中使用它。它只是 “拉出” 我们在函数中指定的变量，因此它可以被转发到管道的下一部分。\n\n\n\n访问 R 文档\n\n\nR 中的许多函数都需要几个参数，并且不可能记住如何正确使用所有函数。谢天谢地，没有必要用心记住如何使用每个函数。R Studio 让我们很容易访问 R 文档，其中每个函数都有一个详细的描述页面。\n\n\n有两种方法可以搜索函数文档页面。第一种是访问 R Studio 左下角的 帮助 窗格，然后使用搜索栏查找关于特定函数的信息。更方便的方法是简单地运行 ?，后跟控制台中函数的名称，例如 ?mean。这将自动打开该函数的文档条目。\n\n\n一个函数的 R 文档通常至少包含一个 用法、参数 和 示例 部分。参数 和 示例 部分通常对于理解如何使用一个函数特别有帮助。\n\n\n\n\n\n\n\n\n一旦我们用我们的数据完成了转换并将它们保存在 R 内部，我们必须在某个时候 导出 它。我们建议你在保存 R 数据框时使用两种类型的文件格式：.rda 和 .csv。\n文件结尾 .rda 代表 R 数据。这是一种专门为 R 设计的文件类型，具有所有的优点和缺点。.rda 文件的优点是它们可以很容易地在 R 中重新打开，并且没有你的数据在导出过程中可能会被扭曲的风险。它们",
    "crumbs": [
      "网站首页",
      "发现R"
    ]
  },
  {
    "objectID": "06-pooling_effect_sizes.html",
    "href": "06-pooling_effect_sizes.html",
    "title": "效应量的合并",
    "section": "",
    "text": "一条漫长而曲折的道路已经展现在我们身后。幸运的是，我们现在已经到达了每个荟萃分析的核心部分：效应量的合并。我们希望您能够抵制住直接从本章开始的诱惑。本书已经讨论了各种主题，包括研究问题的定义、搜索、选择和提取研究数据的指南，以及如何准备我们的效应量。\n彻底的准备是良好荟萃分析的关键要素，并且对接下来要执行的步骤非常有帮助。我们可以向您保证，您花在学习前几章上的时间是物有所值的。\n\n有很多包可以让我们在 R 中合并效应量。在这里，我们将重点介绍 {meta} 包的功能，该包我们在 @ref(packages) 章中已经安装过了。这个包非常用户友好，只需几行代码就可以为我们提供几乎所有重要的荟萃分析结果。在前一章中，我们介绍了效应量有不同的“风味”，具体取决于感兴趣的结果。{meta} 包包含专门的荟萃分析函数，用于处理每种效应量指标。所有函数也几乎遵循相同的结构。\n因此，一旦我们对 {meta} 的工作方式有了基本的了解，编写荟萃分析代码就会变得简单明了，无论我们关注哪种效应量。在本章中，我们将介绍 {meta} 包的总体结构。当然，我们还将通过实践示例更详细地探索该包的荟萃分析函数。\n{meta} 包允许我们调整效应量合并方式的许多细节。正如我们之前提到的，荟萃分析伴随着许多“研究者自由度”。关于我们可以应用的统计技术和方法有很多选择，而且一种方法是否比另一种方法更好通常取决于具体情况。\n \n在我们开始在 R 中进行分析之前，我们首先要对荟萃分析的统计假设和背后的数学原理有一个基本的了解。重要的是，我们还将讨论荟萃分析背后的“思想”。在统计学中，这个“思想”转化为一个模型，我们将了解荟萃分析模型是什么样的。\n正如我们将看到的，荟萃分析的性质要求我们立即做出一个根本性的决定：我们必须假设一个固定效应模型或一个随机效应模型。需要了解荟萃分析合并背后的概念，以便在知情的情况下决定哪种模型，以及其他分析规范，在何种情况下更合适。\n\n\n\n\n在我们指定荟萃分析模型之前，我们首先应该明确统计模型实际上是什么。统计学充满了“模型”，而且您很可能以前在这个语境中听说过这个术语。有“线性模型”、“广义线性模型”、“混合模型”、“高斯加性模型”、“结构方程模型”等等。\n模型在统计学中的普遍存在表明了这个概念的重要性。在某种程度上，模型构成了我们几乎所有统计工具箱的基础。在 \\(t\\) 检验、方差分析和回归分析的背后都有一个模型。每个假设检验都有其相应的统计模型。\n在定义统计模型时，我们从已经给我们的信息开始。这实际上就是我们的数据1。在荟萃分析中，数据是在纳入研究中观察到的效应量。我们的模型用于描述生成这些观察数据的过程。\n这些数据被视为一个黑盒子的产物，而我们的模型旨在阐明黑盒子内部发生的事情。\n\n\n\n\n\n\n\n\n\n通常，统计模型就像一种特殊的理论。模型试图解释生成我们观察数据的机制，尤其是当这些机制本身无法直接观察到时。它们是对生活的模仿，使用数学公式以理想化的方式描述我们周围世界中的过程。\n模型的这种解释性特征深深地根植于现代统计学中，荟萃分析也不例外。将模型概念化为解释工具是统计学“文化”的标志，正如 Breiman [-@breiman2001statistical] 著名地估计，98% 的统计学家都坚持这种文化。\n通过指定一个统计模型，我们试图找到一个近似表示我们数据背后“现实”的模型。我们想要一个数学公式来解释如何根据研究的观察结果找到所有研究背后的真实效应量。正如我们在 @ref(what-are-mas) 章中学到的，荟萃分析的最终目标之一是找到一个数值来表征我们的研究作为一个整体，即使观察到的效应量因研究而异。因此，荟萃分析模型必须解释为什么以及观察到的研究结果差异有多大的原因，即使只有一个总体效应。\n有两种模型试图准确地回答这个问题，即固定效应模型和随机效应模型。尽管两者都基于不同的假设，但它们之间仍然存在很强的联系，我们很快就会看到。\n\n\n\n\n \n固定效应模型假设所有效应量都来自一个单一的、同质的总体。它指出所有研究都共享相同的真实效应量。这个真实效应是我们想要在荟萃分析中计算的总体效应量，用 \\(\\theta\\) 表示。\n根据固定效应模型，研究 \\(k\\) 的观察效应量 \\(\\hat\\theta_k\\) 偏离 \\(\\theta\\) 的唯一原因是由于其抽样误差 \\(\\epsilon_k\\)。固定效应模型告诉我们，产生研究不同效应量的过程，即“黑盒子”的内容，很简单：所有研究都是相同真实效应量的估计量。然而，由于每项研究只能从无限大的研究人群中抽取或大或小的样本，因此结果会受到抽样误差的影响。这种抽样误差导致观察到的效应偏离总体真实效应。\n我们可以这样描述这种关系 [@borenstein2011introduction, 第 11 章]：\n\\[\\begin{equation}\n\\hat\\theta_k = \\theta + \\epsilon_k\n(\\#eq:pes1)\n\\end{equation}\\]\n对于警觉的读者来说，这个公式可能与 @ref(what-is-es) 章中的公式非常相似。您没有错。在之前的公式中，我们定义了某个研究 \\(k\\) 的观察效应量 \\(\\hat\\theta_k\\) 是该研究真实效应量 \\(\\theta_k\\) 的估计量，受到该研究抽样误差 \\(\\epsilon_k\\) 的影响。\n之前的公式与固定效应模型的公式之间只有一个很小但很有见地的差异。在固定效应模型的公式中，真实效应量不是用 \\(\\theta_k\\) 符号表示，而是用 \\(\\theta\\) 表示；下标 \\(k\\) 被省略了。\n以前，我们只是对一项个体研究 \\(k\\) 的真实效应量进行陈述。固定效应模型更进一步。它告诉我们，如果我们找到研究 \\(k\\) 的真实效应量，这个效应量不仅对 \\(k\\) 而言是真的，而且对我们荟萃分析中的所有研究而言也是真的。一个研究的真实效应量 \\(\\theta_k\\)，和总体合并的效应量 \\(\\theta\\)，是相同的。\n\n\n\n固定效应模型背后的思想是，观察到的效应量可能因研究而异，但这只是由于抽样误差造成的。实际上，它们的真实效应量都相同：它们是固定的。因此，固定效应模型有时也被称为“等效应”或“共同效应”模型。2\n\n\n固定效应模型的公式告诉我们，观察到的效应量 \\(\\theta_k\\) 偏离真实总体效应的唯一原因是：由于抽样误差 \\(\\epsilon_k\\)。在 @ref(what-is-es) 章中，我们已经讨论了抽样误差与研究样本量之间存在联系。在所有条件相同的情况下，随着样本量的增大，抽样误差减小。我们还了解到，抽样误差可以用标准误差来数值表示，标准误差也会随着样本量的增加而减小。\n虽然我们不知道研究的真实总体效应量，但我们可以利用这种关系来得出真实总体效应的最佳估计值，\\(\\hat\\theta\\)。我们知道标准误差越小，对应的抽样误差也越小；因此，与标准误差大的研究相比，标准误差小的研究应该能更好地估计真实总体效应。\n我们可以用一个模拟来说明这一点。使用我们之前使用过的 rnorm 函数，我们模拟了一系列研究，其中真实总体效应为 \\(\\theta = 0\\)。我们选取了几个样本，但改变了样本量，使得“观察到”的效应之间的标准误差不同。模拟的结果可以在图 @ref(fig:funnel1) 中找到。\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n效应量与标准误差之间的关系。\n\n\n\n\n模拟结果显示出一种有趣的模式。我们看到具有较小抽样误差的效应量紧密地聚集在真实效应量 \\(\\theta = 0\\) 附近。随着 y 轴上的标准误差3 的增加，效应量的离散程度变得越来越大，并且观察到的效应越来越偏离真实效应。\n这种行为可以通过固定效应模型的公式来预测。我们知道具有较小标准误差的研究具有较小的抽样误差，因此它们对总体效应量的估计更可能接近真实值。\n\n我们已经看到，虽然所有观察到的效应量都是真实效应的估计量，但有些比其他的好。当我们合并荟萃分析中的效应时，我们应该给予具有更高精度（即更小的标准误差）的效应量更大的权重。如果我们想要计算固定效应模型下的合并效应量，我们只需使用所有研究的加权平均值。\n要计算每个研究 \\(k\\) 的权重 \\(w_k\\)，我们可以使用标准误差，对其进行平方以获得每个效应量的方差 \\(s^2_k\\)。由于较低的方差表示较高的精度，因此使用方差的倒数来确定每个研究的权重。\n\\[\\begin{equation}\nw_k = \\frac{1}{s^2_k}\n(\\#eq:pes2)\n\\end{equation}\\]\n一旦我们知道权重，我们就可以计算加权平均值，即我们对真实合并效应 \\(\\hat\\theta\\) 的估计。我们只需要将每个研究的效应量 \\(\\hat\\theta_k\\) 与其对应的权重 \\(w_k\\) 相乘，将荟萃分析中所有研究 \\(K\\) 的结果相加，然后除以所有个体权重的总和。\n\\[\\begin{equation}\n\\hat\\theta = \\frac{\\sum^{K}_{k=1} \\hat\\theta_kw_k}{\\sum^{K}_{k=1} w_k}\n(\\#eq:pes3)\n\\end{equation}\\]\n \n这种方法是荟萃分析中计算平均效应的最常见方法。由于我们使用方差的倒数，因此它通常被称为逆方差加权或简称为逆方差荟萃分析。\n对于二元效应量数据，有其他方法来计算加权平均值，包括 Mantel-Haenszel、Peto 或 Bakbergenuly [-@bakbergenuly2020methods] 的样本量加权法。我们将在 @ref(pooling-or-rr) 章中讨论这些方法。\n{meta} 包使得执行固定效应荟萃分析非常容易。但是，在此之前，让我们尝试在 R 中“手动”进行逆方差合并。在我们的例子中，我们将使用 SuicidePrevention 数据集，我们已经在 @ref(data-prep-R) 章中导入了该数据集。\n\n\n\n\n“SuicidePrevention”数据集\nSuicidePrevention 数据集也直接包含在 {dmetar} 包中。如果您已经安装了 {dmetar} 并且已从您的库中加载了它，则运行 data(SuicidePrevention) 会自动将数据集保存在您的 R 环境中。然后就可以使用该数据集了。如果您没有安装 {dmetar}，您可以从 Internet 下载数据集作为 .rda 文件，将其保存在您的工作目录中，然后在您的 R Studio 窗口中单击它以导入它。\n\n\n \nSuicidePrevention 数据集包含原始效应量数据，这意味着我们必须首先计算效应量。在本例中，我们计算了小样本调整的标准化均数差（Hedges’ \\(g\\)）。为此，我们使用了 {esc} 包中的 esc_mean_sd 函数（@ref(b-group-smd) 章）。\n该函数有一个额外的参数 es.type，通过该参数我们可以指定是否要执行小样本校正（通过设置 es.type = \"g\"；@ref(hedges-g) 章）。\n自 R 4.2.1 版本发布以来，我们还必须将对 esc_mean_sd 的调用插入到 pmap_dfr 函数中，以便为数据集中的每一行计算一个标准化均数差：\n\n# 加载 dmetar、esc 和 tidyverse (用于管道)\nlibrary(dmetar)\nlibrary(esc)\nlibrary(tidyverse)\n\n# 从 dmetar 加载数据集\ndata(SuicidePrevention)\n\n# 计算 Hedges' g 和标准误差\n# - 我们将研究名称保存在 \"study\" 中。\n# - 我们使用 pmap_dfr 函数来计算\n#   每一行的效应量。\nSP_calc &lt;- pmap_dfr(SuicidePrevention,\n                    function(mean.e, sd.e, n.e, mean.c,\n                             sd.c, n.c, author, ...){\n                      esc_mean_sd(grp1m = mean.e,\n                                  grp1sd = sd.e,\n                                  grp1n = n.e,\n                                  grp2m = mean.c,\n                                  grp2sd = sd.c,\n                                  grp2n = n.c,\n                                  study = author,\n                                  es.type = \"g\") %&gt;%\n                        as.data.frame()})\n\n# 让我们快速浏览一下数据\n# 数据集包含 Hedges' g (\"es\") 和标准误差 (\"se\")\nglimpse(SP_calc)\n\n## Rows: 9\n## Columns: 9\n## $ study       &lt;chr&gt; \"Berry et al.\", \"DeVries et …\n## $ es          &lt;dbl&gt; -0.14279447, -0.60770928, -0…\n## $ weight      &lt;dbl&gt; 46.09784, 34.77314, 14.97625…\n## $ sample.size &lt;dbl&gt; 185, 146, 60, 129, 100, 220,…\n## $ se          &lt;dbl&gt; 0.1472854, 0.1695813, 0.2584…\n## $ var         &lt;dbl&gt; 0.02169299, 0.02875783, 0.06…\n## $ ci.lo       &lt;dbl&gt; -0.4314686, -0.9400826, -0.6…\n## $ ci.hi       &lt;dbl&gt; 0.145879624, -0.275335960, 0…\n## $ measure     &lt;chr&gt; \"g\", \"g\", \"g\", \"g\", \"g\", \"g\"…\n接下来，我们使用这些结果来应用固定效应模型的公式：\n\n# 计算每个研究的逆方差权重\nSP_calc$w &lt;- 1/SP_calc$se^2\n\n# 然后，我们使用权重来计算合并效应\npooled_effect &lt;- sum(SP_calc$w*SP_calc$es)/sum(SP_calc$w)\npooled_effect\n\n## [1] -0.2311121\n我们的计算结果表明，假设一个固定效应模型，合并效应量为 \\(g \\approx\\) -0.23。\n\n\n\n\n\n\n正如我们所看到的，固定效应模型是一种概念化荟萃分析数据生成方式以及如何合并效应的方式。然而，重要的问题是：这种方法是否充分反映了现实？\n固定效应模型假设我们所有的研究都是同质群体的一部分，并且观察到的效应差异的唯一原因是研究的抽样误差。如果我们在没有抽样误差的情况下计算每项研究的效应量，那么所有真实效应量将完全相同。\n\n对这个概念进行快速的现实检验，我们发现固定效应模型的假设在许多实际应用中可能过于简单。荟萃分析中的研究总是完全同质的，这简直是不现实的。研究经常会存在差异，即使只是在细微的方式上。感兴趣的结果可能以不同的方式测量。也许治疗的类型不完全相同，或者治疗的强度和持续时间不同。研究的目标人群可能不完全相同，或者可能使用的对照组存在差异。\n您荟萃分析中的研究很可能不仅在一个方面存在差异，而且在几个方面同时存在差异。如果这是真的，我们可以预期真实效应中存在相当大的研究间异质性。\n所有这些都使固定效应模型的有效性受到质疑。例如，如果一些研究使用了不同类型的治疗，那么似乎很正常的是，一种形式比另一种更有效。假设这些差异只是噪音，由研究的抽样误差产生，这未免有些牵强。\n恰恰相反，可能存在无数的原因导致研究的真实效应量存在实际差异。随机效应模型解决了这个担忧。它为我们提供了一个模型，该模型通常能更好地反映我们数据背后的现实。\n\n在随机效应模型中，我们希望解释效应量显示的方差大于从一个单一同质群体中抽取的方差这一事实 [@hedges1998fixed]。因此，我们假设个体研究的效应不仅由于抽样误差而有所偏差，而且还存在另一个方差来源。\n这个额外的方差分量是由研究不是来自一个单一群体这一事实引入的。相反，每项研究都被视为从一个“宇宙”群体中独立抽取的结果。\n\n\n\n随机效应模型假设不仅存在一个真实的效应量，而且存在一个真实效应量的分布。因此，随机效应模型的目标不是估计所有研究的一个真实效应量，而是真实效应分布的均值。\n\n\n让我们看看如何用公式表达随机效应模型。与固定效应模型类似，随机效应模型首先假设观察到的效应量 \\(\\hat\\theta_k\\) 是研究真实效应量 \\(\\theta_k\\) 的估计量，受到抽样误差 \\(\\epsilon_k\\) 的影响：\n\\[\\begin{equation}\n\\hat\\theta_k = \\theta_k + \\epsilon_k\n(\\#eq:pes4)\n\\end{equation}\\]\n我们使用 \\(\\theta_k\\) 而不是 \\(\\theta\\) 这一事实已经表明了一个重要的差异。随机效应模型仅假设 \\(\\theta_k\\) 是一项单一研究 \\(k\\) 的真实效应量。它规定存在第二个误差来源，用 \\(\\zeta_k\\) 表示。这个第二个误差来源是由以下事实引入的：即使研究 \\(k\\) 的真实效应量 \\(\\theta_k\\) 也只是真实效应总体分布的一部分，该分布的均值为 \\(\\mu\\)。\n\\[\\begin{equation}\n\\theta_k  = \\mu + \\zeta_k\n(\\#eq:pes5)\n\\end{equation}\\]\n随机效应模型告诉我们，在我们的黑盒子里发生了两个过程的层次结构 [@thompson2001multilevel]：一项研究的观察效应量由于抽样误差而偏离了它们的真实值。但是，即使真实效应量也只是从真实效应总体中抽取的一个样本，我们希望将该总体的均值 \\(\\mu\\) 估计为我们荟萃分析的合并效应。\n通过将第二个公式插入到第一个公式中（即，用它在第二个公式中的定义替换 \\(\\theta_k\\)），我们可以用一行来表达随机效应模型 [@borenstein2011introduction, 第 12 章]：\n\\[\\begin{equation}\n\\hat\\theta_k = \\mu + \\zeta_k + \\epsilon_k\n(\\#eq:pes6)\n\\end{equation}\\]\n这个公式清楚地表明，我们观察到的效应量由于两个误差项 \\(\\zeta_k\\) 和 \\(\\epsilon_k\\) 而偏离了合并效应 \\(\\mu\\)。这种关系在图 @ref(fig:random) 中进行了可视化。\n\n随机效应模型的一个关键假设是 \\(\\zeta_k\\) 的大小与 \\(k\\) 无关。换句话说，我们假设没有任何东西可以先验地表明一项研究中的 \\(\\zeta_k\\) 高于另一项研究。我们预先假定 \\(\\zeta_k\\) 的大小是偶然的产物，而且仅仅是偶然的产物。\n这被称为随机效应模型的可交换性假设 [@higgins2009re; @lunn2012bugs, 第 10.1 章]。假设所有真实效应量都是可交换的，因为在我们看到数据之前，我们没有任何东西可以告诉我们一些研究 \\(k\\) 中 \\(\\zeta_k\\) 将有多大。\n\n\n\n\n我应该使用哪个模型？\n在实践中，发现一组研究是完全同质的非常罕见。即使我们遵循最佳实践，并通过我们的 PICO（@ref(research-question) 章）尽可能精确地确定分析的范围，也是如此。\n因此，在包括医学和社会科学在内的许多领域，通常总是使用随机效应模型，因为几乎总是可以预期到一定程度的研究间异质性。只有当我们没有检测到任何研究间异质性（我们将在 @ref(heterogeneity) 章中讨论如何做到这一点）并且当我们有非常好的理由假设真实效应是固定的时，才可以使用固定效应模型。例如，当只考虑一项研究的精确复制时，或者当我们对一项大型研究的子集进行荟萃分析时，可能会出现这种情况。毋庸置疑，这种情况很少发生，并且固定效应模型“在野外”的应用相当罕见。\n即使先验地使用随机效应模型是常规做法，但这种方法也并非没有争议。在计算荟萃分析的总体效应时，随机效应模型会更多地关注小型研究 [@schwarzer2015meta, 第 2.3 章]。然而，特别是小型研究通常充满偏见（参见 @ref(small-study-effects) 章）。这就是为什么有些人认为固定效应模型（有时）更可取 [@poole1999random; @furukawa2003low]。Stanley、Doucouliagos 和 Ioannidis [-@stanley2022beyond] 提出了类似的观点，并认为在某些学科中，应该使用所谓的“无限制加权最小二乘法”（UWLS）模型来代替随机效应模型。\n\n\n\n\n\n\n\n随机效应模型参数的图示。\n\n\n\n\n\n\n\n\n\n与随机效应模型相关的挑战是我们必须考虑误差 \\(\\zeta_k\\)。为此，我们必须估计真实效应量分布的方差。这个方差被称为 \\(\\tau^2\\)，或 tau 平方。一旦我们知道 \\(\\tau^2\\) 的值，我们就可以在确定每个效应量的逆方差权重时包括研究间异质性。\n因此，在随机效应模型中，我们为每个观察值计算一个调整后的随机效应权重 \\(w^*_k\\)。该公式如下所示：\n\\[\\begin{equation}\nw^*_k = \\frac{1}{s^2_k+\\tau^2}\n(\\#eq:pes7)\n\\end{equation}\\]\n\n使用调整后的随机效应权重，我们然后使用逆方差方法计算合并效应量，就像我们使用固定效应模型所做的那样：\n\\[\\begin{equation}\n\\hat\\theta = \\frac{\\sum^{K}_{k=1} \\hat\\theta_kw^*_k}{\\sum^{K}_{k=1} w^*_k}\n(\\#eq:pes8)\n\\end{equation}\\]\n有几种方法来估计 \\(\\tau^2\\)，其中大多数方法过于复杂而无法手动完成。幸运的是，这些估计量在 {meta} 包的函数中实现，该包会自动为我们进行计算。以下是最常见估计量的列表，以及它们在 {meta} 中引用的代码：\n \n\nDerSimonian-Laird (\"DL\") 估计量 [@dersimonian1986meta]。\n限制最大似然 (\"REML\") 或 最大似然 (\"ML\") 程序 [@viechtbauer2005bias]。\nPaule-Mandel (\"PM\") 程序 [@paule1982consensus]。\n经验贝叶斯 (\"EB\") 程序 [@sidik2019note]，实际上与 Paule-Mandel 方法相同。\nSidik-Jonkman (\"SJ\") 估计量 [@sidik2005simple]。\n\n哪种估计量最适合不同类型的数据是一个持续研究的问题。一种方法是否比另一种方法更好通常取决于参数，例如研究的数量 \\(k\\)、每个研究中的参与者数量 \\(n\\)、\\(n\\) 在研究之间的变化程度以及 \\(\\tau^2\\) 有多大。几项研究分析了在这些不同情况下 \\(\\tau^2\\) 估计量的偏差 [@veroniki2016methods; @viechtbauer2005bias; @sidik2007comparison; @langan2019comparison]。\n \n可以说，最常用的估计量是 DerSimonian 和 Laird 的估计量。该估计量已在过去荟萃分析人员常用的软件中实现，例如 RevMan（Cochrane 开发的程序）或 Comprehensive Meta-Analysis。它也曾经是 {meta} 中使用的默认估计量4。由于这种历史遗产，人们经常发现研究论文中使用“使用随机效应模型”等同于使用 DerSimonian-Laird 估计量。\n然而，人们发现这种估计量可能存在偏差，尤其是在研究数量较少且异质性较高时 [@hartung1999alternative; @hartung2001refined; @hartung2001tests; @follmann1999valid; @makambi2004effect]。这是非常成问题的，因为发现研究数量少且异质性高的荟萃分析非常常见。\n \n在一篇概述性论文中，Veroniki 及其同事 [-@veroniki2016methods] 回顾了各种 \\(\\tau^2\\) 估计量稳健性的证据。他们推荐了 Paule-Mandel 方法用于二元和连续效应量数据，并推荐了限制最大似然估计量用于连续结果。限制最大似然估计量也是 {metafor} 包使用的默认方法。\nLangan 及其同事 [-@langan2019comparison] 最近的一项模拟研究得出了类似的结果，但发现当研究的样本量差异很大时，Paule-Mandel 估计量可能不是最佳选择。Bakbergenuly 及其同事 [-@bakbergenuly2020methods] 的另一项研究发现，Paule-Mandel 估计量特别适用于研究数量较少的情况。Sidik-Jonkman 估计量，也称为模型误差方差法，仅在 \\(\\tau^2\\) 非常大时才适用 [@sidik2007comparison]。\n\n\n\n我应该使用哪个估计量？\n关于何时应该使用哪个估计量，没有铁律。在许多情况下，各种估计量产生的结果只会存在微小的差异，这意味着您不应该太担心这个问题。\n如有疑问，您可以随时使用不同的 \\(\\tau^2\\) 估计量重新运行您的分析，看看这是否会改变您对结果的解释。以下是一些您可以在自己的荟萃分析中遵循的初步指南：\n\n对于基于连续结果数据的效应量，限制最大似然估计量可以用作第一个起点。\n对于二元效应量数据，Paule-Mandel 估计量是一个很好的首选，前提是样本量没有极端变化。\n当您有非常好的理由相信样本中效应的异质性非常大，并且避免假阳性具有非常高的优先级时，您可以使用 Sidik-Jonkman 估计量。\n如果您希望其他人在 R 之外尽可能精确地复制您的结果，则 DerSimonian-Laird 估计量是首选方法。\n\n\n\n总的来说，\\(\\tau^2\\) 的估计量分为两类。一些，如 DerSimonian-Laird 和 Sidik-Jonkman 估计量，基于封闭形式表达式，这意味着它们可以使用公式直接计算。\n（限制）最大似然、Paule-Mandel 和经验贝叶斯估计量通过迭代算法找到 \\(\\tau^2\\) 的最佳值。因此，后者的估计量有时可能需要更长的时间来计算结果。然而，在大多数实际情况下，这些时间差异最多只是微不足道的。\n\n\n\n\n\n \n除了我们选择的 \\(\\tau^2\\) 估计量之外，我们还必须决定是否要应用所谓的 Knapp-Hartung 调整5 [@knapp2003improved; @sidik2002simple]。这些调整会影响我们合并效应量 \\(\\hat\\theta\\) 的标准误差（以及因此置信区间）的计算方式。\nKnapp-Hartung 调整试图控制我们对研究间异质性估计的不确定性。虽然合并效应的显著性检验通常假设正态分布（所谓的 Wald 型检验），但 Knapp-Hartung 方法基于 \\(t\\) 分布。Knapp-Hartung 调整只能在随机效应模型中使用，并且通常会导致合并效应的置信区间略微变大。\n\n\n\n\n报告在您的荟萃分析中使用的模型类型\n\n\n强烈建议您在荟萃分析报告的方法部分指定您使用的模型类型。以下是一个示例：\n\n\n\n“由于我们预计到相当大的研究间异质性，因此使用随机效应模型来合并效应量。使用限制最大似然估计量 (Viechtbauer, 2005) 来计算异质性方差 (^2)。我们使用 Knapp-Hartung 调整 (Knapp & Hartung, 2003) 来计算合并效应周围的置信区间。”\n\n\n\n\n应用 Knapp-Hartung 调整通常是明智的。几项研究 [@inthout2014hartung; @langan2019comparison] 表明，这些调整可以减少假阳性的可能性，尤其是在研究数量较少时。\n然而，使用 Knapp-Hartung 调整并非没有争议。例如，Wiksten 及其同事 [-@wiksten2016hartung] 认为，该方法在效应非常同质的情况下（很少发生）会导致反保守的结果。\n\n\n\n\n\n\n\n\n是时候将我们所学到的知识付诸实践了。在本章的其余部分，我们将探讨如何在 R 中直接运行不同效应量的荟萃分析。我们将用于执行此操作的 {meta} 包具有特殊的结构。它包含几个荟萃分析函数，每个函数都专注于一种类型的效应量数据。有一组参数可以在所有这些函数中以相同的方式指定；例如，如果我们想要应用固定效应或随机效应模型，或者应该使用哪个 \\(\\tau^2\\) 估计量。除此之外，还有一些特定于函数的参数，这些参数允许我们调整荟萃分析的细节，这些细节仅与特定类型的数据相关。\n图 @ref(fig:metaflow) 提供了 {meta} 结构的概述。要确定要使用的函数，我们首先必须明确我们想要合成哪种效应量数据。最根本的区别是原始和预计算效应量数据之间的区别。当我们拥有计算所需效应量所需的所有必要信息存储在我们的数据框中但尚未计算实际效应量时，我们称之为“原始”数据。我们之前使用的 SuicidePrevention 数据集包含原始数据：计算标准化均数差所需的两组的均值、标准差和样本量。\n另一方面，当效应量数据已经包含每个研究的最终效应量以及标准误差时，我们称之为“预计算”。如果我们想要使用效应指标的校正版本（例如 Hedges’ \\(g\\)，@ref(hedges-g) 章），则在开始合并",
    "crumbs": [
      "网站首页",
      "合并效应量"
    ]
  },
  {
    "objectID": "06-pooling_effect_sizes.html#fem-rem",
    "href": "06-pooling_effect_sizes.html#fem-rem",
    "title": "效应量的合并",
    "section": "",
    "text": "在我们指定荟萃分析模型之前，我们首先应该明确统计模型实际上是什么。统计学充满了“模型”，而且您很可能以前在这个语境中听说过这个术语。有“线性模型”、“广义线性模型”、“混合模型”、“高斯加性模型”、“结构方程模型”等等。\n模型在统计学中的普遍存在表明了这个概念的重要性。在某种程度上，模型构成了我们几乎所有统计工具箱的基础。在 \\(t\\) 检验、方差分析和回归分析的背后都有一个模型。每个假设检验都有其相应的统计模型。\n在定义统计模型时，我们从已经给我们的信息开始。这实际上就是我们的数据1。在荟萃分析中，数据是在纳入研究中观察到的效应量。我们的模型用于描述生成这些观察数据的过程。\n这些数据被视为一个黑盒子的产物，而我们的模型旨在阐明黑盒子内部发生的事情。\n\n\n\n\n\n\n\n\n\n通常，统计模型就像一种特殊的理论。模型试图解释生成我们观察数据的机制，尤其是当这些机制本身无法直接观察到时。它们是对生活的模仿，使用数学公式以理想化的方式描述我们周围世界中的过程。\n模型的这种解释性特征深深地根植于现代统计学中，荟萃分析也不例外。将模型概念化为解释工具是统计学“文化”的标志，正如 Breiman [-@breiman2001statistical] 著名地估计，98% 的统计学家都坚持这种文化。\n通过指定一个统计模型，我们试图找到一个近似表示我们数据背后“现实”的模型。我们想要一个数学公式来解释如何根据研究的观察结果找到所有研究背后的真实效应量。正如我们在 @ref(what-are-mas) 章中学到的，荟萃分析的最终目标之一是找到一个数值来表征我们的研究作为一个整体，即使观察到的效应量因研究而异。因此，荟萃分析模型必须解释为什么以及观察到的研究结果差异有多大的原因，即使只有一个总体效应。\n有两种模型试图准确地回答这个问题，即固定效应模型和随机效应模型。尽管两者都基于不同的假设，但它们之间仍然存在很强的联系，我们很快就会看到。\n\n\n\n\n \n固定效应模型假设所有效应量都来自一个单一的、同质的总体。它指出所有研究都共享相同的真实效应量。这个真实效应是我们想要在荟萃分析中计算的总体效应量，用 \\(\\theta\\) 表示。\n根据固定效应模型，研究 \\(k\\) 的观察效应量 \\(\\hat\\theta_k\\) 偏离 \\(\\theta\\) 的唯一原因是由于其抽样误差 \\(\\epsilon_k\\)。固定效应模型告诉我们，产生研究不同效应量的过程，即“黑盒子”的内容，很简单：所有研究都是相同真实效应量的估计量。然而，由于每项研究只能从无限大的研究人群中抽取或大或小的样本，因此结果会受到抽样误差的影响。这种抽样误差导致观察到的效应偏离总体真实效应。\n我们可以这样描述这种关系 [@borenstein2011introduction, 第 11 章]：\n\\[\\begin{equation}\n\\hat\\theta_k = \\theta + \\epsilon_k\n(\\#eq:pes1)\n\\end{equation}\\]\n对于警觉的读者来说，这个公式可能与 @ref(what-is-es) 章中的公式非常相似。您没有错。在之前的公式中，我们定义了某个研究 \\(k\\) 的观察效应量 \\(\\hat\\theta_k\\) 是该研究真实效应量 \\(\\theta_k\\) 的估计量，受到该研究抽样误差 \\(\\epsilon_k\\) 的影响。\n之前的公式与固定效应模型的公式之间只有一个很小但很有见地的差异。在固定效应模型的公式中，真实效应量不是用 \\(\\theta_k\\) 符号表示，而是用 \\(\\theta\\) 表示；下标 \\(k\\) 被省略了。\n以前，我们只是对一项个体研究 \\(k\\) 的真实效应量进行陈述。固定效应模型更进一步。它告诉我们，如果我们找到研究 \\(k\\) 的真实效应量，这个效应量不仅对 \\(k\\) 而言是真的，而且对我们荟萃分析中的所有研究而言也是真的。一个研究的真实效应量 \\(\\theta_k\\)，和总体合并的效应量 \\(\\theta\\)，是相同的。\n\n\n\n固定效应模型背后的思想是，观察到的效应量可能因研究而异，但这只是由于抽样误差造成的。实际上，它们的真实效应量都相同：它们是固定的。因此，固定效应模型有时也被称为“等效应”或“共同效应”模型。2\n\n\n固定效应模型的公式告诉我们，观察到的效应量 \\(\\theta_k\\) 偏离真实总体效应的唯一原因是：由于抽样误差 \\(\\epsilon_k\\)。在 @ref(what-is-es) 章中，我们已经讨论了抽样误差与研究样本量之间存在联系。在所有条件相同的情况下，随着样本量的增大，抽样误差减小。我们还了解到，抽样误差可以用标准误差来数值表示，标准误差也会随着样本量的增加而减小。\n虽然我们不知道研究的真实总体效应量，但我们可以利用这种关系来得出真实总体效应的最佳估计值，\\(\\hat\\theta\\)。我们知道标准误差越小，对应的抽样误差也越小；因此，与标准误差大的研究相比，标准误差小的研究应该能更好地估计真实总体效应。\n我们可以用一个模拟来说明这一点。使用我们之前使用过的 rnorm 函数，我们模拟了一系列研究，其中真实总体效应为 \\(\\theta = 0\\)。我们选取了几个样本，但改变了样本量，使得“观察到”的效应之间的标准误差不同。模拟的结果可以在图 @ref(fig:funnel1) 中找到。\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n效应量与标准误差之间的关系。\n\n\n\n\n模拟结果显示出一种有趣的模式。我们看到具有较小抽样误差的效应量紧密地聚集在真实效应量 \\(\\theta = 0\\) 附近。随着 y 轴上的标准误差3 的增加，效应量的离散程度变得越来越大，并且观察到的效应越来越偏离真实效应。\n这种行为可以通过固定效应模型的公式来预测。我们知道具有较小标准误差的研究具有较小的抽样误差，因此它们对总体效应量的估计更可能接近真实值。\n\n我们已经看到，虽然所有观察到的效应量都是真实效应的估计量，但有些比其他的好。当我们合并荟萃分析中的效应时，我们应该给予具有更高精度（即更小的标准误差）的效应量更大的权重。如果我们想要计算固定效应模型下的合并效应量，我们只需使用所有研究的加权平均值。\n要计算每个研究 \\(k\\) 的权重 \\(w_k\\)，我们可以使用标准误差，对其进行平方以获得每个效应量的方差 \\(s^2_k\\)。由于较低的方差表示较高的精度，因此使用方差的倒数来确定每个研究的权重。\n\\[\\begin{equation}\nw_k = \\frac{1}{s^2_k}\n(\\#eq:pes2)\n\\end{equation}\\]\n一旦我们知道权重，我们就可以计算加权平均值，即我们对真实合并效应 \\(\\hat\\theta\\) 的估计。我们只需要将每个研究的效应量 \\(\\hat\\theta_k\\) 与其对应的权重 \\(w_k\\) 相乘，将荟萃分析中所有研究 \\(K\\) 的结果相加，然后除以所有个体权重的总和。\n\\[\\begin{equation}\n\\hat\\theta = \\frac{\\sum^{K}_{k=1} \\hat\\theta_kw_k}{\\sum^{K}_{k=1} w_k}\n(\\#eq:pes3)\n\\end{equation}\\]\n \n这种方法是荟萃分析中计算平均效应的最常见方法。由于我们使用方差的倒数，因此它通常被称为逆方差加权或简称为逆方差荟萃分析。\n对于二元效应量数据，有其他方法来计算加权平均值，包括 Mantel-Haenszel、Peto 或 Bakbergenuly [-@bakbergenuly2020methods] 的样本量加权法。我们将在 @ref(pooling-or-rr) 章中讨论这些方法。\n{meta} 包使得执行固定效应荟萃分析非常容易。但是，在此之前，让我们尝试在 R 中“手动”进行逆方差合并。在我们的例子中，我们将使用 SuicidePrevention 数据集，我们已经在 @ref(data-prep-R) 章中导入了该数据集。\n\n\n\n\n“SuicidePrevention”数据集\nSuicidePrevention 数据集也直接包含在 {dmetar} 包中。如果您已经安装了 {dmetar} 并且已从您的库中加载了它，则运行 data(SuicidePrevention) 会自动将数据集保存在您的 R 环境中。然后就可以使用该数据集了。如果您没有安装 {dmetar}，您可以从 Internet 下载数据集作为 .rda 文件，将其保存在您的工作目录中，然后在您的 R Studio 窗口中单击它以导入它。\n\n\n \nSuicidePrevention 数据集包含原始效应量数据，这意味着我们必须首先计算效应量。在本例中，我们计算了小样本调整的标准化均数差（Hedges’ \\(g\\)）。为此，我们使用了 {esc} 包中的 esc_mean_sd 函数（@ref(b-group-smd) 章）。\n该函数有一个额外的参数 es.type，通过该参数我们可以指定是否要执行小样本校正（通过设置 es.type = \"g\"；@ref(hedges-g) 章）。\n自 R 4.2.1 版本发布以来，我们还必须将对 esc_mean_sd 的调用插入到 pmap_dfr 函数中，以便为数据集中的每一行计算一个标准化均数差：\n\n# 加载 dmetar、esc 和 tidyverse (用于管道)\nlibrary(dmetar)\nlibrary(esc)\nlibrary(tidyverse)\n\n# 从 dmetar 加载数据集\ndata(SuicidePrevention)\n\n# 计算 Hedges' g 和标准误差\n# - 我们将研究名称保存在 \"study\" 中。\n# - 我们使用 pmap_dfr 函数来计算\n#   每一行的效应量。\nSP_calc &lt;- pmap_dfr(SuicidePrevention,\n                    function(mean.e, sd.e, n.e, mean.c,\n                             sd.c, n.c, author, ...){\n                      esc_mean_sd(grp1m = mean.e,\n                                  grp1sd = sd.e,\n                                  grp1n = n.e,\n                                  grp2m = mean.c,\n                                  grp2sd = sd.c,\n                                  grp2n = n.c,\n                                  study = author,\n                                  es.type = \"g\") %&gt;%\n                        as.data.frame()})\n\n# 让我们快速浏览一下数据\n# 数据集包含 Hedges' g (\"es\") 和标准误差 (\"se\")\nglimpse(SP_calc)\n\n## Rows: 9\n## Columns: 9\n## $ study       &lt;chr&gt; \"Berry et al.\", \"DeVries et …\n## $ es          &lt;dbl&gt; -0.14279447, -0.60770928, -0…\n## $ weight      &lt;dbl&gt; 46.09784, 34.77314, 14.97625…\n## $ sample.size &lt;dbl&gt; 185, 146, 60, 129, 100, 220,…\n## $ se          &lt;dbl&gt; 0.1472854, 0.1695813, 0.2584…\n## $ var         &lt;dbl&gt; 0.02169299, 0.02875783, 0.06…\n## $ ci.lo       &lt;dbl&gt; -0.4314686, -0.9400826, -0.6…\n## $ ci.hi       &lt;dbl&gt; 0.145879624, -0.275335960, 0…\n## $ measure     &lt;chr&gt; \"g\", \"g\", \"g\", \"g\", \"g\", \"g\"…\n接下来，我们使用这些结果来应用固定效应模型的公式：\n\n# 计算每个研究的逆方差权重\nSP_calc$w &lt;- 1/SP_calc$se^2\n\n# 然后，我们使用权重来计算合并效应\npooled_effect &lt;- sum(SP_calc$w*SP_calc$es)/sum(SP_calc$w)\npooled_effect\n\n## [1] -0.2311121\n我们的计算结果表明，假设一个固定效应模型，合并效应量为 \\(g \\approx\\) -0.23。\n\n\n\n\n\n\n正如我们所看到的，固定效应模型是一种概念化荟萃分析数据生成方式以及如何合并效应的方式。然而，重要的问题是：这种方法是否充分反映了现实？\n固定效应模型假设我们所有的研究都是同质群体的一部分，并且观察到的效应差异的唯一原因是研究的抽样误差。如果我们在没有抽样误差的情况下计算每项研究的效应量，那么所有真实效应量将完全相同。\n\n对这个概念进行快速的现实检验，我们发现固定效应模型的假设在许多实际应用中可能过于简单。荟萃分析中的研究总是完全同质的，这简直是不现实的。研究经常会存在差异，即使只是在细微的方式上。感兴趣的结果可能以不同的方式测量。也许治疗的类型不完全相同，或者治疗的强度和持续时间不同。研究的目标人群可能不完全相同，或者可能使用的对照组存在差异。\n您荟萃分析中的研究很可能不仅在一个方面存在差异，而且在几个方面同时存在差异。如果这是真的，我们可以预期真实效应中存在相当大的研究间异质性。\n所有这些都使固定效应模型的有效性受到质疑。例如，如果一些研究使用了不同类型的治疗，那么似乎很正常的是，一种形式比另一种更有效。假设这些差异只是噪音，由研究的抽样误差产生，这未免有些牵强。\n恰恰相反，可能存在无数的原因导致研究的真实效应量存在实际差异。随机效应模型解决了这个担忧。它为我们提供了一个模型，该模型通常能更好地反映我们数据背后的现实。\n\n在随机效应模型中，我们希望解释效应量显示的方差大于从一个单一同质群体中抽取的方差这一事实 [@hedges1998fixed]。因此，我们假设个体研究的效应不仅由于抽样误差而有所偏差，而且还存在另一个方差来源。\n这个额外的方差分量是由研究不是来自一个单一群体这一事实引入的。相反，每项研究都被视为从一个“宇宙”群体中独立抽取的结果。\n\n\n\n随机效应模型假设不仅存在一个真实的效应量，而且存在一个真实效应量的分布。因此，随机效应模型的目标不是估计所有研究的一个真实效应量，而是真实效应分布的均值。\n\n\n让我们看看如何用公式表达随机效应模型。与固定效应模型类似，随机效应模型首先假设观察到的效应量 \\(\\hat\\theta_k\\) 是研究真实效应量 \\(\\theta_k\\) 的估计量，受到抽样误差 \\(\\epsilon_k\\) 的影响：\n\\[\\begin{equation}\n\\hat\\theta_k = \\theta_k + \\epsilon_k\n(\\#eq:pes4)\n\\end{equation}\\]\n我们使用 \\(\\theta_k\\) 而不是 \\(\\theta\\) 这一事实已经表明了一个重要的差异。随机效应模型仅假设 \\(\\theta_k\\) 是一项单一研究 \\(k\\) 的真实效应量。它规定存在第二个误差来源，用 \\(\\zeta_k\\) 表示。这个第二个误差来源是由以下事实引入的：即使研究 \\(k\\) 的真实效应量 \\(\\theta_k\\) 也只是真实效应总体分布的一部分，该分布的均值为 \\(\\mu\\)。\n\\[\\begin{equation}\n\\theta_k  = \\mu + \\zeta_k\n(\\#eq:pes5)\n\\end{equation}\\]\n随机效应模型告诉我们，在我们的黑盒子里发生了两个过程的层次结构 [@thompson2001multilevel]：一项研究的观察效应量由于抽样误差而偏离了它们的真实值。但是，即使真实效应量也只是从真实效应总体中抽取的一个样本，我们希望将该总体的均值 \\(\\mu\\) 估计为我们荟萃分析的合并效应。\n通过将第二个公式插入到第一个公式中（即，用它在第二个公式中的定义替换 \\(\\theta_k\\)），我们可以用一行来表达随机效应模型 [@borenstein2011introduction, 第 12 章]：\n\\[\\begin{equation}\n\\hat\\theta_k = \\mu + \\zeta_k + \\epsilon_k\n(\\#eq:pes6)\n\\end{equation}\\]\n这个公式清楚地表明，我们观察到的效应量由于两个误差项 \\(\\zeta_k\\) 和 \\(\\epsilon_k\\) 而偏离了合并效应 \\(\\mu\\)。这种关系在图 @ref(fig:random) 中进行了可视化。\n\n随机效应模型的一个关键假设是 \\(\\zeta_k\\) 的大小与 \\(k\\) 无关。换句话说，我们假设没有任何东西可以先验地表明一项研究中的 \\(\\zeta_k\\) 高于另一项研究。我们预先假定 \\(\\zeta_k\\) 的大小是偶然的产物，而且仅仅是偶然的产物。\n这被称为随机效应模型的可交换性假设 [@higgins2009re; @lunn2012bugs, 第 10.1 章]。假设所有真实效应量都是可交换的，因为在我们看到数据之前，我们没有任何东西可以告诉我们一些研究 \\(k\\) 中 \\(\\zeta_k\\) 将有多大。\n\n\n\n\n我应该使用哪个模型？\n在实践中，发现一组研究是完全同质的非常罕见。即使我们遵循最佳实践，并通过我们的 PICO（@ref(research-question) 章）尽可能精确地确定分析的范围，也是如此。\n因此，在包括医学和社会科学在内的许多领域，通常总是使用随机效应模型，因为几乎总是可以预期到一定程度的研究间异质性。只有当我们没有检测到任何研究间异质性（我们将在 @ref(heterogeneity) 章中讨论如何做到这一点）并且当我们有非常好的理由假设真实效应是固定的时，才可以使用固定效应模型。例如，当只考虑一项研究的精确复制时，或者当我们对一项大型研究的子集进行荟萃分析时，可能会出现这种情况。毋庸置疑，这种情况很少发生，并且固定效应模型“在野外”的应用相当罕见。\n即使先验地使用随机效应模型是常规做法，但这种方法也并非没有争议。在计算荟萃分析的总体效应时，随机效应模型会更多地关注小型研究 [@schwarzer2015meta, 第 2.3 章]。然而，特别是小型研究通常充满偏见（参见 @ref(small-study-effects) 章）。这就是为什么有些人认为固定效应模型（有时）更可取 [@poole1999random; @furukawa2003low]。Stanley、Doucouliagos 和 Ioannidis [-@stanley2022beyond] 提出了类似的观点，并认为在某些学科中，应该使用所谓的“无限制加权最小二乘法”（UWLS）模型来代替随机效应模型。\n\n\n\n\n\n\n\n随机效应模型参数的图示。\n\n\n\n\n\n\n\n\n\n与随机效应模型相关的挑战是我们必须考虑误差 \\(\\zeta_k\\)。为此，我们必须估计真实效应量分布的方差。这个方差被称为 \\(\\tau^2\\)，或 tau 平方。一旦我们知道 \\(\\tau^2\\) 的值，我们就可以在确定每个效应量的逆方差权重时包括研究间异质性。\n因此，在随机效应模型中，我们为每个观察值计算一个调整后的随机效应权重 \\(w^*_k\\)。该公式如下所示：\n\\[\\begin{equation}\nw^*_k = \\frac{1}{s^2_k+\\tau^2}\n(\\#eq:pes7)\n\\end{equation}\\]\n\n使用调整后的随机效应权重，我们然后使用逆方差方法计算合并效应量，就像我们使用固定效应模型所做的那样：\n\\[\\begin{equation}\n\\hat\\theta = \\frac{\\sum^{K}_{k=1} \\hat\\theta_kw^*_k}{\\sum^{K}_{k=1} w^*_k}\n(\\#eq:pes8)\n\\end{equation}\\]\n有几种方法来估计 \\(\\tau^2\\)，其中大多数方法过于复杂而无法手动完成。幸运的是，这些估计量在 {meta} 包的函数中实现，该包会自动为我们进行计算。以下是最常见估计量的列表，以及它们在 {meta} 中引用的代码：\n \n\nDerSimonian-Laird (\"DL\") 估计量 [@dersimonian1986meta]。\n限制最大似然 (\"REML\") 或 最大似然 (\"ML\") 程序 [@viechtbauer2005bias]。\nPaule-Mandel (\"PM\") 程序 [@paule1982consensus]。\n经验贝叶斯 (\"EB\") 程序 [@sidik2019note]，实际上与 Paule-Mandel 方法相同。\nSidik-Jonkman (\"SJ\") 估计量 [@sidik2005simple]。\n\n哪种估计量最适合不同类型的数据是一个持续研究的问题。一种方法是否比另一种方法更好通常取决于参数，例如研究的数量 \\(k\\)、每个研究中的参与者数量 \\(n\\)、\\(n\\) 在研究之间的变化程度以及 \\(\\tau^2\\) 有多大。几项研究分析了在这些不同情况下 \\(\\tau^2\\) 估计量的偏差 [@veroniki2016methods; @viechtbauer2005bias; @sidik2007comparison; @langan2019comparison]。\n \n可以说，最常用的估计量是 DerSimonian 和 Laird 的估计量。该估计量已在过去荟萃分析人员常用的软件中实现，例如 RevMan（Cochrane 开发的程序）或 Comprehensive Meta-Analysis。它也曾经是 {meta} 中使用的默认估计量4。由于这种历史遗产，人们经常发现研究论文中使用“使用随机效应模型”等同于使用 DerSimonian-Laird 估计量。\n然而，人们发现这种估计量可能存在偏差，尤其是在研究数量较少且异质性较高时 [@hartung1999alternative; @hartung2001refined; @hartung2001tests; @follmann1999valid; @makambi2004effect]。这是非常成问题的，因为发现研究数量少且异质性高的荟萃分析非常常见。\n \n在一篇概述性论文中，Veroniki 及其同事 [-@veroniki2016methods] 回顾了各种 \\(\\tau^2\\) 估计量稳健性的证据。他们推荐了 Paule-Mandel 方法用于二元和连续效应量数据，并推荐了限制最大似然估计量用于连续结果。限制最大似然估计量也是 {metafor} 包使用的默认方法。\nLangan 及其同事 [-@langan2019comparison] 最近的一项模拟研究得出了类似的结果，但发现当研究的样本量差异很大时，Paule-Mandel 估计量可能不是最佳选择。Bakbergenuly 及其同事 [-@bakbergenuly2020methods] 的另一项研究发现，Paule-Mandel 估计量特别适用于研究数量较少的情况。Sidik-Jonkman 估计量，也称为模型误差方差法，仅在 \\(\\tau^2\\) 非常大时才适用 [@sidik2007comparison]。\n\n\n\n我应该使用哪个估计量？\n关于何时应该使用哪个估计量，没有铁律。在许多情况下，各种估计量产生的结果只会存在微小的差异，这意味着您不应该太担心这个问题。\n如有疑问，您可以随时使用不同的 \\(\\tau^2\\) 估计量重新运行您的分析，看看这是否会改变您对结果的解释。以下是一些您可以在自己的荟萃分析中遵循的初步指南：\n\n对于基于连续结果数据的效应量，限制最大似然估计量可以用作第一个起点。\n对于二元效应量数据，Paule-Mandel 估计量是一个很好的首选，前提是样本量没有极端变化。\n当您有非常好的理由相信样本中效应的异质性非常大，并且避免假阳性具有非常高的优先级时，您可以使用 Sidik-Jonkman 估计量。\n如果您希望其他人在 R 之外尽可能精确地复制您的结果，则 DerSimonian-Laird 估计量是首选方法。\n\n\n\n总的来说，\\(\\tau^2\\) 的估计量分为两类。一些，如 DerSimonian-Laird 和 Sidik-Jonkman 估计量，基于封闭形式表达式，这意味着它们可以使用公式直接计算。\n（限制）最大似然、Paule-Mandel 和经验贝叶斯估计量通过迭代算法找到 \\(\\tau^2\\) 的最佳值。因此，后者的估计量有时可能需要更长的时间来计算结果。然而，在大多数实际情况下，这些时间差异最多只是微不足道的。\n\n\n\n\n\n \n除了我们选择的 \\(\\tau^2\\) 估计量之外，我们还必须决定是否要应用所谓的 Knapp-Hartung 调整5 [@knapp2003improved; @sidik2002simple]。这些调整会影响我们合并效应量 \\(\\hat\\theta\\) 的标准误差（以及因此置信区间）的计算方式。\nKnapp-Hartung 调整试图控制我们对研究间异质性估计的不确定性。虽然合并效应的显著性检验通常假设正态分布（所谓的 Wald 型检验），但 Knapp-Hartung 方法基于 \\(t\\) 分布。Knapp-Hartung 调整只能在随机效应模型中使用，并且通常会导致合并效应的置信区间略微变大。\n\n\n\n\n报告在您的荟萃分析中使用的模型类型\n\n\n强烈建议您在荟萃分析报告的方法部分指定您使用的模型类型。以下是一个示例：\n\n\n\n“由于我们预计到相当大的研究间异质性，因此使用随机效应模型来合并效应量。使用限制最大似然估计量 (Viechtbauer, 2005) 来计算异质性方差 (^2)。我们使用 Knapp-Hartung 调整 (Knapp & Hartung, 2003) 来计算合并效应周围的置信区间。”\n\n\n\n\n应用 Knapp-Hartung 调整通常是明智的。几项研究 [@inthout2014hartung; @langan2019comparison] 表明，这些调整可以减少假阳性的可能性，尤其是在研究数量较少时。\n然而，使用 Knapp-Hartung 调整并非没有争议。例如，Wiksten 及其同事 [-@wiksten2016hartung] 认为，该方法在效应非常同质的情况下（很少发生）会导致反保守的结果。",
    "crumbs": [
      "网站首页",
      "合并效应量"
    ]
  },
  {
    "objectID": "06-pooling_effect_sizes.html#pooling-es-r",
    "href": "06-pooling_effect_sizes.html#pooling-es-r",
    "title": "效应量的合并",
    "section": "",
    "text": "是时候将我们所学到的知识付诸实践了。在本章的其余部分，我们将探讨如何在 R 中直接运行不同效应量的荟萃分析。我们将用于执行此操作的 {meta} 包具有特殊的结构。它包含几个荟萃分析函数，每个函数都专注于一种类型的效应量数据。有一组参数可以在所有这些函数中以相同的方式指定；例如，如果我们想要应用固定效应或随机效应模型，或者应该使用哪个 \\(\\tau^2\\) 估计量。除此之外，还有一些特定于函数的参数，这些参数允许我们调整荟萃分析的细节，这些细节仅与特定类型的数据相关。\n图 @ref(fig:metaflow) 提供了 {meta} 结构的概述。要确定要使用的函数，我们首先必须明确我们想要合成哪种效应量数据。最根本的区别是原始和预计算效应量数据之间的区别。当我们拥有计算所需效应量所需的所有必要信息存储在我们的数据框中但尚未计算实际效应量时，我们称之为“原始”数据。我们之前使用的 SuicidePrevention 数据集包含原始数据：计算标准化均数差所需的两组的均值、标准差和样本量。\n另一方面，当效应量数据已经包含每个研究的最终效应量以及标准误差时，我们称之为“预计算”。如果我们想要使用效应指标的校正版本（例如 Hedges’ \\(g\\)，@ref(hedges-g) 章），则在开始合并",
    "crumbs": [
      "网站首页",
      "合并效应量"
    ]
  },
  {
    "objectID": "06-pooling_effect_sizes.html#footnotes",
    "href": "06-pooling_effect_sizes.html#footnotes",
    "title": "效应量的合并",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n“数据”来源于拉丁语 datum，意思是“给定的事物”↩︎\n{metafor} 包使用术语“等效应模型”，而 {meta} 使用术语“共同效应模型”。↩︎\n我们在绘制之前对标准误差进行了对数转换，以便更容易看到该模式。↩︎\n在较新版本的 {meta} 中，限制最大似然 (\"REML\") 估计量现在用作默认值。↩︎\n这种方法也被称为“Hartung-Knapp 调整”或“Hartung-Knapp-Sidik-Jonkman” (HKSJ) 方法。↩︎",
    "crumbs": [
      "网站首页",
      "合并效应量"
    ]
  },
  {
    "objectID": "08-forestplots.html",
    "href": "08-forestplots.html",
    "title": "森林图",
    "section": "",
    "text": "在 前面的章节中，我们学习了如何在 R 中合并效应量，以及如何评估 meta 分析中的异质性。现在我们来到了 meta 分析中稍微令人愉快的部分，在这里我们将可视化我们在前面步骤中获得的结果。\n可视化 meta 分析最常见的方法是使用森林图。这种图以图形方式显示了每个研究的观察效应、置信区间，通常还包括权重。它们还显示了我们在 meta 分析中计算出的合并效应。总的来说，这使其他人可以快速检查纳入研究的精度和分布，以及合并效应与观察效应大小的关系。\n\n{meta} 包有一个内置函数，可以非常容易地直接在 R 中生成美观的森林图。该函数具有广泛的功能，并允许根据需要更改图的外观。本章将主要关注此森林图函数以及如何在实践中使用它。此外，我们还将简要讨论另一种可视化 meta 分析结果的方法。\n\n\n\n\n图 @ref(fig:forest) 显示了森林图的主要组成部分。在左侧，森林图显示了 meta 分析中包含的每个研究的名称。对于每个研究，都提供了效应量的图形表示，通常在图的中心。此可视化在 x 轴上显示研究的点估计。该点估计由一条线补充，该线表示为观察到的效应量计算出的置信区间的范围。通常，点估计被一个正方形包围。该正方形的大小由效应量的权重（第 @ref(fem) 章）决定：权重较大的研究会得到较大的正方形，而权重较低的研究会得到较小的正方形。\n按照惯例，森林图还应包含用于执行 meta 分析的效应量数据。这为其他人提供了复制我们结果所需的数据。\n\n\n\n\n\n森林图的关键要素。\n\n\n\n\n在图的底部，一个菱形表示平均效应。菱形的长度象征着合并结果在 x 轴上的置信区间。通常，森林图还包括一条垂直的参考线，指示 x 轴上等于没有效应的点。正如我们将在接下来的示例中看到的那样，可以通过显示异质性度量（例如 \\(I^2\\) 或 \\(\\tau^2\\)）来增强森林图。\n\n森林图中的效应量和置信区间通常以线性刻度显示。然而，当汇总指标是一个比率（例如优势比或风险比）时，通常在 x 轴上使用对数刻度。这意味着 1 附近的值比远低于或高于 1 的值更接近。\n这对于比率来说是有意义的，因为这些效应量指标不能以“线性”方式解释（即 RR = 0.50 的“相反”是 2，而不是 1.5；请参阅第 @ref(ratios) 章）。此类效应量的参考线通常为 1，表示没有效应。\n\n\n\n\n\n我们可以使用 meta::forest 函数为任何类型的 {meta} meta 分析对象（例如 metagen、metacont 或 metabin 的结果）生成森林图1。我们只需为 meta::forest 提供我们的 {meta} 对象，即可创建一个图。通常，这些森林图默认情况下看起来已经很不错了，但是该函数还有无数其他参数可以进一步调整外观。所有这些参数都在函数文档中进行了描述（可以通过运行 ?meta::forest 访问）。以下是更重要的参数的列表：\n\nsortvar。meta 分析数据集中用于在森林图中对研究进行排序的变量。例如，如果我们想按效应量对结果进行排序，可以使用代码 sortvar = TE。\ncomb.fixed。逻辑值，指示是否应在图中包含固定效应模型估计值。\ncomb.random。逻辑值，指示是否应在图中包含随机效应模型估计值。\ntext.fixed。根据固定效应模型合并效应的标签。默认情况下，打印 \"Fixed effect model\"。\ntext.random。根据随机效应模型合并效应的标签。默认情况下，打印 \"Random effects model\"。\nprediction。逻辑值，指示是否应将预测区间添加到图中。\nlabel.left 和 label.right。添加到森林图左侧和右侧的标签。这可以用于指定，例如，此侧的效应有利于治疗（例如，label.left = \"Favors treatment\"）。\nsmlab。显示在图顶部的标签。这可以用于显示使用了哪种效应量指标。\nxlim。x 轴的限制，或字符 “s” 以生成对称森林图。当您的结果与零有很大偏差，或者您还想描绘异常值时，此参数尤其相关。例如，如果我们希望 x 轴的范围为 0 到 2，则代码为 xlim = c(0,2)。\nref。图中的参考线。根据我们使用的汇总指标，默认情况下，此值为 0 或 1。\nleftcols 和 rightcols。在这里，您可以指定应在森林图的左侧和右侧显示哪些变量。该函数默认使用一些内置元素。例如，\"studlab\" 代表研究标签，\"effect\" 代表观察到的效应量，effect.ci 代表效应量及其置信区间。也可以添加用户定义的列，只要这些列包含在我们最初提供给 {meta} 函数的 data.frame 中。在这种情况下，我们只需要将列的名称添加为字符串即可。\nleftlabs 和 rightlabs。应用于森林图左侧和右侧显示的列的标签。\nprint.I2 和 print.I2.ci。逻辑值，指示是否应打印 \\(I^2\\) 值及其置信区间。默认情况下，此值为 TRUE。\nprint.tau2 和 print.tau。逻辑值，指示是否应打印 \\(\\tau^2\\) 和 \\(\\tau\\) 值。默认情况下，打印 \\(\\tau^2\\) 的值。\ncol.square、col.diamond 和 col.predict。正方形、菱形和预测区间的颜色（例如，\"blue\"）。\n\n现在是生成我们的第一个森林图的时候了。在此示例中，我们绘制了我们在前面的示例中也使用的 m.gen 对象。我们按效应量对森林图中的研究进行排序，添加预测区间，并在左侧添加用户定义的标签。meta::forest 函数默认打印 \\(\\tau^2\\) 值，我们在这里不需要它，因此我们将 print.tau2 设置为 FALSE。\n这是我们的代码最终的样子：\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"作者\", \"g\", \"SE\"))\n\n\n\n\n\n\n\n\n\n\nmeta::forest 为我们提供的图看起来已经相当不错了。我们还看到图中添加了一条细的黑线，表示我们合并效应周围的预测区间。\n\n我们可以通过添加一列显示每个研究的偏倚风险来增强该图。我们用于生成 m.gen 的 ThirdWave 数据集包含一列名为 RiskOfBias 的列，其中存储了每个研究的偏倚风险评估。\n当我们使用 metagen 计算 meta 分析（第 @ref(pre-calculated-es) 章）时，该函数会自动将此数据保存在 m.gen 中。因此，我们可以使用 leftcols 参数将该列添加到图中。这将导致以下代码：\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftcols = c(\"studlab\", \"TE\", \"seTE\", \"RiskOfBias\"),\n             leftlabs = c(\"作者\", \"g\", \"SE\", \"偏倚风险\"))\n\n\n\n\n\n\n\n\n\n\n我们看到，现在，每个研究的偏倚风险信息已添加到森林图中。\n\n\n\n\nmeta::forest 函数有两种“预先打包”的布局，我们可以使用它们将我们的森林图引入特定格式，而无需指定大量参数。其中之一是 \"JAMA\" 布局，它为我们提供了一个符合美国医学会杂志指南的森林图。如果您想在医学期刊上发表您的 meta 分析，可以使用此布局。\n\nmeta::forest(m.gen, layout = \"JAMA\")\n\n\n\n\n\n\n\n\n\n\n\n另一种布局是 \"RevMan5\"，它生成的森林图类似于 Cochrane 的 Review Manager 5 生成的森林图。\n\nmeta::forest(m.gen, layout = \"RevMan5\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n由 meta::forest 生成的森林图可以保存为 PDF、PNG 或可缩放矢量图形 (SVG) 文件。与其他通过基本 R 或 {ggplot2} 包生成的图不同，当我们将其另存为文件时，meta::forest 的输出不会自动重新缩放。这意味着森林图有时会在两个或四个侧面被截断，我们必须手动调整宽度和高度，以便所有内容都可见。\npdf、png 和 svg 函数可用于通过 R 代码保存图。我们必须从调用这些函数之一开始，该函数告诉 R 以下代码的输出应保存在文档中。然后，我们添加对 meta::forest 函数的调用。在最后一行，我们必须包含 dev.off()，它会将生成的输出保存到我们在上面指定的文件中。\n所有这三个函数都需要我们指定 file 参数，该参数应包含文件的名称。然后，该文件会自动保存在工作目录中，并使用该名称。此外，我们可以使用 width 和 height 参数来控制图的大小，这在输出被截断时可能会有所帮助。\n假设我们要将我们的初始森林图另存为“forestplot”，我们可以使用以下代码来生成 PDF、PNG 和 SVG 文件。\nPDF\n\npdf(file = \"forestplot.pdf\", width = 8, height = 7)\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"作者\", \"g\", \"SE\"))\n\ndev.off()\n\nPNG\n\npng(file = \"forestplot.png\", width = 2800, height = 2400, res = 300)\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"作者\", \"g\", \"SE\"))\n\ndev.off()\n\nSVG\n\nsvg(file = \"forestplot.svg\", width = 8, height = 7)\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"作者\", \"g\", \"SE\"))\n\ndev.off()\n\n\n\n\n\n\n\n\n\n到目前为止，森林图是可视化 meta 分析的最常见方法。大多数已发表的 meta 分析都包含森林图，并且许多研究人员都了解如何解释它们。建议您也在您的 meta 分析报告中包含一个森林图，因为森林图提供了对您的发现的全面且易于理解的摘要。\n但是，森林图并不是说明我们结果的唯一方法。例如，meta 分析也可以通过织锦图 [@rucker2020beyond] 可视化。森林图的一个缺点是，它们只能显示假设固定显着性阈值（通常为 \\(p&lt;\\) 0.05）的置信区间。正是基于这些置信区间，研究人员才能确定效应是否显着。\n近年来，围绕 \\(p\\) 值的使用一直存在争议 [@wellek2017critical]，并且有些人认为基于 \\(p\\) 值的假设检验导致了许多研究领域的“复制危机”[@nuzzo2014statistical]。\n织锦图基于 \\(p\\) 值函数。已经提出了这样的 \\(p\\) 值函数，以防止我们在解释分析结果时仅仅依赖于 \\(p\\)&lt;0.05 显着性阈值 [@infanger2019p]。\n因此，除了仅计算 95% 置信区间之外，\\(p\\) 值函数还提供了一条连续曲线，该曲线显示了 \\(p\\) 的不同值的置信区间。在织锦图中，为每个研究以及平均效应绘制一条置信曲线。x 轴显示效应量指标，y 轴显示假设的 \\(p\\) 值。\n可以通过 {meta} 中的 drapery 函数生成织锦图。与 meta::forest 一样，一旦我们为其提供 {meta} meta 分析对象，此函数就会自动生成图。还有一些其他参数，其中最重要的参数是：\n\ntype：定义要在 y 轴上绘制的值的类型。对于检验统计量，可以是 \"zvalue\"（默认值），也可以是 \\(p\\) 值 (\"pvalue\")。\nstudy.results：逻辑值，指示是否应在图中包含每个研究的结果。如果 FALSE，则仅打印汇总效应。\nlabels：当我们把这个参数设置为 \"studlab\"，研究标签将包含在图中。\nlegend：逻辑值，指示是否应打印图例。\npos.legend：图例的位置。可以是 \"bottomright\"、\"bottom\"、\"bottomleft\"、\"left\"、\"topleft\"、\"top\"、\"topright\"、\"right\" 或 \"center\"。\n\n让我们在一个示例中使用我们的 m.gen meta 分析对象来试用 drapery 函数。\n\ndrapery(m.gen, \n        labels = \"studlab\",\n        type = \"pval\", \n        legend = FALSE)\n\n\n\n\n\n\n\n\n\n\n生成的图包含每个效应量的 \\(p\\) 值曲线，所有曲线都呈倒 V 形。粗线表示根据随机效应模型的平均效应。我们在图中看到的阴影区域表示预测区间，该区间比合并效应的置信区间宽得多。\n\\(p\\) 值函数的“峰值”表示我们的 meta 分析中效应量的确切值。当我们沿着 y 轴向下移动时，\\(p\\) 值变得更小，并且置信区间越来越宽，直到我们达到由虚线水平线指示的常规显着性阈值。\n根据该图，我们看到我们可以非常确信合并效应量大于零，因为当 \\(p\\) 已经非常非常小（&lt;0.01）时，粗线在 x 轴上达到零。\nRücker 等人 [-@rucker2020beyond] 建议织锦图应主要除了森林图之外使用。简单地用织锦图代替森林图可能不是一个好主意，因为后者不包含其他方可能需要重现我们的结果的许多效应量信息。\n\\[\\tag*{$\\blacksquare$}\\]\n\n\n\n\n\n\n\n测试您的知识！\n\n\n\n森林图的关键组成部分是什么？\n\n\n\n\n展示我们的 meta 分析的森林图有什么优势？\n\n\n\n\n森林图的局限性是什么？织锦图如何克服这一局限性？\n\n\n\n这些问题的答案在本章末尾的 附录 A 中列出。\n\n\n\n\n\n\n\n\n习惯上通过森林图可视化 meta 分析的结果。\n森林图包含每个研究的效应量和置信区间的图形表示，并且还显示计算出的总体效应。此外，它们还包含用于合并的效应量数据。\n也可以将其他类型的信息添加到森林图中，例如每个研究收到的质量评级。\n森林图只能显示假设固定显着性阈值（通常为 \\(p&lt;\\) 0.05）的结果。为了可视化结果如何随不同的显着性阈值变化，可以另外生成织锦图。",
    "crumbs": [
      "网站首页",
      "森林图"
    ]
  },
  {
    "objectID": "08-forestplots.html#什么是森林图",
    "href": "08-forestplots.html#什么是森林图",
    "title": "森林图",
    "section": "",
    "text": "图 @ref(fig:forest) 显示了森林图的主要组成部分。在左侧，森林图显示了 meta 分析中包含的每个研究的名称。对于每个研究，都提供了效应量的图形表示，通常在图的中心。此可视化在 x 轴上显示研究的点估计。该点估计由一条线补充，该线表示为观察到的效应量计算出的置信区间的范围。通常，点估计被一个正方形包围。该正方形的大小由效应量的权重（第 @ref(fem) 章）决定：权重较大的研究会得到较大的正方形，而权重较低的研究会得到较小的正方形。\n按照惯例，森林图还应包含用于执行 meta 分析的效应量数据。这为其他人提供了复制我们结果所需的数据。\n\n\n\n\n\n森林图的关键要素。\n\n\n\n\n在图的底部，一个菱形表示平均效应。菱形的长度象征着合并结果在 x 轴上的置信区间。通常，森林图还包括一条垂直的参考线，指示 x 轴上等于没有效应的点。正如我们将在接下来的示例中看到的那样，可以通过显示异质性度量（例如 \\(I^2\\) 或 \\(\\tau^2\\)）来增强森林图。\n\n森林图中的效应量和置信区间通常以线性刻度显示。然而，当汇总指标是一个比率（例如优势比或风险比）时，通常在 x 轴上使用对数刻度。这意味着 1 附近的值比远低于或高于 1 的值更接近。\n这对于比率来说是有意义的，因为这些效应量指标不能以“线性”方式解释（即 RR = 0.50 的“相反”是 2，而不是 1.5；请参阅第 @ref(ratios) 章）。此类效应量的参考线通常为 1，表示没有效应。",
    "crumbs": [
      "网站首页",
      "森林图"
    ]
  },
  {
    "objectID": "08-forestplots.html#forest-R",
    "href": "08-forestplots.html#forest-R",
    "title": "森林图",
    "section": "",
    "text": "我们可以使用 meta::forest 函数为任何类型的 {meta} meta 分析对象（例如 metagen、metacont 或 metabin 的结果）生成森林图1。我们只需为 meta::forest 提供我们的 {meta} 对象，即可创建一个图。通常，这些森林图默认情况下看起来已经很不错了，但是该函数还有无数其他参数可以进一步调整外观。所有这些参数都在函数文档中进行了描述（可以通过运行 ?meta::forest 访问）。以下是更重要的参数的列表：\n\nsortvar。meta 分析数据集中用于在森林图中对研究进行排序的变量。例如，如果我们想按效应量对结果进行排序，可以使用代码 sortvar = TE。\ncomb.fixed。逻辑值，指示是否应在图中包含固定效应模型估计值。\ncomb.random。逻辑值，指示是否应在图中包含随机效应模型估计值。\ntext.fixed。根据固定效应模型合并效应的标签。默认情况下，打印 \"Fixed effect model\"。\ntext.random。根据随机效应模型合并效应的标签。默认情况下，打印 \"Random effects model\"。\nprediction。逻辑值，指示是否应将预测区间添加到图中。\nlabel.left 和 label.right。添加到森林图左侧和右侧的标签。这可以用于指定，例如，此侧的效应有利于治疗（例如，label.left = \"Favors treatment\"）。\nsmlab。显示在图顶部的标签。这可以用于显示使用了哪种效应量指标。\nxlim。x 轴的限制，或字符 “s” 以生成对称森林图。当您的结果与零有很大偏差，或者您还想描绘异常值时，此参数尤其相关。例如，如果我们希望 x 轴的范围为 0 到 2，则代码为 xlim = c(0,2)。\nref。图中的参考线。根据我们使用的汇总指标，默认情况下，此值为 0 或 1。\nleftcols 和 rightcols。在这里，您可以指定应在森林图的左侧和右侧显示哪些变量。该函数默认使用一些内置元素。例如，\"studlab\" 代表研究标签，\"effect\" 代表观察到的效应量，effect.ci 代表效应量及其置信区间。也可以添加用户定义的列，只要这些列包含在我们最初提供给 {meta} 函数的 data.frame 中。在这种情况下，我们只需要将列的名称添加为字符串即可。\nleftlabs 和 rightlabs。应用于森林图左侧和右侧显示的列的标签。\nprint.I2 和 print.I2.ci。逻辑值，指示是否应打印 \\(I^2\\) 值及其置信区间。默认情况下，此值为 TRUE。\nprint.tau2 和 print.tau。逻辑值，指示是否应打印 \\(\\tau^2\\) 和 \\(\\tau\\) 值。默认情况下，打印 \\(\\tau^2\\) 的值。\ncol.square、col.diamond 和 col.predict。正方形、菱形和预测区间的颜色（例如，\"blue\"）。\n\n现在是生成我们的第一个森林图的时候了。在此示例中，我们绘制了我们在前面的示例中也使用的 m.gen 对象。我们按效应量对森林图中的研究进行排序，添加预测区间，并在左侧添加用户定义的标签。meta::forest 函数默认打印 \\(\\tau^2\\) 值，我们在这里不需要它，因此我们将 print.tau2 设置为 FALSE。\n这是我们的代码最终的样子：\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"作者\", \"g\", \"SE\"))\n\n\n\n\n\n\n\n\n\n\nmeta::forest 为我们提供的图看起来已经相当不错了。我们还看到图中添加了一条细的黑线，表示我们合并效应周围的预测区间。\n\n我们可以通过添加一列显示每个研究的偏倚风险来增强该图。我们用于生成 m.gen 的 ThirdWave 数据集包含一列名为 RiskOfBias 的列，其中存储了每个研究的偏倚风险评估。\n当我们使用 metagen 计算 meta 分析（第 @ref(pre-calculated-es) 章）时，该函数会自动将此数据保存在 m.gen 中。因此，我们可以使用 leftcols 参数将该列添加到图中。这将导致以下代码：\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftcols = c(\"studlab\", \"TE\", \"seTE\", \"RiskOfBias\"),\n             leftlabs = c(\"作者\", \"g\", \"SE\", \"偏倚风险\"))\n\n\n\n\n\n\n\n\n\n\n我们看到，现在，每个研究的偏倚风险信息已添加到森林图中。\n\n\n\n\nmeta::forest 函数有两种“预先打包”的布局，我们可以使用它们将我们的森林图引入特定格式，而无需指定大量参数。其中之一是 \"JAMA\" 布局，它为我们提供了一个符合美国医学会杂志指南的森林图。如果您想在医学期刊上发表您的 meta 分析，可以使用此布局。\n\nmeta::forest(m.gen, layout = \"JAMA\")\n\n\n\n\n\n\n\n\n\n\n\n另一种布局是 \"RevMan5\"，它生成的森林图类似于 Cochrane 的 Review Manager 5 生成的森林图。\n\nmeta::forest(m.gen, layout = \"RevMan5\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n由 meta::forest 生成的森林图可以保存为 PDF、PNG 或可缩放矢量图形 (SVG) 文件。与其他通过基本 R 或 {ggplot2} 包生成的图不同，当我们将其另存为文件时，meta::forest 的输出不会自动重新缩放。这意味着森林图有时会在两个或四个侧面被截断，我们必须手动调整宽度和高度，以便所有内容都可见。\npdf、png 和 svg 函数可用于通过 R 代码保存图。我们必须从调用这些函数之一开始，该函数告诉 R 以下代码的输出应保存在文档中。然后，我们添加对 meta::forest 函数的调用。在最后一行，我们必须包含 dev.off()，它会将生成的输出保存到我们在上面指定的文件中。\n所有这三个函数都需要我们指定 file 参数，该参数应包含文件的名称。然后，该文件会自动保存在工作目录中，并使用该名称。此外，我们可以使用 width 和 height 参数来控制图的大小，这在输出被截断时可能会有所帮助。\n假设我们要将我们的初始森林图另存为“forestplot”，我们可以使用以下代码来生成 PDF、PNG 和 SVG 文件。\nPDF\n\npdf(file = \"forestplot.pdf\", width = 8, height = 7)\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"作者\", \"g\", \"SE\"))\n\ndev.off()\n\nPNG\n\npng(file = \"forestplot.png\", width = 2800, height = 2400, res = 300)\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"作者\", \"g\", \"SE\"))\n\ndev.off()\n\nSVG\n\nsvg(file = \"forestplot.svg\", width = 8, height = 7)\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"作者\", \"g\", \"SE\"))\n\ndev.off()",
    "crumbs": [
      "网站首页",
      "森林图"
    ]
  },
  {
    "objectID": "08-forestplots.html#drapery",
    "href": "08-forestplots.html#drapery",
    "title": "森林图",
    "section": "",
    "text": "到目前为止，森林图是可视化 meta 分析的最常见方法。大多数已发表的 meta 分析都包含森林图，并且许多研究人员都了解如何解释它们。建议您也在您的 meta 分析报告中包含一个森林图，因为森林图提供了对您的发现的全面且易于理解的摘要。\n但是，森林图并不是说明我们结果的唯一方法。例如，meta 分析也可以通过织锦图 [@rucker2020beyond] 可视化。森林图的一个缺点是，它们只能显示假设固定显着性阈值（通常为 \\(p&lt;\\) 0.05）的置信区间。正是基于这些置信区间，研究人员才能确定效应是否显着。\n近年来，围绕 \\(p\\) 值的使用一直存在争议 [@wellek2017critical]，并且有些人认为基于 \\(p\\) 值的假设检验导致了许多研究领域的“复制危机”[@nuzzo2014statistical]。\n织锦图基于 \\(p\\) 值函数。已经提出了这样的 \\(p\\) 值函数，以防止我们在解释分析结果时仅仅依赖于 \\(p\\)&lt;0.05 显着性阈值 [@infanger2019p]。\n因此，除了仅计算 95% 置信区间之外，\\(p\\) 值函数还提供了一条连续曲线，该曲线显示了 \\(p\\) 的不同值的置信区间。在织锦图中，为每个研究以及平均效应绘制一条置信曲线。x 轴显示效应量指标，y 轴显示假设的 \\(p\\) 值。\n可以通过 {meta} 中的 drapery 函数生成织锦图。与 meta::forest 一样，一旦我们为其提供 {meta} meta 分析对象，此函数就会自动生成图。还有一些其他参数，其中最重要的参数是：\n\ntype：定义要在 y 轴上绘制的值的类型。对于检验统计量，可以是 \"zvalue\"（默认值），也可以是 \\(p\\) 值 (\"pvalue\")。\nstudy.results：逻辑值，指示是否应在图中包含每个研究的结果。如果 FALSE，则仅打印汇总效应。\nlabels：当我们把这个参数设置为 \"studlab\"，研究标签将包含在图中。\nlegend：逻辑值，指示是否应打印图例。\npos.legend：图例的位置。可以是 \"bottomright\"、\"bottom\"、\"bottomleft\"、\"left\"、\"topleft\"、\"top\"、\"topright\"、\"right\" 或 \"center\"。\n\n让我们在一个示例中使用我们的 m.gen meta 分析对象来试用 drapery 函数。\n\ndrapery(m.gen, \n        labels = \"studlab\",\n        type = \"pval\", \n        legend = FALSE)\n\n\n\n\n\n\n\n\n\n\n生成的图包含每个效应量的 \\(p\\) 值曲线，所有曲线都呈倒 V 形。粗线表示根据随机效应模型的平均效应。我们在图中看到的阴影区域表示预测区间，该区间比合并效应的置信区间宽得多。\n\\(p\\) 值函数的“峰值”表示我们的 meta 分析中效应量的确切值。当我们沿着 y 轴向下移动时，\\(p\\) 值变得更小，并且置信区间越来越宽，直到我们达到由虚线水平线指示的常规显着性阈值。\n根据该图，我们看到我们可以非常确信合并效应量大于零，因为当 \\(p\\) 已经非常非常小（&lt;0.01）时，粗线在 x 轴上达到零。\nRücker 等人 [-@rucker2020beyond] 建议织锦图应主要除了森林图之外使用。简单地用织锦图代替森林图可能不是一个好主意，因为后者不包含其他方可能需要重现我们的结果的许多效应量信息。\n\\[\\tag*{$\\blacksquare$}\\]",
    "crumbs": [
      "网站首页",
      "森林图"
    ]
  },
  {
    "objectID": "08-forestplots.html#问题与解答",
    "href": "08-forestplots.html#问题与解答",
    "title": "森林图",
    "section": "",
    "text": "测试您的知识！\n\n\n\n森林图的关键组成部分是什么？\n\n\n\n\n展示我们的 meta 分析的森林图有什么优势？\n\n\n\n\n森林图的局限性是什么？织锦图如何克服这一局限性？\n\n\n\n这些问题的答案在本章末尾的 附录 A 中列出。",
    "crumbs": [
      "网站首页",
      "森林图"
    ]
  },
  {
    "objectID": "08-forestplots.html#总结",
    "href": "08-forestplots.html#总结",
    "title": "森林图",
    "section": "",
    "text": "习惯上通过森林图可视化 meta 分析的结果。\n森林图包含每个研究的效应量和置信区间的图形表示，并且还显示计算出的总体效应。此外，它们还包含用于合并的效应量数据。\n也可以将其他类型的信息添加到森林图中，例如每个研究收到的质量评级。\n森林图只能显示假设固定显着性阈值（通常为 \\(p&lt;\\) 0.05）的结果。为了可视化结果如何随不同的显着性阈值变化，可以另外生成织锦图。",
    "crumbs": [
      "网站首页",
      "森林图"
    ]
  },
  {
    "objectID": "08-forestplots.html#footnotes",
    "href": "08-forestplots.html#footnotes",
    "title": "森林图",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n在本章中，我们在调用 forest 函数时总是附加 meta::。这不是绝对必要的，但在实践中可能有时有助于避免错误消息（以及相关的混淆），因为 metafor 包中还有另一个 forest 函数，我们在这里不介绍。↩︎",
    "crumbs": [
      "网站首页",
      "森林图"
    ]
  },
  {
    "objectID": "10-metareg.html",
    "href": "10-metareg.html",
    "title": "Meta回归",
    "section": "",
    "text": "I 在上一章中，我们增加了亚组分析作为元分析“工具箱”中的一种新方法。正如我们所学到的，亚组分析将我们分析的重点从寻找一个总体效应转移开。相反，它们允许我们研究数据中异质性的模式，以及导致这些模式的原因。\n\n我们还提到亚组分析是 元回归 的一种特殊形式。您很可能以前听说过“回归”这个术语。回归分析是最常见的统计方法之一，被用于各个学科。在其最简单的形式中，回归模型试图使用某个变量 \\(x\\) 的值来预测另一个变量 \\(y\\) 的值。通常，回归模型基于包含个体或样本的数据，对于这些个体或样本，测量了 \\(x\\) 和 \\(y\\) 的值。\n\n在元回归中，这种逻辑被应用于 整个研究。变量 \\(x\\) 代表研究的特征，例如进行研究的年份。基于这些信息，元回归模型试图预测 \\(y\\)，即研究的效应量。然而，使用效应量作为预测变量这一事实增加了一些复杂性。\n在第 @ref(what-is-es) 章中，我们已经了解到观察到的效应量 \\(\\hat\\theta\\) 可能是研究真实效应的或多或少的 精确 估计量，这取决于它们的标准误差。在“正常”的元分析中，我们通过给予研究较小或较高的权重来考虑到这一点。在元回归中，我们还必须确保模型更加关注抽样误差较低的研究，因为我们可以假设它们的估计值更接近“真相”。\n\n元回归通过假设一个 混合效应模型 来实现这一点。该模型解释了观察到的研究由于抽样误差和研究间异质性而偏离真实总体效应的事实。然而，更重要的是，它还使用一个或多个变量 \\(x\\) 来预测真实效应量中的差异。我们已经在上一章中提到亚组分析也基于混合效应模型。在本章中，我们将深入探讨一下，并讨论为什么亚组分析和元回归本质上是相关的。\n元回归虽然有其自身的局限性，但在元分析中可能是一种非常强大的工具。它也用途广泛：例如，多元元回归 允许我们不仅包括一个，而是包括几个预测变量，以及它们的交互作用。因此，在本章的第二部分，我们还将了解多元元回归，以及如何使用 R 进行分析。\n\n\n\n\n过去，您可能已经使用主要研究数据执行过回归，其中参与者是分析的单位。在元分析中，通常无法获得每个参与者的个人数据，我们只能求助于汇总结果。这就是为什么我们必须使用 研究层面 的预测变量来进行元回归。\n这也意味着，虽然我们对样本进行分析，其样本量远大于主要研究的通常样本量，但我们仍然可能没有足够的数据点来使元回归有用。在第 @ref(limits-subgroup) 章中，我们已经介绍了当 \\(K&lt;\\) 10 时，亚组分析通常没有意义。Borenstein 及其同事 [-@borenstein2011introduction, 第 20 章] 提到，该指导原则也可以应用于元回归模型，但不应将其视为铁律。\n在传统的回归中，我们想要使用具有回归系数 \\(\\beta\\) 的 预测变量 (或 协变量) \\(x_i\\) 来估计人 \\(i\\) 的值 \\(y_i\\)。因此，标准的回归方程如下所示：\n\\[\\begin{equation}\n\\hat{y_i} = \\beta_0 + \\beta_1x_i\n(\\#eq:mr1)\n\\end{equation}\\]\n在元回归中，我们想要预测的变量 \\(y\\) 是研究 \\(k\\) 的观察到的效应量 \\(\\hat\\theta_k\\)。元回归 的公式与普通回归模型的公式相似：\n\\[\\begin{equation}\n\\hat\\theta_k = \\theta + \\beta x_{k} + \\epsilon_k+\\zeta_k\n(\\#eq:mr2)\n\\end{equation}\\]\n请注意，此公式包含两个额外的项，\\(\\epsilon_k\\) 和 \\(\\zeta_k\\)。在随机效应模型 (第 @ref(rem) 章) 的公式中也可以找到相同的项，并且表示两种类型的独立误差。第一个误差 \\(\\epsilon_k\\) 是抽样误差，通过该抽样误差，研究的效应量偏离了其真实效应。\n第二个误差 \\(\\zeta_k\\) 表示即使研究的真实效应量也仅是从效应量的一个总体分布中抽样的。这意味着我们的数据中存在研究间异质性，异质性方差 \\(\\tau^2\\) 捕捉了这一点。\n \n由于上面的公式包含一个 固定 效应 (\\(\\beta\\) 系数) 以及一个 随机 效应 (\\(\\zeta_k\\))，因此元回归中使用的模型通常被称为 混合效应模型。从概念上讲，该模型与我们在第 @ref(comparing-the-subgroup-effects) 章中描述的混合效应模型相同，我们在该章中解释了亚组分析如何工作。\n\n\n\n\n\n实际上，正如之前提到的，亚组分析只不过是用分类预测变量进行的元回归。这种分类变量可以通过 虚拟编码 来包括，例如：\n\\[\\begin{equation}\n  D_g=\\begin{cases}\n    0: & \\text{亚组 A}\\\\\n    1: & \\text{亚组 B.}\n  \\end{cases}\n  (\\#eq:mr3)\n\\end{equation}\\]\n要以元回归的形式指定亚组分析，我们只需将协变量 \\(x_k\\) 替换为 \\(D_g\\)：\n\\[\\begin{equation}\n\\hat\\theta_k = \\theta + \\beta D_g +\\epsilon_k+\\zeta_k.\n(\\#eq:mr4)\n\\end{equation}\\]\n要理解这个公式，我们必须从左到右阅读它。与每个统计模型一样，元回归模型的目标是解释观察到的数据是如何生成的。在我们的例子中，这是我们的元分析中某个研究 \\(k\\) 的观察到的效应量 \\(\\hat\\theta_k\\)。上面的公式就像一个食谱，告诉我们产生观察到的效应量需要哪些成分。\n首先，我们取 \\(\\theta\\)，它充当我们的回归模型中的 截距。\\(\\theta\\) 的值与亚组 A 的真实总体效应量相同。要了解为什么会这样，我们需要查看下一个“成分”，即项 \\(\\beta D_g\\)。此项中的 \\(\\beta\\) 值表示亚组 A 和亚组 B 之间的效应量差异 \\(\\theta_{\\Delta}\\)。\\(\\beta\\) 的值乘以 \\(D_g\\)，它可以是 0 或 1，具体取决于研究是亚组 A (\\(D_g = 0\\)) 还是亚组 B (\\(D_g = 1\\)) 的一部分。\n由于乘以零得到零，因此当我们处理亚组 A 中的研究时，\\(\\beta D_g\\) 项完全从方程中消失了。另一方面，当 \\(D_g=1\\) 时，我们乘以 1，这意味着 \\(\\beta\\) 留在方程中并添加到 \\(\\theta\\)，这为我们提供了亚组 B 中的总体效应量。从本质上讲，虚拟预测变量是将 两个 公式集成到 一个 公式中的一种方法。当我们分别为每个亚组写下公式时，我们可以很容易地看到这一点：\n\\[\\begin{equation}\n  D_g=\\begin{cases}\n    0: & \\text{$\\hat\\theta_k = \\theta_A + \\epsilon_k+\\zeta_k$}\\\\\n    1: & \\text{$\\hat\\theta_k = \\theta_A + \\theta_{\\Delta} +\\epsilon_k+\\zeta_k$}\n  \\end{cases}\n  (\\#eq:mr5)\n\\end{equation}\\]\n以这种方式编写，可以更清楚地看到我们的公式实际上包含两个模型，一个用于亚组 A，一个用于亚组 B。模型之间的主要区别在于，第二个亚组的效应根据 \\(\\beta\\) 的值（我们在上面的公式中表示为 \\(\\theta_{\\Delta}\\)）向上或向下“移动”。\n\n\n\n\n\n具有分类预测变量的元回归（亚组分析）。\n\n\n\n\n这应该清楚地表明，亚组分析的工作方式就像普通的回归一样：它们使用某个变量 \\(x\\) 来预测 \\(y\\) 的值，在我们的例子中，它是研究的效应量。特别之处在于 \\(\\beta x_k\\) 不是连续的——这是一个固定值，我们根据研究是否属于某个亚组来添加到预测中。\\(\\beta\\) 的这个固定值是两个亚组之间效应量估计的差异。\n\n\n\n\n\n\n然而，当人们谈论“元回归”时，他们通常会想到使用 连续 变量作为预测变量的模型。这使我们回到方程 8.2 中所示的通用元回归公式。在这里，我们之前讨论过的回归项也被使用，但它们的目的略有不同。\\(\\theta\\) 项再次代表截距，但现在代表当 \\(x = 0\\) 时的预测效应量。\n截距加上了项 \\(\\beta x_k\\)。这一部分产生一个 回归斜率：连续变量 \\(x\\) 乘以 回归权重 \\(\\beta\\)，从而降低或提高协变量不同值的预测效应。\n元回归模型的目标是找到 \\(\\theta\\) 和 \\(\\beta\\) 的值，这些值可以最小化 预测 效应量与研究的 真实 效应量之间的差异 (参见图 @ref(fig:subgroups3))。\n\n\n\n\n\n具有连续预测变量和四项研究的元回归。\n\n\n\n\n仔细观察元回归公式，我们看到它包含两种类型的项。有些项包含下标 \\(k\\)，而另一些则不包含。下标 \\(k\\) 表示一个值在研究之间 变化。当一个项不包含下标 \\(k\\) 时，这意味着它对于所有研究保持不变。\n\n\n\n\n\n\n\n\n\n在元回归中，\\(\\theta\\) 和 \\(\\beta\\) 都是不变的，或固定的。这告诉我们元回归的作用：基于预测变量的变化和观察到的效应，它试图以 回归线 的形式“提炼”出我们数据的基础 固定模式。如果元回归模型与数据拟合良好，则可以使用估计的参数 \\(\\theta\\) 和 \\(\\beta\\) 来预测模型 以前从未见过 的研究的效应量 (前提是我们知道 \\(x\\))。\n考虑到抽样误差 \\(\\epsilon_k\\) 和研究间异质性 \\(\\zeta_k\\)，元回归因此试图找到一个 泛化 良好的模型；不仅适用于观察到的效应量，还适用于所有可能感兴趣的研究的“宇宙”。\n\n\n\n\n\n关于元回归模型的一个重要细节是，它们可以被视为我们用来汇集效应量的“正常”随机效应模型的扩展。随机效应模型只不过是一个 没有斜率项 的元回归模型。由于它不包含斜率，因此随机效应模型仅预测每个研究的 相同值：汇集效应量 \\(\\mu\\) 的估计值，该估计值与截距等效。\n \n因此，在第一步中，元回归的计算与随机效应元分析的计算非常相似，因为使用我们在第 @ref(tau-estimators) 章中描述的方法之一 (例如，DerSimonian-Laird 或 REML 方法) 估计了研究间异质性 \\(\\tau^2\\)。在下一步中，估计固定权重 \\(\\theta\\) 和 \\(\\beta\\)。正常的线性回归模型使用 普通最小二乘法 (OLS) 来找到最适合数据的回归线。在元回归中，使用一种称为 加权最小二乘法 (WLS) 的修改方法，该方法确保标准误差较小的研究获得较高的权重。\n找到最佳解决方案后，我们可以检查新添加的回归项是否解释了效应量异质性的部分。如果元回归模型与数据拟合良好，则与汇集效应 \\(\\hat\\mu\\) 相比，真实效应量应更少地偏离回归线。如果是这种情况，则预测变量 \\(x\\) 解释 了我们元分析中的一些异质性方差。\n\n\n\n\n\n\n\n\n\n因此，可以通过检查它解释了多少异质性方差来评估元回归模型的拟合度。混合效应模型中包含的预测变量应最小化 残差 或未解释的异质性方差量，我们用 \\(\\tau^2_{\\text{unexplained}}\\) 表示。\n在回归分析中，通常使用 \\(R^2\\) 指数来量化模型解释的变异百分比。对于元回归，也可以计算一个类似的指数 \\(R^2_{*}\\)。我们在此处添加一个星号，以表明元回归中的 \\(R^2\\) 与传统回归中使用的 \\(R^2\\) 略有不同，因为我们处理的是 真实效应量 而不是观察到的数据点。\\(R^2_*\\) 的公式如下所示：\n\\[\\begin{equation}\nR^2_* = 1- \\frac{\\hat\\tau^2_{\\text{unexplained}}}{\\hat\\tau^2_{\\text{(total)}}}\n(\\#eq:mr6)\n\\end{equation}\\]\n\\(R^2_*\\) 使用了即使元回归斜率也无法解释的残余异质性方差量，并将其与我们最初在元分析中发现的总异质性相关联。从 1 中减去该分数后，我们可以得到预测变量解释的研究间异质性的百分比。\n还有另一种表示 \\(R^2_*\\) 的方法。我们可以说它表示与初始随机效应汇集模型相比，混合效应模型 减少 了多少异质性方差，以百分比表示。这将产生以下公式：\n\\[\\begin{equation}\nR^2_* =  \\frac{\\hat\\tau^2_{\\text{REM}}-\\hat\\tau^2_{\\text{MEM}}}{\\hat\\tau^2_{\\text{REM}}}\n(\\#eq:mr7)\n\\end{equation}\\]\n在此公式中，\\(\\hat\\tau^2_{\\text{REM}}\\) 表示在随机效应汇集模型中发现的研究间异质性的量，\\(\\hat\\tau^2_{\\text{MEM}}\\) 表示混合效应元回归模型中的 (残余) 方差 (即，关于真实效应量的“预测误差”)。\n\n通常，我们不仅对回归模型解释的异质性量感兴趣，还对我们的预测变量 \\(x\\) 的回归权重是否显着感兴趣。如果是这种情况，我们可以非常有把握地认为 \\(x\\) 对研究的效应量有影响。在传统回归和元回归中，通常通过 Wald 型 检验来评估回归权重的显着性。这涉及通过将其标准误差除以 \\(\\beta\\) 的估计值来计算检验统计量 \\(z\\)：\n\\[\\begin{equation}\nz = \\frac{\\hat\\beta}{SE_{\\hat\\beta}}\n(\\#eq:mr8)\n\\end{equation}\\]\n在 \\(\\beta = 0\\) 的原假设下，此 \\(z\\) 统计量服从标准正态分布。这使我们能够计算相应的 \\(p\\) 值，该值确定预测变量是否显着。\n然而，基于 \\(z\\) 统计量的检验并不是评估预测变量显着性的唯一方法。与正常的元分析模型一样，我们也可以使用 Knapp-Hartung 调整，这会导致基于 \\(t\\) 分布的检验统计量 (参见第 @ref(knapp-hartung) 章)。正如我们之前所了解的，通常建议使用 Knapp-Hartung 方法，因为它降低了误报的风险。\n\n\n\n\n\n\n{meta} 包包含一个名为 metareg 的函数，该函数允许我们进行元回归。metareg 函数只需要一个 {meta} 元分析对象和一个协变量的名称作为输入。\n在此示例中，我们将再次使用我们的 m.gen 元分析对象，该对象基于 ThirdWave 数据集 (参见第 @ref(pre-calculated-es) 章)。使用元回归，我们想要检查研究的 发表年份 是否可用于预测其效应量。默认情况下，ThirdWave 数据集不包含存储发表年份的变量，因此我们必须创建一个新的 numeric 变量，其中包含此信息。我们只需连接所有研究的发表年份，其顺序与它们在 ThirdWave 数据集中出现的顺序相同。我们将此变量保存在名称 year 下1。\n\nyear &lt;- c(2014, 1998, 2010, 1999, 2005, 2014, \n          2019, 2010, 1982, 2020, 1978, 2001,\n          2018, 2002, 2009, 2011, 2011, 2013)\n\n现在，我们拥有运行元回归所需的所有信息。在 metareg 函数中，我们将我们的元分析对象 m.gen 的名称指定为第一个参数，并将我们的预测变量 year 的名称指定为第二个参数。我们将结果命名为 m.gen.reg。\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.1-0).\nType 'help(meta)' for a brief overview.\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\ndata(ThirdWave)\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = ThirdWave,\n                 sm = \"SMD\",\n                 comb.fixed = FALSE,\n                 comb.random = TRUE,\n                 method.tau = \"REML\",\n                 method.random.ci = \"HK\",\n                 title = \"Third Wave Psychotherapies\")\n\nWarning: Use argument 'common' instead of 'comb.fixed' (deprecated).\n\n\nWarning: Use argument 'random' instead of 'comb.random' (deprecated).\n\nm.gen.reg &lt;- metareg(m.gen, ~year)\n\n现在，让我们看一下结果：\n\nm.gen.reg\n\n## Mixed-Effects Model (k = 18; tau^2 estimator: REML)\n## \n## tau^2 (estimated amount of residual heterogeneity):     0.019 (SE = 0.023)\n## tau (square root of estimated tau^2 value):             0.1371\n## I^2 (residual heterogeneity / unaccounted variability): 29.26%\n## H^2 (unaccounted variability / sampling variability):   1.41\n## R^2 (amount of heterogeneity accounted for):            77.08%\n## \n## Test for Residual Heterogeneity:\n## QE(df = 16) = 27.8273, p-val = 0.0332\n## \n## Test of Moderators (coefficient 2):\n## F(df1 = 1, df2 = 16) = 9.3755, p-val = 0.0075\n## \n## Model Results:\n## \n##         estimate     se   tval   pval    ci.lb    ci.ub \n## intrcpt   -36.15  11.98  -3.01  0.008  -61.551  -10.758  ** \n## year        0.01   0.00   3.06  0.007    0.005    0.031  ** \n## \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n让我们回顾一下我们在这里可以看到的内容。在第一行中，输出告诉我们一个混合效应模型已拟合到数据，正如预期的那样。接下来的几行提供了有关模型解释的异质性量的详细信息。我们看到残余异质性方差 (未被预测变量解释的方差) 的估计值为 \\(\\hat\\tau^2_{\\text{unexplained}}=\\) 0.019。\n输出还为我们提供了一个 \\(I^2\\) 等效值，该值告诉我们，在包含预测变量后，我们数据中 29.26% 的变异性可归因于剩余的研究间异质性。在正常的随机效应元分析模型中，我们发现 \\(I^2\\) 异质性为 63%，这意味着该预测变量能够“解释掉”真实效应量差异的相当一部分。\n在最后一行中，我们看到 \\(R^2_*\\) 的值，在本示例中为 77%。这意味着真实效应量差异的 77% 可以通过发表年份来解释，这是一个相当大的值。\n下一部分包含“残余异质性检验”，这本质上是我们之前已经了解的 \\(Q\\) 检验 (参见第 @ref(cochran-q) 章)。但是，现在，我们测试未被预测变量解释的异质性是否显着。我们看到情况就是这样，其中 \\(p\\) = 0.03。但是，我们知道 \\(Q\\) 检验的局限性 (第 @ref(cochran-q) 章)，因此不应过分依赖此结果。\n下一部分显示“调节变量检验”。我们看到此检验也很显着 (\\(p\\) = 0.0075)。这意味着我们的预测变量 (发表年份) 确实会影响研究的效应量。\n最后一部分提供了有关估计的回归系数的更多详细信息。第一行显示截距 (intrcpt) 的结果。当我们的预测变量发表年份为零时，这是预期的效应量 (在我们的例子中：Hedges 的 \\(g\\))。在我们的示例中，这代表了一种可以说的有点人为的情况：它显示了在第 0 年进行的研究的预测效应，为 \\(\\hat{g}=\\) -36.15。这再次提醒我们，好的统计模型不必是现实的完美表示；它们只需要 有用。\n我们主要感兴趣的系数是第二行中的系数。我们看到该模型对 year 的回归权重的估计值为 0.01。这意味着对于每增加一年，预计研究的效应量 \\(g\\) 将增加 0.01。因此，我们可以说研究的效应量随着时间的推移而增加。95% 的置信区间范围为 0.005 到 0.3，表明该效应很显着。\n重要的是，我们还获得了每个回归系数的相应 \\(t\\) 统计量 (tval)。这告诉我们 Knapp-Hartung 方法用于计算置信区间和 \\(p\\) 值。由于我们也在最初的元分析模型中使用了此调整，因此 metareg 会自动在此处再次使用它。否则，将提供 \\(z\\) 值和 Wald 型置信区间。\n\n{meta} 包允许我们使用 bubble 函数可视化元回归。这将创建一个 气泡图，该图显示估计的回归斜率以及每个研究的效应量。为了指示研究的权重，气泡具有不同的大小，较大的大小表示较高的权重。\n要生成气泡图，我们只需将我们的元回归对象插入 bubble 函数即可。因为我们也希望显示研究标签，所以我们将 studlab 设置为 TRUE。\n\nbubble(m.gen.reg, studlab = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n为了完整起见，我们还可以尝试重复上一章 (第 @ref(subgroup-R) 章) 中的亚组分析，但这次在元回归框架内。这意味着我们使用偏倚风险评估作为分类预测变量。由于变量 RiskOfBias 已经包含在 ThirdWave 数据集中，因此我们不必将此信息保存在额外的对象中。只需再次运行 metareg 函数就足够了，但这次，我们使用 RiskOfBias 作为第二个函数参数。\n\nmetareg(m.gen, RiskOfBias)\n\n## [...]\n## R^2 (amount of heterogeneity accounted for):            15.66%\n## \n## Test for Residual Heterogeneity:\n## QE(df = 16) = 39.3084, p-val = 0.0010\n## \n## Test of Moderators (coefficient 2):\n## F(df1 = 1, df2 = 16) = 2.5066, p-val = 0.1329\n## \n## Model Results:\n## \n##               estimate    se   tval    pval  ci.lb ci.ub \n## intrcpt           0.76  0.15   5.00  0.0001   0.44  1.09  *** \n## RiskOfBiaslow    -0.29  0.18  -1.58  0.1329  -0.69  0.10      \n## [...]\n\n在输出中，我们看到 \\(R^2_*\\) 的值 (15.66%) 远小于 year 的值。与我们之前的结果一致，我们看到偏倚风险变量不是显着的效应量预测变量 (\\(p\\) = 0.13)。\n在 Model Results 下，我们看到 metareg 已自动将 RiskOfBias 转换为虚拟变量。表示“高风险”亚组的汇集效应的截距估计值为 \\(g\\)=0.76。表示具有 低 偏倚风险的研究的回归系数的估计值为 -0.29。\n为了获得此亚组的效应量，我们必须将回归权重添加到截距，这将导致 \\(g=\\) 0.76 - 0.29 \\(\\approx\\) 0.47。这些结果与假设 \\(\\tau^2\\) 的共同估计值的亚组分析的结果相同。\n\n\n\n\n\n\n之前，我们只考虑了在我们的元回归模型中使用 一个 预测变量 \\(\\beta x_k\\) 的情况。在该示例中，我们检查了研究的效应量是否取决于发表年份。但是现在，假设报告的效应量也取决于研究发表的科学期刊的 声誉。我们认为，在高声誉期刊上的研究可能会报告更高的效应。这可能是因为享有盛誉的期刊更具选择性，并且主要发表具有“突破性”发现的研究。\n另一方面，信誉良好的期刊通常发表 更高质量 的研究也是合理的。也许仅仅是更好的研究质量与更高的效应量相关。因此，为了检查期刊声誉是否确实与更高的效应相关，我们必须确保这种关系不会因享有盛誉的期刊更有可能发表高质量证据的事实而 混淆。这意味着我们在检查期刊声誉与效应量之间的关系时，必须 控制 研究质量。\n这个问题以及许多其他研究问题都可以使用 多元元回归 来处理。在多元元回归中，我们使用多个预测变量而不是仅使用一个来解释效应的变化。为了允许使用多个预测变量，我们需要修改我们之前的元回归公式 (参见方程 8.2)，使其如下所示：\n\\[\\begin{equation}\n\\hat \\theta_k = \\theta + \\beta_1x_{1k} + ... + \\beta_nx_{nk} + \\epsilon_k + \\zeta_k\n(\\#eq:mr10)\n\\end{equation}\\]\n此公式告诉我们可以向我们的元回归模型添加 \\(n-1\\) 个以上的预测变量 \\(x\\)，从而将其转换为多元元回归。公式中的三个点表示从理论上讲，我们可以根据需要添加任意数量的预测变量。然而，在现实中，事情通常更棘手。在下文中，我们将讨论多元元回归中的一些重要陷阱，以及如何构建稳健且值得信赖的模型。但首先，让我们介绍多元元回归的另一个重要特征，交互作用。\n\n\n\n\n\n到目前为止，我们仅考虑了在我们的模型中具有多个预测变量 \\(x_1, x_2, \\dots x_n\\) 的情况，这些预测变量与它们的回归权重 \\(\\beta\\) 一起加在一起。然而，多元元回归模型不仅限于这种 加法 关系。它们还可以对预测变量 交互作用 进行建模。交互作用意味着一个预测变量 (例如，\\(x_1\\)) 和估计的效应量之间的 关系 对于另一个协变量 (例如，\\(x_2\\)) 的不同值会 改变。\n假设我们想要对两个预测变量以及它们与效应量的关联方式进行建模：研究的发表年份 (\\(x_1\\)) 和质量 (\\(x_2\\))。研究质量的编码如下：\n\\[\\begin{equation}\n  x_2=\\begin{cases}\n    0: & \\text{低}\\\\\n    1: & \\text{中等}\\\\\n    2: & \\text{高.}\n  \\end{cases}\n  (\\#eq:mr11)\n\\end{equation}\\]\n当我们假设发表年份和研究质量之间没有交互作用时，我们可以通过为 \\(x_1\\) 和 \\(x_2\\) 都赋予一个回归权重 \\(\\beta\\)，并在我们的公式中 添加 这些项来构建元回归模型：\n\\[\\begin{equation}\n\\hat \\theta_k = \\theta + \\beta_1x_{1k} + \\beta_2x_{2k} + \\epsilon_k + \\zeta_k\n(\\#eq:mr12)\n\\end{equation}\\]\n但是，如果 \\(x_1\\) 和 \\(x_2\\) 之间的关系更复杂呢？与我们之前的示例一样，发表年份越近，效应越高，这是有可能的。但并非所有研究都必须遵循这一趋势。也许这种增长在高质量研究中最为明显，而低质量研究的结果随着时间的推移基本上保持不变。我们可以通过以下方式可视化效应量 (\\(\\hat\\theta_k\\))、发表年份 (\\(x_1\\)) 和研究质量 (\\(x_2\\)) 之间假设的关系：\n\n\n\n\n\n\n\n\n\n该图显示了交互作用的经典示例。我们看到回归斜率的陡峭程度取决于另一个预测变量的值。虽然高质量研究的斜率非常陡峭，表明年份和效应之间存在很强的关系，但低质量研究的情况有所不同。该亚组中的回归线几乎是水平的，表明发表年份对结果没有影响，甚至有轻微的负面影响。\n此示例显示了交互作用的优势之一：它们允许我们检查预测变量的影响在所有研究中是否相同，或者它是否受到另一个特征的调节。\n为了通过元回归评估交互作用，我们需要向模型中添加一个 交互项。在我们的示例中，这可以通过添加第三个回归权重 \\(\\beta_3\\) 来实现，该权重捕获我们想要在模型中测试的交互作用 \\(x_{1k}x_{2k}\\)。这给出了以下公式：\n\\[\\begin{equation}\n\\hat \\theta_k = \\theta + \\beta_1x_{1k} + \\beta_2x_{2k} + \\beta_3x_{1k}x_{2k}+ \\epsilon_k + \\zeta_k\n(\\#eq:mr13)\n\\end{equation}\\]\n虽然线性多元元回归模型仅包含这些简单的构建块，但它们适用于各种应用。但是，在我们开始使用 R 拟合多元元回归之前，我们应该首先考虑它们的局限性和陷阱。\n\n\n\n\n\n多元元回归虽然在正确应用时非常有用，但存在一定的注意事项。有些人认为，在实践中经常不正确地使用和解释 (多元) 元回归，导致结果的有效性较低 [@higgins2004controlling]。在拟合多元元回归模型时，我们必须牢记一些要点，我们将在下文中介绍。\n\n\n\n\n\n为了更好地理解 (多元) 元回归模型的风险，我们必须理解 过拟合 的概念。当我们构建一个与数据 过于 紧密拟合的统计模型时，就会发生过拟合。从本质上讲，这意味着我们构建了一个统计模型，它可以 非常 好地预测 手头 的数据，但在预测 未来 数据方面表现不佳。\n当我们的模型假设我们数据中的某些变化来自真实的“信号”时，实际上我们只捕获了随机噪声 [@iniesta2016machine]，就会发生这种情况。因此，该模型会产生 假阳性 结果：它会在没有关系的地方看到关系。\n\n\n\n\n\n过拟合模型与具有稳健拟合的模型相比的预测。\n\n\n\n\n \n对于模型拟合，回归使用 优化 技术，例如普通最小二乘法或最大似然估计。正如我们所了解的，元回归使用加权版本的普通最小二乘法 (参见第 @ref(metareg-model-fit) 章)，因此也不例外。\n然而，这种“贪婪”的优化意味着回归方法可能容易过度拟合 [@gigerenzer2004mindless]。不幸的是，一旦我们从传统回归过渡到元回归，构建非稳健模型的风险就会更高。出现这种情况有几个原因 [@higgins2004controlling]：\n\n在元回归中，数据点的数量通常很小，因为我们只能使用包含研究的汇总信息。\n由于元分析旨在全面概述所有可用的证据，因此我们没有额外的数据可以用来“测试”我们的回归模型在预测未见数据方面的表现如何。\n在元回归中，我们必须处理效应量异质性的潜在存在。想象一下，我们有两个具有不同效应量和非重叠置信区间的研究的情况。对于这两项研究具有不同值的每个变量都可能是效应量差异的潜在解释。然而，似乎很明显，这些解释中的大多数将是虚假的。\n元回归通常，尤其是多元元回归，可以非常容易地“摆弄”预测变量。我们可以测试许多元回归模型，包括更多预测变量或删除它们，以尝试解释我们数据中的异质性。这种方法很诱人，并且在实践中经常发现，因为元分析师想要找到效应量不同的原因 [@higgins2002statistical]。然而，这种行为已被证明会大大增加虚假发现的风险，因为我们可以无限期地更改我们模型的各个部分，直到我们找到一个显着的模型，该模型很可能被过度拟合 (即，它主要模拟统计噪声)。\n\n已经提出了一些指导原则，以避免",
    "crumbs": [
      "网站首页",
      "Meta回归"
    ]
  },
  {
    "objectID": "10-metareg.html#the-metareg-model",
    "href": "10-metareg.html#the-metareg-model",
    "title": "Meta回归",
    "section": "",
    "text": "过去，您可能已经使用主要研究数据执行过回归，其中参与者是分析的单位。在元分析中，通常无法获得每个参与者的个人数据，我们只能求助于汇总结果。这就是为什么我们必须使用 研究层面 的预测变量来进行元回归。\n这也意味着，虽然我们对样本进行分析，其样本量远大于主要研究的通常样本量，但我们仍然可能没有足够的数据点来使元回归有用。在第 @ref(limits-subgroup) 章中，我们已经介绍了当 \\(K&lt;\\) 10 时，亚组分析通常没有意义。Borenstein 及其同事 [-@borenstein2011introduction, 第 20 章] 提到，该指导原则也可以应用于元回归模型，但不应将其视为铁律。\n在传统的回归中，我们想要使用具有回归系数 \\(\\beta\\) 的 预测变量 (或 协变量) \\(x_i\\) 来估计人 \\(i\\) 的值 \\(y_i\\)。因此，标准的回归方程如下所示：\n\\[\\begin{equation}\n\\hat{y_i} = \\beta_0 + \\beta_1x_i\n(\\#eq:mr1)\n\\end{equation}\\]\n在元回归中，我们想要预测的变量 \\(y\\) 是研究 \\(k\\) 的观察到的效应量 \\(\\hat\\theta_k\\)。元回归 的公式与普通回归模型的公式相似：\n\\[\\begin{equation}\n\\hat\\theta_k = \\theta + \\beta x_{k} + \\epsilon_k+\\zeta_k\n(\\#eq:mr2)\n\\end{equation}\\]\n请注意，此公式包含两个额外的项，\\(\\epsilon_k\\) 和 \\(\\zeta_k\\)。在随机效应模型 (第 @ref(rem) 章) 的公式中也可以找到相同的项，并且表示两种类型的独立误差。第一个误差 \\(\\epsilon_k\\) 是抽样误差，通过该抽样误差，研究的效应量偏离了其真实效应。\n第二个误差 \\(\\zeta_k\\) 表示即使研究的真实效应量也仅是从效应量的一个总体分布中抽样的。这意味着我们的数据中存在研究间异质性，异质性方差 \\(\\tau^2\\) 捕捉了这一点。\n \n由于上面的公式包含一个 固定 效应 (\\(\\beta\\) 系数) 以及一个 随机 效应 (\\(\\zeta_k\\))，因此元回归中使用的模型通常被称为 混合效应模型。从概念上讲，该模型与我们在第 @ref(comparing-the-subgroup-effects) 章中描述的混合效应模型相同，我们在该章中解释了亚组分析如何工作。\n\n\n\n\n\n实际上，正如之前提到的，亚组分析只不过是用分类预测变量进行的元回归。这种分类变量可以通过 虚拟编码 来包括，例如：\n\\[\\begin{equation}\n  D_g=\\begin{cases}\n    0: & \\text{亚组 A}\\\\\n    1: & \\text{亚组 B.}\n  \\end{cases}\n  (\\#eq:mr3)\n\\end{equation}\\]\n要以元回归的形式指定亚组分析，我们只需将协变量 \\(x_k\\) 替换为 \\(D_g\\)：\n\\[\\begin{equation}\n\\hat\\theta_k = \\theta + \\beta D_g +\\epsilon_k+\\zeta_k.\n(\\#eq:mr4)\n\\end{equation}\\]\n要理解这个公式，我们必须从左到右阅读它。与每个统计模型一样，元回归模型的目标是解释观察到的数据是如何生成的。在我们的例子中，这是我们的元分析中某个研究 \\(k\\) 的观察到的效应量 \\(\\hat\\theta_k\\)。上面的公式就像一个食谱，告诉我们产生观察到的效应量需要哪些成分。\n首先，我们取 \\(\\theta\\)，它充当我们的回归模型中的 截距。\\(\\theta\\) 的值与亚组 A 的真实总体效应量相同。要了解为什么会这样，我们需要查看下一个“成分”，即项 \\(\\beta D_g\\)。此项中的 \\(\\beta\\) 值表示亚组 A 和亚组 B 之间的效应量差异 \\(\\theta_{\\Delta}\\)。\\(\\beta\\) 的值乘以 \\(D_g\\)，它可以是 0 或 1，具体取决于研究是亚组 A (\\(D_g = 0\\)) 还是亚组 B (\\(D_g = 1\\)) 的一部分。\n由于乘以零得到零，因此当我们处理亚组 A 中的研究时，\\(\\beta D_g\\) 项完全从方程中消失了。另一方面，当 \\(D_g=1\\) 时，我们乘以 1，这意味着 \\(\\beta\\) 留在方程中并添加到 \\(\\theta\\)，这为我们提供了亚组 B 中的总体效应量。从本质上讲，虚拟预测变量是将 两个 公式集成到 一个 公式中的一种方法。当我们分别为每个亚组写下公式时，我们可以很容易地看到这一点：\n\\[\\begin{equation}\n  D_g=\\begin{cases}\n    0: & \\text{$\\hat\\theta_k = \\theta_A + \\epsilon_k+\\zeta_k$}\\\\\n    1: & \\text{$\\hat\\theta_k = \\theta_A + \\theta_{\\Delta} +\\epsilon_k+\\zeta_k$}\n  \\end{cases}\n  (\\#eq:mr5)\n\\end{equation}\\]\n以这种方式编写，可以更清楚地看到我们的公式实际上包含两个模型，一个用于亚组 A，一个用于亚组 B。模型之间的主要区别在于，第二个亚组的效应根据 \\(\\beta\\) 的值（我们在上面的公式中表示为 \\(\\theta_{\\Delta}\\)）向上或向下“移动”。\n\n\n\n\n\n具有分类预测变量的元回归（亚组分析）。\n\n\n\n\n这应该清楚地表明，亚组分析的工作方式就像普通的回归一样：它们使用某个变量 \\(x\\) 来预测 \\(y\\) 的值，在我们的例子中，它是研究的效应量。特别之处在于 \\(\\beta x_k\\) 不是连续的——这是一个固定值，我们根据研究是否属于某个亚组来添加到预测中。\\(\\beta\\) 的这个固定值是两个亚组之间效应量估计的差异。\n\n\n\n\n\n\n然而，当人们谈论“元回归”时，他们通常会想到使用 连续 变量作为预测变量的模型。这使我们回到方程 8.2 中所示的通用元回归公式。在这里，我们之前讨论过的回归项也被使用，但它们的目的略有不同。\\(\\theta\\) 项再次代表截距，但现在代表当 \\(x = 0\\) 时的预测效应量。\n截距加上了项 \\(\\beta x_k\\)。这一部分产生一个 回归斜率：连续变量 \\(x\\) 乘以 回归权重 \\(\\beta\\)，从而降低或提高协变量不同值的预测效应。\n元回归模型的目标是找到 \\(\\theta\\) 和 \\(\\beta\\) 的值，这些值可以最小化 预测 效应量与研究的 真实 效应量之间的差异 (参见图 @ref(fig:subgroups3))。\n\n\n\n\n\n具有连续预测变量和四项研究的元回归。\n\n\n\n\n仔细观察元回归公式，我们看到它包含两种类型的项。有些项包含下标 \\(k\\)，而另一些则不包含。下标 \\(k\\) 表示一个值在研究之间 变化。当一个项不包含下标 \\(k\\) 时，这意味着它对于所有研究保持不变。\n\n\n\n\n\n\n\n\n\n在元回归中，\\(\\theta\\) 和 \\(\\beta\\) 都是不变的，或固定的。这告诉我们元回归的作用：基于预测变量的变化和观察到的效应，它试图以 回归线 的形式“提炼”出我们数据的基础 固定模式。如果元回归模型与数据拟合良好，则可以使用估计的参数 \\(\\theta\\) 和 \\(\\beta\\) 来预测模型 以前从未见过 的研究的效应量 (前提是我们知道 \\(x\\))。\n考虑到抽样误差 \\(\\epsilon_k\\) 和研究间异质性 \\(\\zeta_k\\)，元回归因此试图找到一个 泛化 良好的模型；不仅适用于观察到的效应量，还适用于所有可能感兴趣的研究的“宇宙”。\n\n\n\n\n\n关于元回归模型的一个重要细节是，它们可以被视为我们用来汇集效应量的“正常”随机效应模型的扩展。随机效应模型只不过是一个 没有斜率项 的元回归模型。由于它不包含斜率，因此随机效应模型仅预测每个研究的 相同值：汇集效应量 \\(\\mu\\) 的估计值，该估计值与截距等效。\n \n因此，在第一步中，元回归的计算与随机效应元分析的计算非常相似，因为使用我们在第 @ref(tau-estimators) 章中描述的方法之一 (例如，DerSimonian-Laird 或 REML 方法) 估计了研究间异质性 \\(\\tau^2\\)。在下一步中，估计固定权重 \\(\\theta\\) 和 \\(\\beta\\)。正常的线性回归模型使用 普通最小二乘法 (OLS) 来找到最适合数据的回归线。在元回归中，使用一种称为 加权最小二乘法 (WLS) 的修改方法，该方法确保标准误差较小的研究获得较高的权重。\n找到最佳解决方案后，我们可以检查新添加的回归项是否解释了效应量异质性的部分。如果元回归模型与数据拟合良好，则与汇集效应 \\(\\hat\\mu\\) 相比，真实效应量应更少地偏离回归线。如果是这种情况，则预测变量 \\(x\\) 解释 了我们元分析中的一些异质性方差。\n\n\n\n\n\n\n\n\n\n因此，可以通过检查它解释了多少异质性方差来评估元回归模型的拟合度。混合效应模型中包含的预测变量应最小化 残差 或未解释的异质性方差量，我们用 \\(\\tau^2_{\\text{unexplained}}\\) 表示。\n在回归分析中，通常使用 \\(R^2\\) 指数来量化模型解释的变异百分比。对于元回归，也可以计算一个类似的指数 \\(R^2_{*}\\)。我们在此处添加一个星号，以表明元回归中的 \\(R^2\\) 与传统回归中使用的 \\(R^2\\) 略有不同，因为我们处理的是 真实效应量 而不是观察到的数据点。\\(R^2_*\\) 的公式如下所示：\n\\[\\begin{equation}\nR^2_* = 1- \\frac{\\hat\\tau^2_{\\text{unexplained}}}{\\hat\\tau^2_{\\text{(total)}}}\n(\\#eq:mr6)\n\\end{equation}\\]\n\\(R^2_*\\) 使用了即使元回归斜率也无法解释的残余异质性方差量，并将其与我们最初在元分析中发现的总异质性相关联。从 1 中减去该分数后，我们可以得到预测变量解释的研究间异质性的百分比。\n还有另一种表示 \\(R^2_*\\) 的方法。我们可以说它表示与初始随机效应汇集模型相比，混合效应模型 减少 了多少异质性方差，以百分比表示。这将产生以下公式：\n\\[\\begin{equation}\nR^2_* =  \\frac{\\hat\\tau^2_{\\text{REM}}-\\hat\\tau^2_{\\text{MEM}}}{\\hat\\tau^2_{\\text{REM}}}\n(\\#eq:mr7)\n\\end{equation}\\]\n在此公式中，\\(\\hat\\tau^2_{\\text{REM}}\\) 表示在随机效应汇集模型中发现的研究间异质性的量，\\(\\hat\\tau^2_{\\text{MEM}}\\) 表示混合效应元回归模型中的 (残余) 方差 (即，关于真实效应量的“预测误差”)。\n\n通常，我们不仅对回归模型解释的异质性量感兴趣，还对我们的预测变量 \\(x\\) 的回归权重是否显着感兴趣。如果是这种情况，我们可以非常有把握地认为 \\(x\\) 对研究的效应量有影响。在传统回归和元回归中，通常通过 Wald 型 检验来评估回归权重的显着性。这涉及通过将其标准误差除以 \\(\\beta\\) 的估计值来计算检验统计量 \\(z\\)：\n\\[\\begin{equation}\nz = \\frac{\\hat\\beta}{SE_{\\hat\\beta}}\n(\\#eq:mr8)\n\\end{equation}\\]\n在 \\(\\beta = 0\\) 的原假设下，此 \\(z\\) 统计量服从标准正态分布。这使我们能够计算相应的 \\(p\\) 值，该值确定预测变量是否显着。\n然而，基于 \\(z\\) 统计量的检验并不是评估预测变量显着性的唯一方法。与正常的元分析模型一样，我们也可以使用 Knapp-Hartung 调整，这会导致基于 \\(t\\) 分布的检验统计量 (参见第 @ref(knapp-hartung) 章)。正如我们之前所了解的，通常建议使用 Knapp-Hartung 方法，因为它降低了误报的风险。",
    "crumbs": [
      "网站首页",
      "Meta回归"
    ]
  },
  {
    "objectID": "10-metareg.html#metareg-R",
    "href": "10-metareg.html#metareg-R",
    "title": "Meta回归",
    "section": "",
    "text": "{meta} 包包含一个名为 metareg 的函数，该函数允许我们进行元回归。metareg 函数只需要一个 {meta} 元分析对象和一个协变量的名称作为输入。\n在此示例中，我们将再次使用我们的 m.gen 元分析对象，该对象基于 ThirdWave 数据集 (参见第 @ref(pre-calculated-es) 章)。使用元回归，我们想要检查研究的 发表年份 是否可用于预测其效应量。默认情况下，ThirdWave 数据集不包含存储发表年份的变量，因此我们必须创建一个新的 numeric 变量，其中包含此信息。我们只需连接所有研究的发表年份，其顺序与它们在 ThirdWave 数据集中出现的顺序相同。我们将此变量保存在名称 year 下1。\n\nyear &lt;- c(2014, 1998, 2010, 1999, 2005, 2014, \n          2019, 2010, 1982, 2020, 1978, 2001,\n          2018, 2002, 2009, 2011, 2011, 2013)\n\n现在，我们拥有运行元回归所需的所有信息。在 metareg 函数中，我们将我们的元分析对象 m.gen 的名称指定为第一个参数，并将我们的预测变量 year 的名称指定为第二个参数。我们将结果命名为 m.gen.reg。\n\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.1-0).\nType 'help(meta)' for a brief overview.\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\ndata(ThirdWave)\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = ThirdWave,\n                 sm = \"SMD\",\n                 comb.fixed = FALSE,\n                 comb.random = TRUE,\n                 method.tau = \"REML\",\n                 method.random.ci = \"HK\",\n                 title = \"Third Wave Psychotherapies\")\n\nWarning: Use argument 'common' instead of 'comb.fixed' (deprecated).\n\n\nWarning: Use argument 'random' instead of 'comb.random' (deprecated).\n\nm.gen.reg &lt;- metareg(m.gen, ~year)\n\n现在，让我们看一下结果：\n\nm.gen.reg\n\n## Mixed-Effects Model (k = 18; tau^2 estimator: REML)\n## \n## tau^2 (estimated amount of residual heterogeneity):     0.019 (SE = 0.023)\n## tau (square root of estimated tau^2 value):             0.1371\n## I^2 (residual heterogeneity / unaccounted variability): 29.26%\n## H^2 (unaccounted variability / sampling variability):   1.41\n## R^2 (amount of heterogeneity accounted for):            77.08%\n## \n## Test for Residual Heterogeneity:\n## QE(df = 16) = 27.8273, p-val = 0.0332\n## \n## Test of Moderators (coefficient 2):\n## F(df1 = 1, df2 = 16) = 9.3755, p-val = 0.0075\n## \n## Model Results:\n## \n##         estimate     se   tval   pval    ci.lb    ci.ub \n## intrcpt   -36.15  11.98  -3.01  0.008  -61.551  -10.758  ** \n## year        0.01   0.00   3.06  0.007    0.005    0.031  ** \n## \n## ---\n## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n让我们回顾一下我们在这里可以看到的内容。在第一行中，输出告诉我们一个混合效应模型已拟合到数据，正如预期的那样。接下来的几行提供了有关模型解释的异质性量的详细信息。我们看到残余异质性方差 (未被预测变量解释的方差) 的估计值为 \\(\\hat\\tau^2_{\\text{unexplained}}=\\) 0.019。\n输出还为我们提供了一个 \\(I^2\\) 等效值，该值告诉我们，在包含预测变量后，我们数据中 29.26% 的变异性可归因于剩余的研究间异质性。在正常的随机效应元分析模型中，我们发现 \\(I^2\\) 异质性为 63%，这意味着该预测变量能够“解释掉”真实效应量差异的相当一部分。\n在最后一行中，我们看到 \\(R^2_*\\) 的值，在本示例中为 77%。这意味着真实效应量差异的 77% 可以通过发表年份来解释，这是一个相当大的值。\n下一部分包含“残余异质性检验”，这本质上是我们之前已经了解的 \\(Q\\) 检验 (参见第 @ref(cochran-q) 章)。但是，现在，我们测试未被预测变量解释的异质性是否显着。我们看到情况就是这样，其中 \\(p\\) = 0.03。但是，我们知道 \\(Q\\) 检验的局限性 (第 @ref(cochran-q) 章)，因此不应过分依赖此结果。\n下一部分显示“调节变量检验”。我们看到此检验也很显着 (\\(p\\) = 0.0075)。这意味着我们的预测变量 (发表年份) 确实会影响研究的效应量。\n最后一部分提供了有关估计的回归系数的更多详细信息。第一行显示截距 (intrcpt) 的结果。当我们的预测变量发表年份为零时，这是预期的效应量 (在我们的例子中：Hedges 的 \\(g\\))。在我们的示例中，这代表了一种可以说的有点人为的情况：它显示了在第 0 年进行的研究的预测效应，为 \\(\\hat{g}=\\) -36.15。这再次提醒我们，好的统计模型不必是现实的完美表示；它们只需要 有用。\n我们主要感兴趣的系数是第二行中的系数。我们看到该模型对 year 的回归权重的估计值为 0.01。这意味着对于每增加一年，预计研究的效应量 \\(g\\) 将增加 0.01。因此，我们可以说研究的效应量随着时间的推移而增加。95% 的置信区间范围为 0.005 到 0.3，表明该效应很显着。\n重要的是，我们还获得了每个回归系数的相应 \\(t\\) 统计量 (tval)。这告诉我们 Knapp-Hartung 方法用于计算置信区间和 \\(p\\) 值。由于我们也在最初的元分析模型中使用了此调整，因此 metareg 会自动在此处再次使用它。否则，将提供 \\(z\\) 值和 Wald 型置信区间。\n\n{meta} 包允许我们使用 bubble 函数可视化元回归。这将创建一个 气泡图，该图显示估计的回归斜率以及每个研究的效应量。为了指示研究的权重，气泡具有不同的大小，较大的大小表示较高的权重。\n要生成气泡图，我们只需将我们的元回归对象插入 bubble 函数即可。因为我们也希望显示研究标签，所以我们将 studlab 设置为 TRUE。\n\nbubble(m.gen.reg, studlab = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n为了完整起见，我们还可以尝试重复上一章 (第 @ref(subgroup-R) 章) 中的亚组分析，但这次在元回归框架内。这意味着我们使用偏倚风险评估作为分类预测变量。由于变量 RiskOfBias 已经包含在 ThirdWave 数据集中，因此我们不必将此信息保存在额外的对象中。只需再次运行 metareg 函数就足够了，但这次，我们使用 RiskOfBias 作为第二个函数参数。\n\nmetareg(m.gen, RiskOfBias)\n\n## [...]\n## R^2 (amount of heterogeneity accounted for):            15.66%\n## \n## Test for Residual Heterogeneity:\n## QE(df = 16) = 39.3084, p-val = 0.0010\n## \n## Test of Moderators (coefficient 2):\n## F(df1 = 1, df2 = 16) = 2.5066, p-val = 0.1329\n## \n## Model Results:\n## \n##               estimate    se   tval    pval  ci.lb ci.ub \n## intrcpt           0.76  0.15   5.00  0.0001   0.44  1.09  *** \n## RiskOfBiaslow    -0.29  0.18  -1.58  0.1329  -0.69  0.10      \n## [...]\n\n在输出中，我们看到 \\(R^2_*\\) 的值 (15.66%) 远小于 year 的值。与我们之前的结果一致，我们看到偏倚风险变量不是显着的效应量预测变量 (\\(p\\) = 0.13)。\n在 Model Results 下，我们看到 metareg 已自动将 RiskOfBias 转换为虚拟变量。表示“高风险”亚组的汇集效应的截距估计值为 \\(g\\)=0.76。表示具有 低 偏倚风险的研究的回归系数的估计值为 -0.29。\n为了获得此亚组的效应量，我们必须将回归权重添加到截距，这将导致 \\(g=\\) 0.76 - 0.29 \\(\\approx\\) 0.47。这些结果与假设 \\(\\tau^2\\) 的共同估计值的亚组分析的结果相同。",
    "crumbs": [
      "网站首页",
      "Meta回归"
    ]
  },
  {
    "objectID": "10-metareg.html#multiple-metareg",
    "href": "10-metareg.html#multiple-metareg",
    "title": "Meta回归",
    "section": "",
    "text": "之前，我们只考虑了在我们的元回归模型中使用 一个 预测变量 \\(\\beta x_k\\) 的情况。在该示例中，我们检查了研究的效应量是否取决于发表年份。但是现在，假设报告的效应量也取决于研究发表的科学期刊的 声誉。我们认为，在高声誉期刊上的研究可能会报告更高的效应。这可能是因为享有盛誉的期刊更具选择性，并且主要发表具有“突破性”发现的研究。\n另一方面，信誉良好的期刊通常发表 更高质量 的研究也是合理的。也许仅仅是更好的研究质量与更高的效应量相关。因此，为了检查期刊声誉是否确实与更高的效应相关，我们必须确保这种关系不会因享有盛誉的期刊更有可能发表高质量证据的事实而 混淆。这意味着我们在检查期刊声誉与效应量之间的关系时，必须 控制 研究质量。\n这个问题以及许多其他研究问题都可以使用 多元元回归 来处理。在多元元回归中，我们使用多个预测变量而不是仅使用一个来解释效应的变化。为了允许使用多个预测变量，我们需要修改我们之前的元回归公式 (参见方程 8.2)，使其如下所示：\n\\[\\begin{equation}\n\\hat \\theta_k = \\theta + \\beta_1x_{1k} + ... + \\beta_nx_{nk} + \\epsilon_k + \\zeta_k\n(\\#eq:mr10)\n\\end{equation}\\]\n此公式告诉我们可以向我们的元回归模型添加 \\(n-1\\) 个以上的预测变量 \\(x\\)，从而将其转换为多元元回归。公式中的三个点表示从理论上讲，我们可以根据需要添加任意数量的预测变量。然而，在现实中，事情通常更棘手。在下文中，我们将讨论多元元回归中的一些重要陷阱，以及如何构建稳健且值得信赖的模型。但首先，让我们介绍多元元回归的另一个重要特征，交互作用。\n\n\n\n\n\n到目前为止，我们仅考虑了在我们的模型中具有多个预测变量 \\(x_1, x_2, \\dots x_n\\) 的情况，这些预测变量与它们的回归权重 \\(\\beta\\) 一起加在一起。然而，多元元回归模型不仅限于这种 加法 关系。它们还可以对预测变量 交互作用 进行建模。交互作用意味着一个预测变量 (例如，\\(x_1\\)) 和估计的效应量之间的 关系 对于另一个协变量 (例如，\\(x_2\\)) 的不同值会 改变。\n假设我们想要对两个预测变量以及它们与效应量的关联方式进行建模：研究的发表年份 (\\(x_1\\)) 和质量 (\\(x_2\\))。研究质量的编码如下：\n\\[\\begin{equation}\n  x_2=\\begin{cases}\n    0: & \\text{低}\\\\\n    1: & \\text{中等}\\\\\n    2: & \\text{高.}\n  \\end{cases}\n  (\\#eq:mr11)\n\\end{equation}\\]\n当我们假设发表年份和研究质量之间没有交互作用时，我们可以通过为 \\(x_1\\) 和 \\(x_2\\) 都赋予一个回归权重 \\(\\beta\\)，并在我们的公式中 添加 这些项来构建元回归模型：\n\\[\\begin{equation}\n\\hat \\theta_k = \\theta + \\beta_1x_{1k} + \\beta_2x_{2k} + \\epsilon_k + \\zeta_k\n(\\#eq:mr12)\n\\end{equation}\\]\n但是，如果 \\(x_1\\) 和 \\(x_2\\) 之间的关系更复杂呢？与我们之前的示例一样，发表年份越近，效应越高，这是有可能的。但并非所有研究都必须遵循这一趋势。也许这种增长在高质量研究中最为明显，而低质量研究的结果随着时间的推移基本上保持不变。我们可以通过以下方式可视化效应量 (\\(\\hat\\theta_k\\))、发表年份 (\\(x_1\\)) 和研究质量 (\\(x_2\\)) 之间假设的关系：\n\n\n\n\n\n\n\n\n\n该图显示了交互作用的经典示例。我们看到回归斜率的陡峭程度取决于另一个预测变量的值。虽然高质量研究的斜率非常陡峭，表明年份和效应之间存在很强的关系，但低质量研究的情况有所不同。该亚组中的回归线几乎是水平的，表明发表年份对结果没有影响，甚至有轻微的负面影响。\n此示例显示了交互作用的优势之一：它们允许我们检查预测变量的影响在所有研究中是否相同，或者它是否受到另一个特征的调节。\n为了通过元回归评估交互作用，我们需要向模型中添加一个 交互项。在我们的示例中，这可以通过添加第三个回归权重 \\(\\beta_3\\) 来实现，该权重捕获我们想要在模型中测试的交互作用 \\(x_{1k}x_{2k}\\)。这给出了以下公式：\n\\[\\begin{equation}\n\\hat \\theta_k = \\theta + \\beta_1x_{1k} + \\beta_2x_{2k} + \\beta_3x_{1k}x_{2k}+ \\epsilon_k + \\zeta_k\n(\\#eq:mr13)\n\\end{equation}\\]\n虽然线性多元元回归模型仅包含这些简单的构建块，但它们适用于各种应用。但是，在我们开始使用 R 拟合多元元回归之前，我们应该首先考虑它们的局限性和陷阱。\n\n\n\n\n\n多元元回归虽然在正确应用时非常有用，但存在一定的注意事项。有些人认为，在实践中经常不正确地使用和解释 (多元) 元回归，导致结果的有效性较低 [@higgins2004controlling]。在拟合多元元回归模型时，我们必须牢记一些要点，我们将在下文中介绍。\n\n\n\n\n\n为了更好地理解 (多元) 元回归模型的风险，我们必须理解 过拟合 的概念。当我们构建一个与数据 过于 紧密拟合的统计模型时，就会发生过拟合。从本质上讲，这意味着我们构建了一个统计模型，它可以 非常 好地预测 手头 的数据，但在预测 未来 数据方面表现不佳。\n当我们的模型假设我们数据中的某些变化来自真实的“信号”时，实际上我们只捕获了随机噪声 [@iniesta2016machine]，就会发生这种情况。因此，该模型会产生 假阳性 结果：它会在没有关系的地方看到关系。\n\n\n\n\n\n过拟合模型与具有稳健拟合的模型相比的预测。\n\n\n\n\n \n对于模型拟合，回归使用 优化 技术，例如普通最小二乘法或最大似然估计。正如我们所了解的，元回归使用加权版本的普通最小二乘法 (参见第 @ref(metareg-model-fit) 章)，因此也不例外。\n然而，这种“贪婪”的优化意味着回归方法可能容易过度拟合 [@gigerenzer2004mindless]。不幸的是，一旦我们从传统回归过渡到元回归，构建非稳健模型的风险就会更高。出现这种情况有几个原因 [@higgins2004controlling]：\n\n在元回归中，数据点的数量通常很小，因为我们只能使用包含研究的汇总信息。\n由于元分析旨在全面概述所有可用的证据，因此我们没有额外的数据可以用来“测试”我们的回归模型在预测未见数据方面的表现如何。\n在元回归中，我们必须处理效应量异质性的潜在存在。想象一下，我们有两个具有不同效应量和非重叠置信区间的研究的情况。对于这两项研究具有不同值的每个变量都可能是效应量差异的潜在解释。然而，似乎很明显，这些解释中的大多数将是虚假的。\n元回归通常，尤其是多元元回归，可以非常容易地“摆弄”预测变量。我们可以测试许多元回归模型，包括更多预测变量或删除它们，以尝试解释我们数据中的异质性。这种方法很诱人，并且在实践中经常发现，因为元分析师想要找到效应量不同的原因 [@higgins2002statistical]。然而，这种行为已被证明会大大增加虚假发现的风险，因为我们可以无限期地更改我们模型的各个部分，直到我们找到一个显着的模型，该模型很可能被过度拟合 (即，它主要模拟统计噪声)。\n\n已经提出了一些指导原则，以避免",
    "crumbs": [
      "网站首页",
      "Meta回归"
    ]
  },
  {
    "objectID": "10-metareg.html#footnotes",
    "href": "10-metareg.html#footnotes",
    "title": "Meta回归",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n我们在本示例中使用的发表年份是虚构的，仅用于说明目的。↩︎",
    "crumbs": [
      "网站首页",
      "Meta回归"
    ]
  },
  {
    "objectID": "12-mlma.html#multilevel-nature",
    "href": "12-mlma.html#multilevel-nature",
    "title": "(PART) 高级方法",
    "section": "Meta 分析的多层次性质",
    "text": "Meta 分析的多层次性质\n\n为了了解为什么 meta 分析默认具有多个层次，让我们回到我们在第 @ref(rem) 章中讨论的随机效应模型的公式：\n\\[\\begin{equation}\n\\hat\\theta_k = \\mu + \\epsilon_k + \\zeta_k\n(\\#eq:mlm1)\n\\end{equation}\\]\n\n我们讨论了在随机效应模型中引入 \\(\\epsilon_k\\) 和 \\(\\zeta_k\\) 项，因为我们假设存在两种变异来源。第一种是由各个研究的抽样误差 (\\(\\epsilon_k\\)) 引起的，这导致效应量估计值偏离真实效应量 \\(\\theta_k\\)。\n第二种，\\(\\zeta_k\\)，代表研究间的异质性。这种异质性是由这样一个事实引起的：某些研究 \\(k\\) 的真实效应量再次只是一个总体的 真实效应量分布 的一部分。这个分布就是个体真实效应量 \\(\\theta_k\\) 的来源。因此，我们在随机效应模型中的目标是估计真实效应量分布的均值，用 \\(\\mu\\) 表示。\n这两个误差项 \\(\\epsilon_k\\) 和 \\(\\zeta_k\\) 对应于我们的 meta 分析数据中的两个层次：“参与者”层次（层次 1）和“研究”层次（层次 2）。下面的图 @ref(fig:multilevel1) 象征着这种结构。\n\n\n\n\n\n传统随机效应模型的多层次结构。\n\n\n\n\n在最低层（层次 1），我们有参与者（或患者、标本等，取决于研究领域）。这些参与者是更大单位的一部分：我们 meta 分析中包含的研究。这个研究的上层构成了我们的第二层。\n当我们进行 meta 分析时，层次 1 的数据通常以“汇集”的形式到达我们手中（例如，论文的作者向我们提供他们研究样本的均值和标准差，而不是原始数据）。然而，层次 2（研究层次）的汇集必须作为 meta 分析的一部分来执行。传统上，这种类型的数据称为 嵌套：可以说参与者“嵌套”在研究中。\n\n让我们回到公式 @ref(eq:mlm1) 中的随机效应模型公式。隐式地，这个公式已经描述了我们 meta 分析数据的多层次结构。为了使这一点更加明显，我们必须将方程分成两个公式，其中每个公式对应于两个层次之一。如果我们这样做，我们将得到以下结果：\n层次 1（参与者）模型：\n\\[\\begin{equation}\n\\hat\\theta_k = \\theta_k + \\epsilon_k\n(\\#eq:mlm2)\n\\end{equation}\\]\n层次 2（研究）模型：\n\\[\\begin{equation}\n\\theta_k = \\mu + \\zeta_k\n(\\#eq:mlm3)\n\\end{equation}\\]\n您可能已经发现我们可以用第二个方程中的定义替换第一个方程中的 \\(\\theta_k\\)。然后我们得到的是与之前的随机效应模型的公式完全相同的公式。固定效应模型也可以用这种方式编写——我们只需要将 \\(\\zeta_k\\) 设置为零。显然，我们普通的 meta 分析模型已经具有“内置”的多层次属性。它表现出这种属性，因为我们假设参与者嵌套在我们数据中的研究中。\n这清楚地表明 meta 分析自然具有多层次结构。可以进一步扩展这种结构，以便更好地捕获生成我们数据的某些机制。这就是 三层次模型 [@cheung2014modeling; @assink2016fitting] 发挥作用的地方。\n\n统计独立性是我们在 meta 分析中汇集效应量时的核心假设之一。如果效应量之间存在依赖关系（即效应量相关），这会人为地降低异质性，从而导致假阳性结果。这个问题被称为 分析单位错误，我们之前已经介绍过（参见第 @ref(unit-of-analysis) 章）。效应量依赖性可能来自不同的来源 [@cheung2014modeling]：\n\n由个体研究的作者引入的依赖性。例如，进行研究的科学家可能从多个地点收集了数据，将多个干预措施与一个单一的对照组进行比较，或者使用不同的问卷来测量相同的结果。在所有这些情况下，我们可以假设在报告的数据中引入了某种依赖关系。\n由 meta 分析师本人引入的依赖性。例如，考虑一个专注于某些心理机制的 meta 分析。此 meta 分析包括在世界不同文化区域（例如，东亚和西欧社会）进行的研究。根据心理机制的类型，在同一文化区域进行的研究结果可能比在不同文化中进行的研究结果更相似。\n\n我们可以通过在我们的 meta 分析模型结构中整合第三层来考虑这种依赖关系。例如，可以建模基于不同问卷的效应量嵌套在研究中。或者可以创建一个模型，其中研究嵌套在文化区域中。这将创建一个三层次 meta 分析模型，如下一个图所示。\n\n\n\n\n\n\n\n\n\n\n我们看到三层次模型包含三个汇集步骤。首先，研究人员自己在他们的主要研究中“汇集”个体参与者的结果，并报告聚合的效应量。然后，在层次 2，这些效应量嵌套在几个 聚类 中，用 \\(\\kappa\\) 表示。这些聚类可以是单个研究（即，许多效应量嵌套在一个研究中），或者研究的子组（即，许多研究嵌套在一个子组中，其中每个研究仅贡献一个效应量）。\n最后，汇集聚合的聚类效应会导致整体真实效应量 \\(\\mu\\)。从概念上讲，此平均效应非常接近固定效应或随机效应模型中汇集的真实效应 \\(\\mu\\)。然而，不同之处在于它基于一个模型，在该模型中，我们明确地考虑了我们数据中的依赖效应量。\n可以使用我们之前使用的相同层次表示法来写下三层次模型的公式。最大的区别是现在我们需要定义三个公式而不是两个：\n层次 1 模型：\n\\[\\begin{equation}\n\\hat\\theta_{ij} = \\theta_{ij} + \\epsilon_{ij}\n(\\#eq:mlm4)\n\\end{equation}\\]\n层次 2 模型：\n\\[\\begin{equation}\n\\theta_{ij} = \\kappa_{j} + \\zeta_{(2)ij}\n(\\#eq:mlm5)\n\\end{equation}\\]\n层次 3 模型：\n\\[\\begin{equation}\n\\kappa_{j} = \\mu + \\zeta_{(3)j}\n(\\#eq:mlm6)\n\\end{equation}\\]\n其中 \\(\\hat\\theta_{ij}\\) 是真实效应量 \\(\\theta_{ij}\\) 的估计值。术语 \\(ij\\) 可以理解为“嵌套在聚类 \\(j\\) 中的某个效应量 \\(i\\)”。参数 \\(\\kappa_{j}\\) 是聚类 \\(j\\) 中的平均效应量，\\(\\mu\\) 是总体平均人口效应。与之前一样，我们可以将这些公式拼凑在一起，从而将公式减少到一行：\n\\[\\begin{equation}\n\\hat\\theta_{ij} = \\mu + \\zeta_{(2)ij} + \\zeta_{(3)j} + \\epsilon_{ij}\n(\\#eq:mlm7)\n\\end{equation}\\]\n我们看到，与随机效应模型相比，此公式现在包含 两个 异质性项。一个是 \\(\\zeta_{(2)ij}\\)，它代表层次 2 上的 聚类内 异质性（即，聚类 \\(j\\) 内的 真实 效应量遵循均值为 \\(\\kappa_j\\) 的分布）。另一个是 \\(\\zeta_{(3)j}\\)，层次 3 上的 聚类间 异质性。因此，拟合三层次 meta 分析模型不仅涉及估计一个异质性方差参数 \\(\\tau^2\\)。我们必须估计两个 \\(\\tau^2\\) 值：一个用于层次 2，另一个用于层次 3。\n \n{metafor} 包特别适合拟合 meta 分析三层次模型。它使用（限制性）最大似然程序来执行此操作。以前，我们主要使用 {meta} 包的函数来运行 meta 分析。我们这样做是因为这个包的技术性稍差，因此更适合初学者。然而，正如我们在第 @ref(multiple-metareg-R) 章中所看到的，一旦数据准备正确，{metafor} 包也相当容易使用。如何在 R 中使用 {metafor} 拟合三层次模型将是下一节的主题1。",
    "crumbs": [
      "网站首页",
      "多元Meta分析"
    ]
  },
  {
    "objectID": "12-mlma.html#multilevel-R",
    "href": "12-mlma.html#multilevel-R",
    "title": "(PART) 高级方法",
    "section": "在 R 中拟合三层次 Meta 分析模型",
    "text": "在 R 中拟合三层次 Meta 分析模型\n\n如前所述，我们需要 {metafor} 包来拟合三层次 meta 分析模型。因此，我们需要首先从我们的库中加载它。\n\nlibrary(metafor)\n\n在我们的实践示例中，我们将使用 Chernobyl 数据集。此数据集大致基于一个真实的 meta 分析，该分析检查了由 1986 年切尔诺贝利反应堆灾难 造成的电离辐射（“核沉降物”）与人类突变率之间的相关性 [@moller2015strong]。\n\n\n\n\n“切尔诺贝利”数据集\n\n\nChernobyl 数据集是 {dmetar} 包的一部分。如果您已安装 {dmetar} 并从您的库中加载它，则运行 data(Chernobyl) 会自动将数据集保存在您的 R 环境中。然后就可以使用该数据集了。\n\n\n如果您没有安装 {dmetar}，您可以从 互联网 下载数据集作为 .rda 文件，将其保存在您的工作目录中，然后单击 R Studio 窗口中的它以导入它。\n\n\n\n\n# 从 'dmetar' 加载数据集\nlibrary(dmetar)\ndata(\"Chernobyl\")\n\n为了查看数据的一般结构，我们可以使用 head 函数。这将打印我们刚加载到我们全局环境中的数据帧的前六行。\n\nhead(Chernobyl)\n\n##                       author  cor   n    z se.z var.z radiation es.id\n## 1 Aghajanyan & Suskov (2009) 0.20  91 0.20 0.10  0.01       low  id_1\n## 2 Aghajanyan & Suskov (2009) 0.26  91 0.27 0.10  0.01       low  id_2\n## 3 Aghajanyan & Suskov (2009) 0.20  92 0.20 0.10  0.01       low  id_3\n## 4 Aghajanyan & Suskov (2009) 0.26  92 0.27 0.10  0.01       low  id_4\n## 5     Alexanin et al. (2010) 0.93 559 1.67 0.04  0.00       low  id_5\n## 6     Alexanin et al. (2010) 0.44 559 0.47 0.04  0.00       low  id_6\n\n数据集包含八列。第一列 author 显示研究的名称。cor 列显示辐射暴露与突变率之间的（未转换的）相关性，而 n 代表样本大小。z、se.z 和 var.z 列是费舍尔 \\(z\\) 转换的相关性（第 @ref(pearson-cors) 章），以及它们的标准误差和方差。radiation 列用作调节变量，将效应量划分为具有低和高总体辐射暴露的子组。es.id 列仅包含每个效应量（即，数据帧中的每一行）的唯一 ID。\n此数据集的一个特殊之处在于它在 author 中包含重复的条目。这是因为此 meta 分析中的大多数研究贡献了不止一个观察到的效应量。一些研究使用了几种方法来测量突变或几种类型的指标人（例如，暴露的父母与他们的后代），所有这些导致每个研究有多个效应。\n查看此结构，很明显我们数据集中的效应量不是独立的。它们遵循嵌套结构，其中各种效应量嵌套在一个研究中。因此，拟合三层次 meta 分析以充分建模我们数据中的这些依赖关系可能是一个好主意。\n\n\n模型拟合\n\n可以使用 {metafor} 中的 rma.mv 函数拟合三层次 meta 分析模型。以下是此函数最重要的参数列表，以及应如何指定它们：\n\nyi。我们的数据集中包含计算的效应量的列的名称。在我们的示例中，这是 z，因为费舍尔 \\(z\\) 转换的相关性比“未转换”的相关性具有更好的数学性质。\nV。我们的数据集中包含计算的效应量的 方差 的列的名称。在我们的示例中，这是 var.z。也可以使用效应量的 平方 标准误差，因为 \\(SE_k^2 = v_k\\)。\nslab。我们的数据集中包含研究标签的列的名称，类似于 {meta} 中的 studlab。\ndata。数据集的名称。\ntest。我们想要应用于我们的回归系数的检验。我们可以从 \"z\"（默认）和 \"t\"（推荐；使用类似于 Knapp-Hartung 方法的检验）中进行选择。\nmethod。用于估计模型参数的方法。\"REML\"（推荐；限制性最大似然法）和 \"ML\"（最大似然法）都是可能的。请注意，其他类型的研究间异质性估计器（例如，Paule-Mandel）不适用于此处。\n\n然而，最重要的参数是 random。可以说，它也是最棘手的参数。在此参数中，我们指定一个公式，该公式定义了（嵌套的）随机效应。对于三层次模型，该公式始终以 ~ 1 开头，后跟竖线 |。在竖线后面，我们将 随机效应 分配给分组变量（例如，研究、度量、区域等）。此分组变量通常称为 随机截距，因为它告诉我们的模型假设每个组有不同的效应（即，截距）。\n在三层次模型中，有两个分组变量：一个在层次 2 上，另一个在层次 3 上。我们假设这些分组变量是嵌套的：层次 2 上的几个效应共同构成层次 3 上的一个更大的聚类。\n有一种特殊的方式可以通过这种方式告诉 rma.mv 假设这种嵌套的随机效应。我们使用斜杠 (/) 分隔较高层次和较低层次的分组变量来实现此目的。在 / 的左侧，我们放入层次 3（聚类）变量。在右侧，我们插入嵌套在较大聚类中的低阶变量。因此，公式的一般结构如下所示：~ 1 | cluster/effects_within_cluster。\n在我们的示例中，我们假设单个效应量（层次 2；由 es.id 定义）嵌套在研究中（层次 3；由 author 定义）。这导致以下公式：~ 1 | author/es.id。完整的 rma.mv 函数调用如下所示：\n\nfull.model &lt;- rma.mv(yi = z,\n                     V = var.z,\n                     slab = author,\n                     data = Chernobyl,\n                     random = ~ 1 | author/es.id,\n                     test = \"t\",\n                     method = \"REML\")\n\n我们给输出命名为 full.model。要打印结果的概述，我们可以使用 summary 函数。\n\nsummary(full.model)\n\n## Multivariate Meta-Analysis Model (k = 33; method: REML)\n## [...]\n## Variance Components:\n##\n##             estim    sqrt  nlvls  fixed        factor\n## sigma^2.1  0.1788  0.4229     14     no        author\n## sigma^2.2  0.1194  0.3455     33     no  author/es.id\n##\n## Test for Heterogeneity:\n## Q(df = 32) = 4195.8268, p-val &lt; .0001\n##\n## Model Results:\n##\n## estimate      se    tval    pval   ci.lb   ci.ub\n##   0.5231  0.1341  3.9008  0.0005  0.2500  0.7963  ***\n## [...]\n首先，查看 Variance Components。在这里，我们看到为我们模型的每个层次计算的随机效应方差。第一个 sigma^2.1 显示了层次 3 聚类间 方差。在我们的示例中，这等效于传统 meta 分析中的研究间异质性方差 \\(\\tau^2\\)（因为聚类代表我们模型中的研究）。\n第二个方差分量 sigma^2.2 显示了 聚类内 的方差（层次 2）。在 nlvls 列中，我们看到每个层次上的组数。层次 3 有 14 个组，等于 \\(K=\\) 14 个包含的研究。总共有 33 个效应量包含在这 14 个研究中，如第二行所示。\n\n在 Model Results 下，我们看到我们汇集的效应的估计值，即 \\(z=\\) 0.52 (95%CI: 0.25–0.80)。为了方便解释，建议将效应转换回正常相关性。可以使用 {esc} 包中的 convert_z2r 函数来完成此操作：\n\nlibrary(esc)\nconvert_z2r(0.52)\n\n[1] 0.4777\n\n\n我们看到这导致相关性约为 \\(r \\approx\\) 0.48。这可以认为是大的。突变率与切尔诺贝利辐射暴露之间似乎存在显着关联。\n输出中的 Test for Heterogeneity 指出了我们数据中真实效应量差异 (\\(p&lt;\\) 0.001)。然而，此结果不是很informative。我们对模型中每个层次捕获的异质性方差的精确量更感兴趣。最好知道有多少异质性是由于研究 内部 的差异（层次 2）引起的，以及有多少是由 研究之间 的差异（层次 3）引起的。\n\n\n\n跨层次的方差分布\n\n\n我们可以通过计算多层次版本的 \\(I^2\\) [@cheung2014modeling] 来回答这个问题。在传统的 meta 分析中，\\(I^2\\) 表示不归因于抽样误差的变异量（参见第 @ref(i-squared) 章；即，研究间异质性）。在三层次模型中，此异质性方差分为两部分：一部分归因于聚类 内部 的真实效应量差异，另一部分归因于 聚类之间 的变异。因此，有两个 \\(I^2\\) 值，量化与层次 2 或层次 3 关联的总变异的百分比。\n\n\n\n\n“var.comp”函数\n\n\n{dmetar} 中的 var.comp 函数可用于计算多层次 (I^2) 值。一旦 {dmetar} 安装并加载到您的计算机上，就可以使用该函数。如果您 没有 安装 {dmetar}，请按照以下说明操作：\n\n\n\n在 网上 访问函数的源代码。\n\n\n通过将整个源代码复制并粘贴到控制台（R Studio 的左下方窗格）中，然后点击“Enter”，让 R“学习”该函数。\n\n\n确保 {ggplot2} 包已安装并加载。\n\n\n\n\nvar.comp 函数只需要一个拟合的 rma.mv 模型作为输入。我们将输出保存在 i2 中，然后使用 summary 函数打印结果。\n\ni2 &lt;- var.comp(full.model)\nsummary(i2)\n\n        % of total variance    I2\nLevel 1            1.254966   ---\nLevel 2           39.525499 39.53\nLevel 3           59.219534 59.22\nTotal I2: 98.75% \n\n\n在输出中，我们看到归因于三个层次中每个层次的总方差的百分比。层次 1 上的抽样误差方差非常小，仅占大约 1%。\\(I^2_{\\text{Level 2}}\\) 的值，即聚类内的异质性方差量，要高得多，总计大约 40%。然而，最大的份额落在层次 3 上。聚类间（此处：研究间）异质性占我们数据中总变异的 \\(I^2_{\\text{Level 3}}=\\) 59%。\n总的来说，这表明在第三层上存在显着的研究间异质性。然而，我们还看到很大一部分总方差，超过三分之一，可以用 研究内部 的差异来解释。\n也可以可视化总方差的这种分布。我们只需要将 var.comp 输出插入到 plot 函数中。\n\nplot(i2)\n\n\n\n\n\n\n\n\n\n\n\n比较模型\n\n\n仅当三层次模型比两层次模型更好地表示我们数据中的变异性时，拟合三层次模型才有意义。当我们发现两层次模型提供的拟合与三层次模型相当时，应应用 奥卡姆剃刀：我们倾向于两层次模型而不是三层次模型，因为它不太复杂，但可以很好地解释我们的数据。\n幸运的是，{metafor} 包可以让我们将三层次模型与删除一个层次的模型进行比较。为此，我们再次使用 rma.mv 函数；但这次，将一个层次的方差分量设置为零。可以通过指定 sigma2 参数来完成此操作。我们必须提供一个具有通用形式 c(level 3, level 2) 的向量。在此向量中，当应将方差分量设置为零时，我们填写 0，而使用 NA 表示应从数据中估计参数。\n在我们的示例中，检查在研究中嵌套单个效应量是否改善了我们的模型是有意义的。因此，我们拟合一个模型，其中层次 3 方差（代表研究间异质性）设置为零。这等于拟合一个简单的随机效应模型，在该模型中，我们假设所有效应量都是独立的（我们知道它们不是）。由于层次 3 固定为零，因此 sigma2 的输入为 c(0, NA)。这导致以下对 rma.mv 的调用，我们将其输出保存在名称 l3.removed 下。\n\nl3.removed &lt;- rma.mv(yi = z,\n                     V = var.z,\n                     slab = author,\n                     data = Chernobyl,\n                     random = ~ 1 | author/es.id,\n                     test = \"t\",\n                     method = \"REML\",\n                     sigma2 =  c(0, NA))\n\nsummary(l3.removed)\n\n## [...]\n## Variance Components:\n##\n##             estim    sqrt  nlvls  fixed        factor\n## sigma^2.1  0.0000  0.0000     14    yes        author\n## sigma^2.2  0.3550  0.5959     33     no  author/es.id\n##\n## Test for Heterogeneity:\n## Q(df = 32) = 4195.8268, p-val &lt; .0001\n##\n## Model Results:\n##\n## estimate      se    tval    pval   ci.lb   ci.ub\n##   0.5985  0.1051  5.6938  &lt;.0001  0.3844  0.8126  ***\n## [...]\n\n在输出中，我们看到 sigma^2.1 已设置为零——正如预期的那样。总体效应也发生了变化。但是此结果是否比三层次模型的结果更好？为了评估这一点，我们可以使用 anova 函数比较两个模型。\n\nanova(full.model, l3.removed)\n\n##         df   AIC   BIC  AICc logLik   LRT   pval      QE\n## Full     3 48.24 52.64 49.10 -21.12              4195.82\n## Reduced  2 62.34 65.27 62.76 -29.17 16.10 &lt;.0001 4195.82\n我们看到，与具有两个层次的 Reduced 模型相比，Full（三层次）模型确实显示出更好的拟合。Akaike (AIC) 和 Bayesian 信息准则 (BIC) 对于此模型较低，这表明性能良好。比较两个模型的似然比检验 (LRT) 显着 (\\(\\chi^2_1=\\) 16.1, \\(p&lt;\\) 0.001)，因此指向相同的方向。\n我们可以说，虽然三层次模型引入了一个额外的参数（即，它有 3 个自由度而不是 2 个），但这种增加的复杂性似乎是合理的。嵌套数据结构的建模可能是一个好主意，并且改善了我们对汇集效应的估计。\n但是，请注意，通常有充分的理由坚持使用三层次结构——即使它 没有 提供显着更好的拟合。特别是，当我们认为它基于坚实的理论基础时，保持三层次模型是有意义的。\n例如，当我们的数据包含具有多个效应量的研究时，我们 知道 这些效应不能是独立的。因此，保持嵌套模型是有意义的，因为它更充分地表示了数据的“生成”方式。如果我们的示例中 anova 的结果支持两层次解决方案，我们将得出结论，研究内部的效应在 很大程度上 是同质的。但无论如何，我们可能会报告三层次模型的结果。这是因为我们知道三层次模型更好地表示了数据生成过程。\n当聚类变量的重要性不明确时，情况会有些不同。例如，假设层次 3 上的聚类在三层次模型中代表不同的文化区域。当我们发现研究中的现象在文化之间没有变化时，完全可以删除第三层并改用两层次模型。",
    "crumbs": [
      "网站首页",
      "多元Meta分析"
    ]
  },
  {
    "objectID": "12-mlma.html#three-level-subgroup",
    "href": "12-mlma.html#three-level-subgroup",
    "title": "(PART) 高级方法",
    "section": "三层次模型中的子组分析",
    "text": "三层次模型中的子组分析\n\n \n一旦设置了我们的三层次模型，就可以评估总体效应的假定调节变量。在本指南的前面，我们发现子组分析可以表示为具有虚拟编码预测变量的 meta 回归模型（第 @ref(the-metareg-model) 章）。以类似的方式，我们可以将回归项添加到“多层次”模型，这将导致 三层次混合效应模型：\n\\[\\begin{equation}\n\\hat\\theta_{ij} = \\theta + \\beta x_i + \\zeta_{(2)ij} + \\zeta_{(3)j} + \\epsilon_{ij}\n(\\#eq:mlm8)\n\\end{equation}\\]\n其中 \\(\\theta\\) 是截距，\\(\\beta\\) 是预测变量 \\(x\\) 的回归权重。当我们用虚拟变量替换 \\(x_i\\) 时（第 @ref(the-metareg-model) 章），我们得到一个可用于子组分析的模型。当 \\(x\\) 是连续的时，上面的公式表示三层次 meta 回归模型。\n可以使用 mods 参数在 rma.mv 中指定分类或连续预测变量。该参数需要一个公式，以波浪号 (~) 开头，然后是预测变量的名称。也可以通过提供多个预测变量来执行多个 meta 回归（例如，~ var1 + var2）。\n在我们的 Chernobyl 示例中，我们想要检查相关性是否因研究样本中的总体辐射量（低、中或高）而异。此信息在我们的数据集中的 radiation 列中提供。我们可以使用以下代码拟合三层次调节变量模型：\n\nmod.model &lt;- rma.mv(yi = z, V = var.z,\n                    slab = author, data = Chernobyl,\n                    random = ~ 1 | author/es.id,\n                    test = \"t\", method = \"REML\",\n                    mods = ~ radiation)\n\nsummary(mod.model)\n\n## [...]\n## Test of Moderators (coefficients 2:3):\n## F(df1 = 2, df2 = 28) = 0.4512, p-val = 0.6414\n##\n## Model Results:\n##                 estimate    se   tval  pval  ci.lb ci.ub\n## intrcpt             0.58  0.36   1.63  0.11  -0.14  1.32\n## radiationlow       -0.19  0.40  -0.48  0.63  -1.03  0.63\n## radiationmedium     0.20  0.54   0.37  0.70  -0.90  1.31\n## [...]\n第一个重要的输出是 Test of Moderators。我们看到 \\(F_{2, 28}=\\) 0.45，其中 \\(p=\\) 0.64。这意味着子组之间没有显着差异。\nModel Results 在 meta 回归框架中打印。这意味着我们无法直接提取估计值以获得子组内的汇集效应量。\n第一个值，截距 (intrcpt)，显示当总体辐射暴露量高时，\\(z\\) 值 (\\(z=\\) 0.58)。低和中组的效应可以通过将它们的 estimate 添加到截距的效应来获得。因此，低辐射组的效应是 \\(z\\) = 0.58 - 0.19 = 0.39，中等暴露组的效应是 \\(z\\) = 0.58 + 0.20 = 0.78。\n\n\n\n报告三层次（调节变量）模型的结果\n当我们报告三层次模型的结果时，我们至少应该在汇集效应旁边提到估计的方差分量。rma.mv 函数分别用 \\(\\sigma^2_1\\) 和 \\(\\sigma^2_2\\) 表示层次 3 和 2 上的随机效应方差。\n然而，当我们报告估计的方差时，使用 \\(\\tau^2_{\\text{Level 3}}\\) 和 \\(\\tau^2_{\\text{Level 2}}\\) 可能是更可取的，因为这清楚地表明我们正在处理 真实（研究）效应 的方差（即，异质性方差）。添加多层次 \\(I^2\\) 值也是有意义的，因为它们更容易让其他人解释——前提是我们首先解释它们代表什么。\n当您使用 anova 进行模型比较时，您至少可以报告似",
    "crumbs": [
      "网站首页",
      "多元Meta分析"
    ]
  },
  {
    "objectID": "12-mlma.html#footnotes",
    "href": "12-mlma.html#footnotes",
    "title": "(PART) 高级方法",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n请注意，最新版本的 {meta} 现在也允许实现 meta 分析三层次模型。在我们第 @ref(pooling-es-r) 章中介绍的所有 meta 分析汇集函数中，现在有一个名为 cluster 的参数。此参数允许定义数据集中变量的名称，该变量包含每个效应量所属的（层次 3）聚类。如果指定了 cluster 参数，则会自动拟合分层三层次模型。例如，我们可以通过运行 metagen(TE, seTE, cluster = InterventionType, data = ThirdWave) 将我们第 @ref(pre-calculated-es) 章中的 meta 分析转换为三层次模型。尽管如此，学习如何使用 {metafor} 拟合三层次模型是很有意义的：首先是因为 {meta} 也在后台使用 {metafor} 来拟合这些类型的模型，其次是因为我们将在本章中介绍的 rma.mv 函数非常通用。正如我们将在第 @ref(rve) 章中看到的那样，它可以用于比“简单”分层三层次模型更多的用途。↩︎",
    "crumbs": [
      "网站首页",
      "多元Meta分析"
    ]
  },
  {
    "objectID": "14-netwma.html",
    "href": "14-netwma.html",
    "title": "网络Meta分析",
    "section": "",
    "text": "当 我们对临床试验或其他类型的干预研究进行meta分析时，我们通常估计一种特定治疗的真实效应量。我们纳入那些将相同类型的干预措施与相似对照组（例如安慰剂）进行比较的研究。在其他条件相同的情况下，这可以评估特定类型的治疗是否有效。\n然而，在许多研究领域，不仅仅存在一种“决定性”的治疗方法，而是存在多种。例如，偏头痛可以用各种药物治疗，也存在非药物治疗的选择。尤其是在“成熟”的研究领域中，证明某种治疗有益往往不太重要。相反，我们想要找出哪种治疗对某些特定适应症最有效。\n这导致了新的问题。为了在传统的meta分析中评估几种治疗方法的比较效果，需要在两种治疗方法之间进行足够的头对头比较。唉，情况往往并非如此。在许多研究领域，通常发现只有少数（如果存在）试验直接比较了两种治疗方法的效果，而不是“较弱”的对照组。这通常意味着传统的meta分析不能用于建立关于几种治疗方法的相对有效性的可靠证据。\n然而，虽然两种或多种治疗方法之间的直接比较可能不存在，但通常可以获得间接证据。不同的治疗方法可能已经在单独的试验中进行了评估，但所有这些试验可能都使用了相同的对照组。例如，两种药物可能从未直接比较过，但与安慰剂相比，这两种药物的效果可能都经过了广泛的研究。\n\n网络meta分析可用于纳入这种间接比较，因此使我们能够同时比较几种干预措施的效果[@dias2013evidence]。网络meta分析也称为混合治疗比较meta分析[@van2012automating]。这是因为它将多个直接和间接的治疗比较整合到一个模型中，该模型可以形式化为一个比较的“网络”。\n\n网络meta分析是一个“热门”的研究课题。在过去的十年中，它越来越受到生物医学领域和其他学科的应用研究人员的青睐。然而，这种方法也带来额外的挑战和陷阱，特别是在异质性和所谓的网络不一致性方面[@salanti2014evaluating]。\n因此，重要的是首先讨论网络meta分析模型的核心组成部分和假设。网络meta分析的基础有时可能有点抽象。因此，我们将逐步介绍必要的细节，以便更好地理解这种方法。\n\n\n\n\n\n\n\n首先，我们必须理解“治疗网络”是什么意思。假设我们已经从一些随机对照试验 \\(i\\) 中提取了数据，该试验比较了治疗方法A与另一种条件B（例如，等候名单对照组）的效果。我们可以用图形来说明这种比较：\n\n\n\n\n\n\n\n\n\n\n这种治疗比较的可视化表示称为图。图是用于模拟不同对象之间如何相互关联的结构，并且存在一个完整的数学子领域，图论，专门研究这个主题。\n我们的图有两个核心组成部分。第一个是两个圆圈（所谓的节点），它们代表试验 \\(i\\) 中的两种条件A和B。第二个组成部分是连接这两个节点的线。这条线被称为边。边表示A和B如何相互关联。在我们的例子中，这条线的解释非常简单。我们可以根据我们在比较A和B时观察到的效应量 \\(\\hat\\theta_{i\\text{,A,B}}\\) 来描述A和B之间的关系。这种效应量可以表示为，例如，SMD或优势比，具体取决于结果测量。\n现在，假设我们还从另一项研究 \\(j\\) 中获得了数据。该试验也使用了对照条件B。但该研究没有施用A，而是使用了另一种治疗方法C。在研究 \\(j\\) 中，治疗方法C也与B进行了比较。我们可以将此信息添加到我们的图中：\n\n\n\n\n\n\n\n\n\n这创建了我们的第一个小型网络。可以清楚地看到，该图现在包含两个效应量估计值：\\(\\hat\\theta_{i\\text{,A,B}}\\)，比较A和B，以及 \\(\\hat\\theta_{j\\text{,C,B}}\\)，比较C和B。由于这两个效应量都是在“真实”试验中直接观察到的，因此我们将此类信息称为直接证据。因此，我们用 \\(\\hat\\theta^{\\text{direct}}_{\\text{B,A}}\\) 和 \\(\\hat\\theta^{\\text{direct}}_{\\text{B,C}}\\) 表示这些效应量。在这种表示法中，条件B排在第一位，因为我们确定它是我们的参考组。我们选择B作为参考条件，因为两项试验都使用它作为对照组。\n在新图中，所有节点（条件）要么直接连接，要么间接连接。B条件（我们的对照组）直接连接到所有其他节点。在图中只需要一个“步骤”就可以从B到达其他两个节点A和C：B \\(\\rightarrow\\) A，B \\(\\rightarrow\\) C。相反，A和C只有一个直接连接，它们都连接到B：A \\(\\rightarrow\\) B 和 C \\(\\rightarrow\\) B。\n但是，A和C之间存在间接连接。这种连接的存在是因为B充当了两种条件之间的链接或桥梁：A \\(\\rightarrow\\) B \\(\\rightarrow\\) C。因此，存在间接证据 表明A和C之间的关系，可以从网络的结构中得出：\n\n\n\n\n\n\n\n\n\n使用来自直接观察到的边的信息，我们可以计算间接观察到的A和C之间比较的效果。我们用 \\(\\hat\\theta^{\\text{indirect}}_{\\text{A,C}}\\) 表示这种未观察到的间接效应量。可以使用以下公式推导效应估计值[@dias2018network, chapter 1]：\n\\[\\begin{equation}\n\\hat\\theta_{\\text{A,C}}^{\\text{indirect}} = \\hat\\theta_{\\text{B,A}}^{\\text{direct}} - \\hat\\theta_{\\text{B,C}}^{\\text{direct}}\n(\\#eq:networkes)\n\\end{equation}\\]\n这一步是网络meta分析的关键组成部分。上面的公式让我们能够估计比较的效应量，即使它从未在试验中直接评估过。\n网络meta分析涉及在一个模型中组合直接和间接证据。基于此信息，我们可以估计每个纳入治疗的（相对）效果。通过添加间接证据，我们还可以提高效应量估计的精度，即使存在该特定比较的直接证据。总的来说，网络meta分析具有以下几个优点：\n\n它允许我们将一组相关研究中的所有可用信息汇集到一个分析中。想想我们通常如何在传统的meta分析中处理将不同治疗方法与安慰剂进行比较的试验。我们将不得不在单独的meta分析中汇集每次比较（例如，治疗A与安慰剂比较，治疗B与安慰剂比较，治疗A与治疗B比较等）。\n网络meta分析可以将间接证据纳入网络中，这在传统的meta分析中是不可能的。在成对meta分析中，我们只能汇集试验中实际包含的比较的直接证据。\n如果满足所有假设，并且结果具有足够的结论性，则网络meta分析允许我们推断出哪种类型的治疗可能更适合所研究的目标人群。\n\n所有这些听起来都很有趣，但我们必须考虑一些重要的限制。首先，看看间接效应量估计值的方差是如何计算的：\n\\[\\begin{equation}\n\\text{Var} \\left(\\hat\\theta_{\\text{A,C}}^{\\text{indirect}} \\right) = \\text{Var} \\left(\\hat\\theta_{\\text{B,A}}^{\\text{direct}} \\right) + \\text{Var} \\left(\\hat\\theta_{\\text{B,C}}^{\\text{direct}} \\right)\n(\\#eq:nw2)\n\\end{equation}\\]\n为了计算间接比较的方差，我们将直接比较的方差相加。这意味着与基于直接证据的效应量相比，从间接证据估计的效应量将始终具有更大的方差，因此精度较低[@dias2018network, chapter 1]。这完全符合逻辑。与必须通过数学推断的结果相比，我们对从观察数据估计的效应量具有更高的置信度。\n \n还有另一个问题。之前的公式@ref(eq:networkes)允许我们从直接比较中估计间接证据，但前提是满足一个关键的先决条件：传递性假设。从统计学角度来看，这个假设转化为网络一致性[@efthimiou2016getreal]。下面，我们将解释这两个术语的含义，以及为什么它们很重要。\n\n\n\n\n\n网络meta分析无疑是标准meta分析方法的有价值的扩展。然而，它们的有效性并没有保持不变。对网络meta分析的大部分批评都围绕着使用间接证据，正如您可能已经猜到的那样[@edwards2009indirect; @ioannidis2006indirect]。这尤其涉及实际存在比较的直接证据的情况。\n关键问题是，虽然（随机）试验中的参与者是偶然地分配到一种治疗条件（例如，A和B）的，但试验条件本身并不是在我们的网络中随机选择的。这当然是完全符合逻辑的。将参与者随机分配到试验的几种条件之一通常没有问题。然而，很难想象研究人员在推出她的研究之前，会通过掷骰子来确定试验中使用的治疗条件。在网络meta分析中，选定的试验条件的组成几乎不会遵循随机模式。\n这对网络meta分析模型本身来说并不构成问题[@dias2018network, chapter 1]。只有当试验中特定比较的选择或不选择取决于该比较的真实效果时，我们的网络meta分析模型才会产生偏差[@dias2013evidence]。这个说法非常抽象，所以让我们详细说明一下。\n \n我们刚才提到的要求源自网络meta分析的传递性假设。关于这是否是网络meta分析独有的假设，或者只是传统成对meta分析中假设的扩展，文献中存在分歧。这种分歧可能部分是由于文献中术语使用不一致造成的[@dias2018network; @efthimiou2016getreal; @song2009methodological; @lu2009modeling]。\n传递性假设的核心原则是，我们可以组合直接证据（例如，来自A \\(−\\) B和C \\(−\\) B的比较）来创建关于相关比较的间接证据（例如，A \\(−\\) C），就像我们之前使用公式@ref(eq:networkes)所做的那样[@efthimiou2016getreal]。\n\n传递性假设与可交换性的概念有关。我们已经在第@ref(rem)章中描述了这个前提条件，我们在该章中讨论了随机效应模型。可交换性假设表明，某些比较 \\(i\\) 的每个真实效应量 \\(\\theta_i\\) 都是从真实效应量的“总体”分布中随机、独立抽取的结果。\n为了将这个假设转化为我们的场景，可以将网络meta分析视为一组 \\(K\\) 试验。现在，我们假设模型中的每个试验都包含网络中所有可能的治疗比较，用 \\(M\\) 表示（例如，A \\(−\\) B，A \\(−\\) C，B \\(−\\) C 等等）。但是，一些治疗比较已经被“删除”，因此在某些试验中“缺失”。原因是，在实践中，研究无法评估所有可能的治疗选择[@dias2013evidence]。\n关键假设是，例如 A \\(-\\) B 的比较效果在试验之间是可交换的——无论试验是否实际评估了这种比较，或者它是否“缺失”。在网络meta分析中，当某些比较 \\(i\\) 的效应 \\(\\hat\\theta_i\\) 基于从真实效应的总体分布中随机、独立抽取的结果时，无论该效应量是通过直接证据还是间接证据得出，都满足可交换性。\n当协变量或其他效应修饰因素（例如，研究人群的年龄组或治疗强度）在评估条件 A 与 B 和 C 与 B 的试验中没有均匀分布时，可能会违反传递性假设[@song2009methodological]。传递性本身无法通过统计学方法进行检验，但可以通过仅纳入人口、方法和目标条件尽可能相似的研究来减轻违反该假设的风险[@salanti2014evaluating]。\n传递性的统计表现形式称为一致性，而缺乏一致性则称为不一致[@efthimiou2016getreal; @cipriani2013conceptual]。一致性意味着基于直接证据的比较（例如，A \\(-\\) B）的相对效果与基于间接证据的效果没有差异[@schwarzer2015meta, chapter 8]：\n\\[\\begin{equation}\n\\theta_{\\text{A,B}}^{\\text{indirect}} = \\theta_{\\text{A,B}}^{\\text{direct}}\n(\\#eq:nw3)\n\\end{equation}\\]\n\n已经提出了几种方法来诊断网络meta分析模型中的不一致性，包括网络热图[@krahn2013graphical]和节点分割方法[@dias2010checking]。我们将在以下章节中更详细地描述这些方法。\n\n\n\n\n\n这结束了我们对网络meta分析模型基本理论和假设的描述。之前，我们使用了一个包含三个节点和边的简单网络作为说明。然而，在实践中，网络meta分析中包含的治疗方法数量通常要高得多。这很快导致了相当复杂的网络，例如看起来像这样的网络：\n\n\n\n\n\n\n\n\n\n然而，随着网络中治疗方法 \\(S\\) 数量的增加，我们需要估计的（直接和间接）成对比较 \\(C\\) 的数量会急剧增加：\n\n\n\n\n\n\n\n\n\n \n因此，我们需要一个计算模型，该模型允许我们以有效且内部一致的方式汇集所有可用的网络数据。已经开发了几种用于网络meta分析的统计方法[@efthimiou2016getreal]。在接下来的章节中，我们将讨论频率学以及贝叶斯分层模型，以及如何在 R 中实现它们。\n\n\n\n我应该使用哪种建模方法？\n\n\n虽然网络meta分析模型在统计方法上可能有所不同，但好消息是，当样本量足够大时，所有模型都应该产生相同的结果[@shim2019network]。一般来说，没有哪种网络meta分析方法比其他方法更有效或更无效。因此，您可以根据您认为更直观的方法，或者基于实现它的 R 包的功能，安全地选择一种方法[@efthimiou2016getreal]。\n\n\n在大多数学科中，基于频率论推断的方法（仍然）比贝叶斯方法更常见。这意味着有些人可能更容易理解频率论模型产生的结果类型。一个缺点是，在 R 中实现频率论网络meta分析（我们将在接下来介绍）还不支持meta回归，而使用贝叶斯模型是可能的。\n\n\n在实践中，一个有用的策略是选择一种方法进行主要分析，然后在敏感性分析中使用另一种方法。如果这两种方法得出相同的结论，这将增加我们对研究结果值得信赖的信心。\n\n\n\n\n\n\n\n\n\n \n下面，我们将介绍如何使用 {netmeta} 包 [@nemeta] 执行网络meta分析。该包允许在频率学框架内估计网络meta分析模型。{netmeta} 使用的方法源自图论技术，该技术最初是为电气网络开发的[@rucker2012network]。\n\n\n\n概率的频率学解释\n\n\n频率论是解释某些事件 (E) 的概率的一种常见的理论方法。频率论方法根据如果我们重复某个过程（例如，实验）很多很多次，预期 (E) 发生的频率来定义 (E) 的概率[@aronow2019foundations, chapter 1.1.1]。\n\n\n频率论的思想是定量研究人员每天使用的许多统计程序的核心，例如显着性检验、置信区间的计算或 (p) 值。\n\n\n\n\n\n\n\n现在让我们描述一下 {netmeta} 包中实现的网络meta分析模型是如何制定的。假设我们已经从几个试验中收集了效应量数据。然后，我们遍历所有 \\(K\\) 个试验，并计算研究中包含的治疗比较的总数。成对比较的数量用 \\(M\\) 表示。\n然后，我们计算每个比较 \\(m\\) 的效应量 \\(\\hat\\theta_m\\)，并将所有效应量收集到一个向量中 \\(\\boldsymbol{\\hat\\theta} = (\\hat\\theta_1, \\hat\\theta_2, \\dots, \\hat\\theta_M)\\)。为了运行网络meta分析，我们现在需要一个模型来描述如何生成观察到的效应量向量 \\(\\boldsymbol{\\hat\\theta}\\)。在 {netmeta} 中，使用以下模型 [@schwarzer2015meta, chapter 8]：\n\\[\\begin{equation}\n\\boldsymbol{\\hat\\theta} =\\boldsymbol{X} \\boldsymbol{\\theta}_{\\text{treat}} + \\boldsymbol{\\epsilon}\n(\\#eq:nw4)\n\\end{equation}\\]\n我们假设观察到的效应量向量 \\(\\boldsymbol{\\hat\\theta}\\) 是由公式的右侧（我们的模型）生成的。第一部分，\\(\\boldsymbol{X}\\) 是一个 \\(m \\times n\\) 设计矩阵，其中列表示不同的治疗方法 \\(n\\)，行表示治疗比较 \\(m\\)。在矩阵中，治疗比较由同一行中的 1 和 -1 定义，其中列位置与正在比较的治疗方法相对应。\n公式中最重要的部分是向量 \\(\\boldsymbol{\\theta}_{\\text{treat}}\\)。该向量包含我们网络中 \\(n\\) 种独特治疗方法的真实效果。这个向量是我们的网络meta分析模型需要估计的，因为它允许我们确定网络中哪些治疗方法是最有效的。\n参数 \\(\\boldsymbol{\\epsilon}\\) 是一个包含所有比较的抽样误差 \\(\\epsilon_m\\) 的向量。假定每个比较的抽样误差是从均值为零且方差为 \\(\\sigma^2_m\\) 的高斯正态分布中随机抽取的：\n\\[\\begin{equation}\n\\epsilon_m \\sim \\mathcal{N}(0,\\sigma_m^2)\n(\\#eq:nw4)\n\\end{equation}\\]\n为了说明模型公式 [参见 @schwarzer2015meta, page 189]，假设我们的网络meta分析由 \\(K=\\) 5 项研究组成。每项研究都包含独特的治疗比较（即 \\(K=M\\)）。这些比较是 A \\(-\\) B、A \\(-\\) C、A \\(-\\) D、B \\(-\\) C 和 B \\(-\\) D。这导致了一个（观察到的）比较向量 \\(\\boldsymbol{\\hat\\theta} = (\\hat\\theta_{1\\text{,A,B}}, \\hat\\theta_{2\\text{,A,C}}, \\hat\\theta_{4\\text{,A,D}}, \\hat\\theta_{4\\text{,B,C}}, \\hat\\theta_{5\\text{,B,D}})^\\top\\)。我们的目标是估计网络中包含的所有四个条件的真实效应量，\\(\\boldsymbol{\\theta}_{\\text{treat}} = (\\theta_{\\text{A}}, \\theta_{\\text{B}}, \\theta_{\\text{C}}, \\theta_{\\text{D}})^\\top\\)。如果我们把这些参数插入到我们的模型公式中，我们会得到下面的等式：\n\\[\\begin{align}\n  \\boldsymbol{\\hat\\theta} &= \\boldsymbol{X} \\boldsymbol{\\theta}_{\\text{treat}} + \\boldsymbol{\\epsilon} \\notag \\\\\n\\begin{bmatrix}\n\\hat\\theta_{1\\text{,A,B}} \\\\\n\\hat\\theta_{2\\text{,A,C}} \\\\\n\\hat\\theta_{3\\text{,A,D}} \\\\\n\\hat\\theta_{4\\text{,B,C}} \\\\\n\\hat\\theta_{5\\text{,B,D}} \\\\\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n1 & -1 & 0 & 0 \\\\\n1 & 0 & -1 & 0 \\\\\n1 & 0 & 0 & -1 \\\\\n0 & 1 & -1 & 0 \\\\\n0 & 1 & 0 & -1 \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\theta_{\\text{A}} \\\\\n\\theta_{\\text{B}} \\\\\n\\theta_{\\text{C}} \\\\\n\\theta_{\\text{D}} \\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\epsilon_{1} \\\\\n\\epsilon_{2} \\\\\n\\epsilon_{3} \\\\\n\\epsilon_{4} \\\\\n\\epsilon_{5} \\\\\n\\end{bmatrix}\n(\\#eq:nw5)\n\\end{align}\\]\n值得注意的是，就目前的形式而言，这个模型公式从数学角度来看是有问题的。现在，该模型是过度参数化的。模型中有太多的参数 \\(\\boldsymbol{\\theta}_{\\text{treat}}\\) 需要根据手头的信息进行估计。\n这与设计矩阵 \\(\\boldsymbol{X}\\) 没有满秩有关。在我们的例子中，当矩阵的列不是全部独立的时，矩阵就没有满秩；或者，换句话说，当独立列的数量小于列的总数 \\(n\\) 时1。因为我们正在处理一个治疗方法的网络，所以很明显，治疗方法的组合不会完全彼此独立。例如，治疗方法 D 的列（第四列）可以描述为前三列的线性组合2。\n总的来说，最多有 \\(n-1\\) 个独立的治疗方法比较，但我们的模型总是需要估计 \\(\\boldsymbol{\\theta}_{\\text{treat}}\\) 中 \\(n\\) 种治疗方法的真实效果。因此，该矩阵没有满秩。\\(\\boldsymbol{X}\\) 没有满秩的事实意味着它是不可逆的；因此，无法使用（加权）最小二乘法直接估计 \\(\\boldsymbol{\\theta}_{\\text{treat}}\\)。\n\n这就是 {netmeta} 中实现的图论方法提供解决方案的地方。我们将为您省去这种方法背后繁琐的数学细节，特别是考虑到 {netmeta} 包无论如何都会为我们完成繁重的工作。我们只提一下，这种方法涉及构建一个所谓的Moore-Penrose 伪逆矩阵，然后可以使用加权最小二乘法计算我们网络模型的拟合值。\n该程序还处理多臂研究，这些研究贡献了多个成对比较（即，比较了两种以上条件的研究）。多臂比较是相关的，因为至少有一个条件被比较多次（第 @ref(unit-of-analysis) 章）。这意味着多臂研究比较的精度被人为地提高了——除非在我们的模型中考虑了这一点。\n该模型还允许我们将研究间异质性的估计值纳入其中。与“传统的”随机效应模型（第 @ref(rem) 章）一样，这是通过将估计的异质性方差 \\(\\hat\\tau^2\\) 添加到比较 \\(m\\) 的方差来实现的：\\(s^2_m + \\hat\\tau^2\\)。在 {netmeta} 包中，\\(\\tau^2\\) 值是使用 DerSimonian-Laird 估计器的改编版本估计的 [@jackson2013matrix, 另请参见第 \\@ref(tau-estimators) 章]。\n\n也可以计算 \\(I^2\\) 的等效值，它现在表示我们网络中的不一致性量。与 Higgins 和 Thompson 的公式（参见第 @ref(i-squared) 章）一样，此 \\(I^2\\) 版本源自 \\(Q\\)。然而，在网络meta分析中，\\(Q\\) 转化为网络中的总异质性（也用 \\(Q_{\\text{total}}\\) 表示）。因此，使用以下公式：\n\\[\\begin{equation}\nI^2 = \\text{max} \\left(\\frac{Q_{\\text{total}}-\\text{d.f.}} {Q_{\\text{total}}}, 0 \\right)\n(\\#eq:nw6)\n\\end{equation}\\]\n其中我们网络中的自由度是：\n\\[\\begin{equation}\n\\text{d.f.} = \\left( \\sum^K_{k=1}p_k-1 \\right)- (n-1)\n(\\#eq:nw7)\n\\end{equation}\\]\n其中 \\(K\\) 是研究的总数，\\(p\\) 是某些研究 \\(k\\) 中条件的数量，\\(n\\) 是我们网络模型中治疗方法的总数。\n\n\n\n\n\n在所有的输入之后，是时候进行一个实践的例子了。下面，我们将使用 {netmeta} 来进行我们自己的网络meta分析。与往常一样，我们首先安装包，然后从库中加载它。\n\nlibrary(netmeta)\n\n\n\n\n\n在这个说明中，我们使用 TherapyFormats 数据。这个数据集是根据一个真实的",
    "crumbs": [
      "网站首页",
      "网络Meta分析"
    ]
  },
  {
    "objectID": "14-netwma.html#what-is-net-ma",
    "href": "14-netwma.html#what-is-net-ma",
    "title": "网络Meta分析",
    "section": "",
    "text": "首先，我们必须理解“治疗网络”是什么意思。假设我们已经从一些随机对照试验 \\(i\\) 中提取了数据，该试验比较了治疗方法A与另一种条件B（例如，等候名单对照组）的效果。我们可以用图形来说明这种比较：\n\n\n\n\n\n\n\n\n\n\n这种治疗比较的可视化表示称为图。图是用于模拟不同对象之间如何相互关联的结构，并且存在一个完整的数学子领域，图论，专门研究这个主题。\n我们的图有两个核心组成部分。第一个是两个圆圈（所谓的节点），它们代表试验 \\(i\\) 中的两种条件A和B。第二个组成部分是连接这两个节点的线。这条线被称为边。边表示A和B如何相互关联。在我们的例子中，这条线的解释非常简单。我们可以根据我们在比较A和B时观察到的效应量 \\(\\hat\\theta_{i\\text{,A,B}}\\) 来描述A和B之间的关系。这种效应量可以表示为，例如，SMD或优势比，具体取决于结果测量。\n现在，假设我们还从另一项研究 \\(j\\) 中获得了数据。该试验也使用了对照条件B。但该研究没有施用A，而是使用了另一种治疗方法C。在研究 \\(j\\) 中，治疗方法C也与B进行了比较。我们可以将此信息添加到我们的图中：\n\n\n\n\n\n\n\n\n\n这创建了我们的第一个小型网络。可以清楚地看到，该图现在包含两个效应量估计值：\\(\\hat\\theta_{i\\text{,A,B}}\\)，比较A和B，以及 \\(\\hat\\theta_{j\\text{,C,B}}\\)，比较C和B。由于这两个效应量都是在“真实”试验中直接观察到的，因此我们将此类信息称为直接证据。因此，我们用 \\(\\hat\\theta^{\\text{direct}}_{\\text{B,A}}\\) 和 \\(\\hat\\theta^{\\text{direct}}_{\\text{B,C}}\\) 表示这些效应量。在这种表示法中，条件B排在第一位，因为我们确定它是我们的参考组。我们选择B作为参考条件，因为两项试验都使用它作为对照组。\n在新图中，所有节点（条件）要么直接连接，要么间接连接。B条件（我们的对照组）直接连接到所有其他节点。在图中只需要一个“步骤”就可以从B到达其他两个节点A和C：B \\(\\rightarrow\\) A，B \\(\\rightarrow\\) C。相反，A和C只有一个直接连接，它们都连接到B：A \\(\\rightarrow\\) B 和 C \\(\\rightarrow\\) B。\n但是，A和C之间存在间接连接。这种连接的存在是因为B充当了两种条件之间的链接或桥梁：A \\(\\rightarrow\\) B \\(\\rightarrow\\) C。因此，存在间接证据 表明A和C之间的关系，可以从网络的结构中得出：\n\n\n\n\n\n\n\n\n\n使用来自直接观察到的边的信息，我们可以计算间接观察到的A和C之间比较的效果。我们用 \\(\\hat\\theta^{\\text{indirect}}_{\\text{A,C}}\\) 表示这种未观察到的间接效应量。可以使用以下公式推导效应估计值[@dias2018network, chapter 1]：\n\\[\\begin{equation}\n\\hat\\theta_{\\text{A,C}}^{\\text{indirect}} = \\hat\\theta_{\\text{B,A}}^{\\text{direct}} - \\hat\\theta_{\\text{B,C}}^{\\text{direct}}\n(\\#eq:networkes)\n\\end{equation}\\]\n这一步是网络meta分析的关键组成部分。上面的公式让我们能够估计比较的效应量，即使它从未在试验中直接评估过。\n网络meta分析涉及在一个模型中组合直接和间接证据。基于此信息，我们可以估计每个纳入治疗的（相对）效果。通过添加间接证据，我们还可以提高效应量估计的精度，即使存在该特定比较的直接证据。总的来说，网络meta分析具有以下几个优点：\n\n它允许我们将一组相关研究中的所有可用信息汇集到一个分析中。想想我们通常如何在传统的meta分析中处理将不同治疗方法与安慰剂进行比较的试验。我们将不得不在单独的meta分析中汇集每次比较（例如，治疗A与安慰剂比较，治疗B与安慰剂比较，治疗A与治疗B比较等）。\n网络meta分析可以将间接证据纳入网络中，这在传统的meta分析中是不可能的。在成对meta分析中，我们只能汇集试验中实际包含的比较的直接证据。\n如果满足所有假设，并且结果具有足够的结论性，则网络meta分析允许我们推断出哪种类型的治疗可能更适合所研究的目标人群。\n\n所有这些听起来都很有趣，但我们必须考虑一些重要的限制。首先，看看间接效应量估计值的方差是如何计算的：\n\\[\\begin{equation}\n\\text{Var} \\left(\\hat\\theta_{\\text{A,C}}^{\\text{indirect}} \\right) = \\text{Var} \\left(\\hat\\theta_{\\text{B,A}}^{\\text{direct}} \\right) + \\text{Var} \\left(\\hat\\theta_{\\text{B,C}}^{\\text{direct}} \\right)\n(\\#eq:nw2)\n\\end{equation}\\]\n为了计算间接比较的方差，我们将直接比较的方差相加。这意味着与基于直接证据的效应量相比，从间接证据估计的效应量将始终具有更大的方差，因此精度较低[@dias2018network, chapter 1]。这完全符合逻辑。与必须通过数学推断的结果相比，我们对从观察数据估计的效应量具有更高的置信度。\n \n还有另一个问题。之前的公式@ref(eq:networkes)允许我们从直接比较中估计间接证据，但前提是满足一个关键的先决条件：传递性假设。从统计学角度来看，这个假设转化为网络一致性[@efthimiou2016getreal]。下面，我们将解释这两个术语的含义，以及为什么它们很重要。\n\n\n\n\n\n网络meta分析无疑是标准meta分析方法的有价值的扩展。然而，它们的有效性并没有保持不变。对网络meta分析的大部分批评都围绕着使用间接证据，正如您可能已经猜到的那样[@edwards2009indirect; @ioannidis2006indirect]。这尤其涉及实际存在比较的直接证据的情况。\n关键问题是，虽然（随机）试验中的参与者是偶然地分配到一种治疗条件（例如，A和B）的，但试验条件本身并不是在我们的网络中随机选择的。这当然是完全符合逻辑的。将参与者随机分配到试验的几种条件之一通常没有问题。然而，很难想象研究人员在推出她的研究之前，会通过掷骰子来确定试验中使用的治疗条件。在网络meta分析中，选定的试验条件的组成几乎不会遵循随机模式。\n这对网络meta分析模型本身来说并不构成问题[@dias2018network, chapter 1]。只有当试验中特定比较的选择或不选择取决于该比较的真实效果时，我们的网络meta分析模型才会产生偏差[@dias2013evidence]。这个说法非常抽象，所以让我们详细说明一下。\n \n我们刚才提到的要求源自网络meta分析的传递性假设。关于这是否是网络meta分析独有的假设，或者只是传统成对meta分析中假设的扩展，文献中存在分歧。这种分歧可能部分是由于文献中术语使用不一致造成的[@dias2018network; @efthimiou2016getreal; @song2009methodological; @lu2009modeling]。\n传递性假设的核心原则是，我们可以组合直接证据（例如，来自A \\(−\\) B和C \\(−\\) B的比较）来创建关于相关比较的间接证据（例如，A \\(−\\) C），就像我们之前使用公式@ref(eq:networkes)所做的那样[@efthimiou2016getreal]。\n\n传递性假设与可交换性的概念有关。我们已经在第@ref(rem)章中描述了这个前提条件，我们在该章中讨论了随机效应模型。可交换性假设表明，某些比较 \\(i\\) 的每个真实效应量 \\(\\theta_i\\) 都是从真实效应量的“总体”分布中随机、独立抽取的结果。\n为了将这个假设转化为我们的场景，可以将网络meta分析视为一组 \\(K\\) 试验。现在，我们假设模型中的每个试验都包含网络中所有可能的治疗比较，用 \\(M\\) 表示（例如，A \\(−\\) B，A \\(−\\) C，B \\(−\\) C 等等）。但是，一些治疗比较已经被“删除”，因此在某些试验中“缺失”。原因是，在实践中，研究无法评估所有可能的治疗选择[@dias2013evidence]。\n关键假设是，例如 A \\(-\\) B 的比较效果在试验之间是可交换的——无论试验是否实际评估了这种比较，或者它是否“缺失”。在网络meta分析中，当某些比较 \\(i\\) 的效应 \\(\\hat\\theta_i\\) 基于从真实效应的总体分布中随机、独立抽取的结果时，无论该效应量是通过直接证据还是间接证据得出，都满足可交换性。\n当协变量或其他效应修饰因素（例如，研究人群的年龄组或治疗强度）在评估条件 A 与 B 和 C 与 B 的试验中没有均匀分布时，可能会违反传递性假设[@song2009methodological]。传递性本身无法通过统计学方法进行检验，但可以通过仅纳入人口、方法和目标条件尽可能相似的研究来减轻违反该假设的风险[@salanti2014evaluating]。\n传递性的统计表现形式称为一致性，而缺乏一致性则称为不一致[@efthimiou2016getreal; @cipriani2013conceptual]。一致性意味着基于直接证据的比较（例如，A \\(-\\) B）的相对效果与基于间接证据的效果没有差异[@schwarzer2015meta, chapter 8]：\n\\[\\begin{equation}\n\\theta_{\\text{A,B}}^{\\text{indirect}} = \\theta_{\\text{A,B}}^{\\text{direct}}\n(\\#eq:nw3)\n\\end{equation}\\]\n\n已经提出了几种方法来诊断网络meta分析模型中的不一致性，包括网络热图[@krahn2013graphical]和节点分割方法[@dias2010checking]。我们将在以下章节中更详细地描述这些方法。\n\n\n\n\n\n这结束了我们对网络meta分析模型基本理论和假设的描述。之前，我们使用了一个包含三个节点和边的简单网络作为说明。然而，在实践中，网络meta分析中包含的治疗方法数量通常要高得多。这很快导致了相当复杂的网络，例如看起来像这样的网络：\n\n\n\n\n\n\n\n\n\n然而，随着网络中治疗方法 \\(S\\) 数量的增加，我们需要估计的（直接和间接）成对比较 \\(C\\) 的数量会急剧增加：\n\n\n\n\n\n\n\n\n\n \n因此，我们需要一个计算模型，该模型允许我们以有效且内部一致的方式汇集所有可用的网络数据。已经开发了几种用于网络meta分析的统计方法[@efthimiou2016getreal]。在接下来的章节中，我们将讨论频率学以及贝叶斯分层模型，以及如何在 R 中实现它们。\n\n\n\n我应该使用哪种建模方法？\n\n\n虽然网络meta分析模型在统计方法上可能有所不同，但好消息是，当样本量足够大时，所有模型都应该产生相同的结果[@shim2019network]。一般来说，没有哪种网络meta分析方法比其他方法更有效或更无效。因此，您可以根据您认为更直观的方法，或者基于实现它的 R 包的功能，安全地选择一种方法[@efthimiou2016getreal]。\n\n\n在大多数学科中，基于频率论推断的方法（仍然）比贝叶斯方法更常见。这意味着有些人可能更容易理解频率论模型产生的结果类型。一个缺点是，在 R 中实现频率论网络meta分析（我们将在接下来介绍）还不支持meta回归，而使用贝叶斯模型是可能的。\n\n\n在实践中，一个有用的策略是选择一种方法进行主要分析，然后在敏感性分析中使用另一种方法。如果这两种方法得出相同的结论，这将增加我们对研究结果值得信赖的信心。",
    "crumbs": [
      "网站首页",
      "网络Meta分析"
    ]
  },
  {
    "objectID": "14-netwma.html#frequentist-ma",
    "href": "14-netwma.html#frequentist-ma",
    "title": "网络Meta分析",
    "section": "",
    "text": "下面，我们将介绍如何使用 {netmeta} 包 [@nemeta] 执行网络meta分析。该包允许在频率学框架内估计网络meta分析模型。{netmeta} 使用的方法源自图论技术，该技术最初是为电气网络开发的[@rucker2012network]。\n\n\n\n概率的频率学解释\n\n\n频率论是解释某些事件 (E) 的概率的一种常见的理论方法。频率论方法根据如果我们重复某个过程（例如，实验）很多很多次，预期 (E) 发生的频率来定义 (E) 的概率[@aronow2019foundations, chapter 1.1.1]。\n\n\n频率论的思想是定量研究人员每天使用的许多统计程序的核心，例如显着性检验、置信区间的计算或 (p) 值。\n\n\n\n\n\n\n\n现在让我们描述一下 {netmeta} 包中实现的网络meta分析模型是如何制定的。假设我们已经从几个试验中收集了效应量数据。然后，我们遍历所有 \\(K\\) 个试验，并计算研究中包含的治疗比较的总数。成对比较的数量用 \\(M\\) 表示。\n然后，我们计算每个比较 \\(m\\) 的效应量 \\(\\hat\\theta_m\\)，并将所有效应量收集到一个向量中 \\(\\boldsymbol{\\hat\\theta} = (\\hat\\theta_1, \\hat\\theta_2, \\dots, \\hat\\theta_M)\\)。为了运行网络meta分析，我们现在需要一个模型来描述如何生成观察到的效应量向量 \\(\\boldsymbol{\\hat\\theta}\\)。在 {netmeta} 中，使用以下模型 [@schwarzer2015meta, chapter 8]：\n\\[\\begin{equation}\n\\boldsymbol{\\hat\\theta} =\\boldsymbol{X} \\boldsymbol{\\theta}_{\\text{treat}} + \\boldsymbol{\\epsilon}\n(\\#eq:nw4)\n\\end{equation}\\]\n我们假设观察到的效应量向量 \\(\\boldsymbol{\\hat\\theta}\\) 是由公式的右侧（我们的模型）生成的。第一部分，\\(\\boldsymbol{X}\\) 是一个 \\(m \\times n\\) 设计矩阵，其中列表示不同的治疗方法 \\(n\\)，行表示治疗比较 \\(m\\)。在矩阵中，治疗比较由同一行中的 1 和 -1 定义，其中列位置与正在比较的治疗方法相对应。\n公式中最重要的部分是向量 \\(\\boldsymbol{\\theta}_{\\text{treat}}\\)。该向量包含我们网络中 \\(n\\) 种独特治疗方法的真实效果。这个向量是我们的网络meta分析模型需要估计的，因为它允许我们确定网络中哪些治疗方法是最有效的。\n参数 \\(\\boldsymbol{\\epsilon}\\) 是一个包含所有比较的抽样误差 \\(\\epsilon_m\\) 的向量。假定每个比较的抽样误差是从均值为零且方差为 \\(\\sigma^2_m\\) 的高斯正态分布中随机抽取的：\n\\[\\begin{equation}\n\\epsilon_m \\sim \\mathcal{N}(0,\\sigma_m^2)\n(\\#eq:nw4)\n\\end{equation}\\]\n为了说明模型公式 [参见 @schwarzer2015meta, page 189]，假设我们的网络meta分析由 \\(K=\\) 5 项研究组成。每项研究都包含独特的治疗比较（即 \\(K=M\\)）。这些比较是 A \\(-\\) B、A \\(-\\) C、A \\(-\\) D、B \\(-\\) C 和 B \\(-\\) D。这导致了一个（观察到的）比较向量 \\(\\boldsymbol{\\hat\\theta} = (\\hat\\theta_{1\\text{,A,B}}, \\hat\\theta_{2\\text{,A,C}}, \\hat\\theta_{4\\text{,A,D}}, \\hat\\theta_{4\\text{,B,C}}, \\hat\\theta_{5\\text{,B,D}})^\\top\\)。我们的目标是估计网络中包含的所有四个条件的真实效应量，\\(\\boldsymbol{\\theta}_{\\text{treat}} = (\\theta_{\\text{A}}, \\theta_{\\text{B}}, \\theta_{\\text{C}}, \\theta_{\\text{D}})^\\top\\)。如果我们把这些参数插入到我们的模型公式中，我们会得到下面的等式：\n\\[\\begin{align}\n  \\boldsymbol{\\hat\\theta} &= \\boldsymbol{X} \\boldsymbol{\\theta}_{\\text{treat}} + \\boldsymbol{\\epsilon} \\notag \\\\\n\\begin{bmatrix}\n\\hat\\theta_{1\\text{,A,B}} \\\\\n\\hat\\theta_{2\\text{,A,C}} \\\\\n\\hat\\theta_{3\\text{,A,D}} \\\\\n\\hat\\theta_{4\\text{,B,C}} \\\\\n\\hat\\theta_{5\\text{,B,D}} \\\\\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n1 & -1 & 0 & 0 \\\\\n1 & 0 & -1 & 0 \\\\\n1 & 0 & 0 & -1 \\\\\n0 & 1 & -1 & 0 \\\\\n0 & 1 & 0 & -1 \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\theta_{\\text{A}} \\\\\n\\theta_{\\text{B}} \\\\\n\\theta_{\\text{C}} \\\\\n\\theta_{\\text{D}} \\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\epsilon_{1} \\\\\n\\epsilon_{2} \\\\\n\\epsilon_{3} \\\\\n\\epsilon_{4} \\\\\n\\epsilon_{5} \\\\\n\\end{bmatrix}\n(\\#eq:nw5)\n\\end{align}\\]\n值得注意的是，就目前的形式而言，这个模型公式从数学角度来看是有问题的。现在，该模型是过度参数化的。模型中有太多的参数 \\(\\boldsymbol{\\theta}_{\\text{treat}}\\) 需要根据手头的信息进行估计。\n这与设计矩阵 \\(\\boldsymbol{X}\\) 没有满秩有关。在我们的例子中，当矩阵的列不是全部独立的时，矩阵就没有满秩；或者，换句话说，当独立列的数量小于列的总数 \\(n\\) 时1。因为我们正在处理一个治疗方法的网络，所以很明显，治疗方法的组合不会完全彼此独立。例如，治疗方法 D 的列（第四列）可以描述为前三列的线性组合2。\n总的来说，最多有 \\(n-1\\) 个独立的治疗方法比较，但我们的模型总是需要估计 \\(\\boldsymbol{\\theta}_{\\text{treat}}\\) 中 \\(n\\) 种治疗方法的真实效果。因此，该矩阵没有满秩。\\(\\boldsymbol{X}\\) 没有满秩的事实意味着它是不可逆的；因此，无法使用（加权）最小二乘法直接估计 \\(\\boldsymbol{\\theta}_{\\text{treat}}\\)。\n\n这就是 {netmeta} 中实现的图论方法提供解决方案的地方。我们将为您省去这种方法背后繁琐的数学细节，特别是考虑到 {netmeta} 包无论如何都会为我们完成繁重的工作。我们只提一下，这种方法涉及构建一个所谓的Moore-Penrose 伪逆矩阵，然后可以使用加权最小二乘法计算我们网络模型的拟合值。\n该程序还处理多臂研究，这些研究贡献了多个成对比较（即，比较了两种以上条件的研究）。多臂比较是相关的，因为至少有一个条件被比较多次（第 @ref(unit-of-analysis) 章）。这意味着多臂研究比较的精度被人为地提高了——除非在我们的模型中考虑了这一点。\n该模型还允许我们将研究间异质性的估计值纳入其中。与“传统的”随机效应模型（第 @ref(rem) 章）一样，这是通过将估计的异质性方差 \\(\\hat\\tau^2\\) 添加到比较 \\(m\\) 的方差来实现的：\\(s^2_m + \\hat\\tau^2\\)。在 {netmeta} 包中，\\(\\tau^2\\) 值是使用 DerSimonian-Laird 估计器的改编版本估计的 [@jackson2013matrix, 另请参见第 \\@ref(tau-estimators) 章]。\n\n也可以计算 \\(I^2\\) 的等效值，它现在表示我们网络中的不一致性量。与 Higgins 和 Thompson 的公式（参见第 @ref(i-squared) 章）一样，此 \\(I^2\\) 版本源自 \\(Q\\)。然而，在网络meta分析中，\\(Q\\) 转化为网络中的总异质性（也用 \\(Q_{\\text{total}}\\) 表示）。因此，使用以下公式：\n\\[\\begin{equation}\nI^2 = \\text{max} \\left(\\frac{Q_{\\text{total}}-\\text{d.f.}} {Q_{\\text{total}}}, 0 \\right)\n(\\#eq:nw6)\n\\end{equation}\\]\n其中我们网络中的自由度是：\n\\[\\begin{equation}\n\\text{d.f.} = \\left( \\sum^K_{k=1}p_k-1 \\right)- (n-1)\n(\\#eq:nw7)\n\\end{equation}\\]\n其中 \\(K\\) 是研究的总数，\\(p\\) 是某些研究 \\(k\\) 中条件的数量，\\(n\\) 是我们网络模型中治疗方法的总数。\n\n\n\n\n\n在所有的输入之后，是时候进行一个实践的例子了。下面，我们将使用 {netmeta} 来进行我们自己的网络meta分析。与往常一样，我们首先安装包，然后从库中加载它。\n\nlibrary(netmeta)\n\n\n\n\n\n在这个说明中，我们使用 TherapyFormats 数据。这个数据集是根据一个真实的",
    "crumbs": [
      "网站首页",
      "网络Meta分析"
    ]
  },
  {
    "objectID": "14-netwma.html#footnotes",
    "href": "14-netwma.html#footnotes",
    "title": "网络Meta分析",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n如果我们的矩阵的行数少于列数 (\\(m &lt; n\\))，那么当独立行的数量小于行的总数 \\(m\\) 时，该矩阵就不是满秩的。↩︎\n当我们把前三列（表示治疗方法 A、B 和 C）乘以 -1 并将结果相加时，我们得到第四列中的值：\\((-\\boldsymbol{x}_1) + (-\\boldsymbol{x}_2) + (-\\boldsymbol{x}_3) = \\boldsymbol{x}_4\\)。↩︎",
    "crumbs": [
      "网站首页",
      "网络Meta分析"
    ]
  },
  {
    "objectID": "16-power-analysis.html#固定效应模型",
    "href": "16-power-analysis.html#固定效应模型",
    "title": "(PART) 有用的工具",
    "section": "固定效应模型",
    "text": "固定效应模型\n\n\n要确定固定效应模型下元分析的功效，我们必须指定一个分布，该分布表示我们的备择假设是正确的。然而，要做到这一点，简单地说 \\(\\theta \\neq 0\\)（即存在某种效应）是不够的。我们必须假设一个特定的真实效应，我们希望能够以足够的（80%）功效检测到该效应。例如 SMD = 0.29。\n我们之前已经介绍过（参见第 @ref(metareg-continuous) 章），将效应大小除以其标准误差会创建一个 \\(z\\) 分数。这些 \\(z\\) 分数遵循标准正态分布，其中 \\(|z| \\geq\\) 1.96 的值表示该效应与零显著不同 (\\(p&lt;\\) 0.05)。这正是我们想要在元分析中实现的：无论我们结果的精确效应大小和标准误差有多大，值 \\(|z|\\) 都应该至少为 1.96，因此具有统计显著性：\n\\[\\begin{equation}\nz  = \\frac{\\theta}{\\sigma_{\\theta}}~~~\\text{其中}~~~|z| \\geq 1.96。\n(\\#eq:pow2)\n\\end{equation}\\]\n\\(\\sigma_{\\theta}\\) 的值，即合并效应大小的标准误差，可以使用以下公式计算：\n\\[\\begin{equation}\n\\sigma_{\\theta}=\\sqrt{\\frac{\\left(\\frac{n_1+n_2}{n_1n_2}\\right)+\\left(\\frac{\\theta^2}{2(n_1+n_2)}\\right)}{K}}\n(\\#eq:pow3)\n\\end{equation}\\]\n其中 \\(n_1\\) 和 \\(n_2\\) 代表研究中第 1 组和第 2 组的样本量，其中 \\(\\theta\\) 是假设的效应大小（表示为标准化均值差），\\(K\\) 是元分析中研究的总数。重要的是，作为简化，此公式假设所有纳入研究中两组的样本量都是相同的。\n该公式与用于计算标准化均值差的标准误差的公式非常相似，但有一个例外。我们现在将标准误差除以 \\(K\\)。这意味着我们合并效应的标准误差减少了 \\(K\\) 倍，代表元分析中研究的总数。换句话说，当假设一个固定效应模型时，合并研究会导致我们整体效应的精度提高 \\(K\\) 倍1。\n在我们定义了 \\(\\theta\\) 并计算出 \\(\\sigma_{\\theta}\\) 之后，我们最终会得到一个 \\(z\\) 值。给定组大小为 \\(n_1\\) 和 \\(n_2\\) 的 \\(K\\) 项研究的数量，可以使用此 \\(z\\) 分数来获得元分析的功效：\n\\[\\begin{align}\n\\text{功效} &= 1-\\beta \\notag \\\\\n             &= 1-\\Phi(c_{\\alpha}-z)+\\Phi(-c_{\\alpha}-z) \\notag \\\\\n             &= 1-\\Phi(1.96-z)+\\Phi(-1.96-z)。 (\\#eq:pow4)\n\\end{align}\\]\n\n其中 \\(c_{\\alpha}\\) 是标准正态分布的临界值，给定指定的 \\(\\alpha\\) 水平。符号 \\(\\Phi\\) 代表标准正态分布的累积分布函数 (CDF)，\\(\\Phi(z)\\)。在 R 中，标准正态分布的 CDF 在 pnorm 函数中实现。\n我们现在可以使用这些公式来计算固定效应元分析的功效。想象一下，我们期望有 \\(K=\\) 10 项研究，每项研究中两组大约有 25 名参与者。我们希望能够检测到 SMD = 0.2 的效应。这样的元分析有什么功效？\n\n# 定义假设\ntheta &lt;- 0.2\nK &lt;- 10\nn1 &lt;- 25\nn2 &lt;- 25\n\n# 计算合并效应标准误差\nsigma &lt;- sqrt(((n1+n2)/(n1*n2)+(theta^2/(2*n1+n2)))/K)\n\n# 计算 z\nz = theta/sigma\n\n# 计算功效\n1 - pnorm(1.96-z) + pnorm(-1.96-z)\n\n[1] 0.6059151\n\n\n我们看到，即使纳入了 10 项研究，这样的元分析也只有 60.6% 的功效，因此功效不足。计算（固定效应）元分析功效的更方便的方法是使用 power.analysis 函数。\n\n\n\n\n“power.analysis”函数\n\n\npower.analysis 函数包含在 {dmetar} 包中。一旦在您的计算机上安装并加载了 {dmetar}，该函数就可以使用了。如果您没有安装 {dmetar}，请按照以下说明操作：\n\n\n\n在网上访问该函数的源代码。\n\n\n通过将源代码的全部内容复制并粘贴到控制台中（R Studio 的左下窗格），然后按“Enter”键，让 R “学习”该函数。\n\n\n确保已安装并加载了 {ggplot2} 包。\n\n\n\n\npower.analysis 函数包含以下参数：\n\nd。假设的或合理的总体效应大小，表示为标准化均值差 (SMD)。效应大小必须是正数值。\nOR。与对照组相比，治疗或干预的假设效应，表示为优势比 (OR)。如果同时指定了 d 和 OR，则只会计算 d 值的输出。\nk。元分析中预期的研究数量。\nn1、n2。纳入研究中第 1 组和第 2 组的预期平均样本量。\np。要使用的 alpha 水平。默认值为 \\(\\alpha\\)=0.05。\nheterogeneity。研究间异质性的水平。可以为 \"fixed\" 表示没有异质性（固定效应模型），\"low\" 表示低异质性，\"moderate\" 表示中等大小的异质性，或 \"high\" 表示高水平的异质性。默认为 \"fixed\"。\n\n让我们使用与之前示例中相同的输入来尝试一下这个函数。\n\nlibrary(dmetar)\npower.analysis(d = 0.2, \n               k = 10, \n               n1 = 25, \n               n2 = 25, \n               p = 0.05)\n\n\n\nFixed-effect model used. \n\n\n\n\n\n\n\n\n\nPower: 60.66%",
    "crumbs": [
      "网站首页",
      "功效分析"
    ]
  },
  {
    "objectID": "16-power-analysis.html#随机效应模型",
    "href": "16-power-analysis.html#随机效应模型",
    "title": "(PART) 有用的工具",
    "section": "随机效应模型",
    "text": "随机效应模型\n\n\n对于假设随机效应模型的功效分析，我们必须考虑研究间异质性方差 \\(\\tau^2\\)。因此，我们需要计算标准误差的调整版本，\\(\\sigma^*_{\\theta}\\):\n\\[\\begin{equation}\n\\sigma^*_{\\theta}=\\sqrt{\\frac{\\left(\\frac{n_1+n_2}{n_1n_2}\\right)+\\left(\\frac{\\theta^2}{2(n_1+n_2)}\\right)+\\tau^2}{K}}\n(\\#eq:pow5)\n\\end{equation}\\]\n问题是 \\(\\tau^2\\) 的值通常在看到数据之前是未知的。然而，Hedges 和 Pigott [-@hedges2001power] 提供了可用于模拟低、中或大研究间异质性的指南：\n低异质性：\n\\[\\begin{equation}\n\\sigma^*_{\\theta} = \\sqrt{1.33\\times\\dfrac{\\sigma^2_{\\theta}}{K}}\n(\\#eq:pow6)\n\\end{equation}\\]\n中等异质性：\n\\[\\begin{equation}\n\\sigma^*_{\\theta} = \\sqrt{1.67\\times\\dfrac{\\sigma^2_{\\theta}}{K}}\n(\\#eq:pow7)\n\\end{equation}\\]\n高异质性：\n\\[\\begin{equation}\n\\sigma^*_{\\theta} = \\sqrt{2\\times\\dfrac{\\sigma^2_{\\theta}}{K}}\n(\\#eq:pow8)\n\\end{equation}\\]\npower.analysis 函数也可以用于随机效应元分析。可以使用 heterogeneity 参数控制假设的研究间异质性的量。可能的值为 \"low\"、\"moderate\" 和 \"high\"。使用与前面示例中相同的值，我们现在计算一下当研究间异质性为中等时，预期的功效。\n\npower.analysis(d = 0.2, \n               k = 10, \n               n1 = 25, \n               n2 = 25, \n               p = 0.05,\n               heterogeneity = \"moderate\")\n\n## 使用了随机效应模型（假设中等异质性）。\n## 功效：40.76%\n我们看到估计的功效为 40.76%。这低于规范的 80% 阈值。这也低于我们假设固定效应模型时获得的 60.66%。这是因为研究间异质性降低了我们合并效应估计的精度，导致统计功效下降。\n图 @ref(fig:power) 可视化了真实效应大小、研究数量和研究间异质性量对元分析功效的影响。2\n\n\n\n\n\n随机效应元分析的功效（每项研究中 \\(n\\)=50）。颜色越深表示研究间异质性越高。",
    "crumbs": [
      "网站首页",
      "功效分析"
    ]
  },
  {
    "objectID": "16-power-analysis.html#power-subgroup",
    "href": "16-power-analysis.html#power-subgroup",
    "title": "(PART) 有用的工具",
    "section": "亚组分析",
    "text": "亚组分析\n\n\n在计划亚组分析时，了解两组之间的差异必须有多大，以便我们可以在我们可用的研究数量下检测到它，这可能是有意义的。这就是亚组差异的功效分析可以应用的地方。可以使用 power.analysis.subgroup 函数在 R 中进行亚组功效分析，该函数实现了 Hedges 和 Pigott [-@hedges2004power] 描述的方法。\n\n\n\n“power.analysis.subgroup”函数\n\n\npower.analysis.subgroup 函数包含在 {dmetar} 包中。一旦在您的计算机上安装并加载了 {dmetar}，该函数就可以使用了。如果您没有安装 {dmetar}，请按照以下说明操作：\n\n\n\n在网上访问该函数的源代码。\n\n\n通过将源代码的全部内容复制并粘贴到控制台中（R Studio 的左下窗格），然后按“Enter”键，让 R “学习”该函数。\n\n\n确保已安装并加载了 {ggplot2} 包。\n\n\n\n\n让我们假设我们期望第一组显示 SMD = 0.3 的效应，标准误差为 0.13，而第二组具有 SMD = 0.66 的效应，标准误差为 0.14。我们可以将这些假设作为输入来调用我们的函数：\n\n# 加载当前目录下的 power.analysis.subgroup.R 文件\nsource(\"power.analysis.subgroup.R\")\npower.analysis.subgroup(TE1 = 0.30, TE2 = 0.66, \n                        seTE1 = 0.13, seTE2 = 0.14)\n\nMinimum effect size difference needed for sufficient power: 0.536 (input: 0.36)\nPower for subgroup difference test (two-tailed): 46.99%\n\n\n\n\n\n\n\n\n\n在输出中，我们可以看到我们想象的亚组检验的功效 (47%) 将不足够。输出还告诉我们，在所有条件相同的情况下，效应大小差异需要至少为 0.54 才能达到足够的功效。\n\\[\\tag*{$\\blacksquare$}\\]",
    "crumbs": [
      "网站首页",
      "功效分析"
    ]
  },
  {
    "objectID": "16-power-analysis.html#footnotes",
    "href": "16-power-analysis.html#footnotes",
    "title": "(PART) 有用的工具",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n请注意，这种说法当然是正确的，因为我们正在使用公式 @ref(eq:pow3) 中的简化公式。↩︎\n如果您想快速检查不同假设下元分析的功效，您还可以使用为此目的开发的功效计算器工具。该工具基于我们在本章中介绍的同一个 R 函数。可以在网上找到它：https://mathiasharrer.shinyapps.io/power_calculator_meta_analysis/.↩︎",
    "crumbs": [
      "网站首页",
      "功效分析"
    ]
  },
  {
    "objectID": "18-reporting-reproducibility.html",
    "href": "18-reporting-reproducibility.html",
    "title": "报告 & 可重复性",
    "section": "",
    "text": "在 前面的章节中，我们讨论了在 R 中进行 Meta 分析的各种技术、方法和策略。然而，在实践中，运行统计分析只占整个 Meta 分析“过程”的一小部分。“在实际应用中”，常见的情况是：\n\n我们在 R 代码中发现错误，因此不得不修改一些内容后重做部分分析。\n合作者或审稿人建议使用不同的方法或模型，或者进行额外的敏感性分析。\n我们需要将部分分析委托给我们的合作者之一，并且必须将我们工作的当前状态发送给她。\n我们不得不停止我们的项目一段时间，这意味着当我们恢复工作时，我们已经忘记了很多东西。\n我们想与项目合作者分享我们的分析结果，但他们不懂 R，也没有安装 R Studio。\n\n这只是一些场景，但它们说明了在 R 中进行 Meta 分析时，可重复的工作流程对您和您的合作者都有好处。追求可重复性也是开放科学实践的基石。完全可重复的 Meta 分析尽可能透明地向他人展示我们是如何得出结果的。\n \nR Studio 是创建可重复工作流程和促进合作的最佳工具。在本章中，我们将介绍三种工具来重现、报告和传播我们的分析：R 项目、R Markdown 和开放科学框架。\n\n\n\n\n\n开始分析的一个好方法是首先在 R Studio 中设置一个 R 项目。R 项目在您电脑上的一个文件夹中创建一个新的环境。在这个文件夹中，保存了您分析所需的所有数据和 R 代码。在 R 项目中进行分析意味着我们创建的所有对象都临时保存在项目环境中，并且下次我们重新打开它时可以访问。要创建一个新的 R 项目，我们可以点击 R Studio 窗口右上角的 R project 字段，然后在下拉菜单中点击 New Project…。\n\n\n\n\n\n\n\n\n\n然后我们创建一个 New Directory，即电脑上的一个新文件夹，它将成为项目的工作目录。\n\n\n\n\n\n\n\n\n\n然后，我们点击 New Project。\n\n\n\n\n\n\n\n\n\n我们给我们的新项目命名为“Meta-Analysis Project”。项目文件夹将存储在 ~Documents/R 中。\n\n\n\n\n\n\n\n\n\n点击 Create Project 后，R 项目就设置好了。R 项目的一个很棒的特性是我们不必使用绝对路径来引用我们想要的文件。我们只使用文件名，或者，如果文件在一个（子）文件夹中，则使用文件夹和文件名。假设我们将我们的数据集 data.xlsx 存储在子文件夹“data”中。使用 {openxlsx} 包（第 @ref(data-prep-R) 章），我们可以使用相对路径导入数据集。\n\nread_excel(\"data/data.xlsx\")\n\n\n\n\n\n\n\nMarkdown 是一种用于文本格式化的简单标记语言。R Markdown [@xie2018r] 是 Markdown 的扩展，可以轻松地在一个文档中组合纯文本、R 代码和 R 输出。这使得 R Markdown 成为一个非常有用的报告工具。使用 R Markdown，我们可以创建包含我们分析中使用的所有代码、代码产生的输出的 HTML 或 PDF 文件，并且可以添加有关我们在每个分析步骤中所做工作的详细信息。\n在 R Studio 中构建 R Markdown 文件非常容易。我们只需要点击 R Studio 窗口左上角的带有绿色“加号”的白色符号。然后，在下拉菜单中，我们点击 R Markdown…。\n\n\n\n\n\n\n\n\n\n在定义了新的 R Markdown 文档的名称后，它应该会出现在 R Studio 窗口的左上角。\n\n\n\n\n\n\n\n\n\n该文件已经包含了一些示例内容，我们可以删除这些内容，除了前六行：\n---\ntitle: \"Analysis\"\nauthor: \"Author Name\"\ndate: \"10/16/2020\"\noutput: html_document\n---\n这部分是所谓的 YAML 头部。它控制文档的标题、作者、日期和导出格式。我们为文档选择的输出格式是 html_document，这意味着文档在渲染后将导出为 HTML 页面。\n所有的 _R Markdown 文档_都由两部分组成：纯 Markdown 文本和所谓的 R 代码块，以灰色显示。我们不会详细介绍 R Markdown 文档中的文本部分是如何格式化的，但是有一个在线备忘单，这是一个开始学习 Markdown 语法的绝佳资源（这应该只需要大约二十分钟）。另一方面，R 代码块只是包含我们通常会在控制台中输入的所有代码。通过点击文档右上角的 Insert 字段，我们可以添加新的代码块。可以通过点击每个代码块上方的小绿色三角形来运行代码。\n\n\n\n\n\n\n\n\n\n完成文档编写后，我们可以通过点击左上角的 Knit 符号将其导出为 HTML、PDF 或 MS Word 文档。这会渲染文档，包括所有文本、代码和输出，并以定义的格式导出它。最终文档会自动保存在我们的项目文件夹中。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n开放科学框架 (OSF) 是一个开源在线平台，旨在促进研究中的协作和可重复性。OSF 包括一个在线仓库，研究人员可以在其中存放他们的研究材料，以进行协作并使研究过程的所有步骤（更）透明。OSF 是开放科学运动的先锋，该运动在过去十年中聚集了很大的势头。\n鼓励所有 Meta 分析师通过公开访问他们收集的数据和用于分析的 R 代码，使其研究和分析过程对公众透明。OSF 是一个很好的工具来做到这一点——您为自己创建的所有仓库默认都是私有的，您可以决定是否、何时以及想要公开什么。下面，我们将向您展示如何在 R 中设置 OSF 仓库，上传和下载文件，以及如何添加合作者。\n\n\n\n\n要开始使用 OSF，我们首先必须在 网站 上创建一个个人帐户。创建帐户后，我们还必须生成一个访问令牌，以便我们可以使用 R 直接操作我们的仓库。要获取访问令牌，我们必须导航到 Profile &gt; Settings &gt; Personal access tokens。在那里，我们点击 Create token。\n\n\n\n\n\n\n\n\n\n然后，在 Scopes 下，我们选中所有复选框，然后再次点击 Create token。之后，我们的个人访问令牌应该会出现。我们复制令牌并保存以供以后使用。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n为了直接通过 R 访问我们的 OSF 仓库，我们可以使用 {osfr} 包 [@osfr]。在我们使用此包的功能之前，我们首先必须使用我们的访问令牌进行身份验证。为此，我们使用 osf_auth 函数，为其提供我们刚刚收到的访问令牌（下面显示的令牌是虚构的）：\n\nlibrary(osfr)\nosf_auth(\"AtmuMZ3pSuS7tceSMz2NNSAmVDNTzpm2Ud87\")\n\n\n\n\n\n\n使用 {osfr}，我们现在可以使用 R 初始化 OSF 仓库。假设我们正在进行一个新的 Meta 分析项目，并且我们想要将我们的数据以及 R Markdown 脚本上传到 OSF 仓库。仓库的名称应为“Meta-Analysis Project”。\n要创建一个新的仓库，可以使用 osf_create_project 函数。我们将新的 OSF 仓库保存在 R 中，命名为 meta_analysis_project。\n\nmeta_analysis_project &lt;- osf_create_project(\"Meta-Analysis Project\")\n\n使用 osf_open 函数，我们可以访问新创建的在线仓库：\n\nosf_open(meta_analysis_project)\n\n\n\n\n\n\n\n\n\n\n现在仓库已经创建，我们可以继续向其中添加 组件。在 OSF 中，组件的工作方式类似于计算机上的文件夹。假设我们要创建两个组件：一个用于我们的数据集，一个用于我们的 R Markdown 脚本。为此，我们可以使用 osf_create_component 函数。我们必须为该函数提供 R 仓库对象 (meta_analysis_project)，然后设置新组件的标题。\n\nscripts &lt;- osf_create_component(meta_analysis_project, \n                                title = \"Analysis Scripts\")\ndatasets &lt;- osf_create_component(meta_analysis_project, \n                                 title = \"Datasets\")\n\n当我们现在转到仓库的在线页面时，我们看到这两个组件已被添加。\n\n\n\n\n\n要将数据上传到 OSF 仓库，我们可以使用 osf_upload 函数。该函数要求我们指定要将文件添加到哪个组件，以及应上传的文件的路径。假设我们要上传一个名为“Analysis.rmd”的 R Markdown 脚本，该脚本当前保存在我们的 R 项目子文件夹“scripts”中。要上传，我们可以使用以下代码：\n\nosf_upload(scripts, \"scripts/Analysis.rmd\")\n\n要查看文件是否已成功上传，我们可以使用 osf_ls_files 函数访问组件的内容。\n\nosf_ls_files(scripts)\n\n## # A tibble: 2 x 3\n##   name            id                       meta            \n##   &lt;chr&gt;           &lt;chr&gt;                    &lt;list&gt;          \n## 1 Analysis.rmd    1db74s7bfcf91f0012567572l &lt;named list [3]&gt;\n我们在输出中看到上传成功。要下载文件，我们可以从 osf_ls_files 函数输出中选择一行，并在 osf_download 函数中使用它，将文件下载回我们计算机上的项目文件夹中。\n\nosf_download(osf_ls_files(scripts)[1,])\n\n\n\n\n\n\n\n在 OSF 仓库网站上，我们也可以在 Contributors 字段下添加合作者。\n\n\n\n\n\n\n\n\n\n在任何时候，都可以通过点击网站右上角的 Make Public 按钮来使仓库公开。\n\n\n\n\n\n\n\n\n\n在第 @ref(analysis-plan) 章中，我们讨论了分析计划和预注册是高质量 Meta 分析的重要组成部分。OSF 可以非常方便地为我们的项目创建一个公开访问的预注册。我们只需点击顶部的 Registrations 按钮，然后创建一个 New registration。这会将我们带到 OSF Registries 网站，我们可以在其中提供有关我们计划研究的详细信息，包括我们的分析计划。\n\n\n\n\n\n\n\n\n\n在指定了所有必需的详细信息后，可以注册该研究。这会创建一个注册条目，可以通过唯一的 ID 访问（例如 osf.io/q2jp7）。完成注册后，无法再更改既定的搜索计划、假设和/或分析策略。\n\\[\\tag*{$\\blacksquare$}\\]",
    "crumbs": [
      "网站首页",
      "报告与可重复性"
    ]
  },
  {
    "objectID": "18-reporting-reproducibility.html#使用-r-项目",
    "href": "18-reporting-reproducibility.html#使用-r-项目",
    "title": "报告 & 可重复性",
    "section": "",
    "text": "开始分析的一个好方法是首先在 R Studio 中设置一个 R 项目。R 项目在您电脑上的一个文件夹中创建一个新的环境。在这个文件夹中，保存了您分析所需的所有数据和 R 代码。在 R 项目中进行分析意味着我们创建的所有对象都临时保存在项目环境中，并且下次我们重新打开它时可以访问。要创建一个新的 R 项目，我们可以点击 R Studio 窗口右上角的 R project 字段，然后在下拉菜单中点击 New Project…。\n\n\n\n\n\n\n\n\n\n然后我们创建一个 New Directory，即电脑上的一个新文件夹，它将成为项目的工作目录。\n\n\n\n\n\n\n\n\n\n然后，我们点击 New Project。\n\n\n\n\n\n\n\n\n\n我们给我们的新项目命名为“Meta-Analysis Project”。项目文件夹将存储在 ~Documents/R 中。\n\n\n\n\n\n\n\n\n\n点击 Create Project 后，R 项目就设置好了。R 项目的一个很棒的特性是我们不必使用绝对路径来引用我们想要的文件。我们只使用文件名，或者，如果文件在一个（子）文件夹中，则使用文件夹和文件名。假设我们将我们的数据集 data.xlsx 存储在子文件夹“data”中。使用 {openxlsx} 包（第 @ref(data-prep-R) 章），我们可以使用相对路径导入数据集。\n\nread_excel(\"data/data.xlsx\")",
    "crumbs": [
      "网站首页",
      "报告与可重复性"
    ]
  },
  {
    "objectID": "18-reporting-reproducibility.html#使用-r-markdown-编写可重复的报告",
    "href": "18-reporting-reproducibility.html#使用-r-markdown-编写可重复的报告",
    "title": "报告 & 可重复性",
    "section": "",
    "text": "Markdown 是一种用于文本格式化的简单标记语言。R Markdown [@xie2018r] 是 Markdown 的扩展，可以轻松地在一个文档中组合纯文本、R 代码和 R 输出。这使得 R Markdown 成为一个非常有用的报告工具。使用 R Markdown，我们可以创建包含我们分析中使用的所有代码、代码产生的输出的 HTML 或 PDF 文件，并且可以添加有关我们在每个分析步骤中所做工作的详细信息。\n在 R Studio 中构建 R Markdown 文件非常容易。我们只需要点击 R Studio 窗口左上角的带有绿色“加号”的白色符号。然后，在下拉菜单中，我们点击 R Markdown…。\n\n\n\n\n\n\n\n\n\n在定义了新的 R Markdown 文档的名称后，它应该会出现在 R Studio 窗口的左上角。\n\n\n\n\n\n\n\n\n\n该文件已经包含了一些示例内容，我们可以删除这些内容，除了前六行：\n---\ntitle: \"Analysis\"\nauthor: \"Author Name\"\ndate: \"10/16/2020\"\noutput: html_document\n---\n这部分是所谓的 YAML 头部。它控制文档的标题、作者、日期和导出格式。我们为文档选择的输出格式是 html_document，这意味着文档在渲染后将导出为 HTML 页面。\n所有的 _R Markdown 文档_都由两部分组成：纯 Markdown 文本和所谓的 R 代码块，以灰色显示。我们不会详细介绍 R Markdown 文档中的文本部分是如何格式化的，但是有一个在线备忘单，这是一个开始学习 Markdown 语法的绝佳资源（这应该只需要大约二十分钟）。另一方面，R 代码块只是包含我们通常会在控制台中输入的所有代码。通过点击文档右上角的 Insert 字段，我们可以添加新的代码块。可以通过点击每个代码块上方的小绿色三角形来运行代码。\n\n\n\n\n\n\n\n\n\n完成文档编写后，我们可以通过点击左上角的 Knit 符号将其导出为 HTML、PDF 或 MS Word 文档。这会渲染文档，包括所有文本、代码和输出，并以定义的格式导出它。最终文档会自动保存在我们的项目文件夹中。",
    "crumbs": [
      "网站首页",
      "报告与可重复性"
    ]
  },
  {
    "objectID": "18-reporting-reproducibility.html#osf",
    "href": "18-reporting-reproducibility.html#osf",
    "title": "报告 & 可重复性",
    "section": "",
    "text": "开放科学框架 (OSF) 是一个开源在线平台，旨在促进研究中的协作和可重复性。OSF 包括一个在线仓库，研究人员可以在其中存放他们的研究材料，以进行协作并使研究过程的所有步骤（更）透明。OSF 是开放科学运动的先锋，该运动在过去十年中聚集了很大的势头。\n鼓励所有 Meta 分析师通过公开访问他们收集的数据和用于分析的 R 代码，使其研究和分析过程对公众透明。OSF 是一个很好的工具来做到这一点——您为自己创建的所有仓库默认都是私有的，您可以决定是否、何时以及想要公开什么。下面，我们将向您展示如何在 R 中设置 OSF 仓库，上传和下载文件，以及如何添加合作者。\n\n\n\n\n要开始使用 OSF，我们首先必须在 网站 上创建一个个人帐户。创建帐户后，我们还必须生成一个访问令牌，以便我们可以使用 R 直接操作我们的仓库。要获取访问令牌，我们必须导航到 Profile &gt; Settings &gt; Personal access tokens。在那里，我们点击 Create token。\n\n\n\n\n\n\n\n\n\n然后，在 Scopes 下，我们选中所有复选框，然后再次点击 Create token。之后，我们的个人访问令牌应该会出现。我们复制令牌并保存以供以后使用。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n为了直接通过 R 访问我们的 OSF 仓库，我们可以使用 {osfr} 包 [@osfr]。在我们使用此包的功能之前，我们首先必须使用我们的访问令牌进行身份验证。为此，我们使用 osf_auth 函数，为其提供我们刚刚收到的访问令牌（下面显示的令牌是虚构的）：\n\nlibrary(osfr)\nosf_auth(\"AtmuMZ3pSuS7tceSMz2NNSAmVDNTzpm2Ud87\")\n\n\n\n\n\n\n使用 {osfr}，我们现在可以使用 R 初始化 OSF 仓库。假设我们正在进行一个新的 Meta 分析项目，并且我们想要将我们的数据以及 R Markdown 脚本上传到 OSF 仓库。仓库的名称应为“Meta-Analysis Project”。\n要创建一个新的仓库，可以使用 osf_create_project 函数。我们将新的 OSF 仓库保存在 R 中，命名为 meta_analysis_project。\n\nmeta_analysis_project &lt;- osf_create_project(\"Meta-Analysis Project\")\n\n使用 osf_open 函数，我们可以访问新创建的在线仓库：\n\nosf_open(meta_analysis_project)\n\n\n\n\n\n\n\n\n\n\n现在仓库已经创建，我们可以继续向其中添加 组件。在 OSF 中，组件的工作方式类似于计算机上的文件夹。假设我们要创建两个组件：一个用于我们的数据集，一个用于我们的 R Markdown 脚本。为此，我们可以使用 osf_create_component 函数。我们必须为该函数提供 R 仓库对象 (meta_analysis_project)，然后设置新组件的标题。\n\nscripts &lt;- osf_create_component(meta_analysis_project, \n                                title = \"Analysis Scripts\")\ndatasets &lt;- osf_create_component(meta_analysis_project, \n                                 title = \"Datasets\")\n\n当我们现在转到仓库的在线页面时，我们看到这两个组件已被添加。\n\n\n\n\n\n要将数据上传到 OSF 仓库，我们可以使用 osf_upload 函数。该函数要求我们指定要将文件添加到哪个组件，以及应上传的文件的路径。假设我们要上传一个名为“Analysis.rmd”的 R Markdown 脚本，该脚本当前保存在我们的 R 项目子文件夹“scripts”中。要上传，我们可以使用以下代码：\n\nosf_upload(scripts, \"scripts/Analysis.rmd\")\n\n要查看文件是否已成功上传，我们可以使用 osf_ls_files 函数访问组件的内容。\n\nosf_ls_files(scripts)\n\n## # A tibble: 2 x 3\n##   name            id                       meta            \n##   &lt;chr&gt;           &lt;chr&gt;                    &lt;list&gt;          \n## 1 Analysis.rmd    1db74s7bfcf91f0012567572l &lt;named list [3]&gt;\n我们在输出中看到上传成功。要下载文件，我们可以从 osf_ls_files 函数输出中选择一行，并在 osf_download 函数中使用它，将文件下载回我们计算机上的项目文件夹中。\n\nosf_download(osf_ls_files(scripts)[1,])\n\n\n\n\n\n\n\n在 OSF 仓库网站上，我们也可以在 Contributors 字段下添加合作者。\n\n\n\n\n\n\n\n\n\n在任何时候，都可以通过点击网站右上角的 Make Public 按钮来使仓库公开。\n\n\n\n\n\n\n\n\n\n在第 @ref(analysis-plan) 章中，我们讨论了分析计划和预注册是高质量 Meta 分析的重要组成部分。OSF 可以非常方便地为我们的项目创建一个公开访问的预注册。我们只需点击顶部的 Registrations 按钮，然后创建一个 New registration。这会将我们带到 OSF Registries 网站，我们可以在其中提供有关我们计划研究的详细信息，包括我们的分析计划。\n\n\n\n\n\n\n\n\n\n在指定了所有必需的详细信息后，可以注册该研究。这会创建一个注册条目，可以通过唯一的 ID 访问（例如 osf.io/q2jp7）。完成注册后，无法再更改既定的搜索计划、假设和/或分析策略。\n\\[\\tag*{$\\blacksquare$}\\]",
    "crumbs": [
      "网站首页",
      "报告与可重复性"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda1",
    "href": "90-appendix.html#qanda1",
    "title": "(附录) 附录",
    "section": "第一章：导论",
    "text": "第一章：导论\n\n1. 元分析如何定义？元分析与其他类型的文献综述有何区别？\n元分析可以定义为对分析的分析（Glass 的定义）。与其他类型的（系统性）综述相比，元分析旨在以定量的方式综合证据。通常，目标是得出一个数值估计，整体描述一个界限明确的研究领域。\n2. 你能说出一位元分析的创始者（不论男女）吗？他/她的成就体现在哪里？\n卡尔·皮尔逊：整合大英帝国各地的伤寒疫苗接种数据；罗纳德·费舍尔：农业研究数据综合方法；玛丽·史密斯和吉恩·格拉斯：创造了“元分析”一词，首次对心理治疗试验进行元分析；约翰·亨特和弗兰克·施密特：通过校正测量误差（心理测量元分析）进行元分析；丽贝卡·德西莫尼安和南·莱尔德：计算随机效应模型元分析的方法；彼得·埃尔伍德和阿奇·科克伦：医学元分析的先驱。\n3. 说出元分析的三个常见问题，并用一两句话描述它们。\n“苹果和橘子”：研究差异太大，无法综合；“垃圾进，垃圾出”：无效证据只会通过元分析重现；“文件抽屉”：阴性结果未发表，导致元分析结果存在偏差；“研究者议程”：研究者可以调整元分析来证明他们想证明的东西。\n4. 说出定义一个好的元分析研究问题的品质。\nFINER：可行、有趣、新颖、符合伦理、相关；PICO：明确定义的人群、干预/暴露、对照组/比较、以及分析的结果。\n5. 再次查看大学生睡眠干预元分析的纳入标准（第 1.4.1 节末尾）。你能从这项研究的纳入和排除标准中提取 PICO 吗？\n人群：高等教育学生；干预：以睡眠为中心的心理干预；比较：被动控制条件；结果：睡眠障碍，通过标准化症状测量量表进行测量。\n6. 说出一些可以用来搜索研究的重要来源。\n综述文章，研究中的参考文献，“向前搜索”（搜索引用了相关文章的研究），搜索相关期刊，书目数据库搜索。\n7. 用一两句话描述“研究质量”和“偏差风险”之间的区别。\n一项研究可以满足研究领域中被认为重要的所有研究质量标准，但仍然具有很高的偏差风险（例如，因为对于这种类型的研究或研究课题，偏差很难避免）。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda2",
    "href": "90-appendix.html#qanda2",
    "title": "(附录) 附录",
    "section": "第二章：探索 R",
    "text": "第二章：探索 R\n\n1. 显示变量 Author。\n\ndata$Author\n\n2. 将 subgroup 转换为因子。\n\ndata$subgroup &lt;- as.factor(data$subgroup)\n\n3. 选择 “Jones” 和 “Martin” 研究的所有数据。\n\nlibrary(tidyverse)\ndata %&gt;%\n    filter(Author %in% c(\"Jones\", \"Martin\"))\n\n4. 将研究 “Rose” 的名称更改为 “Bloom”。\n\ndata[5,1] &lt;- \"Bloom\"\n\n5. 通过从 TE 中减去 seTE 来创建一个新的变量 TE_seTE_diff。将结果保存在 data 中。\n\nTE_seTE_diff &lt;- data$TE - data$seTE\n\n6. 使用管道来（1）过滤所有在 subgroup “one” 或 “two” 中的研究，（2）选择变量 TE_seTE_diff，（3）取该变量的平均值，然后将 exp 函数应用于它。\n\ndata %&gt;%\n    deplyr::filter(subgroup %in% c(\"one\", \"two\")) %&gt;%\n    pull(TE_seTE_diff) %&gt;%\n    mean() %&gt;%\n    exp()",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda3",
    "href": "90-appendix.html#qanda3",
    "title": "(附录) 附录",
    "section": "第三章：效应量",
    "text": "第三章：效应量\n\n1. 对于“效应量”一词是否有明确的定义？当人们谈论效应量时，他们指的是什么？\n不，没有普遍接受的定义。有些人保留“效应量”一词来表示干预组和对照组之间的差异。另一些人使用更自由的定义，仅排除“单变量”测量（例如，均值和比例）。\n2. 说出观察到的效应量偏离人群真实效应量的主要原因。如何量化它？\n假设观察到的效应量因抽样误差而偏离真实效应量。一项研究的抽样误差的预期大小可以用其标准误差来表示。\n3. 为什么大型研究比小型研究更能更好地估计真实效应？\n因为假设它们具有较小的抽样误差，这会导致更精确的效应估计。\n4. 效应量指标必须满足哪些标准才能用于元分析？\n它需要具有可比性、可计算性、可靠性和可解释性。\n5. 标准化均值差 1 代表什么？\n它代表两组的均值相差一个合并标准差。\n6. 需要进行什么样的转换才能合并基于比率的效应量（例如，优势比）？\n效应量需要进行对数转换（为了使用逆方差合并方法）。\n7. 说出三种类型的效应量校正。\n标准化均值差的小样本偏差校正（Hedges’ \\(g\\)）；不可靠性校正；范围限制校正。\n8. 什么时候会发生单位分析问题？如何避免它？\n当我们的数据集中的效应量相关时（例如，因为它们是同一研究的一部分）。单位分析问题可以通过以下方式（部分或完全）避免：（1）拆分共享组的样本量，（2）移除比较，（3）合并组，或（4）使用考虑效应量依赖性的模型（例如，三级模型）。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda4",
    "href": "90-appendix.html#qanda4",
    "title": "(附录) 附录",
    "section": "第四章：效应量的合并",
    "text": "第四章：效应量的合并\n\n1. 固定效应模型和随机效应模型之间有什么区别？\n固定效应模型假设所有研究都是相同真实效应量的估计量。随机效应模型假设研究的真实效应量因研究间的异质性（由方差 \\(\\tau^2\\) 捕获）而异，这需要进行估计。\n2. 你能想到固定效应模型和随机效应模型的结果相同的情况吗？\n当研究间的异质性方差 \\(\\tau^2\\) 为零时。\n3. 什么是 \\(\\tau^2\\)？如何估计它？\n研究间的异质性方差。可以使用不同的方法来估计它，例如限制最大似然法（REML）、Paule-Mandel 估计量或 DerSimonian-Laird 估计量。\n4. Knapp-Hartung 调整基于哪个分布？它有什么影响？\n它基于 \\(t\\)-分布。Knapp-Hartung 调整通常会导致更保守（即更宽）的置信区间。\n5. 什么是“逆方差”合并？这种方法什么时候不是最佳解决方案？\n该方法称为逆方差合并，因为它使用研究方差的倒数作为合并权重。对于二元结果数据的元分析（例如，风险或优势比），通用的逆方差方法不是首选选项。\n6. 你想对二元结果数据进行元分析。研究组中的观察数量大致相似，观察到的事件非常罕见，并且你不期望治疗效果很大。你会使用哪种合并方法？\n在这种情况下，Peto 方法可能表现良好。\n7. 广义线性混合模型可以用于哪些结果测量？\n比例。也可以将它们用于其他二元结果测量，但不建议这样做。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda5",
    "href": "90-appendix.html#qanda5",
    "title": "(附录) 附录",
    "section": "第五章：研究间异质性",
    "text": "第五章：研究间异质性\n\n1. 为什么检查元分析的研究间异质性很重要？\n当研究间异质性很大时，可以假设真实效应量差异很大。在这种情况下，平均真实效应的点估计可能无法很好地代表所有数据。研究间异质性也可能导致效应估计不稳健，例如，因为一些离群研究扭曲了总体结果。\n2. 你能说出异质性的两种类型吗？哪一种与计算元分析相关？\n基线/设计相关异质性和统计异质性。只有统计异质性在元分析中进行定量评估。\n3. 为什么 Cochran 的 \\(Q\\) 的显著性不是研究间异质性的充分测量？\n因为 \\(Q\\) 检验的显著性很大程度上取决于我们元分析中包含的研究数量及其规模。\n4. 使用预测区间来表达元分析中异质性量的优势是什么？\n预测区间允许在与汇总测量相同的尺度上表达研究间异质性对未来研究的影响。\n5. 统计离群值和有影响力研究之间的区别是什么？\n统计离群值是具有极端效应量的研究。当研究对总体结果的影响很大时，研究是有影响力的。一项研究有可能被定义为统计离群值但影响力不大，反之亦然。例如，一项大型研究可能对合并结果产生很大影响，即使其效应量不是特别小或大。\n6. GOSH 图可以用于什么？\nGOSH 图可用于探索我们数据中的异质性模式，以及哪些研究导致了这些模式。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda6",
    "href": "90-appendix.html#qanda6",
    "title": "(附录) 附录",
    "section": "第六章：森林图",
    "text": "第六章：森林图\n\n1. 森林图的关键组成部分是什么？\n每项研究的观察到的效应量及其置信区间的图形表示；每项研究的权重，由观察到的效应量周围的正方形的大小表示；每项研究的观察到的效应和权重的数值；合并效应，由菱形表示；参考线，通常表示无效应。\n2. 展示我们元分析的森林图的优势是什么？\n它们可以快速检查所有包含的研究的数量、效应量和精度，以及观察到的效应如何“加起来”形成合并效应。\n3. 森林图的局限性是什么？并且幕帘图如何克服这一局限性？\n森林图只能显示假设固定显著性阈值的效应的置信区间（通常 \\(\\alpha\\) = 0.05）。幕帘图可用于显示不同 \\(p\\)-值的效应大小的置信区间（以及因此的显著性）。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda7",
    "href": "90-appendix.html#qanda7",
    "title": "(附录) 附录",
    "section": "第七章：亚组分析",
    "text": "第七章：亚组分析\n\n1. 在最好的情况下，亚组分析可以告诉我们影响和离群值分析无法提供的信息是什么？\n亚组分析有可能解释为什么我们的数据中存在某些异质性模式，而不仅仅是告诉我们它们存在。\n2. 为什么亚组分析背后的模型被称为固定效应（复数）模型？\n因为它假设，虽然亚组内的研究遵循随机效应模型，但亚组级别本身是固定的。存在几个固定的亚组效应。\n3. 作为元分析的一部分，你想检查教育培训计划的效果是否因其交付的学区而异。使用固定效应（复数）模型进行亚组分析是否适合回答这个问题？\n可能不适合。假设学区代表从更大的学区人群中抽取，而不是所有存在的学区，更有意义。\n4. 你的一个朋友进行了一项元分析，共包含九项研究。其中五项研究属于一个亚组，四项研究属于另一个亚组。她问你进行亚组分析是否有意义。你会推荐什么？\n进行亚组分析可能不是一个好主意，因为研究总数小于十项。\n5. 你发现了一项元分析，其中的作者声称分析的治疗在女性中比在男性中更有效。这一发现基于一项亚组分析，在该分析中，研究根据研究人群中包含的女性的份额分为亚组。这一发现可信吗？为什么（不）？\n该发现基于使用聚合研究数据创建的亚组变量。这可能会引入生态偏差，因此结果值得怀疑。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda8",
    "href": "90-appendix.html#qanda8",
    "title": "(附录) 附录",
    "section": "第八章：元回归",
    "text": "第八章：元回归\n\n1. 初级研究中使用的传统回归分析和元回归之间有什么区别？\n分析单位是研究（而不是人），其效应量或多或少是精确的。在元回归中，我们必须构建回归模型，该模型考虑到某些研究应比其他研究具有更大的权重。\n2. 亚组分析和元回归密切相关。如何调整元回归公式以适应亚组数据？\n通过使用虚拟/分类预测变量。\n3. 元回归中使用哪种方法来给各个研究不同的权重？\n元回归使用加权最小二乘法来给具有更高精度的研究更大的权重。\n4. 什么特征标志着一个元回归模型能够很好地拟合我们的数据？可以使用哪个指标来检查这一点？\n一个“好”的元回归模型应该导致未解释的研究间异质性方差的减少。涵盖这种解释方差增加的指标是 \\(R^2\\) 类似物。\n5. 当我们使用元回归技术计算亚组分析时，我们假设亚组中 \\(\\tau^2\\) 的单独值还是共同值？\n在亚组中假设 \\(\\tau^2\\) 的共同估计。\n6. （多重）元回归的局限性和陷阱是什么？\n过度拟合元回归可能导致假阳性结果；多重共线性可能导致不稳健的参数估计。\n7. 说出两种可以用来提高（多重）元回归模型稳健性的方法，以及它们为什么有用。\n我们可以进行排列检验或使用多模型推断。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda9",
    "href": "90-appendix.html#qanda9",
    "title": "(附录) 附录",
    "section": "第九章：发表偏倚",
    "text": "第九章：发表偏倚\n\n1. “发表偏倚”一词如何定义？为什么它在元分析中存在问题？\n当一项研究的发表概率取决于其结果时，就存在发表偏倚。这在元分析中存在问题，因为它可能导致有偏差的结果。由于并非所有证据都被考虑，因此元分析可能会导致在考虑所有现有信息时不会实现的发现。\n2. 还有哪些其他的报告偏倚？说出并解释至少三个。\n引用偏倚：具有阴性发现的研究不太可能被引用；时间滞后偏倚：具有阴性发现的研究发表较晚；多重发表偏倚：具有阳性发现的研究更可能在几篇文章中报告；语言偏倚：证据可能因为未以英语发表而被省略；结果报告偏倚：一项研究的阳性结果比阴性结果更可能被报告。\n3. 说出两种可疑的研究实践 (QRPs)，并解释它们如何威胁我们元分析的有效性。\nP 值操纵 (P-hacking)，结果后假设 (HARKing)。两者都会导致阳性发现的膨胀，即使没有真正的效果。\n4. 解释小样本效应方法背后的核心假设。\n大型研究（即具有小标准误差的研究）很可能被发表，无论他们的发现如何。较小的研究具有较小的精度，这意味着需要非常高的效应量才能达到统计显著性。因此，只有具有非常高效应的小型研究才会被发表，而其余的研究则最终出现在“文件抽屉”中。\n5. 当我们发现我们的数据表现出小样本效应时，这是否自动意味着存在发表偏倚？\n不。还有几种其他的解释，说明为什么我们发现小样本效应，包括研究间异质性、协变量的影响（例如，较小研究中的治疗保真度更高）或机会。\n6. P 曲线估计什么：包含在我们元分析中的所有研究的真实效应，还是仅所有_显著_效应量的真实效应？\nP 曲线仅估计所有显著效应量的真实效应。这就是为什么当存在研究间异质性时，它的表现不佳的原因之一。\n7. 哪种发表偏倚方法具有最佳性能？\n没有一种发表偏倚方法始终优于所有其他方法。因此，应用几种方法并查看它们的结果是否一致是有帮助的。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda10",
    "href": "90-appendix.html#qanda10",
    "title": "(附录) 附录",
    "section": "第十章：“多层”元分析",
    "text": "第十章：“多层”元分析\n\n1. 说“三级”模型而不是“多层”模型更准确的原因是什么？\n因为“传统”随机效应模型已经是多层模型。它假设参与者嵌套在研究中，并且研究本身是从真实效应量人群中抽取的。\n2. 三级元分析模型什么时候有用？\n当我们处理相关或嵌套数据时。当研究贡献多个效应量，或者有充分的理由相信研究本身属于更大的集群时，三级模型特别有用。\n3. 说出效应量依赖性的两个常见原因。\n由参与初级研究的研究人员引起的依赖性；由元分析师自己创建的依赖性。\n4. 如何解释多层 \\(I^2\\) 统计量？\n它告诉我们不属于抽样误差的方差量，并区分集群内的异质性方差和集群间的异质性方差。\n5. 如何扩展三级模型以纳入调节变量的影响？\n通过将固定效应项整合到模型公式中。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda11",
    "href": "90-appendix.html#qanda11",
    "title": "(附录) 附录",
    "section": "第十一章：结构方程建模元分析",
    "text": "第十一章：结构方程建模元分析\n\n1. 什么是结构方程建模？它用于什么？\n结构方程建模是一种统计方法，可用于测试显变量和潜变量之间假设的关系。\n2. 可以通过哪两种方式表示 SEM？\nSEM 可以通过图形或矩阵表示。\n3. 从 SEM 的角度描述随机效应元分析。\n从 SEM 的角度来看，随机效应元分析中的真实总体效应量可以被视为潜变量。它受到两个方面的影响：第一级的抽样误差和第二级的真实效应量异质性方差。\n4. 什么是多元元分析？它什么时候有用？\n多元元分析允许同时合并研究的两个（或更多）结果。联合估计两个结果变量的一个优点是可以考虑结果之间的相关性。\n5. 当我们发现我们提出的元分析 SEM 能够很好地拟合数据时，这是否自动意味着该模型是“正确”的模型？\n不。通常，有不止一个模型能够很好地拟合数据。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda12",
    "href": "90-appendix.html#qanda12",
    "title": "(附录) 附录",
    "section": "第十二章：网络元分析",
    "text": "第十二章：网络元分析\n\n1. 网络元分析什么时候有用？与标准元分析相比，它们的优势是什么？\n当某些问题领域存在几种相互竞争的治疗方法，并且我们想估计哪种治疗方法具有最大的益处时，网络元分析很有用。与传统的元分析相比，网络元分析模型可以整合直接和间接证据。\n2. 在治疗网络中，直接证据和间接证据之间有什么区别？如何使用直接证据来生成间接证据？\n直接证据是包含的研究中实际调查的比较所提供的信息。间接证据是通过从相关比较的效应中减去一个（直接观察到的）比较的效应来从直接证据中得出的（例如，使用相同对照组的比较）。\n3. 网络元分析中传递性假设背后的主要思想是什么？\n传递性假设规定，直接证据可用于推断未观察到的间接证据，并且直接和间接证据是一致的。\n4. 传递性和一致性之间的关系是什么？\n传递性是进行网络元分析的先决条件，不能直接测试。传递性的统计表现形式是一致性，当基于直接证据的效应量估计与基于间接证据的估计相同/相似时，即满足一致性。\n5. 说出两种可用于进行网络元分析的建模方法。其中一种比另一种更好吗？\n可以使用频率主义或贝叶斯模型进行网络元分析。两种模型是等效的，并且随着样本量的增加产生收敛的结果。\n6. 当我们包含来自一项研究的几个比较（即多臂研究）时，这会导致什么问题？\n这意味着效应估计是相关的，从而导致单位分析错误。\n7. 在解释不同治疗的 P 或 SUCRA 分数时，我们必须牢记什么？\n不同治疗的效应估计经常重叠。这意味着 P-/SUCRA 分数应始终谨慎解释。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "90-appendix.html#qanda13",
    "href": "90-appendix.html#qanda13",
    "title": "(附录) 附录",
    "section": "第十三章：贝叶斯元分析",
    "text": "第十三章：贝叶斯元分析\n\n1. “传统”随机效应模型和贝叶斯分层模型之间的异同是什么？\n频率主义元分析背后的随机效应模型在概念上与贝叶斯分层模型相同。主要区别在于贝叶斯分层模型包括总体真实效应量 \\(\\mu\\) 和研究间异质性 \\(\\tau\\) 的（弱信息）先验分布。\n2. 与频率主义对应物相比，说出贝叶斯元分析的三个优势。\n\\(\\tau^2\\) 估计的不确定性被直接建模；生成 \\(\\mu\\) 的后验分布，可用于计算 \\(\\mu\\) 位于某个值以下的概率；先验知识或信念可以整合到模型中。\n3. 解释弱信息先验和非信息先验之间的区别。\n非信息先验假设所有或一系列可能的值同样可能。弱信息先验表示对某些值比其他值更可能的微弱信念。\n4. 什么是半柯西分布？为什么它对贝叶斯元分析有用？\n半柯西分布是一种仅为正值定义的柯西分布。它由一个位置和缩放参数控制，后者决定了分布的尾部有多重。半柯西分布可以用作 \\(\\tau\\) 的先验。\n5. 什么是 ECDF？如何在贝叶斯元分析中使用它？\nECDF 代表经验累积分布函数。基于 \\(\\mu\\)（或 \\(\\tau\\)）的后验分布的 ECDF 可用于确定估计参数低于或高于某个指定阈值的（累积）概率。",
    "crumbs": [
      "网站首页",
      "附录"
    ]
  },
  {
    "objectID": "99-references.html",
    "href": "99-references.html",
    "title": "R Meta 分析",
    "section": "",
    "text": "# 参考文献 {-}\n\n\n---\n\n&lt;style&gt;\np { margin-top: 0; margin-bottom: 20px; }\n&lt;/style&gt;\n\n&lt;br&gt;&lt;/br&gt;",
    "crumbs": [
      "网站首页",
      "参考文献"
    ]
  },
  {
    "objectID": "daizuo.html",
    "href": "daizuo.html",
    "title": "Meta 代做",
    "section": "",
    "text": "Meta 分析代做\n如果你的研究中使用了Meta分析方法, 我们可以提供哪些帮助:\n\n从文献提取数据\n分析数据\n撰写APA风格报告\n统计咨询\n\n\n\n联系我们\n\nQQ: 2726725926\nwechat: mllncn\nemail: mllncn@126.com\n咨询+交流平台: https://wx.zsxq.com/group/88888188828842"
  }
]