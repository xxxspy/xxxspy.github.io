{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "title: 多重共线性的诊断\n",
    "date: 2020-09-10 12:47:05\n",
    "tags: [spss, 问卷数据分析]\n",
    "mathjax: true\n",
    "\n",
    "---\n",
    "\n",
    "我们通常在线性回归或者多元方差分析中听过这个词, 它通常指的是当回归模型中的自变量相关太高时，它们将无法独立预测因变量的值。换句话说，他们解释了因变量中的某些相同方差，从而降低了其统计显着性。\n",
    "\n",
    "本篇文章主要介绍了诊断多重共线性的方法以及当出现多重共线性时如何处理。\n",
    "\n",
    "<!--more-->\n",
    "<!-- toc -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多重共线性\n",
    "\n",
    "\n",
    "当两个自变量之间存在高度相关性时，其中一个变量的存在可能导致另一个变量的回归系数的显著性急剧升高，但这并不代表这个变量对因变量没有预测作用, 共线性成为回归分析中的一个问题。在回归模型中，方差膨胀因子(VIF)提供共线性度的量度，如果VIF<5, 基本不存在共线性，而VIF超过10就应该认为存在共线性[10], 如果超过20就存在极度共线性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPSS操作\n",
    "\n",
    "打开\"回归\"对话框\n",
    "\n",
    "<img src=\"imgs/04s-01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/04s-02.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/04s-03.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果解读\n",
    "\n",
    "VIF超过10, 我们就认为存在共线性[1]\n",
    "\n",
    "<img src=\"imgs/04s-04.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这个表格更能帮助我们找到共线性的问题出在哪几个变量了\n",
    "<img src=\"imgs/04s-05.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 维(Dimension)\n",
    "\n",
    "让我们从表的第一列开始。与因子分析或PCA（主成分分析）相似但不完全相同，但是我们需要利用因子分析的\"因子\"的概念来理解\"维\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 条件指标(Condition Index)\n",
    "\n",
    "条件指标的及算法方法是: 特征值除以第一个维度的特征值, 比如, 第三维的条件指标= (10.644/0.070)**o.5=12.33, 由于四舍五入会导致一些精确度的差异\n",
    "\n",
    "如果条件指标超过15, 我们就可以认为出现了共线性的问题, 如果该维度上有共线性的问题, 我们需要在该行找到方差比例超过0.9的变量, 比如第十维有三个变量的方差比例超过了0.9, 他们是:名人效应/女名人效应/男名人效应, 因此我们可以考虑删掉两个变量, 只保留一个变量\n",
    "\n",
    "再比如第11维, 我们可以看到有四个变量的方差比例超过了0.9, 因此我们需要删除三个变量, 只保留一个\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 删除冗余变量后的结果\n",
    "\n",
    "删除冗余变量后, 我们可以看到已经没有共线性问题了\n",
    "\n",
    "<img src=\"imgs/04s-06.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共线性的处理方法\n",
    "\n",
    "- 删除共线的变量, 只保留一个\n",
    "- 将多个贡献变量求和或者均值, 合成一个变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考\n",
    "\n",
    "- [1]Hair, J. F., Black, W. C., Babin, B. J., & Anderson, R. E. (2013). Multivariate data analysis: Advanced diagnostics for multiple regression [Online supplement]. Retrieved from http://www.mvstats.com/Downloads/Supplements/Advanced_Regression_Diagnostics.pdf\n",
    "\n",
    "- IBM (n.d.). Collinearity diagnostics. Retrieved August 19, 2019, from https://www.ibm.com/support/knowledgecenter/en/SSLVMB_23.0.0/spss/tutorials/reg_cars_collin_01.html\n",
    "\n",
    "- Snee, R. D. (1983). Regression Diagnostics: Identifying Influential Data and Sources of Collinearity. Journal of Quality Technology, 15, 149-153. doi:10.1080/00224065.1983.11978865\n",
    "\n",
    "- Wikipedia (n.d.). Singular value decomposition. Retrieved August 19, 2019, from https://en.wikipedia.org/wiki/Singular_value_decomposition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
